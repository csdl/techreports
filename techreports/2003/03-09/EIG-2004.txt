It is conventional wisdom in the software engineering research community
that metrics can improve the effectiveness of project management.
Proponents of software metrics quote theorists and practitioners from
Galileo's ``What is not measurable, make measurable'' to DeMarco's ``You
can neither predict nor control what you cannot measure''.  Software
metrics range from internal product attributes, such as size, complexity,
and modularity, to external process attributes, such as effort,
productivity, testing quality, and reliability.

Despite the potential of metrics in theory, effectively applying them
appears to be far from mainstream in practice. For example, a recent case
study of over 600 software professionals revealed that only 27% viewed
metrics as ``very'' or ``extremely'' important to their software project
decision making process. The study also revealed that cost and schedule
estimation was the only use of metrics attempted by a majority of
respondents.

For the past several years, we have been experimenting with a new approach
to empirical software project management based upon the notion of
"telemetry".

According to Encyclopedia Brittanica, telemetry is a ``highly automated
communications process by which measurements are made and other data
collected at remote or inaccessible points and transmitted to receiving
equipment for monitoring, display, and recording.''  Perhaps the highest
profile user of telemetry is NASA, where telemetry has been used since 1965
to monitor the early Gemini missions to the modern Mars rover flights.  At
NASA's Mission Control Center, for example, dozens of specialists monitor
telemetry data sent from sensors attached to a space vehicle and its
occupants.  This data is used for many purposes, including early warning of
anomalies indicating problems, for better insight into the current status
of the mission, and for the impact of making incremental course or mission
adjustments.

We define ``software project telemetry" as a style of software metrics
definition, collection, and analysis with the following essential
properties:

   Software project telemetry data is collected automatically by tools
   that unobtrusively monitor some form of state in the project
   development environment. In other words, the software developers are
   working in a ``remote or inaccessable location'' from the perspective of
   metrics collection activities. This contrasts with software metrics data
   that requires human intervention or developer effort to collect, such as
   PSP/TSP metrics.
        
   Software project telemetry data consists of a stream of
   time-stamped events, where the time-stamp is significant for analysis.
   Software project telemetry data is thus focused on evolutionary
   processes in development.  This contrasts, for example, with Cocomo,
   where the time at which the calibration data was
   collected about the project is not significant.

   Software project telemetry data is continuously and immediately 
   available to both developers and managers.  Telemetry data is not hidden
   away in some obscure database guarded by the software quality improvement
   group.  It is easily visible to all members of the project for 
   interpretation. 

   Software project telemetry exhibits graceful degradation.
   While complete telemetry data provides the best support for project
   management, the analyses should not be brittle: they should still provide
   value even if sensor data occasionally ``drops out'' during the
   project. Telemetry collection and analysis should provide decision-making
   value even if these activities start midway through a project.
         
   Software project telemetry is used for in-process
   monitoring, control, and short-term prediction. Telemetry analyses
   provide representations of current project state and how it is changing
   at the time scales of days, weeks, or months.  The simultaneous display
   of multiple project state values and how they change over the same time
   periods allow opportunistic analyses---the emergent knowledge that one
   state variable appears to co-vary with another in the context of the
   current project.

Software Project Telemetry enables a more incremental, distributed,
visible, and experiential approach to project decision-making. For example,
if one finds that complexity telemetry values are increasing, and
that defect density telemetry values are also increasing, then one could
try corrective action (such as simplification of overly complex modules)
and see if that results in a decrease in defect density telemetry
values. One can also monitor other telemetry data to see if such
simplification has unintended side-effects (such as performance
degradation).  Project management using telemetry thus involves cycles of
hypothesis generation (Does module complexity correlate with defect
density?), hypothesis testing (If I reduce module complexity, then will
defect density decrease?), and impact analysis (Do the process changes
required to reduce module complexity produce unintended side-effects?).
Finally, Software Project Telemetry supports decentralized project
management: since telemetry data is visible to all members of the project,
it enables all members of the project--developers and managers--to engage
in these management activities.

For the past several years, we have been designing, implementing, and
evaluating tools and techniques to support a telemetry-based approach to
software project management as part of Project Hackystat.  In this
approach, the project development environment must be instrumented by
installing Hackystat sensors, which developers attach to the various tools
such as their editor, build system, configuration management system, and so
forth. Once installed, the Hackystat sensors unobtrusively monitor
development activities and send process and product data to a centralized
web service.  Project members can log in to the web server to see the
collected raw data and run analyses that integrate and abstract the raw
sensor data streams into telemetry.  Hackystat also allows project members
to configure "alerts" that watch for specific conditions in the telemetry
stream and send email when these conditions occur.

Hackystat supports the following general classes of software project telemetry:

Development telemetry is data gathered by observing the
behavior of project developers and managers as reflected in their tool
usage, and includes information about the files they edit, the time they
spend using various tools, the changes they make to project artifacts, the
sequences of tool or command invocations, and so forth. Development
telemetry can be gathered by attaching sensors to editors, such as Eclipse
or Emacs, to Office applications such as Word or Frontpage, to
configuration management tools such as CVS, to issue management tools such
as Bugzilla or Jira, and so forth.

Build telemetry is data gathered by observing the results of
tools invoked to compile, link, and test the system. Build telemetry can be
gathered from build tools like Ant, Make, or CruiseControl, testing tools
like JUnit, size and complexity tools like LOCC, and so forth.

Execution telemetry is data gathered by observing the behavior of
the system as it executes. This telemetry can be gathered by instrumenting
the run-time environment of the system to collect data about its internal
state (heap size, occurrence of exceptions, etc.) as well as by tools that
perform load or stress testing of the system, such as JMeter.  

Usage telemetry is data gathered by observing the behavior of
users as they interact with the system, such as the frequency, types, and sequences
of command invocations during a given period of time in a given subsystem.

In this research, we propose to augment our current Eclipse-based sensors
with new reporting and analytic tools to make Eclipse a 'round-trip'
environment for Software Project Telemetry. Currently, Eclipse-based sensor
data is collected only during development-time, and the resulting
telemetry-based analyses are accessable by navigating to an external
website where the Hackystat server is running.  In this proposed research,
we wish to both (a) increase the range of data that is sent for telemetry based
processing by the Eclipse environment, and (b) enable Eclipse to "pull"
results from telemetry analysis back into Eclipse for post-processing and
manipulation by the user. 

Project objectives and goals

The objectives of this project are to:

(a) Develop new Hackystat sensors for the Eclipse environment that will
    enable data to be collected not only from the development time
    activities of users, but also from the run-time behavior of the
    system. For example, if the user runs a Java program from within
    Eclipse and it generates a run-time exception, this Run Time Telemetry
    data would be automatically captured and sent to the Hackystat server,
    thus providing a more comprehensive understanding of the system under
    development and the interplay between development time and run time
    behaviors.

(b) New interfaces within the Eclipse environment for display of telemetry
    based analyses. We would collaborate with the BIRT (Business
    Intelligence and Report Tools) project within Eclipse to make this
    integration compatible with their efforts. The result would be far
    better insights into the course of development in a manner that would
    be available directly within the Eclipse environment. 

(c) Knowledge-based decision management within Eclipse. Once data about
    development time, build time, and run time telemetry are being
    gathered in Eclipse and the results made available back to Eclipse,
    various knowledge-based suggestions could be made to the user. This
    could be implemented similarly to the Quick Fix facility already
    available in Eclipse, except that instead of being limited to syntactic
    fixes, the operations could deal with much larger issues in
    development. For example, the quick fix could state "Reduce the
    complexity of this module since this level of complexity has been
    correlated with excessive defect-proneness".  Unlike Quick Fix, of
    course, the developer would have to decide for themselves how to reduce
    the complexity.

The Long term impact

The long term of impact of Eclipse Telemetry on the IT industry is to support improved 
software quality by providing a new, tightly integrated approach for
feeding diverse forms of software project telemetry back into the
development environment. 

The long term impact of Eclipse Telemetry on the Eclipse community involves all those 
factors discussed for the IT industry, of course. In addition, there are two 
impacts specific to Eclipse. The first is to provide Eclipse with a new 
competitive advantage in the IDE marketplace: we do not believe any other IDE 
(Emacs, JBuilder, Together/J, Netbeans, or Forte) provides tightly integrated, 
lightweight support for telemetry.   Second, the Eclipse tool development community 
forms a very natural user community for this technology.  After initial 
classroom deployment and evaluation, our next step will be to publicize it 
within this community and solicit trial use.  Over time, we hope that this tool 
will become a valuable resource to the Eclipse developer community in their 
efforts to sustain and improve the quality of the Eclipse implementation itself. 






