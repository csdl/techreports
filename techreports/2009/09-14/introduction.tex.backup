\chapter{Introduction}

\section{Background.}
Contemporary software projects typically have a considerably long life-cycle - well over decade.
Their development and maintenance usually carried out by geographically distributed teams 
and individuals. The development pace, the experience, and the structure of these development 
teams continuously change as developers are joining and leaving. When combined with
schedule and requirements changes, all these create numerous difficulties 
for stakeholders, community, and developers, ultimately affecting the project success. 

This software development complexity phenomena was identified in 1968 as ``Software crisis'' \cite{crisis}, 
and was addressed by bringing the research and the practice of software development 
(or as it was called ``programming'') under the umbrella of Engineering - in an effort to provide a 
control over the process of software development. 
Following the engineering paradigm, numerous methodologies and models of \textit{software processes}
were proposed \cite{citeulike:10002165}.

A \textbf{\textit{software process}} is a set of activities performed in order to design, develop and maintain 
software systems. Examples of such activities include design methods; requirements collection and creation of
UML diagrams; requirements testing; and performance analysis. 
The intent behind a software process is to structure and coordinate human activities in order to achieve 
the goal - deliver a software system successfully in time and under a budget.
Since then, much work has been done in software process research resulting in a number of industrial standards for 
process models which were widely accepted (CMM, ISO, PSP etc. \cite{citeulike:5043104}) in industry. 

Nevertheless, industrial software development remains error-prone and more than half of all commercial software
development projects ending up failing or being very poorly executed (Rubinstein, ``Chaos Reports'', 2006). 
Some of them are abandoned due to running over budget, some are delivered with such low quality or so late that
they are useless, and some, when delivered, are never used because they do not fulfill requirements. 
Through the years, it turned out, that software engineering is very different from any other engineering fields. 
There is almost no cost associated with materials and fabrication which dominate cost in all other 
engineering disciplines, but, ironically, software engineering is suffering from the costs and challenges
associated with continuous re-design of the product design and its design processes - 
the issue which is rarely seen at all in any of other engineering areas \cite{citeulike:5203446}.

Along with industrial, engineering-like, processes, a number of alternative software processes emerged from hobbyists
and practitioners. Among others, the Free/Libre/Open-Source Software model (FLOSS) and the software craftmanship  
approaches gained a significant credibility. While the former \textit{holistic} software process paradigm emphasizes
loosely-organized collaboration, frequent releases, and removes the boundary between developers and customers, 
the latter is focusing on the roles of highly motivated, skilled individuals in a process of software creation
\cite{citeulike:262020} \cite{citeulike:2759198}. 

Similarly, software process complexity issues affect the alternative processes. As was shown, most of FLOSS projects 
never reach a ``magic'' 1.0 version \cite{citeulike:12480029}. Among others, the great "infant mortality rate" of OSS
projects was related to a burnout, inability to acquire a critical mass of users, loss of leading developer(s), and
forking \cite{richter2007critique}. Software craftsmanship, from other hands, not only challenge developers
with technological advances requiring continuous education, but create cost and effort estimation difficulties for
stakeholders and project managers \cite{citeulike:11058784}.

%The recent study by Standish Group (Rubinstein, ``Chaos Reports'', 2006) indicates,
%that while `\textit{`Software development shops are doing a better job creating software than they were 
%12 years ago}'', still, only ``\textit{35\% of software projects in 2006 can be categorized 
%as successful meaning they were completed on time, on budget and met user requirements}”.
%Another, widely acknowledged problem with existing models is their rigidity - usually 
%once a project executed, the cost of incorporating a change in the process or a product 
%not only becomes significant, but also grows proportionally to the project execution time.

Currently, it is widely acknowledged, that there exists no single ``silver bullet'' process \cite{citeulike:1986013}
which can bring any software development project to success - processes are numerous, each has advantages and
drawbacks, and each is accompanied with numerous application recommendations, success stories, and 
failures. However, the alarming rate of failing projects suggests, that all this knowledge is not enough for making 
a proper process choice in any particular situation. The enormous cost of the lost effort, and the lack of understanding 
of software process mechanics continue to fuel research community. 

\section{Software process discovery}
Historically, there are two categories of approaches to software process design, analysis and improvement. 
The first category consists of traditional to engineering \textit{top-down} approaches to software process 
design and improvement through proposing a specific patterns of software development. 
For example, the Waterfall Model process proposes a sequential pattern in which developers first create a 
Requirements document, then create a Design, then create an Implementation, and finally develop Tests. 
The Test Driven Development process, from other hands, proposes an iterative pattern in which
the developer must first write a test case, then write the code to implement that test case, then refactor the 
system for maximum clarity and minimal code duplication. 

While the top-down approach seems to be a natural extension of creative processes - such as experimentation
and invention, and follows the usual path of trial and error, one of the problems is that ``inventing'' the adequate 
to the task software process is far from trivial \cite{citeulike:5043104} \cite{citeulike:1986013}. 
Moreover, it was shown, that the process inventors are often limited in their scope and tend to assume an idealized
versions of real processes, thus, often producing ``paper lions'' - process models which are likely to be disruptive 
and unacceptable for end users, at least in their proposed form \cite{citeulike:9758924}. 
Finally, the evaluation cycle of an invented process is considerably long and expensive. 

The second category consists of opposite, \textit{bottom-up} techniques for true process reconstruction 
through noticing of recurrent patterns of behaviors. Typically, in this field, the process inference problem is viewed 
as a two-levels problem, where the first level consists of a patterns discovery problem, and the 
second level consists of pattern recognition and a network analysis problems.
Following this paradigm, one of the first work in the field by Cook and Wolf
shows a possibility to automatically extract a process model through mining of recorded event logs
\cite{citeulike:328044} \cite{citeulike:5120757} \cite{citeulike:5128143}. 
Later work by Huo et al., shows that through event logs analyses it is possible to improve existing 
processes \cite{citeulike:7691059} \cite{citeulike:7690766}. 

While the bottom-up approaches seem to be more systematic, and less complex than invention, they 
also affected by a number of issues. A chief among these is the observability issue - 
it is usually difficult to conduct a full depth study on a live project due to the privacy concerns, 
moreover, it is expensive to observe a process performed by a team for a whole life-cycle of a project. 
Another issue is the capacity of the process discovery techniques - these often need to be supervised 
and fine tuned in order to reconstruct distributed and concurrent processes. 

\section{Software process discovery from publicly available artifacts}
Recently, the situation changed, and the interest for process reconstruction has been largely revived. 
It is driven by increase in public data, that were made available by the proliferation of open source communities.
Currently, software artifacts are abundant: source code repositories, public bug/issue tracking systems, 
mailing list communications, social networks, Q\&A websites - all these are easily accessible. 
This effectively removes not only the high cost of observation, but most of the privacy concerns - both 
issues that previously made large-scale analysis of software projects unfeasible for most researchers.

Scientific community response on the availability of public artifacts was overwhelming, and a number of 
venues was established addressing increased interest. 
Since 2004, the International Conference on Software Engineering (ICSE) hosts a Working Conference on 
Mining Software Repositories (MSR). Its original call for papers stated MSR's purpose as 
\textit{``... to use the data stored in these software repositories to further understanding of software 
development practices ... [and enable repositories to be] used by researchers to gain empirically based 
understanding of software development, and by software practitioners to predict and plan various aspects 
of their project''} \cite{msr2004} \cite{citeulike:7853299}. 
Several other venues, International Conference on Predictive Models in Software Engineering \cite{promise12}, 
International Conference on Open Source Systems, the Workshop on Public Data about Software Development, 
and the International Workshop on Emerging Trends in FLOSS Research have also played
an important role in shaping and advancing this research domain.

Nevertheless, while availability of public software artifacts partially solves problems of observability and privacy, 
at the same time, they introduce a number of additional challenges, significantly elevating the complexity 
of process discovery problem. The main challenges facing process research based on public software process 
artifacts formed by these  artifacts nature:
\begin{itemize}
 \item First of all, the artifacts created by developers and users not in order to enable the research, but merely 
          support software development activities. Thus, the informational content of these artifacts is questionable.
 \item Secondly, majority of these artifacts (change records, defect reports, assigned tasks, etc) represent the current 
          state - a snapshot - of a software project, rather than an action, and it is simply impossible to infer any of
          the development events. 
          This fact invalidates most of the previously developed solution based on the development events.
 \item Thirdly, developers and users create the artifacts (a system snapshots) on their own volition, in other words,
          artifacts can be significantly displaced in time, thus, it is impossible to know exactly the state of the software 
 \item Finally, the high volume of artifacts, possibility of redundancy (for example there might be multiple reports for 
          the same defect from many users, or there might be a number of changes addressing a single defect), and their 
          imprecise time placement effectively render supervised and manual techniques as ineffective. 
\end{itemize}

Overall, I argue that Machine learning is required not only to make an inference about project state change and a performed 
process, but an external knowledge 


\section{Motivation}
In my work I address exactly this problem - discovery of software process primitives from publicly available 
software process artifacts. I will apply knowledge discovery and data mining techniques to the

domain of software engineering in order to evaluate their ability to automatically notice

interesting recurrent patterns of behavior. While I am not proposing to be able to infer a

complete and correct software process model, my system will provide its users with a formal

description of recurrent behaviors in their software development. As a simple example,

consider a development team in which committing code to a repository triggers a build of

the system. Sometimes the build passes, and sometimes the build fails. To improve the

productivity of the team, it would be useful to be aware of any recurrent behaviors of the

developers. My system might generate one recurrent pattern consisting of a) implementing

code b) running unit tests, c) committing code and d) a passed build: i → u → c → s, and

another recurrent pattern consisting of a) implementing code, b) committing code, and c) a

failed build: i → c → f. The automated generation of these recurrent patterns can provide

actionable knowledge to developers; in this case, the insight that running test cases prior to

committing code reduces the frequency of build failures.

Although the latest trends in software process research emphasize mining of software

process artifacts and behaviors [23] [45] [39] [45], to the best of my knowledge, the approach

I am taking has never been attempted. This may be partly due to the lack of means of

automated, real-time data collection of ﬁne-grained developer behaviors. By leveraging the

ability of the Hackystat system [25] to collect such a ﬁne grained data, I propose to extend

previous research with new knowledge that will support improvements in our understanding

of software process.

In my work, I focus on the single type of such primitives - recurrent behaviors. 
Since recurrent behaviors extraction While further, I show a novel algorithm and a reference workflow for that In this dissertation, that instead of deducting atomic events it is
possible to increase the level of basic tractable units to behaviors, and simplify they discovery through automated
application of data mining techniques.

%Finally, there is third, people-oriented approach to software processes pioneered
%by Weinberg as early as 1971
%\cite{citeulike:262020}. This wok shifts focus from technical aspects towards understanding
%and improving how software processes are shaped by humans and social behaviors. recently been revived.  

%All these - the uneven and often unpredictable performance of software processes with experiences 
%ranging from success to complete failures, and the lack of efficient research methodologies, clearly indicate, that our
%understanding of underlying ``software process mechanics'' is incomplete. This fact continues to fuel further research
%in software processes.

%Not surprisingly, as per today, most of the research in the field is focused on engineering-like software processes
%following 
%business interests and leveraging the ability to perform experimentation in a controlled environment - where it is
%possible to 
%evaluate a proposed by solution to (often \textit{cherry-picked}) research problems. 
%One problem with this approach to process development is that it requires the process analyst to invent, or to notice 
%a recurrent pattern of behavior, addressing the problem in the first place \cite{citeulike:5043104}. 
%In addition to difficulties with ``invention'' itself, another issue pinpointed by van der Alast in
%\cite{citeulike:9758924}, 
%is 

%Nevertheless, despite to success of formalized approaches to manufacturing processes in other 
%engineering fields, current state-of-the-art industrial models of software processes perform somewhat 
%poorly and do not deliver consistently. 
%For example, the recent study by Standish Group (Rubinstein, ``Chaos Reports'', 2006) indicates,
%that while `\textit{`Software development shops are doing a better job creating software than they were 
%12 years ago}'', still, only ``\textit{35\% of software projects in 2006 can be categorized 
%as successful meaning they were completed on time, on budget and met user requirements}”.
%Another, widely acknowledged problem with existing models is their rigidity - usually 
%once a project executed, the cost of incorporating a change in the process or a product 
%not only becomes significant, but also grows proportionally to the project execution time.

%Along with engineering-like industrial process models, a number of software processes 
%emerged from hobbyists and were successfully adopted by practitioners seeking for alternative solutions.
%Some of these, proven to be applicable for large scale industrial projects 
%(Android OS: LoC$>$15M, $\sim$2K contributors). 
%Among others, the Free/Libre/Open-Source Software model (FLOSS) and the software craftmanship 
%approaches gained a significant credibility among practitioners.
%While the former \textit{holistic} software process paradigm emphasizes extensive collaboration, 
%frequent releases and removes the boundary between developers and customers, the latter is focusing 
%on the roles of highly motivated, creative and skilled individuals in a process of software creation. 
\subsection{Learning from time series}

\section{Research questions, hypothesis, and a scope of the dissertation}
Software is coded by humans. Whether in team or individually, we perform a number of daily activities - 
commuting to an office, answering emails, attending meetings, writing a code, and many others. 
The ordering of these activities and their durations are driven and constrained by internal and external factors, 
such as a role, motivation, working schedule, project phase, physical location of the office, etc. 
When summarized together, the range of these activities and the mannerisms form our behavioral portraits.

A subset of daily activities can be attributed as relevant to the project goal - delivering a software. 
Thus, one of the preliminary research questions is the \textit{partitioning of the activities} into those that 
relevant to the process and those which are auxiliary. 


By limiting the scope of my research to a discovery of knowledge only from software process artifacts, 
I address the above question at large by obviously considering only related to software process entities.
This partitioning scheme, however, leads to another research questions: \textit{is it possible to discover 
recurrent behaviors from a very limited set of software process by-products?} and, if it is possible, 
\textit{will the discovered behaviors be meaningful, i.e. interpretable?}

Some of the previous research, especially in MSR field  \cite{citeulike:9114115, citeulike:7853299}, 
indicates, that by application of a variety of a techniques it is not only possible to discover evidence of 
software process \cite{citeulike:9007622}, but, at least partially, to infer the process as a 
whole \cite{citeulike:5128808}. However, in the mentioned research, software process artifact features 
were mostly captured by using of an expert knowledge of measurable discriminative properties of the 
event classes, which effectively limits analyses to The feature selection
process entails manual expert involvement and repeated experiments. Automatic feature
selection is necessary when (i) expert knowledge is unavailable, (ii) distinguishing features
among classes cannot be quantified, or (iii) when a fixed length feature description cannot
faithfully reflect all possible variations of the classes as in the case of sequential patterns
(e.g. time series data).

These combine into the research hypothesis - \textit{it is possible to discover recurrent behaviors 
from software process artifacts by application of appropriate data-mining techniques} - 
which I investigate in this dissertation. 

In order to approach this hypothesis questions, I choose to reduce the problem of mining of software artifacts to a narrower,
but more generic software treat software artifacts as time-series and design an interpretable time 
series classification technique, which, 
as I will show, temporal 


Exactly as it sounds, my research is interdisciplinary - it combines together knowledge discovery and software process 
analysis, focusing on a very narrow subject - exploring approaches for recurrent behaviors or ``programming habits'' 
discovery from software process artifacts.
While I will show, that recurrent and significant software-development behaviors can be discovered,
their precise categorization, effect, and performance are beyond the scope of this thesis.

\section{Contributions}
I show a novel, generic algorithm for interpretable time series classification: SAX-VSM. 
While the performance of this algorithm is at the level of current state of the art, it offers an outstanding feature -
discovery, generalization and ranking of class-characteristic structural features. This feature, in turn, enables
knowledge discovery by offering much clearer insight into data specificity than any other competing technique.
In addition, SAX-VSM uses only N weight vectors for classification of unlabeled data by computing N cosines, where N is
a number of classes, - therefore it is very fast and has a very small memory footprint.
Overall, I expect this algorithm to play an important role in future because of the growing ubiquity of time series and
growing interest in behaviors.

I provide SAX-VSM implementation to the community. This implementation uses several computational tricks to optimize,
reduce, and reuse computation. Within last years, this implementation was regularly downloaded and used in academia and
industry. 

Powered by SAX-VSM, through the application of Software Trajectory Analysis (STA) to software process artifacts, I show
through the case studies: that it is possible to discover known recurrent behaviors, thus positively confirming the
research hypothesis. In the PostgreSQL study I was able to discover characteristic recurrent behaviors in source code
editing churns corresponding
to Software release and to the Commit Fest processes.
that STA and SAX-VSM can be used as a knowledge discovery tool in the StackOverflow case study. In particular, I show,
that the temporal primitives discovered by the algorithm provide not only quantitative evidence for processes
interpretation, but can be used for a qualitative assessment of discovered recurrent behaviors.
In Android case study...

Finally, I provide an implementation of STA analysis framework to the community. 

\section{Organization of the dissertation}