\chapter{Introduction}\label{chapter_introduction}
\textit{The central issue addressed in this dissertation is a possibility of recurrent behaviors discovery from 
publicly available software process artifacts. I approach this problem by transforming artifact trails into 
time series by metrics extraction and temporal ordering of measurements. After reviewing of previous and related 
work, I shall propose a novel technique for characteristic patterns discovery from time series and show its 
applicability to the problem of recurrent behaviors discovery through three case studies.}

\textit{The problem's background is given in Section \ref{section_background}. 
Section \ref{section_software_process_design} presents classical approaches for software process design and 
shows its limitations. 
Sections \ref{floss_processes} and \ref{section_public_repositories} discuss software processes occurring in 
self-organized, open-source community, and introduce their software artifacts.
Section \ref{section_research_hypothesis} introduces the research hypothesis.
Section \ref{section_knowledge_discovery} provides introduction into the problem of knowledge discovery from time-series.
Section \ref{section_trajectory_definition} connects two research areas and provides definitions.
Section \ref{section_contributions} enumerates main contributions of the thesis, 
while section \ref{section_organization} explains the thesis organization.}

%
% >> section
%
\section{Background}\label{section_background}
Contemporary software projects concern with development of complex software systems and typically have 
a considerably long life-cycle - well over decade.
A project's development and maintenance activities are usually carried out by geographically 
distributed teams and individuals. The development pace, the experience, and the structure of the 
development team continuously change with project progression and as developers joining and leaving. 
When combined with schedule and requirements adjustments, these create numerous difficulties 
for developers, users, and stakeholders, ultimately affecting the project success \cite{citeulike:2207657}. 

This software development complexity phenomena was identified in 1968 as ``Software crisis'' 
\cite{naur_crisis_68}, and was addressed by bringing the research and the practice of software development 
(or as it was called ``programming'') under the umbrella of Engineering - in an effort to provide 
the control over the process of software development. 
Following the engineering paradigm, numerous methodologies and models of software design and development 
process, known as \textit{software processes}, were proposed \cite{citeulike:10002165}.

\begin{defn}\label{def_process}
A \textbf{\textit{Software Process}} defines a sequence of activities performed in order 
to design, develop, and maintain software systems.
\end{defn}
Examples of such activities include requirements collection and creation of UML diagrams, 
requirements testing, code development,  testing, etc. The intent behind a software process is 
to provide a control over software evolution by implementing a global strategy and by structuring
and coordinating human activities in order to achieve the goal - deliver a functional software system 
on time and under the budget. 

Since then, much research has been done on software processes resulting in a number
of software development models and paradigms. Some of these were widely accepted by practitioners 
and evolved into industrial standards for software development processes such as CMM, ISO, PSP, 
and others \cite{citeulike:5043104}. However, in spite of this effort, industrial software 
development remains error-prone and more than half of all 
commercial software development projects ending up failing or being very poorly executed 
(Rubinstein, ``Chaos Reports'', 2006) \cite{chaos2006}. Some of them are abandoned due to running 
over budget, some are delivered with such low quality, or so late, that they are useless, and some, 
when delivered, are never used because they do not fulfill requirements. 

Through the analyses of software project failures, it was acknowledged, that the engineering 
paradigm might not be the best way to provide a control over software development processes 
(\cite{citeulike:3729379} \cite{citeulike:5203446}) due to the fact that Software engineering 
is dealing with significantly different from other Engineering fields problems \cite{citeulike:2207657} .
The chief argument supporting this point of view is the drastic difference in the cost model:
while in Software Engineering there is almost no cost associated with materials and 
fabrication, these usually dominate cost in all other Engineering disciplines, but, 
ironically, Software Engineering is suffering from the costs and challenges associated with 
continuous re-design of the product and its design processes - the issue which is 
hardly seen at all in other Engineering areas. 
Moreover the most of engineering-like models are ``context-free'', rigid, and prescriptive - 
i.e. they are universally defined and are difficult to tailor for organizational structure or 
a project specificities  - thus, the degree to which processes can be structured 
and controlled varies between teams and projects and does not guarantee the success \cite{sacchi_2001}.
Finally, increasing understanding and appreciation of the human role in software development 
processes over tools, technologies, and standards, suggests that the human-driven software process 
aspects are likely to define a software project fate \cite{citeulike:6580825} \cite{citeulike:149387} 
\cite{1605185} \cite{citeulike:113403} \cite{citeulike:12743107}. 

This finding has been long known in the software development community practicing alternative to Software 
Engineering processes. A number of flexible and developer-oriented software processes emerged from academy,
hobbyists, and practitioners addressing aforementioned issues with engineering \cite{citeulike:3729379}. 
Among others, the Free/Libre/Open-Source Software model (FLOSS) and the software craftsmanship  
approaches gained a significant credibility in community. 
While the former \textit{holistic} software process paradigm emphasizes loosely-organized 
collaboration, frequent releases, and effectively removes the boundary between developers 
and customers, the latter, human-centric approach, is built upon the roles of highly 
motivated skilled individuals \cite{citeulike:262020} \cite{citeulike:2759198}. 

Nevertheless, alternative processes were found to be plagued by the same complexity issues. 
As it was shown, most of FLOSS projects never reach a ``magic'' 1.0 version \cite{citeulike:12480029}. 
Among others, the great "infant mortality rate" of FLOSS projects was related to a burnout, 
inability to acquire a critical mass of users, loss of leading developer(s), and forking \cite{richter2007critique}. 
Software craftsmanship, from other hands, not only challenges developers with technological advances 
requiring continuous skills improvement, but creates significant cost and effort estimation difficulties for
stakeholders and project managers \cite{citeulike:11058784}. However, despite to these issues, 
it was proven, that the user- and developer-centric, disciplined manner of programming, along with the high 
degree of the software modularization create a process that is not only comparable with industrial 
engineering-like processes in quality, but is capable of delivering of large and reliable software systems, 
most notably Linux OS.

Currently, it is widely acknowledged, that there exists no single ``silver bullet'' process which 
guarantee to bring a software project to success \cite{citeulike:1986013}. 
Processes are numerous, each has advantages and drawbacks, and each one accompanied with 
numerous success stories, and failure experiences making the choice difficult. 
This and the alarming rate of projects failures suggest that our understanding of software 
development ``mechanics''  is limited and insufficient \cite{citeulike:12550665}. 
The enormous cost of the lost effort, measured in hundreds of billions of US dollars 
\cite{citeulike:2207657} \cite{citeulike:2207653} \cite{citeulike:2207655}, 
continues to provide motivation for further research on software processes. 

%
% >> section
%
\section{Software process design}\label{section_software_process_design}
Traditionally, approaches to software process design and improvement are divided into two distinct categories. 

The first category of software process design approaches consists of traditional to engineering 
\textit{top-down} techniques through 
\textit{proposing a process based on specific patterns of software development}. 
For example, the Waterfall Model process proposes a sequential pattern in which developers first create a 
Requirements document, then create a Design, then create an Implementation, and finally develop Tests. 
The Test Driven Development process, from other hands, proposes an iterative behavioral pattern in which
the developer must first write a test case, then write the code to implement that test case, then re-factor the 
system for maximum clarity and minimal code duplication \cite{citeulike:6086365}. 

While the top-down approach follows the usual path of trials and errors, and seems to be an 
extension of natural to humans creative processes of invention and experimentation, 
the ``invention'' of an adequate to the task software process is far from trivial 
\cite{citeulike:5043104} \cite{citeulike:1986013}. 
Moreover, the evaluation cycle of an invented process is usually very expensive and considerably long.
In addition, it was shown that the process inventors are usually limited in their scope and tend to 
assume idealized versions of real processes, thus, often produce ``paper lions'' - process models which are 
likely to be disruptive and unacceptable for end users, at least in their proposed form \cite{citeulike:9758924}.

The second category of software design approaches consists of \textit{bottom-up} techniques 
that focus on a \textit{performed process reconstruction through noticing of recurrent development 
events and behaviors} or as it also called \textit{process enactment}. 
Usually, the process reconstruction task is viewed as a two-levels problem where the first level 
consists of a patterns discovery (segmentation) while the second level consists of patterns recognition 
and their network analysis \cite{citeulike:2703162}.
One of the first works in this category was by Cook and Wolf, where they show a
possibility of automated extraction of a process model through the mining of recorded 
process event logs \cite{citeulike:328044} \cite{citeulike:5120757} \cite{citeulike:5128143}. 
Later work by Huo et al. shows that it is also possible to improve an existing process
through the event logs analysis \cite{citeulike:7691059} \cite{citeulike:7690766}. 

While the bottom-up approaches seem to be more systematic and potentially less complex than invention, 
they also affected by a number of issues, among which the observability is the largest: 
while the live project observation is difficult to implement due to its cost and privacy concerns, 
the post-process interviewing introduces discrepancies between actually performed and reported actions. 
Yet another significant issue is the capacity of currently available process discovery and representation 
techniques - typically these need to be supervised by experts and finely tuned in order to reconstruct 
typically distributed and concurrent software processes. 

While these approaches are opposite in their nature, they both yielding process models that, effectively,
are the series of actions (or states) that must be performed (visited) successively in order to deliver a 
software. The ``process inventors'' put the best of their knowledge, experience, creativity, and logical 
reasoning into the proposed sequence of steps, the process re-constructors 
strive to eliminate the noise and to converge to a concise sequence of steps that is supported by the 
majority of observations. 
This particular attention to the synthesis of sequential steps, leaves other phenomenas, 
such as team's structure, work schedule, developer's discipline, behaviors, and motivation behind. 
While this issue was recognized previously and resulted in a number of studies which called for attention 
to human element in software production \cite{citeulike:149387} \cite{citeulike:113403} 
\cite{citeulike:205322} \cite{citeulike:12798652}, 
it is still largely ignored in industrial practices \cite{citeulike:12798659}, mostly due to the 
difficulties with its benefit estimation \cite{citeulike:12798662} \cite{csdl2-12-11}.

%
% >> section
%
\section{Free/Libre Open Source processes}\label{floss_processes}
Another phenomenon generating novel software processes is the social movement inspired by the philosophy 
of source code sharing and collaborative improvement, that is called called ``free-software movement''. 
This social phenomenon originating from 1960s was partially formalized in 1983 by Richard Stallman,
who launched GNU Project and later, in 1985, founded the Free Software Foundation in order to support 
it. The ``open-source'' term, that is commonly used for description of free/libre software, 
was coined later, in 1998 at the very first Open Source Initiative (OSI) meeting \cite{osi-history}.

The open-source community, consists of self-organized individuals and teams of mostly non-professional 
programmers - amateurs, hobbyists, students, and academic software developers. The software 
developed by the community is distributed freely along with its source code and is usually called 
free/libre/open-source software (FLOSS). 
In order to partially cover the cost of the development, fund the software customization, maintenance 
and support, open source developers are often paid by commercial users or the use of a software is 
licensed for a fee.

Over the years, this software development model has proven its ability to deliver increasingly complex 
and surprisingly popular software in a ``global'' scale - when thousands of non-professional developers 
and users are scattered all over the world. A number of open source projects such as Linux and its 
derivatives, Gnome, Apache HTTP Server, MySQL database, and others, succeeded to develop efficient 
distributed software processes that provide control over the large development team and code-base.
Moreover, these processes allowed to deliver the state of the art software whose quality is similar 
or exceeding that of industrial projects \cite{coverity2012}. 
In turn, this attracted a considerable attention not only from industrial companies that seek to emulate 
successful open source software processes in traditional closed-source commercial environment 
\cite{oss_virtual_organizations} \cite{oss_balance} \cite{oss_hp} \cite{oss_4industry}, 
but from software process research community, that is fond of finding of novel software processes
\cite{citeulike:12550640} \cite{citeulike:5043664} \cite{citeulike:5128808} \cite{citeulike:10377366}.

\begin{figure}[ht!]
   \centering
   \includegraphics[width=140mm]{figures/Linus.Kernel.ps}
   \caption{A Torvald's response in the mailing list suggesting that practical reasons, the ``real-life'', 
   should be always considered over specifications.
   Excerpt from Linux mailing list. \url{http://lkml.indiana.edu/hypermail/linux/kernel/0509.3/1441.html}}
   \label{fig:kernel}
\end{figure}

A number of studies conducted previously on open source processes discovered, that open-source processes 
differ from a traditional software development at many levels. One of the major of discovered differences 
is the flexibility of FLOSS processes. For example, the most significant document in industrial software 
processes - the specification - is rarely considered in FLOSS projects, moreover, if exists, it is often 
discarded as not corresponding to changing project needs. Even in the Linux kernel development, which is 
probably one of the few strictly moderated FLOSS development processes, developers prise practical reasons 
over specifications \ref{fig:kernel}.

In order to overcome issues created by this hyper-flexibility in the concurrent development, many FLOSS 
projects view the final software ``look and feel'' and its functionality as open-ended questions and 
encourage their developers to make only small incremental improvements and to commit code changes often 
\cite{so-checkin} \cite{git-best-practices1}. This frequent commits policy and the small change visibility 
practice are often cited as vital for health of open-source software processes 
\cite{checkin-ch-2012} \cite{checkin-dgd-2008} as allowing developers to follow the project evolution
and to respond to changes promptly.
Another way to manage the distributed development complexity practiced in open-source communities is the 
limitation of the access to a software main development tree and encouraging of ``forking'' by non-core developers. 
Later, if a forked version satisfies to project needs, the changes are merged with the main tree by core developers.

Note, that both techniques providing control over open-source development processes do not prescribe any of specific 
sequences of development actions or any methodology which contributors are obliged to follow.
This characteristic flexibility driven by open-source philosophy provides a thriving human-driven environment for 
self-organizing individuals and teams to invent and to test any of ideas through their own experiences. 
This environment, potentially, generates novel software processes, improves existing, and test them in a real life
at the same time. 
In addition, the small incremental change philosophy and the frequent commit policy, potentially contribute to the 
creation of numerous public artifacts providing a fine resolution into performed FLOSS processes making open-source 
software processes research the only viable option for large-scale software process research.


%
% >> section
%
\section{Public software repositories}\label{section_public_repositories}
As mentioned above, the proliferation of open-source software development model and increasing abundance of 
publicly available software process artifacts changed the software process research landscape reviving the 
interest for process enactment and reconstruction, as well as bringing the attention to the human-specific 
components of software processes. 

Currently, with accessible personal computers, friendly software development toolkits, and massification of 
high-speed Internet access, small-scale commercial and recreational programming become very popular. 
The web is commonly used as a platform for collaborative work: free code hosting sites such as SourceForge, 
GoogleCode, and GitHub host thousands of FLOSS projects offering free public access to numerous software 
process artifacts, such as design documents, source codes, bugs and issue records, and developers communications.
In addition, Q\&A and social websites for developers such as StackOverflow, TopCoder, and others, becoming 
increasingly popular among software developers and users as places to exchange expertise, to learn new tools, 
and to improving skills. These also offer anonymized public data which is studied by the research community.

The public availability of numerous software process artifacts covering the full life cycle of the software,
effectively removes not only the high cost of observation, but most of the privacy concerns - the two issues 
that previously made any large-scale analysis of software projects unfeasible for most researchers.

Scientific community response on the availability of public artifacts was overwhelming, and a number of 
venues was established addressing the increased interest. 
Since 2004, the International Conference on Software Engineering (ICSE) hosts a Working Conference on 
Mining Software Repositories (MSR). The original call for papers stated MSR's purpose as 
\textit{``... to use the data stored in these software repositories to further understanding of software 
development practices ... [and enable repositories to be] used by researchers to gain empirically based 
understanding of software development, and by software practitioners to predict and plan various aspects 
of their project''} \cite{msr2004} \cite{citeulike:7853299}. 
Several other venues: International Conference on Predictive Models in Software Engineering \cite{promise12}, 
International Conference on Open Source Systems, the Workshop on Public Data about Software Development, 
and the International Workshop on Emerging Trends in FLOSS Research have also played
an important role in shaping and advancing this research domain.

Some of the published work addresses the software process discovery. Among others, most notable and 
relevant to my research is work by Jensen \& Scacchi. In their early work, they demonstrated, that 
information reflecting software processes can be gathered from public systems \cite{citeulike:12550640}. 
Later, in \cite{citeulike:5043664} and \cite{citeulike:5128808}, they show, that by manual mapping of 
collected process evidence to a pre-defined process meta-model it is possible to reconstruct some 
of the FLOSS processes. 
Another closely related to my research is work by Hindle et al. where they has shown that it is possible to 
discover software process evidence through partitioning \cite{citeulike:10377366}.

However, the research work based on mining of software process artifacts shows, that while public availability 
of artifacts is minimizing observability and privacy issues, the nature of these artifacts creates a number of 
challenges which I discuss in the chapter X, which limit the possible scope of the research and significantly 
elevate the complexity of the process discovery effectively rendering previously designed techniques inefficient.
Thus, the novel analysis and discovery techniques are needed to be developed for public software process artifacts 
analysis \cite{citeulike:7853299}.
% when ``\textit{... going beyond code and bugs...}'' 

%
% >> section
%
\section{Research hypothesis, scope of the dissertation}\label{section_research_hypothesis}
In previous sections, I have outlined the evidence of a limited performance of existing engineering-like 
software processes (Section \ref{section_background}),
as well the oversight of a variety of human factors that fall beyond a typical sequence of development 
actions by traditional approaches to software process design (Section \ref{section_software_process_design}).
Then, I have identified a number of key differences of FLOSS processes from traditional Software Engineering 
(Section \ref{floss_processes}), which can potentially shed light on human-driven aspects of software development.
Finally, I have pointed out a growing wealth of publicly available software process artifacts worth to explore 
for a better understanding  of software development processes (Section \ref{section_public_repositories}) and 
indicated a need for new techniques capable of processing of large, heterogeneous datasets.

All this, provided a motivation for my work, in which, I attempted to explore the possibility of discovery of a 
specific human-driven aspect from FLOSS software processes artifacts - the \textit{\textbf{recurrent behaviors}}.
\begin{defn}\label{def_process}
A \textbf{\textit{recurrent behavior}}, in context of software process, defines a \textit{frequent (supported by 
a numerous evidence) mannerism} in which a developer, or a team, conduct their everyday work.
\end{defn}

For example, if within an observation interval one developer frequently runs unit tests before committing 
changes into repository, while another usually commit changes without running the tests, the first developer's
habit of testing a code before the commit is a recurrent behavior that may reflect the developer's discipline,
or an unusual attention to some particular part of the code. 
Consider another example, if one of the developers usually commits code changes in mornings, while another 
developer late in the day, these two recurrent behaviors, might indicate a constraints that are put on the 
project, or the process, or on the developers themselves.
Obviously, latter behaviors should be possible to quantify by simple analysis of commit timestamps, while 
the former can be discovered by the analysis of co-occurring changes in the source code. 
Moreover, these and similar recurrent behaviors could be further associated with certain project's or process 
traits, such as pace, agility, size, complexity, code quality and others, which will not only extend our 
knowledge of human factors in software processes, but will lay a foundation for future research in software 
processes.

To begin with, I hypothesized, that \textbf{\textit{it is possible to discover recurrent behaviors from 
publicly available software process artifacts}}. 

Following the hypothesis, I have investigated a number of publicly available software repositories,
their artifacts, and a number of applicable data-mining techniques in a preliminary exploratory study 
\cite{csdl2-10-09}. However, similarly to other studies in the field, I have discovered, that while FLOSS 
process artifacts are numerous and readily accessible, their irregular, snapshot-like nature and the poor 
informational content significantly limit the applicability of known techniques for process mining.

In order to overcome this issue, I have casted the initial problem of event-based recurrent behaviors 
discovery into more generic problem of knowledge discovery from time series and approached it
by developing a novel technique for interpretable comparative analysis of time series that allows 
characteristic patterns discovery and ranking called SAX-VSM \cite{sax-vsm}. 

Further, I have developed a software artifacts analysis framework, called Software Trajectory Analysis, 
which aids in software artifacts collection, software process and product evolutionary metrics extraction, 
and their comparative analyses that enable discovery and ranking of characteristic patterns.


 in rank highlight is  transformation into  and by using I approached the problem of knowledge discovery 

developed a 
software process artifacts mining framework called Software Trajectory Analysis which is built upon 
a novel technique for comparative analysis of time series that allows characteristic patterns discovery 
and ranking.

This dissertation presents its results, as well as introduces a novel data mining technique designed to 
alleviate difficulties with interpretability of quantitative results obtained through mining of software
artifacts trails. 

%
% >> section
%
\section{Knowledge discovery from time series}\label{section_knowledge_discovery}
In data mining, time series are used as a proxy representing a large variety of real-life phenomena 
in wide range of fields including, but not limited to physics, medicine, meteorology, 
music, motion capture, image recognition, signal processing, and text mining. 
While time series usually directly represent observed phenomenas by capturing their measurable evolution 
in time, the pseudo time series often used for representation of various high-dimensional data 
by combining data points into ordered sequences. 
For example in spectrography data values are ordered by component wavelengths \cite{citeulike:12550833};
in shape analysis the order is the clockwise walk direction starting from a
specific point in the outline \cite{citeulike:12550835}, in image classification the numbers of pixels
are sorted by color component values \cite{citeulike:2900542}.

Many important problems of knowledge discovery from time series reduce to the core task of finding 
characteristic, likely to be repeated, sub-sequences in a longer time series. 
In the early work these were called as 
\textit{frequent patterns} \cite{citeulike:5159615}, 
\textit{approximate periodic patterns} \cite{citeulike:1959582},
\textit{primitive shapes} \cite{citeulike:5898869}, 
\textit{class prototypes} \cite{citeulike:4406444}, 
or \textit{understandable patterns} \cite{citeulike:3978076}. 
Later, similarly to Bioinformatics, these were unified under the term \textit{motif} \cite{citeulike:3977965}.
Once found, motifs can be used for a hypothesis generation by finding their associations with known,
or unknown phenomenas \cite{citeulike:3977965}. 

The recent advances in semi-supervised and unsupervised finding of such characteristic sub-sequences, 
in particular work based on \textit{shapelets} \cite{citeulike:7344347} \cite{citeulike:11957982}
\cite{citeulike:12552293} and \textit{bag of patterns} \cite{citeulike:10525778}, show a great potential 
of application of time series data-mining techniques to a wide variety of high-dimensional data.

Unfortunately, both techniques provide a limited insight into the data and suffer from performance issues. 
While exact shapelet techniques allow discovery of class-characteristic patterns and facilitate classification,
algorithm is almost quadratic and provides limited insight into class specificities. 
The bag of patterns algorithm, while performs in a linear time, requires a previous knowledge for input parameters 
selection and does not offer class generalization.

In order to overcome this limitations, in this thesis I propose a novel approach for time-series classification and 
knowledge discovery that is called SAX-VSM and is based on symbolic approximation of time series and vector space model. 
As I shall show, SAX-VSM is capable to discover and to rank characteristic subsequences representing time series classes. 
The proposed algorithm not only facilitates classification, but provides insights into the both: classification results 
and time series classes specificities. As I shall show, by facilitating the class' characteristics patterns ranking,
SAX-VSM enables the discovery of recurrent behaviors and their heat-map like visualization. 

\section{Software trajectory analysis}\label{section_trajectory_definition}
Previously, Johnson et al. defined \textit{software metrics telemetry streams} \cite{citeulike:12550871}, 
(what they re?) and showed, that it is possible to improve software development process by using the 
knowledge extracted by experts through visual analysis of these streams.
 
Similarly to software metrics telemetry streams, I abstract software process artifact by collecting their 
metrics and arrange these measurements by artifact creation time into high-dimensional vectors. 
These non-equidistant, often sparse and uneven in length time series 
I call ``\textbf{software trajectories}''. Similarly to approximate trajectories of objects in 
a physical space, or reduced in complexity sequence of states of a dynamic system (Poincare' maps), 
the \textit{software trajectory is a curve that describes a software project progression in a space 
of a chosen metrics}.

Through an exploratory study, I have discovered, that by the comparative analysis of software trajectories 
with SAX-VSM it is possible to discover and to interpret recurrent behaviors. This workflow that 
consists of software artifacts collection, their metrics extraction, and comparative analyses I call 
\textit{\textbf{Software Trajectory Analysis}} (STA). 

In this thesis, through three case studies, I will show, that Software Trajectory Analysis is capable 
of discovering of a various characteristic patterns which ca be associated with recurrent behaviors.

\section{Contributions}\label{section_contributions}
Main contributions of my work can be summarized as follows: 
\begin{itemize}
\item I propose a novel, generic algorithm for interpretable time series classification: SAX-VSM. 
While the classification performance of this algorithm is at the level of current state of the art, 
it offers an outstanding feature - discovery, generalization, and ranking of class-characteristic features. 
This, in turn, enables knowledge discovery by offering much clearer insight into classification results than any of 
competing techniques.
In addition, SAX-VSM is very fast in classification and has a small memory footprint. 
Overall, I expect this algorithm to play an important role in future because of the growing ubiquity of time series and 
a growing interest in behaviors.
\item Powered by SAX-VSM, I design a Software Trajectory Analysis (STA) framework, and through case-studies 
show its capacity for recurrent behaviors discovery from publicly available software process
artifacts. While case studies are obviously limited, I argue that STA is a useful knowledge discovery tool applicable for a 
variety of software process artifacts and metrics. 
\item Finally, I provide SAX-VSM and STA implementations to community.
\end{itemize}

\section{Dissertation Outline}\label{section_organization}
The rest of this dissertation is organized as follows. Chapter \ref{chapter_background_work} discusses the history 
of Software Engineering, previous work in software process discovery, mining of software repositories, and current 
state of the art in time series mining. Chapter \ref{chapter_sax_vsm} proposes an algorithm for interpretable 
time series classification. Chapter \ref{chapter_sta} discusses the design of STA framework and presents case studies.
Chapter \ref{chapter_conclusions} concludes and discusses several directions for future study.