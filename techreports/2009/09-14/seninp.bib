@book{citeulike:13374128,
    author = {Jacobson, Ivar and Booch, Grady and Rumbaugh, James},
    citeulike-article-id = {13374128},
    day = {14},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0321822005},
    month = feb,
    posted-at = {2014-09-25 17:05:18},
    priority = {2},
    publisher = {Addison-Wesley Professional},
    title = {The Unified Software Development Process (Paperback) ({Addison-Wesley} Object Technology Series)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0321822005},
    year = {1999}
}

@article{citeulike:13374124,
    author = {Boegh, J.},
    citeulike-article-id = {13374124},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ms.2008.30},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4455633},
    doi = {10.1109/ms.2008.30},
    issn = {0740-7459},
    journal = {Software, IEEE},
    month = mar,
    number = {2},
    pages = {57--63},
    posted-at = {2014-09-25 17:04:01},
    priority = {2},
    publisher = {IEEE},
    title = {A New Standard for Quality Requirements},
    url = {http://dx.doi.org/10.1109/ms.2008.30},
    volume = {25},
    year = {2008}
}

@inproceedings{citeulike:1802027,
    abstract = {An abstract is not available.},
    address = {Los Alamitos, CA, USA},
    author = {Royce, W. W.},
    booktitle = {Proceedings of the 9th International Conference on Software Engineering},
    citeulike-article-id = {1802027},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=41765.41801},
    isbn = {0-89791-216-0},
    location = {Monterey, California, USA},
    pages = {328--338},
    posted-at = {2014-09-25 17:03:03},
    priority = {2},
    publisher = {IEEE Computer Society Press},
    series = {ICSE '87},
    title = {Managing the Development of Large Software Systems: Concepts and Techniques},
    url = {http://portal.acm.org/citation.cfm?id=41765.41801},
    year = {1987}
}

@inproceedings{grammarviz2,
    author = {Senin, P. and Lin, J. and Wang, X. and Oates, T. and Gandhi, S. and Boedihardjo, A. P. and Chen, C. and Frankenstein, S. and Lerner, M.},
    booktitle = {ECML/PKDD 2014},
    citeulike-article-id = {13318201},
    editor = {Calders, T.},
    number = {LNCS 8726},
    pages = {468--472},
    posted-at = {2014-08-07 14:48:37},
    priority = {2},
    title = {{GrammarViz} 2.0: a tool for grammar-based pattern discovery in time series.}
}

@article{citeulike:12394286,
    author = {Kotsiantis, Sotiris and Kanellopoulos, Dimitris}
    citeulike-article-id = {12394286},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.3084},
    posted-at = {2014-06-22 08:10:57},
    priority = {2},
    title = {Discretization Techniques: A recent survey},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.109.3084}
}

@article{hartigan1979,
    author = {Hartigan, J. A. and Wong, M. A.},
    citeulike-article-id = {4369920},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/2346830},
    citeulike-linkout-1 = {http://www.jstor.org/stable/2346830},
    doi = {10.2307/2346830},
    issn = {00359254},
    journal = {Applied Statistics},
    keywords = {classification, clustering, mdb-thesis, statistics},
    number = {1},
    pages = {100--108},
    posted-at = {2014-06-18 22:33:12},
    priority = {2},
    publisher = {Blackwell Publishing for the Royal Statistical Society},
    title = {Algorithm {AS} 136: A k-means clustering algorithm},
    url = {http://dx.doi.org/10.2307/2346830},
    volume = {28},
    year = {1979}
}

@Manual{R_software,
  title        = {R: A Language and Environment for Statistical
                  Computing},
  author       = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address      = {Vienna, Austria},
  year         = 2014,
  url          = {http://www.R-project.org}
}

@book{citeulike:167581,
    abstract = {This edition has been completely revised, enlarged and formatted in two colour. It is a systematic account of the major topics in pattern recognition, based on the fundamental principles. It includes extensive examples, exercises and a solutions manual.},
    author = {Duda, Richard O. and Hart, Peter E. and Stork, David G.},
    citeulike-article-id = {167581},
    day = {09},
    edition = {2},
    howpublished = {Hardcover},
    isbn = {0471056693},
    keywords = {litreview},
    month = nov,
    posted-at = {2009-04-26 20:58:15},
    priority = {2},
    publisher = {Wiley-Interscience},
    title = {Pattern Classification (Pt.1)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0471056693},
    year = {2000}
}

@article{senin2008dynamic,
  title={Dynamic time warping algorithm review},
  author={Senin, Pavel},
  journal={CSDL Technical report},
  year={2008}
}

@phdthesis{cbf,
    author = {Naoki, Saito},
    school = {Yale University},
    title = {Local feature extraction and its application using a library of bases},
    type = {{Ph.D.} Thesis},
    year = {1994}
}

@phdthesis{two_patterns,
    author = {Pierre, Geurts},
    school = {University of Liège, Belgium},
    title = {Contributions to decision tree induction: bias/variance tradeoff and time series classification},
    type = {{Ph.D.} Thesis},
    url = {http://hdl.handle.net/2268/25737},
    year = {2002}
}

@article{citeulike:7549051,
    address = {Los Alamitos, CA, USA},
    author = {Godfrey, Michael W. and Hassan, Ahmed E. and Herbsleb, James and Murphy, Gail C. and Robillard, Martin and Devanbu, Prem and Mockus, Audris and Perry, Dewayne E. and Notkin, David},
    citeulike-article-id = {7549051},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1495958},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ms.2009.10},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4721185},
    doi = {10.1109/ms.2009.10},
    institution = {University of Waterloo},
    issn = {0740-7459},
    journal = {Software, IEEE},
    month = jan,
    number = {1},
    pages = {67--70},
    posted-at = {2014-06-03 12:42:18},
    priority = {2},
    publisher = {IEEE},
    title = {Future of Mining Software Archives: A Roundtable},
    url = {http://dx.doi.org/10.1109/ms.2009.10},
    volume = {26},
    year = {2009}
}

@incollection{citeulike:13208461,
    abstract = {An abstract is not available.},
    address = {Cambridge, MA, USA},
    author = {Norman, Donald A.},
    chapter = {Cognitive Engineering -- Cognitive Science},
    citeulike-article-id = {13208461},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=28458},
    editor = {Carroll, John M.},
    isbn = {0-262-03125-6},
    pages = {325--336},
    posted-at = {2014-06-03 11:46:58},
    priority = {2},
    publisher = {MIT Press},
    title = {Interfacing Thought: Cognitive Aspects of Human-computer Interaction},
    url = {http://portal.acm.org/citation.cfm?id=28458},
    year = {1987}
}

@article{citeulike:13197378,
    abstract = {Time series motifs are repeated segments in a long time series that, if exist, carry precise information about the underlying source of the time series. Motif discovery in time series data has received significant attention in the data mining community since its inception, principally because, motif discovery is meaningful and more likely to succeed when the data is large. Algorithms for motif discovery generally deal with three aspects  the definition of the motifs, domain based preprocessing, and finally, the algorithmic steps. Typical definitions of motifs signify the similarity or the support of the motifs. Domains impose preprocessing requirements to meaningful motif finding such as data alignment, interpolation, and transformation. Motif discovery algorithms vary based on exact or approximate evaluation of the definition. In addition, algorithms require different representations [Symbolic Aggregate {approXimation} ({SAX}), {DFT} etc.] and similarity measures [correlation, dynamic time warping ({DTW}) distance etc.] for time series segments. In this paper, we discuss these  three facets  in detail with examples taken from the literature. We briefly describe a set of applications of time series motif in various domains and elaborate on  a certain  application in entomology to analyze insect behavior. Conflict of interest: The author has declared no conflicts of interest for this article. For further resources related to this article, please visit the {WIREs} website.},
    author = {Mueen, Abdullah},
    citeulike-article-id = {13197378},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/widm.1119},
    day = {1},
    doi = {10.1002/widm.1119},
    journal = {WIREs Data Mining Knowl Discov},
    month = mar,
    number = {2},
    pages = {152--159},
    posted-at = {2014-05-23 10:27:08},
    priority = {2},
    publisher = {John Wiley \& Sons, Inc.},
    title = {Time series motif discovery: dimensions and applications},
    url = {http://dx.doi.org/10.1002/widm.1119},
    volume = {4},
    year = {2014}
}

@article{ostrand2004tool,
  title={A tool for mining defect-tracking systems to predict fault-prone files},
  author={Ostrand, Thomas J and Weyuker, Elaine J},
  year={2004},
  publisher={IET}
}

@article{citeulike:9495129,
    abstract = {Since code revisions reflect the extent of human involvement in the software development process, revision histories reveal the interactions and interfaces between developers and {modules.We} therefore divide developers and modules into groups according to the revision histories of the open source software repository, for example, sourceforge.net. To describe the interactions in the open source development process, we use a representative model, Legitimate Peripheral Participation ({LPP}) [6], to divide developers into groups such as core and peripheral teams, based on the evolutionary process of learning {behavior.With} the conventional module relationship, we divide modules into kernel and non-kernel types (such as {UI}). In the past, groups of developers and modules have been partitioned naturally with informal criteria. In this work, however, we propose a developer-module relationship model to analyze the grouping structures between developers and modules. Our results show some process cases of relative importance on the constructed graph of project development. The graph reveals certain subtle relationships in the interactions between core and non-core team developers, and the interfaces between kernel and non-kernel modules.},
    address = {New York, NY, USA},
    author = {Huang, Shih K. and Liu, Kang M.},
    citeulike-article-id = {9495129},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1083158},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1082983.1083158},
    doi = {10.1145/1082983.1083158},
    issn = {0163-5948},
    journal = {SIGSOFT Softw. Eng. Notes},
    month = may,
    number = {4},
    pages = {1--5},
    posted-at = {2014-05-22 20:42:58},
    priority = {2},
    publisher = {ACM},
    title = {Mining Version Histories to Verify the Learning Process of Legitimate Peripheral Participants},
    url = {http://dx.doi.org/10.1145/1082983.1083158},
    volume = {30},
    year = {2005}
}

@inproceedings{citeulike:1366052,
    abstract = {A programmer performing a change task to a system can benefit from accurate comments on the source code. As part of good programming practice described by Kernighan and Pike in the book The Practice of Programming, comments should "aid the understanding of a program by briefly pointing out salient details or by providing a larger-scale view of the proceedings." In this paper, we explore the widely varying uses of comments in source code. We find that programmers not only use comments for describing the actual source code, but also use comments for many other purposes, such as "talking" to colleagues through the source code using a comment "Joan, please fix this method." This kind of comments can complicate the mining of project information because such team communication is often perceived to reside in separate archives, such as emails or newsgroup postings, rather than in the source code. Nevertheless, these and other types of comments can be very useful inputs for mining project information.},
    address = {New York, NY, USA},
    author = {Ying, Annie T. T. and Wright, James L. and Abrams, Steven},
    booktitle = {Proceedings of the 2005 International Workshop on Mining Software Repositories},
    citeulike-article-id = {1366052},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1083152},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1083142.1083152},
    doi = {10.1145/1083142.1083152},
    isbn = {1-59593-123-6},
    issn = {0163-5948},
    location = {St. Louis, Missouri},
    pages = {1--5},
    posted-at = {2014-05-22 20:27:19},
    priority = {2},
    publisher = {ACM},
    series = {MSR '05},
    title = {Source Code That Talks: An Exploration of Eclipse Task Comments and Their Implication to Repository Mining},
    url = {http://dx.doi.org/10.1145/1083142.1083152},
    year = {2005}
}

@inproceedings{MSRChallenge2012,
    author = {Shihab, E. and Kamei, Y. and Bhattacharya, P.},
    booktitle = {Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on},
    citeulike-article-id = {13196317},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/msr.2012.6224307},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6224307},
    doi = {10.1109/msr.2012.6224307},
    institution = {Queen''s Univ., Kingston, ON, Canada},
    isbn = {978-1-4673-1760-3},
    issn = {2160-1852},
    month = jun,
    pages = {112--115},
    posted-at = {2014-05-22 09:18:05},
    priority = {2},
    publisher = {IEEE},
    title = {Mining challenge 2012: The Android platform},
    url = {http://dx.doi.org/10.1109/msr.2012.6224307},
    year = {2012}
}

@inproceedings{citeulike:10896305,
    abstract = {Temporal segmentation partitions time series data with the intent of producing more homogeneous segments. It is a technique used to preprocess data so that subsequent time series analysis on individual segments can detect trends that may not be evident when performing time series analysis on the entire dataset. This technique allows data miners to partition a large dataset without making any assumption of periodicity or any other a priori knowledge of the dataset's features. We investigate the insights that can be gained from the application of time series segmentation to software version repositories. Software version repositories from large projects contain on the order of hundreds of thousands of timestamped entries or more. It is a continuing challenge to aggregate such data so that noise is reduced and important characteristics are brought out. In this paper, we present a way to summarize developer work history in terms of the files they have modified over time by segmenting the {CVS} change data of individual Eclipse developers. We show that the files they modify tends to change significantly over time though most of them tend to work within the same directories.},
    address = {New York, NY, USA},
    author = {Siy, Harvey and Chundi, Parvathi and Subramaniam, Mahadevan},
    booktitle = {Proceedings of the 2008 International Working Conference on Mining Software Repositories},
    citeulike-article-id = {10896305},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1370784},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1370750.1370784},
    doi = {10.1145/1370750.1370784},
    isbn = {978-1-60558-024-1},
    location = {Leipzig, Germany},
    pages = {137--140},
    posted-at = {2014-05-21 20:09:35},
    priority = {2},
    publisher = {ACM},
    series = {MSR '08},
    title = {Summarizing Developer Work History Using Time Series Segmentation: Challenge Report},
    url = {http://dx.doi.org/10.1145/1370750.1370784},
    year = {2008}
}

@inproceedings{citeulike:6055293,
    abstract = {Prediction of software defects works well within projects as long as there is a sufficient amount of data available to train any models. However, this is rarely the case for new software projects and for many companies. So far, only a few have studies focused on transferring prediction models from one project to another. In this paper, we study cross-project defect prediction models on a large scale. For 12 real-world applications, we ran 622 cross-project predictions. Our results indicate that cross-project prediction is a serious challenge, i.e., simply using models from projects in the same domain or with the same process does not lead to accurate predictions. To help software engineers choose models wisely, we identified factors that do influence the success of cross-project predictions. We also derived decision trees that can provide early estimates for precision, recall, and accuracy before a prediction is attempted.},
    address = {New York, NY, USA},
    author = {Zimmermann, Thomas and Nagappan, Nachiappan and Gall, Harald and Giger, Emanuel and Murphy, Brendan},
    booktitle = {Proceedings of the the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering},
    citeulike-article-id = {6055293},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1595696.1595713},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1595696.1595713},
    doi = {10.1145/1595696.1595713},
    isbn = {978-1-60558-001-2},
    location = {Amsterdam, The Netherlands},
    pages = {91--100},
    posted-at = {2014-05-16 21:06:51},
    priority = {2},
    publisher = {ACM},
    series = {ESEC/FSE '09},
    title = {Cross-project Defect Prediction: A Large Scale Experiment on Data vs. Domain vs. Process},
    url = {http://dx.doi.org/10.1145/1595696.1595713},
    year = {2009}
}

@inproceedings{citeulike:12343296,
    author = {Mockus, A.},
    booktitle = {Mining Software Repositories, 2009. MSR \&\#039;09. 6th IEEE International Working Conference on},
    citeulike-article-id = {12343296},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/msr.2009.5069476},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5069476},
    doi = {10.1109/msr.2009.5069476},
    institution = {Avaya Labs. Res., Basking Ridge, NJ},
    isbn = {978-1-4244-3493-0},
    location = {Vancouver, BC, Canada},
    month = may,
    pages = {11--20},
    posted-at = {2014-05-11 13:11:20},
    priority = {2},
    publisher = {IEEE},
    title = {Amassing and indexing a large sample of version control systems: Towards the census of public source code history},
    url = {http://dx.doi.org/10.1109/msr.2009.5069476},
    year = {2009}
}

@article{citeulike:342840,
    abstract = {Presents an initial set of findings from an empirical study of social processes, technical system configurations, organisational contexts and interrelationships that give rise to open software. The focus is directed at understanding the requirements for open software development efforts, and how the development of these requirements differs from those traditional to software engineering and requirements engineering. Four open software development communities are described, examined and compared to help discover what these differences may be. Eight kinds of software informalisms are found to play a critical role in the elicitation, analysis, specification, validation and management of requirements for developing open software systems. Subsequently, understanding the roles these software informalisms take in a new formulation of the requirements development process for open source software is the focus of the study. This focus enables the consideration of a reformulation of the requirements engineering process and its associated artefacts, or (in)formalisms, to better account for the requirements for developing open source software systems},
    author = {Scacchi, W.},
    citeulike-article-id = {342840},
    citeulike-linkout-0 = {http://dx.doi.org/10.1049/ip-sen:20020202},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=999088},
    doi = {10.1049/ip-sen:20020202},
    institution = {Inst. for Software Res., California Univ., Irvine, CA, USA},
    issn = {1462-5970},
    journal = {Software, IEE Proceedings -},
    month = feb,
    number = {1},
    pages = {24--39},
    posted-at = {2014-05-11 07:01:13},
    priority = {2},
    publisher = {IET},
    title = {Understanding the requirements for developing open source software systems},
    url = {http://dx.doi.org/10.1049/ip-sen:20020202},
    volume = {149},
    year = {2002}
}

@inproceedings{citeulike:7260421,
    abstract = {Large-scale software engineering requires communication and collaboration to successfully build and ship products. We conducted a survey with Microsoft engineers on inter-team coordination and found that the most impactful problems concerned finding and keeping track of other engineers. Since engineers are connected by their shared work, a tool that discovers connections in their work-related repositories can help. Here we describe the Codebook framework for mining software repositories. It is flexible enough to address all of the problems identified by our survey with a single data structure (graph of people and artifacts) and a single algorithm (regular language reachability). Codebook handles a larger variety of problems than prior work, analyzes more kinds of work artifacts, and can be customized by and for end-users. To evaluate our framework's flexibility, we built two applications, Hoozizat and Deep Intellisense. We evaluated these applications with engineers to show effectiveness in addressing multiple inter-team coordination problems.},
    address = {New York, NY, USA},
    author = {Begel, A. and Khoo, Yit P. and Zimmermann, T.},
    booktitle = {Software Engineering, 2010 ACM/IEEE 32nd International Conference on},
    citeulike-article-id = {7260421},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1806799.1806821},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1806799.1806821},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6062080},
    doi = {10.1145/1806799.1806821},
    institution = {Microsoft Res., Redmond, WA, USA},
    isbn = {978-1-60558-719-6},
    issn = {0270-5257},
    location = {Cape Town, South Africa},
    month = may,
    pages = {125--134},
    posted-at = {2014-05-10 20:12:07},
    priority = {2},
    publisher = {IEEE},
    series = {ICSE '10},
    title = {Codebook: discovering and exploiting relationships in software repositories},
    url = {http://dx.doi.org/10.1145/1806799.1806821},
    volume = {1},
    year = {2010}
}

@inproceedings{citeulike:7954249,
    abstract = {An approach to recover/discover traceability links between software artifacts via the examination of a software system's version history is presented. A heuristic-based approach that uses sequential-pattern mining is applied to the commits in software repositories for uncovering highly frequent co-changing sets of artifacts (e.g., source code and documentation). If different types of files are committed together with high frequency then there is a high probability that they have a traceability link between them. The approach is evaluated on a number of versions of the open source system {KDE}. As a validation step, the discovered links are used to predict similar changes in the newer versions of the same system. The results show highly precision predictions of certain types of traceability links.},
    author = {Kagdi, H. and Maletic, J. I. and Sharif, B.},
    booktitle = {Program Comprehension, 2007. ICPC \&\#039;07. 15th IEEE International Conference on},
    citeulike-article-id = {7954249},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icpc.2007.28},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4268249},
    doi = {10.1109/icpc.2007.28},
    institution = {Dept. of Comput. Sci., Kent State Univ., Kent, OH},
    isbn = {0-7695-2860-0},
    issn = {1092-8138},
    location = {Banff, AB, Canada},
    month = jun,
    pages = {145--154},
    posted-at = {2014-05-10 20:10:23},
    priority = {2},
    publisher = {IEEE},
    title = {Mining software repositories for traceability links},
    url = {http://dx.doi.org/10.1109/icpc.2007.28},
    year = {2007}
}

@inproceedings{citeulike:3064738,
    abstract = {We propose a quantitative measure of socio-technical congruence as an indicator of the performance of an organization in carrying out a software development project. We show how the information necessary to implement that measure can be mined from commonly used software repositories, and we describe how socio-technical congruence can be computed based on that information.},
    address = {Washington, DC, USA},
    author = {Valetto, Giuseppe and Helander, Mary and Ehrlich, Kate and Chulani, Sunita and Wegman, Mark and Williams, Clay},
    booktitle = {Proceedings of the Fourth International Workshop on Mining Software Repositories},
    citeulike-article-id = {3064738},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1269039},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/msr.2007.33},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228662},
    doi = {10.1109/msr.2007.33},
    isbn = {0-7695-2950-X},
    journal = {Mining Software Repositories, 2007. ICSE Workshops MSR '07. Fourth International Workshop on},
    pages = {25},
    posted-at = {2014-05-10 20:06:40},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {MSR '07},
    title = {Using Software Repositories to Investigate Socio-technical Congruence in Development Projects},
    url = {http://dx.doi.org/10.1109/msr.2007.33},
    year = {2007}
}

@inproceedings{citeulike:4000311,
    abstract = {Software repositories have been getting a lot of attention from researchers in recent years. In order to analyze software repositories, it is necessary to first extract raw data from the version control and problem tracking systems. This poses two challenges: (1) extraction requires a non-trivial effort, and (2) the results depend on the heuristics used during extraction. These challenges burden researchers that are new to the community and make it difficult to benchmark software repository mining since it is almost impossible to reproduce experiments done by another team. In this paper we present the {TA}-{RE} corpus. {TA}-{RE} collects extracted data from software repositories in order to build a collection of projects that will simplify extraction process. Additionally the collection can be used for benchmarking. As the first step we propose an exchange language capable of making sharing and reusing data as simple as possible.},
    address = {New York, NY, USA},
    author = {Kim, Sunghun and Zimmermann, Thomas and Kim, Miryung and Hassan, Ahmed and Mockus, Audris and Girba, Tudor and Pinzger, Martin and Whitehead, E. James and Zeller, Andreas},
    booktitle = {Proceedings of the 2006 International Workshop on Mining Software Repositories},
    citeulike-article-id = {4000311},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1137983.1137990},
    citeulike-linkout-1 = {http://dblp.uni-trier.de/rec/bibtex/conf/msr/KimZKHMGPWZ06},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/1137983.1137990},
    doi = {10.1145/1137983.1137990},
    isbn = {1-59593-397-2},
    location = {Shanghai, China},
    pages = {22--25},
    posted-at = {2014-05-10 20:05:04},
    priority = {2},
    publisher = {ACM},
    series = {MSR '06},
    title = {{TA}-{RE}: An Exchange Language for Mining Software Repositories},
    url = {http://dx.doi.org/10.1145/1137983.1137990},
    year = {2006}
}

@techreport{citeulike:13159603,
    author = {Senin, Pavel},
    booktitle = {Dissertation proposal},
    citeulike-article-id = {13159603},
    posted-at = {2014-05-05 17:12:43},
    priority = {2},
    title = {Software Trajectory Analysis: an empirically based method for automated software process discovery},
    year = {2009}
}

@inproceedings{citeulike:13158806,
    author = {Chapin, Ned},
    booktitle = {AFIPS National Computer Conference},
    citeulike-article-id = {13158806},
    pages = {995--1002},
    posted-at = {2014-05-04 08:59:50},
    priority = {2},
    title = {A Measure of Software Complexity},
    year = {1979}
}

@book{citeulike:13158802,
    author = {Gilb, Tom},
    citeulike-article-id = {13158802},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/9780876268551},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9780876268551},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9780876268551\&index=books\&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/9780876268551},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/2424816},
    isbn = {9780876268551},
    posted-at = {2014-05-04 08:54:32},
    priority = {2},
    publisher = {Winthrop Publishers},
    title = {Software metrics},
    url = {http://www.worldcat.org/isbn/9780876268551},
    year = {1977}
}

@inproceedings{german04_softchange,
    abstract = {{CVS} logs are a rich source of software trails (information left behind by the contributors to the development process, usually in the forms of logs). This paper describes how {softChange} extracts these trails, and enhances them. This paper also addresses some challenges that {CVS} fact extraction poses to researchers.},
    address = {Edinburg, Scotland, UK},
    author = {German, Daniel M.},
    booktitle = {Proceedings of the First International Workshop on Mining Software Repositories},
    citeulike-article-id = {423259},
    citeulike-linkout-0 = {http://www.turingmachine.org/\~{}dmg/dchurch/mining.pdf},
    keywords = {mining-cvs},
    pages = {17--21},
    posted-at = {2014-04-24 14:11:12},
    priority = {2},
    title = {Mining {CVS} repositories, the softchange experience},
    url = {http://www.turingmachine.org/\~{}dmg/dchurch/mining.pdf},
    year = {2004}
}

@INPROCEEDINGS{MSRChallenge2013,
  author={Alberto Bacchelli},
  title={Mining Challenge 2013: Stack Overflow},
  booktitle={The 10th Working Conference on Mining Software Repositories},
  year={2013},
  pages={to appear}
}

@inproceedings{citeulike:13156191,
    abstract = {One of the more unique features of open source software development is the continuity of projects over large time scales and incremental development efforts. For this reason, the open development process provides an interesting environment for investigation of the software development process. The problems of data collection and analysis of two particular long-running repositories, the X Window System and the Nickle Programming Language, are considered here as instructive examples. The use of uniform software tools ({CVS}/{RCS}) with open formats and interfaces makes it possible to collect data that provide unique analysis opportunities.},
    address = {New York, NY, USA},
    author = {Massey, Bart},
    booktitle = {Proceedings of the 2005 Workshop on Predictor Models in Software Engineering},
    citeulike-article-id = {13156191},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1083165.1083167},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1082983.1083167},
    doi = {10.1145/1082983.1083167},
    isbn = {-159593-125-2},
    location = {St. Louis, Missouri},
    pages = {1--5},
    posted-at = {2014-05-01 09:06:46},
    priority = {2},
    publisher = {ACM},
    series = {PROMISE '05},
    title = {Longitudinal Analysis of Long-timescale Open Source Repository Data},
    url = {http://dx.doi.org/10.1145/1082983.1083167},
    year = {2005}
}

@inproceedings{Massey:2005:LAL:1083165.1083167,
 author = {Massey, Bart},
 title = {Longitudinal Analysis of Long-timescale Open Source Repository Data},
 booktitle = {Proceedings of the 2005 Workshop on Predictor Models in Software Engineering},
 series = {PROMISE '05},
 year = {2005},
 isbn = {-159593-125-2},
 location = {St. Louis, Missouri},
 pages = {1--5},
 numpages = {5},
 url = {http://doi.acm.org.eres.library.manoa.hawaii.edu/10.1145/1082983.1083167},
 doi = {10.1145/1082983.1083167},
 acmid = {1083167},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {open source, source repositories},
}

@inproceedings{citeulike:13125481,
    abstract = {Software analytics is to enable software practitioners to perform data exploration and analysis in order to obtain insightful and actionable information for data-driven tasks around software and services. In this position paper, we advocate that when applying analytic technologies in practice of software analytics, one should (1) incorporate a broad spectrum of domain knowledge and expertise, e.g., management, machine learning, large-scale data processing and computing, and information visualization; and (2) investigate how practitioners take actions on the produced information, and provide effective support for such information-based action taking. Our position is based on our experiences of successful technology transfer on software analytics at Microsoft Research Asia.},
    address = {New York, NY, USA},
    author = {Zhang, Dongmei and Dang, Yingnong and Lou, Jian G. and Han, Shi and Zhang, Haidong and Xie, Tao},
    booktitle = {Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering},
    citeulike-article-id = {13125481},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2070829},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2070821.2070829},
    doi = {10.1145/2070821.2070829},
    isbn = {978-1-4503-1022-2},
    location = {Lawrence, Kansas, USA},
    pages = {55--58},
    posted-at = {2014-04-03 15:22:16},
    priority = {2},
    publisher = {ACM},
    series = {MALETS '11},
    title = {Software Analytics As a Learning Case in Practice: Approaches and Experiences},
    url = {http://dx.doi.org/10.1145/2070821.2070829},
    year = {2011}
}

@article{citeulike:277045,
    abstract = {We apply data mining to version histories in order to guide programmers along related changes: "Programmers who changed these functions also changed...." Given a set of existing changes, the mined association rules 1) suggest and predict likely further changes, 2) show up item coupling that is undetectable by program analysis, and 3) can prevent errors due to incomplete changes. After an initial change, our {ROSE} prototype can correctly predict further locations to be changed; the best predictive power is obtained for changes to existing software. In our evaluation based on the history of eight popular open source projects, {ROSE}'s topmost three suggestions contained a correct location with a likelihood of more than 70 percent.},
    address = {Los Alamitos, CA, USA},
    author = {Zimmermann, T. and Zeller, A. and Weissgerber, P. and Diehl, S.},
    booktitle = {Software Engineering, IEEE Transactions on},
    citeulike-article-id = {277045},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/TSE.2005.72},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/tse.2005.72},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1463228},
    day = {11},
    doi = {10.1109/tse.2005.72},
    institution = {Dept. of Comput. Sci., Saarlandes Univ., Saarbrucken, Germany},
    issn = {0098-5589},
    journal = {Software Engineering, IEEE Transactions on},
    month = jun,
    number = {6},
    pages = {429--445},
    posted-at = {2014-03-16 20:47:15},
    priority = {2},
    publisher = {IEEE},
    title = {Mining version histories to guide software changes},
    url = {http://dx.doi.org/10.1109/tse.2005.72},
    volume = {31},
    year = {2005}
}

@inproceedings{citeulike:3017440,
    abstract = {The success of a software development project depends on the technical competency of the development team, the quality of the tools they use, and the project-management decisions they make during the software lifecycle. Instructors of software-engineering courses that involve small project teams are often overwhelmed with the task of monitoring the progress of multiple teams. Without adequate monitoring and advice on best practices, problems in the team's process or the developed product may go unnoticed until it is too late to be easily fixed. This paper introduces the {JRefleX} environment, with components built upon Eclipse, to support the education of small software teams.},
    address = {New York, NY, USA},
    author = {Wong, Kenny and Blanchet, Warren and Liu, Ying and Schofield, Curtis and Stroulia, Eleni and Xing, Zhenchang},
    booktitle = {Proceedings of the 2003 OOPSLA Workshop on Eclipse Technology eXchange},
    citeulike-article-id = {3017440},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=965660.965671},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/965660.965671},
    doi = {10.1145/965660.965671},
    location = {Anaheim, California},
    pages = {50--54},
    posted-at = {2014-04-03 13:54:24},
    priority = {2},
    publisher = {ACM},
    series = {eclipse '03},
    title = {{JRefleX}: Towards Supporting Small Student Software Teams},
    url = {http://dx.doi.org/10.1145/965660.965671},
    year = {2003}
}

@misc{bonsai,
  title = {Bonsai project},
  howpublished = {\url{https://wiki.mozilla.org/Bonsai}},
  note = {Accessed: 2014-04-02},
  year = {2014}
}

@inproceedings{citeulike:13125395,
    abstract = {The proliferation of open source projects raises a number of vital economic, social, and software engineering questions that are subject of intense research. Based on experience analyzing numerous open source and commercial projects we propose a set of tools to support extraction and validation of software project data. Such tools would streamline empirical investigation of open source projects and make it possible to test existing and new theories about the nature of open source projects. Our software includes tools to extract and summarize information from mailing lists, {CVS} logs, {ChangeLog} files, and defect tracing databases. More importantly, it cross-links records from various data sources and identifies all contributors for a software change. We illustrate some of the capabilities by analyzing data from Ximian Evolution project. 1.},
    author = {German, Daniel},
    booktitle = {In Proceedings of the 3rd Workshop on Open Source Software Engineering},
    citeulike-article-id = {13125395},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.136.3067},
    pages = {63--67},
    posted-at = {2014-04-03 13:19:02},
    priority = {2},
    title = {Automating the measurement of open source projects},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.136.3067},
    year = {2003}
}

@inproceedings{citeulike:13125389,
    abstract = {Software tools can improve the quality and maintainability ofsoftware, but are expensive to acquire, deploy and maintain, especially in large organizations. We explore how toquantify the e ects of a software tool once it has been deployed in a development environment. We present a simple methodology for tool evaluation that correlates tool usage statistics with estimates of developer e ort, as derived from a project's change history (version control system). Our work complements controlled experiments on software tools, which usually take place outside the industrial setting, and tool assessment studies that predict the impact of software tools before deployment. Our analysis is inexpensive, non-intrusive and can be appliedtoanentire software project in its actual setting. Akey part of our analysis is how tocontrol confounding variables such asdeveloper work-style and experience in order accurately to quantify the impact of a tool on developer e ort. We demonstrate our method in a case study of a software tool called {VE}, a version-sensitive editor used in Bell Labs. {VE} aids software developers in coping with the rampant use of preprocessor directives (such as \#if/\#endif) in C source les. Our analysis found that developers were approximately 36 \% more productive when using {VE} than when using standard text editors.},
    author = {Atkins, David and Ball, Thomas and Graves, Todd and Mockus, Audris},
    booktitle = {IEEE Transactions on Software Engineering},
    citeulike-article-id = {13125389},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.6490},
    pages = {324--333},
    posted-at = {2014-04-03 13:10:29},
    priority = {2},
    title = {Using version control data to evaluate the impact of software tools: A case study of the version editor},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.6490},
    year = {2002}
}

@inproceedings{citeulike:5803126,
    abstract = {Large scale software products must constantly change in order to
adapt to a changing environment. Studies of historic data from legacy
software systems have identified three specific causes of this change:
adding new features; correcting faults; and restructuring code to
accommodate future changes. Our hypothesis is that a textual description
field of a change is essential to understanding why that change was
performed. Also, we expect that difficulty, size, and interval would
vary strongly across different types of changes. To test these
hypotheses we have designed a program which automatically classifies
maintenance activity based on a textual description of changes.
Developer surveys showed that the automatic classification was in
agreement with developer opinions. Tests of the classifier on a
different product found that size and interval for different types of
changes did not vary across two products. We have found strong
relationships between the type and size of a change and the time
required to carry it out. We also discovered a relatively large amount
of perfective changes in the system we examined. From this study we have
arrived at several suggestions on how to make version control data
useful in diagnosing the state of a software project, without
significantly increasing the overhead for the developer using the change
management system},
    address = {Los Alamitos, CA, USA},
    author = {Mockus, A. and Votta, L. G.},
    booktitle = {Software Maintenance, 2000. Proceedings. International Conference on},
    citeulike-article-id = {5803126},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/ICSM.2000.883028},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icsm.2000.883028},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=883028},
    day = {06},
    doi = {10.1109/icsm.2000.883028},
    institution = {Dept. of Software Production Res., Lucent Technol. Bell Labs., Naperville, IL, USA},
    isbn = {0-7695-0753-0},
    issn = {1063-6773},
    journal = {Software Maintenance, 2000. Proceedings. International Conference on},
    location = {Victoria, BC, Canada},
    month = aug,
    pages = {120--130},
    posted-at = {2014-04-03 13:04:24},
    priority = {2},
    publisher = {IEEE},
    title = {Identifying reasons for software changes using historic databases},
    url = {http://dx.doi.org/10.1109/icsm.2000.883028},
    volume = {0},
    year = {2000}
}

@inproceedings{citeulike:13125375,
    abstract = {Online service systems have been increasingly popular and important nowadays, with an increasing demand on the availability of services provided by these systems, while significant efforts have been made to strive for keeping services up continuously. Therefore, reducing the {MTTR} (Mean Time to Restore) of a service remains the most important step to assure the user-perceived availability of the service. To reduce the {MTTR}, a common practice is to restore the service by identifying and applying an appropriate healing action (i.e., a temporary workaround action such as rebooting a {SQL} machine). However, manually identifying an appropriate healing action for a given new issue (such as service down) is typically time consuming and error prone. To address this challenge, in this paper, we present an automated mining-based approach for suggesting an appropriate healing action for a given new issue. Our approach generates signatures of an issue from its corresponding transaction logs and then retrieves historical issues from a historical issue repository. Finally, our approach suggests an appropriate healing action by adapting healing actions for the retrieved historical issues. We have implemented a healing suggestion system for our approach and applied it to a real-world product online service that serves millions of online customers globally. The studies on 77 incidents (severe issues) over 3 months showed that our approach can effectively provide appropriate healing actions to reduce the {MTTR} of the service.},
    address = {New York, NY, USA},
    author = {Ding, Rui and Fu, Qiang and Lou, Jian G. and Lin, Qingwei and Zhang, Dongmei and Shen, Jiajun and Xie, Tao},
    booktitle = {Proceedings of the 27th IEEE/ACM International Conference on Automated Software Engineering},
    citeulike-article-id = {13125375},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2351735},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2351676.2351735},
    doi = {10.1145/2351676.2351735},
    isbn = {978-1-4503-1204-2},
    location = {Essen, Germany},
    pages = {318--321},
    posted-at = {2014-04-03 12:45:10},
    priority = {2},
    publisher = {ACM},
    series = {ASE 2012},
    title = {Healing Online Service Systems via Mining Historical Issue Repositories},
    url = {http://dx.doi.org/10.1145/2351676.2351735},
    year = {2012}
}

@inproceedings{citeulike:393158,
    abstract = {A great deal of attention has lately been given to addressing software bugs such as errors in operating system drivers or security bugs. However, there are many other lesser known errors specific to individual applications or {APIs} and these violations of application-specific coding rules are responsible for a multitude of errors. In this paper we propose {DynaMine}, a tool that analyzes source code check-ins to find highly correlated method calls as well as common bug fixes in order to automatically discover application-specific coding patterns. Potential patterns discovered through mining are passed to a dynamic analysis tool for validation; finally, the results of dynamic analysis are presented to the {user.The} combination of revision history mining and dynamic analysis techniques leveraged in {DynaMine} proves effective for both discovering new application-specific patterns and for finding errors when applied to very large applications with many man-years of development and debugging effort behind them. We have analyzed Eclipse and {jEdit}, two widely-used, mature, highly extensible applications consisting of more than 3,600,000 lines of code combined. By mining revision histories, we have discovered 56 previously unknown, highly application-specific patterns. Out of these, 21 were dynamically confirmed as very likely valid patterns and a total of 263 pattern violations were found.},
    address = {New York, NY, USA},
    author = {Livshits, Benjamin and Zimmermann, Thomas},
    booktitle = {Proceedings of the 10th European Software Engineering Conference Held Jointly with 13th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
    citeulike-article-id = {393158},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1081754},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1081706.1081754},
    doi = {10.1145/1081706.1081754},
    isbn = {1-59593-014-0},
    issn = {0163-5948},
    location = {Lisbon, Portugal},
    month = sep,
    number = {5},
    pages = {296--305},
    posted-at = {2014-04-03 12:45:47},
    priority = {2},
    publisher = {ACM},
    series = {ESEC/FSE-13},
    title = {{DynaMine}: Finding Common Error Patterns by Mining Software Revision Histories},
    url = {http://dx.doi.org/10.1145/1081706.1081754},
    volume = {30},
    year = {2005}
}

@inproceedings{citeulike:10567306,
    abstract = {The ideas and findings in this report should not be construed as an official {DoD} position. It is published in the interest of scientific and technical information exchange. {FOR} {THE} {COMMANDER} (signature on file)},
    author = {Florac, William A. and Florac, William A. and Park, Robert E. and Park, Robert E. and Carleton, Anita D. and Carleton, Anita D. and Miller, Thomas R. and Col, Lt},
    booktitle = {Electronic Communication and Changing Organizational Forms,\^{a} Organization Science (6},
    citeulike-article-id = {10567306},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.8638},
    pages = {337--349},
    posted-at = {2014-04-03 08:20:04},
    priority = {2},
    title = {Practical Software Measurement: Measuring for process management and Improvement},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.8638},
    year = {1997}
}

@article{citeulike:1803429,
    abstract = {Software measurement, like measurement in any other discipline,
must adhere to the science of measurement if it is to gain widespread
acceptance and validity. The observation of some very simple, but
fundamental, principles of measurement can have an extremely beneficial
effect on the subject. Measurement theory is used to highlight both
weaknesses and strengths of software metrics work, including work on
metrics validation. We identify a problem with the well-known Weyuker
properties ({E.J}. Weyuker, 1988), but also show that a criticism of these
properties by {J.C}. Cherniavsky and {C.H}. Smith (1991) is invalid. We show
that the search for general software complexity measures is doomed to
failure. However, the theory does help us to define and validate
measures of specific complexity attributes. Above all, we are able to
view software measurement in a very wide perspective, rationalising and
relating its many diverse activities},
    author = {Fenton, N.},
    booktitle = {Software Engineering, IEEE Transactions on},
    citeulike-article-id = {1803429},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/32.268921},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=268921},
    doi = {10.1109/32.268921},
    institution = {Centre for Software Reliability, City Univ., London, UK},
    issn = {0098-5589},
    journal = {Software Engineering, IEEE Transactions on},
    month = mar,
    number = {3},
    pages = {199--206},
    posted-at = {2014-03-14 14:05:44},
    priority = {2},
    publisher = {IEEE},
    title = {Software measurement: a necessary scientific basis},
    url = {http://dx.doi.org/10.1109/32.268921},
    volume = {20},
    year = {1994}
}

@inproceedings{citeulike:1525462,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Fenton, Norman E. and Neil, Martin},
    booktitle = {Proceedings of the Conference on The Future of Software Engineering},
    citeulike-article-id = {1525462},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=336588},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/336512.336588},
    doi = {10.1145/336512.336588},
    isbn = {1-58113-253-0},
    location = {Limerick, Ireland},
    pages = {357--370},
    posted-at = {2014-03-14 13:09:23},
    priority = {2},
    publisher = {ACM},
    series = {ICSE '00},
    title = {Software Metrics: Roadmap},
    url = {http://dx.doi.org/10.1145/336512.336588},
    year = {2000}
}

@book{demillo1980software,
    author = {DeMillo, R. A. and Lipton, R. J. and Information, Georgia I. and Science},
    citeulike-article-id = {13106780},
    citeulike-linkout-0 = {http://books.google.fr/books?id=yr0SOAAACAAJ},
    keywords = {*file-import-14-03-14},
    posted-at = {2014-03-14 11:54:09},
    priority = {2},
    publisher = {Defense Technical Information Center},
    title = {Software Project Forecasting},
    url = {http://books.google.fr/books?id=yr0SOAAACAAJ},
    year = {1980}
}

@article{citeulike:2710928,
    abstract = {Source code version repositories provide a treasure of information encompassing the changes introduced
in the system throughout its evolution. These repositories are typically managed by tools such as {CVS}. However, these
tools identify and express changes in terms of physical attributes i.e., file and line numbers. Recently, to help
support the mining of software repositories ({MSR}), researchers have proposed methods to derive and express changes
from source code repositories in a more source-code "aware" manner (i.e., syntax and semantic). Here, we discuss these
{MSR} techniques in light of what changes are identified, how they are expressed, the adopted methodology, evaluation,
and results. This work forms the basis for a taxonomic description of {MSR} approaches.},
    address = {New York, NY, USA},
    author = {Kagdi, Huzefa and Collard, Michael L. and Maletic, Jonathan I.},
    citeulike-article-id = {2710928},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1082983.1083159},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1082983.1083159},
    doi = {10.1145/1082983.1083159},
    issn = {0163-5948},
    journal = {SIGSOFT Softw. Eng. Notes},
    month = may,
    number = {4},
    pages = {1--5},
    posted-at = {2014-02-27 08:28:17},
    priority = {2},
    publisher = {ACM},
    title = {Towards a Taxonomy of Approaches for Mining of Source Code Repositories},
    url = {http://dx.doi.org/10.1145/1082983.1083159},
    volume = {30},
    year = {2005}
}

@article{citeulike:7770568,
    address = {Hingham, MA, USA},
    author = {Samalikova, Jana and Kusters, Rob and Trienekens, Jos and Weijters, Ton and Siemons, Paul},
    citeulike-article-id = {7770568},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1938211.1938265},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s11219-010-9105-8},
    citeulike-linkout-2 = {http://www.springerlink.com/content/35n37v3718njw501},
    day = {23},
    doi = {10.1007/s11219-010-9105-8},
    issn = {0963-9314},
    journal = {Software Quality Control},
    month = mar,
    number = {1},
    pages = {101--120},
    posted-at = {2014-02-27 08:32:19},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Toward Objective Software Process Information: Experiences from a Case Study},
    url = {http://dx.doi.org/10.1007/s11219-010-9105-8},
    volume = {19},
    year = {2011}
}

@article{citeulike:9976868,
    address = {Los Alamitos, CA, USA},
    author = {Dinh-Trong, T. T. and Bieman, J. M.},
    citeulike-article-id = {9976868},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/TSE.2005.73},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/tse.2005.73},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1463231},
    doi = {10.1109/tse.2005.73},
    issn = {0098-5589},
    journal = {Software Engineering, IEEE Transactions on},
    month = jun,
    number = {6},
    pages = {481--494},
    posted-at = {2014-02-26 13:33:08},
    priority = {2},
    publisher = {IEEE},
    title = {The {FreeBSD} project: a replication case study of open source development},
    url = {http://dx.doi.org/10.1109/tse.2005.73},
    volume = {31},
    year = {2005}
}

@article{citeulike:13072239,
    author = {Humphrey, W. S.},
    citeulike-article-id = {13072239},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/52.493023},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=493023},
    doi = {10.1109/52.493023},
    issn = {0740-7459},
    journal = {Software, IEEE},
    month = may,
    number = {3},
    pages = {77--88},
    posted-at = {2014-02-26 10:00:40},
    priority = {2},
    publisher = {IEEE},
    title = {Using a defined and measured Personal Software Process},
    url = {http://dx.doi.org/10.1109/52.493023},
    volume = {13},
    year = {1996}
}

@inproceedings{citeulike:13071448,
    author = {Redig, G. and Swanson, M.},
    booktitle = {Computer-Based Medical Systems, 1993. Proceedings of Sixth Annual IEEE Symposium on},
    citeulike-article-id = {13071448},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/cbms.1993.263002},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=263002},
    doi = {10.1109/cbms.1993.263002},
    isbn = {0-8186-3752-8},
    month = jun,
    pages = {301--306},
    posted-at = {2014-02-25 17:38:56},
    priority = {2},
    publisher = {IEEE},
    title = {Total quality management for software development},
    url = {http://dx.doi.org/10.1109/cbms.1993.263002},
    year = {1993}
}

@inproceedings{citeulike:13058334,
    abstract = {{F/OSS} research faces a new and unusual situation: the traditional difficulties of gathering enough empirical data have been replaced by issues of dealing with enormous amounts of freely available data from many disparate sources (forums, code, bug reports, etc.) At present no means exist for assembling these data under common access points and frameworks for comparative, longitudinal, and collaborative research. Gathering and maintaining large {F/OSS} data collections reliably and making them usable present several research challenges. For example, current projects usually rely on \^{a}web scraping \^{a} or on direct access to raw data from groups that generate it, and both of these methods require unique effort for each new corpus, or even for updating existing corpora. In this paper we identify several common needs and critical factors in {F/OSS} empirical research, and suggest orientations and recommendations for the design of a shared research infrastructure. 1.},
    author = {Gasser, Les and Ripoche, Gabriel and Sandusky, Robert J.},
    booktitle = {Proc. Intern. Workshop on Mining Software Repositories},
    citeulike-article-id = {13058334},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.163.3717},
    posted-at = {2014-02-23 15:43:25},
    priority = {2},
    title = {Research Infrastructure for Empirical Science of {F/OSS}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.163.3717},
    year = {2004}
}

@phdthesis{cvsanaly,
    author = {Robles, Gregorio},
    month = feb,
    priority = {2},
    school = {Departamento de Informática, Estadística y Telemática},
    title = {Empirical Software Engineering Research on Libre Software: Data Sources, Methodologies and Results},
    type = {{Ph.D.} Thesis},
    url = {http://www.libresoft.es/publications/thesis-grex},
    year = {2006}
}

@book{Cohn_SCRUM,
    author = {Rubin, Kenneth S.},
    citeulike-article-id = {12972505},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0137043295\&index=books\&linkCode=qs},
    day = {05},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0137043295},
    month = aug,
    posted-at = {2014-02-06 09:10:17},
    priority = {2},
    publisher = {Addison-Wesley Professional},
    title = {Essential Scrum: A Practical Guide to the Most Popular Agile Process ({Addison-Wesley} Signature Series (Cohn))},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0137043295},
    year = {2012}
}

@book{Beck_XP,
    author = {Beck, Kent and Andres, Cynthia},
    citeulike-article-id = {260117},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0321278658\&index=books\&linkCode=qs},
    day = {26},
    edition = {2nd},
    howpublished = {Paperback},
    isbn = {0321278658},
    month = nov,
    posted-at = {2014-02-06 09:05:18},
    priority = {2},
    publisher = {Addison-Wesley},
    title = {Extreme Programming Explained: Embrace Change, 2nd Edition (The {XP} Series)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0321278658},
    year = {2004}
}

@book{Beck_TDD,
    author = {Beck, Kent},
    citeulike-article-id = {225134},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0321146530\&index=books\&linkCode=qs},
    day = {18},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0321146530},
    month = nov,
    posted-at = {2014-02-06 09:00:26},
    priority = {2},
    publisher = {Addison-Wesley Professional},
    title = {Test Driven Development: By Example},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0321146530},
    year = {2002}
}

@inproceedings{sax-vsm,
    author = {Senin, Pavel and Malinchik, Sergey},
    booktitle = {Data Mining (ICDM), 2013 IEEE 13th International Conference on},
    citeulike-article-id = {12966492},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icdm.2013.52},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6729617},
    doi = {10.1109/icdm.2013.52},
    issn = {1550-4786},
    month = dec,
    pages = {1175--1180},
    posted-at = {2014-02-05 20:50:05},
    priority = {2},
    publisher = {IEEE},
    title = {{SAX}-{VSM}: Interpretable Time Series Classification Using {SAX} and Vector Space Model},
    url = {http://dx.doi.org/10.1109/icdm.2013.52},
    year = {2013}
}

@article{citeulike:12944456,
    author = {Scacchi, Walt},
    citeulike-article-id = {12944456},
    citeulike-linkout-0 =
{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.9145},
    posted-at = {2014-02-02 07:39:17},
    priority = {2},
    title = {Process Models in Software Engineering},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.9145},
    year = {2002}
}

@inproceedings{citeulike:12944447,
  author = {Aalst, W. M. P. van der and Adriansyah, A. and Medeiros, A. K. Alves
   de and F. Arcieri and T. Baier and T. Blickle and Bose, R. P. Jagadeesh Chandra
   and Brand, P. van den and Brandtjen, R. and Buijs, J. C. A. M. and Burattin, A.
   and Carmona, J. and Castellanos, M. and Claes, J. and Cook, J. and Costantini,
   N. and Curbera, F. and E. Damiani and M. de Leoni and P. Delias and Dongen, B.
   F. van and Dumas, M. and S. Dustdar and Fahland, D. and Ferreira, D. R. and
   Gaaloul, W. and Geffen, F. van and Goel, S. and Günther, C. W. and Guzzo, A. and
   Harmon, P. and Hofstede, A. H. M. ter and Hoogland, J. and Espen Ingvaldsen, J.
   and Kato, K. and Kuhn, R. and Kumar, A. and La Rosa, M. and Maggi, F. and
   Malerba, D. and Mans, R. S. and Manuel, A. and McCreesh, M. and Mello, P. and
   Mendling, J. and Montali, M. and Motahari Nezhad, H. and zur Muehlen, M. and
   Munoz-Gama, J. and Pontieri, L. and Ribeiro, J. and Rozinat, A. and Seguel
   Pérez, H. and Seguel Pérez, R. and Sepúlveda, M. and Sinur, J. and Soffer, P.
   and Song, M. S. and Sperduti, A. and Stilo, G. and Stoel, C. and Swenson, K. and
   Talamo, M. and Tan, W. and Turner, C. and Vanthienen, J. and Varvaressos, G. and
   Verbeek, H. M. W. and Verdonk, M. and Vigo, R. and Wang, J. and Weber, B. and
   Weidlich, M. and Weijters, A. J. M. M. and Wen, L. and Westergaard, M. and Wynn,
   M. T.},
  title = {Process Mining Manifesto},
  booktitle = {BPM 2011 Workshops, Part I},
  publisher = {Springer-Verlag},
  year = {2012},
  volume = {99},
  pages = {169--194},
  url = {http://www.win.tue.nl/ieeetfpm/doku.php?id=shared:process_mining_manifesto}
}

@article{1903,
    author = {Andrews, B. R.},
    citeulike-article-id = {12937221},
    citeulike-linkout-0 = {http://www.jstor.org/stable/1412711},
    journal = {The American Journal of Psychology},
    keywords = {*file-import-14-01-26},
    number = {2},
    posted-at = {2014-01-26 09:33:02},
    priority = {2},
    publisher = {University of Illinois Press},
    title = {Habit},
    url = {http://www.jstor.org/stable/1412711},
    volume = {14},
    year = {1903}
}

@article{neal2012habits,
    author = {Neal, David T. and Wood, Wendy and Labrecque, Jennifer S. and Lally, Phillippa},
    citeulike-article-id = {12937220},
    journal = {Journal of Experimental Social Psychology},
    keywords = {*file-import-14-01-26},
    number = {2},
    pages = {492--498},
    posted-at = {2014-01-26 09:30:11},
    priority = {2},
    publisher = {Academic Press},
    title = {How do habits guide behavior? Perceived and actual triggers of habits in daily life},
    volume = {48},
    year = {2012}
}

@article{citeulike:12933080,
    author = {Janert, P. K.},
    citeulike-article-id = {12933080},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ms.2003.1241380},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1241380},
    doi = {10.1109/ms.2003.1241380},
    institution = {beyondCode},
    issn = {0740-7459},
    journal = {Software, IEEE},
    month = nov,
    number = {6},
    pages = {108--109},
    posted-at = {2014-01-21 15:59:23},
    priority = {2},
    publisher = {IEEE},
    title = {Software craftsmanship [Book Review]},
    url = {http://dx.doi.org/10.1109/ms.2003.1241380},
    volume = {20},
    year = {2003}
}

@inproceedings{citeulike:12929227,
    author = {Johnson, P. M.},
    booktitle = {Empirical Software Engineering and Measurement, 2007. ESEM 2007. First International Symposium on},
    citeulike-article-id = {12929227},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/esem.2007.36},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4343735},
    doi = {10.1109/esem.2007.36},
    institution = {Univ. of Hawaii, Honolulu},
    isbn = {978-0-7695-2886-1},
    issn = {1938-6451},
    pages = {81--90},
    posted-at = {2014-01-20 17:09:34},
    priority = {2},
    publisher = {IEEE},
    title = {Requirement and Design Trade-offs in Hackystat: An {In-Process} Software Engineering Measurement and Analysis System},
    url = {http://dx.doi.org/10.1109/esem.2007.36},
    year = {2007}
}

@book{citeulike:12929216,
    abstract = {From the {Publisher:This} new work from Watts Humphrey, author of the influential book, Managing the Software Process, broadens his orderly view of software process management, and lays the foundation for a disciplined approach to software engineering. In his earlier book, the author developed concrete methods for managing software development and maintenance. These methods, now commonly practiced in industry, provide programmers and managers with specific steps they can take to evaluate and improve their software capabilities. In this new book, Humphrey scales those methods down to a personal level, helping software engineers develop the skills and habits needed to plan, track, and analyze large, complex projects. Humphrey and others have used material from this book to train professionals and students around the world in a projects-oriented software engineering course. First establishing the need for discipline in software engineering, and the benefits to practitioners of learning how to 
manage their personal software process, Humphrey then develops a model that they can use to monitor, test, and improve their work. Examples drawn from industry enhance the practical focus of the book, while project exercises give readers the opportunity to practice software process management as they learn it. Features: presents concepts and methods for a disciplined software engineering process; scales down industrial practices for planning, tracking, analysis, and defect management to fit the needs of small-scale program development; and shows how small project disciplines provide a solid base for larger projects.},
    address = {Boston, MA, USA},
    author = {Humphrey, Watts S.},
    citeulike-article-id = {12929216},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=526906},
    isbn = {0201847485},
    posted-at = {2014-01-20 16:50:56},
    priority = {2},
    publisher = {Addison-Wesley Longman Publishing Co., Inc.},
    title = {A Discipline for Software Engineering},
    url = {http://portal.acm.org/citation.cfm?id=526906},
    year = {1995}
}

@misc{spice-standard,
  title = {Information technology -- Process assessment.},
  howpublished = {\url{http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=38932}},
  note = {Accessed: 2013-12-18},
  year = {2008}
}

@misc{iso-standard,
  title = {Quality systems -- Model for quality assurance in design, development, production, installation and servicing.},
  howpublished = {\url{http://www.iso.org/iso/catalogue_detail.htm?csnumber=16534}},
  note = {Accessed: 2013-12-18},
  year = {2000}
}

@inproceedings{citeulike:11538873,
    booktitle = {Agile Conference (AGILE), 2007},
    citeulike-article-id = {11538873},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/agile.2007.16},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4293572},
    doi = {10.1109/agile.2007.16},
    institution = {Univ. of Hawaii, Honolulu},
    isbn = {0-7695-2872-4},
    month = aug,
    pages = {15--25},
    posted-at = {2014-01-18 14:36:31},
    priority = {2},
    publisher = {IEEE},
    title = {Automated Recognition of {Test-Driven} Development with Zorro},
    url = {http://dx.doi.org/10.1109/agile.2007.16},
    year = {2007}
}

@article{citeulike:6180831,
    author = {Kou, Hongbing and Johnson, PhilipM and Erdogmus, Hakan},
    booktitle = {Automated Software Engineering},
    citeulike-article-id = {6180831},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10515-009-0058-8},
    citeulike-linkout-1 = {http://www.springerlink.com/content/4362667326046148},
    citeulike-linkout-2 = {http://link.springer.com/article/10.1007/s10515-009-0058-8},
    doi = {10.1007/s10515-009-0058-8},
    journal = {Automated Software Engineering},
    number = {1},
    pages = {57--85},
    posted-at = {2014-01-18 10:07:38},
    priority = {2},
    publisher = {Springer US},
    title = {Operational definition and automated inference of test-driven development with Zorro},
    url = {http://dx.doi.org/10.1007/s10515-009-0058-8},
    volume = {17},
    year = {2010}
}

@book{citeulike:766768,
    author = {Endres, Albert and Rombach, Dieter},
    citeulike-article-id = {766768},
    day = {12},
    edition = {illustrated edition},
    howpublished = {Hardcover},
    isbn = {0321154207},
    month = may,
    posted-at = {2014-01-16 19:29:04},
    priority = {2},
    publisher = {Addison-Wesley},
    title = {A Handbook of Software and Systems Engineering: Empirical Observations, Laws and Theories},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0321154207},
    year = {2003}
}

@article{citeulike:557296,
    abstract = {Conventional wisdom in the software engineering research community says that 
metrics can make project management more effective. Software metrics range from internal product attributes such as size, complexity, 
and modularity to external process attributes such as effort, productivity, and reliability. Software project telemetry facilitates local, 
in-process decision making.},
    author = {Johnson, P. M. and Kou, Hongbing and Paulding, M. and Zhang, Qin and Kagawa, A. and Yamashita, T.},
    citeulike-article-id = {557296},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ms.2005.95},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1463212},
    doi = {10.1109/ms.2005.95},
    institution = {Collaborative Software Dev. Lab., Hawaii Univ., Honolulu, HI, USA},
    issn = {0740-7459},
    journal = {Software, IEEE},
    month = jul,
    number = {4},
    pages = {76--85},
    posted-at = {2014-01-13 17:36:05},
    priority = {2},
    publisher = {IEEE},
    title = {Improving software development management through software project telemetry},
    url = {http://dx.doi.org/10.1109/ms.2005.95},
    volume = {22},
    year = {2005}
}

@book{citeulike:200721,
    author = {Hunt, Andrew and Thomas, David},
    citeulike-article-id = {200721},
    day = {30},
    edition = {1},
    howpublished = {Paperback},
    isbn = {020161622X},
    month = oct,
    posted-at = {2014-01-07 21:14:37},
    priority = {2},
    publisher = {Addison-Wesley Professional},
    title = {The Pragmatic Programmer: From Journeyman to Master},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/020161622X},
    year = {1999}
}

@misc{osi-history,
  title = {History of the {OSI}.},
  howpublished = {\url{http://opensource.org/history}},
  note = {Accessed: 2013-12-18},
  year={2006}
}

@article{citeulike:12859637,
    abstract = {
                Mid-infrared spectroscopy was used to discriminate between pure beef and beef containing 20\% w/w of a
range of potential adulterants (heart, tripe, kidney, and liver). Spectra were acquired from raw samples and from
samples cooked using two different cooking regimes. Chemometric methods (principal component analysis, partial least
squares regression, and linear discriminant analysis) applied to the spectra showed that discrimination between the pure
and adulterated sample types was possible, irrespective of cooking regime. The cross-validated classification success
rate obtained was approximately 97\%. Discrimination between all five sample types (pure beef and beef containing one of
each of the four adulterants) at each level of cook was also possible, but became more difficult as the cooking level
increased.
            },
    author = {Al-Jowder, Osama and Kemsley, E. K. and Wilson, Reginald H.},
    citeulike-article-id = {12859637},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/11878997},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=11878997},
    day = {13},
    issn = {0021-8561},
    journal = {Journal of agricultural and food chemistry},
    month = mar,
    number = {6},
    pages = {1325--1329},
    pmid = {11878997},
    posted-at = {2013-12-24 11:11:07},
    priority = {2},
    title = {Detection of adulteration in cooked meat products by mid-infrared spectroscopy.},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/11878997},
    volume = {50},
    year = {2002}
}

@misc{postgre-commitfest,
  title = {PostgreSQL. CommitFest Index.},
  howpublished = {\url{https://commitfest.postgresql.org/}},
  note = {Accessed: 2013-12-18}
}

@misc{postgre-contrib,
  title = {PostgreSQL. Contributor Profiles.},
  howpublished = {\url{http://www.postgresql.org/community/contributors/}},
  note = {Accessed: 2013-12-18}
}

@inproceedings{citeulike:12849771,
    abstract = {Abstract. In this paper, we introduce and analyze a new, dynamic generative user model to explain the behavior of file size distributions. Our Recursive Forest File model combines multiplicative models that generate lognormal distributions with recent work on random graph models for the web. Unlike similar previous work, our Recursive Forest File model allows new files to be created and old files to be deleted over time, and our analysis covers problematic issues such as correlation among file sizes. Moreover, our model allows natural variations where files that are copied or modified are more likely to be copied or modified subsequently. Previous empirical work suggests that file sizes tend to have a lognormal body but a Pareto tail. The Recursive Forest File model explains this behavior, yielding a double Pareto distribution, which has a Pareto tail but close to a lognormal body. We believe the Recursive Forest model may be useful for describing other power law phenomena in computer systems 
as well as other fields. 1.},
    author = {Mitzenmacher, Michael},
    booktitle = {Internet Mathematics},
    citeulike-article-id = {12849771},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.123.8811},
    pages = {305--333},
    posted-at = {2013-12-17 11:21:29},
    priority = {2},
    title = {Dynamic models for file sizes and double pareto distributions},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.123.8811},
    year = {2002}
}

@inproceedings{citeulike:330266,
    abstract = {Most studies of software evolution have been performed on systems developed within a single company using traditional management techniques. With the widespread availability of several large software systems that have been developed using an \&ldquo;open source\&rdquo; development approach, we now have a chance to examine these systems in detail, and see if their evolutionary narratives are significantly different from commercially developed systems. The paper summarizes our preliminary investigations into the evolution of the best known open source system: the Linux operating system kernel. Because Linux is large (over two million lines of code in the most recent version) and because its development model is not as tightly planned and managed as most industrial software processes, we had expected to find that Linux was growing more slowly as it got bigger and more complex. Instead, we have found that Linux has been growing at a super-linear rate for several years. The authors explore the 
evolution of the Linux kernel both at the system level and within the major subsystems, and they discuss why they think Linux continues to exhibit such strong growth},
    author = {Godfrey, M. W. and Tu, Qiang},
    booktitle = {Software Maintenance, 2000. Proceedings. International Conference on},
    citeulike-article-id = {330266},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icsm.2000.883030},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=883030},
    doi = {10.1109/icsm.2000.883030},
    institution = {Dept. of Comput. Sci., Waterloo Univ., Ont., Canada},
    isbn = {0-7695-0753-0},
    issn = {1063-6773},
    journal = {Software Maintenance, 2000. Proceedings. International Conference on},
    pages = {131--142},
    posted-at = {2013-12-17 11:13:49},
    priority = {2},
    publisher = {IEEE},
    title = {Evolution in open source software: a case study},
    url = {http://dx.doi.org/10.1109/icsm.2000.883030},
    year = {2000}
}

@inproceedings{citeulike:12849755,
    author = {Herraiz, I. and Gonzalez-Barahona, J. M. and Robles, G.},
    booktitle = {Mining Software Repositories, 2007. ICSE Workshops MSR \&\#039;07. Fourth International Workshop on},
    citeulike-article-id = {12849755},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/msr.2007.31},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228658},
    doi = {10.1109/msr.2007.31},
    institution = {Grupo de Sist. y Comun., Univ. Rey Juan Carlos, Rey Juan Carlos},
    isbn = {0-7695-2950-X},
    month = may,
    pages = {21},
    posted-at = {2013-12-17 11:13:00},
    priority = {2},
    publisher = {IEEE},
    title = {Towards a Theoretical Model for Software Growth},
    url = {http://dx.doi.org/10.1109/msr.2007.31},
    year = {2007}
}

@inproceedings{citeulike:12849753,
    abstract = {An abstract is not available.},
    address = {London, UK, UK},
    author = {Lehman, M. M.},
    booktitle = {Proceedings of the 5th European Workshop on Software Process Technology},
    citeulike-article-id = {12849753},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=681473},
    isbn = {3-540-61771-X},
    pages = {108--124},
    posted-at = {2013-12-17 11:12:15},
    priority = {2},
    publisher = {Springer-Verlag},
    series = {EWSPT '96},
    title = {Laws of Software Evolution Revisited},
    url = {http://portal.acm.org/citation.cfm?id=681473},
    year = {1996}
}

@article{citeulike:328047,
    abstract = {With the approach of the new millennium, a primary focus in software engineering involves issues relating to upgrading, migrating, and evolving existing software systems. In this environment, the role of careful empirical studies as the basis for improving software maintenance processes, methods, and tools is highlighted. One of the most important processes that merits empirical evaluation is software evolution. Software evolution refers to the dynamic behaviour of software systems as they are maintained and enhanced over their lifetimes. Software evolution is particularly important as systems in organizations become longer-lived. However, evolution is challenging to study due to the longitudinal nature of the phenomenon in addition to the usual difficulties in collecting empirical data. We describe a set of methods and techniques that we have developed and adapted to empirically study software evolution. Our longitudinal empirical study involves collecting, coding, and analyzing more than 
25000 change events to 23 commercial software systems over a 20-year period. Using data from two of the systems, we illustrate the efficacy of flexible phase mapping and gamma sequence analytic methods, originally developed in social psychology to examine group problem solving processes. We have adapted these techniques in the context of our study to identify and understand the phases through which a software system travels as it evolves over time. We contrast this approach with time series analysis. Our work demonstrates the advantages of applying methods and techniques from other domains to software engineering and illustrates how, despite difficulties, software evolution can be empirically studied},
    author = {Kemerer, C. F. and Slaughter, S.},
    citeulike-article-id = {328047},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/32.799945},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=799945},
    doi = {10.1109/32.799945},
    institution = {Pittsburgh Univ., PA, USA},
    issn = {0098-5589},
    journal = {Software Engineering, IEEE Transactions on},
    month = jul,
    number = {4},
    pages = {493--509},
    posted-at = {2013-12-17 10:14:17},
    priority = {2},
    publisher = {IEEE},
    title = {An empirical approach to studying software evolution},
    url = {http://dx.doi.org/10.1109/32.799945},
    volume = {25},
    year = {1999}
}

@article{citeulike:12636726,
    author = {Baydogan, M. G. and Runger, G. and Tuv, E.},
    citeulike-article-id = {12636726},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tpami.2013.72},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6497440},
    doi = {10.1109/tpami.2013.72},
    institution = {Security \& Defense Syst. Initiative, Tempe, AZ, USA},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    month = nov,
    number = {11},
    pages = {2796--2802},
    posted-at = {2013-12-13 13:28:38},
    priority = {2},
    publisher = {IEEE},
    title = {A {Bag-of-Features} Framework to Classify Time Series},
    url = {http://dx.doi.org/10.1109/tpami.2013.72},
    volume = {35},
    year = {2013}
}

@misc{ucr,
  author = {Keogh, E., Zhu, Q., Hu, B., Hao, Y.,  Xi, X., Wei, L., Ratanamahatana, C.},
  title = {The UCR Time Series Classification/Clustering Homepage},
  howpublished = {\url{http://www.cs.ucr.edu/~eamonn/time_series_data/}},
  note = {Accessed: 2013-12-01}
}

@misc{so-checkin,
  title = {How often to commit changes to source control?},
  howpublished = {\url{http://stackoverflow.com/questions/107264/how-often-to-commit-changes-to-source-control}},
  note = {Accessed: 2013-12-01}
}


@misc{git-best-practices1,
  title = {Commit Often, Perfect Later, Publish Once: Git Best Practices},
  howpublished = {\url{http://sethrobertson.github.io/GitBestPractices/}},
  note = {Accessed: 2013-12-01}
}

@misc{checkin-dgd-2008,
  title = {Don't Go Dark},
  howpublished = {\url{http://www.codinghorror.com/blog/2008/06/dont-go-dark.html}},
  note = {Accessed: 2013-12-01}
}

@misc{checkin-ch-2012,
  title = {Check In Early, Check In Often},
  howpublished = {\url{http://www.codinghorror.com/blog/2008/08/check-in-early-check-in-often.html}},
  note = {Accessed: 2013-12-01}
}

@misc{coverity2012,
  title = {Coverity {S}can {O}pen {S}ource {R}eport, 2012},
  howpublished = {\url{http://wpcme.coverity.com/wp-content/uploads/2012-Coverity-Scan-Report.pdf}},
  note = {Accessed: 2013-12-01}
}

@misc{chaos2006,
  title = {CHAOS Report 2006},
  howpublished = {\url{https://secure.standishgroup.com/reports/reports.php}},
  note = {Accessed: 2012-09-13}
}

@inproceedings{oss_4industry,
    author = {Gaughan, G. and Fitzgerald, B. and Shaikh, M.},
    booktitle = {Software Engineering and Advanced Applications, 2009. SEAA '09. 35th Euromicro Conference on},
    citeulike-article-id = {12806822},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/seaa.2009.86},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349899},
    doi = {10.1109/seaa.2009.86},
    institution = {Lero The Irish Software Eng. Res. Centre, Ireland},
    isbn = {978-0-7695-3784-9},
    issn = {1089-6503},
    month = aug,
    pages = {20--27},
    posted-at = {2013-11-30 12:53:44},
    priority = {2},
    publisher = {IEEE},
    title = {An Examination of the Use of Open Source Software Processes as a Global Software Development Solution for Commercial Software Engineering},
    url = {http://dx.doi.org/10.1109/seaa.2009.86},
    year = {2009}
}

@incollection{oss_hp,
    author = {Melian, Catharina and M\"{a}hring, Magnus},
    booktitle = {Open Source Development, Communities and Quality},
    citeulike-article-id = {12806820},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-0-387-09684-1\_8},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-0-387-09684-1\_8},
    doi = {10.1007/978-0-387-09684-1\_8},
    editor = {Russo, Barbara and Damiani, Ernesto and Hissam, Scott and Lundell, Bj\"{o}rn and Succi, Giancarlo},
    pages = {93--104},
    posted-at = {2013-11-30 12:52:35},
    priority = {2},
    publisher = {Springer US},
    series = {IFIP – The International Federation for Information Processing},
    title = {Lost and Gained in Translation: Adoption of Open Source Software Development at {Hewlett-Packard}},
    url = {http://dx.doi.org/10.1007/978-0-387-09684-1\_8},
    volume = {275},
    year = {2008}
}

@article{oss_balance,
    author = {Gallivan, Michael J.},
    citeulike-article-id = {12806813},
    citeulike-linkout-0 = {http://dx.doi.org/10.1046/j.1365-2575.2001.00108.x},
    day = {1},
    doi = {10.1046/j.1365-2575.2001.00108.x},
    journal = {Information Systems Journal},
    month = oct,
    number = {4},
    pages = {277--304},
    posted-at = {2013-11-30 12:43:01},
    priority = {2},
    publisher = {Blackwell Science Ltd},
    title = {Striking a balance between trust and control in a virtual organization: a content analysis of open source software case studies},
    url = {http://dx.doi.org/10.1046/j.1365-2575.2001.00108.x},
    volume = {11},
    year = {2001}
}

@article{oss_virtual_organizations,
    author = {Crowston, K. and Scozzi, B.},
    citeulike-article-id = {12806812},
    citeulike-linkout-0 = {http://dx.doi.org/10.1049/ip-sen:20020197},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=999086},
    doi = {10.1049/ip-sen:20020197},
    institution = {Sch. of Inf. Studies, Syracuse Univ., NY, USA},
    issn = {1462-5970},
    journal = {Software, IEE Proceedings -},
    month = feb,
    number = {1},
    pages = {3--17},
    posted-at = {2013-11-30 12:40:38},
    priority = {2},
    publisher = {IET},
    title = {Open source software projects as virtual organisations: competency rallying for software development},
    url = {http://dx.doi.org/10.1049/ip-sen:20020197},
    volume = {149},
    year = {2002}
}

@article{sacchi_2001,
    abstract = {Software systems come and go through a series of passages that account for their inception, initial development, productive operation, upkeep, and retirement from one generation to another. This article categorizes and examines a number of methods for describing or modeling how software systems are developed. It begins with background and definitions of traditional software life-cycle models that dominate most textbook discussions and current software development practices. This is followed by a more comprehensive review of the alternative models of software evolution that are of current use as the basis for organizing software engineering projects and technologies.},
    author = {Scacchi, Walt},
    booktitle = {Encyclopedia of Software Engineering},
    citeulike-article-id = {12806471},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/0471028959.sof250},
    doi = {10.1002/0471028959.sof250},
    posted-at = {2013-11-29 19:43:00},
    priority = {2},
    publisher = {John Wiley \& Sons, Inc.},
    title = {Process Models in Software Engineering},
    url = {http://dx.doi.org/10.1002/0471028959.sof250},
    year = {2002}
}

@article{csdl2-12-11,
    abstract = {For more than 15 years, researchers at the Collaborative Software Development Laboratory ({CSDL}) at the University of Hawaii at Manoa have looked for analytics that help developers understand and improve development processes and products. Through this research, we've come to believe that the  ” searching under the streetlight” metaphor is useful for understanding both our research and that of others in this area.},
    author = {Johnson, Philip M.},
    citeulike-article-id = {12458067},
    citeulike-linkout-0 = {http://csdl.ics.hawaii.edu/techreports/2012/12-11/12-11.pdf},
    journal = {IEEE Software},
    keywords = {hackystat, leap, psp, publications-journals},
    month = jul,
    posted-at = {2013-11-23 09:38:15},
    priority = {2},
    title = {Searching under the streetlight for useful software analytics},
    url = {http://csdl.ics.hawaii.edu/techreports/2012/12-11/12-11.pdf},
    year = {2013}
}

@article{citeulike:12798662,
    address = {New York, NY, USA},
    author = {Rombach, Dieter and M\"{u}nch, J\"{u}rgen and Ocampo, Alexis and Humphrey, Watts S. and Burton, Dan},
    citeulike-article-id = {12798662},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1353060},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.jss.2007.06.004},
    doi = {10.1016/j.jss.2007.06.004},
    issn = {0164-1212},
    journal = {J. Syst. Softw.},
    month = may,
    number = {5},
    pages = {747--763},
    posted-at = {2013-11-23 08:15:33},
    priority = {2},
    publisher = {Elsevier Science Inc.},
    title = {Teaching Disciplined Software Development},
    url = {http://dx.doi.org/10.1016/j.jss.2007.06.004},
    volume = {81},
    year = {2008}
}


@book{citeulike:12798659,
    author = {Humphrey, Watts S.},
    citeulike-article-id = {12798659},
    day = {07},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0201545977},
    month = nov,
    posted-at = {2013-11-23 08:11:18},
    priority = {2},
    publisher = {Addison-Wesley Professional},
    title = {Managing Technical People: Innovation, Teamwork, and the Software Process},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201545977},
    year = {1996}
}

@book{citeulike:12798652,
    author = {Humphrey, Watts S.},
    citeulike-article-id = {12798652},
    day = {10},
    edition = {1},
    howpublished = {Hardcover},
    isbn = {0201546108},
    month = jan,
    posted-at = {2013-11-23 07:53:17},
    priority = {2},
    publisher = {Addison-Wesley Professional},
    title = {A Discipline for Software Engineering},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201546108},
    year = {1995}
}

@book{citeulike:205322,
    author = {McConnell, Steve},
    citeulike-article-id = {205322},
    day = {16},
    edition = {2nd},
    howpublished = {Paperback},
    isbn = {0735619670},
    month = jun,
    posted-at = {2013-11-23 07:47:37},
    priority = {2},
    publisher = {Microsoft Press},
    title = {Code Complete: A Practical Handbook of Software Construction, Second Edition},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0735619670},
    year = {2004}
}

@article{citeulike:3729379,
    abstract = {This personal perspective on the art of programming begins with a look at the state of programming from about 1960, and it follows programming's development through the present day. The article examines key contributions to the field of software engineering and identifies major obstacles, which persist even today.},
    author = {Wirth, N.},
    booktitle = {Annals of the History of Computing, IEEE},
    citeulike-article-id = {3729379},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/mahc.2008.33},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4617912},
    doi = {10.1109/mahc.2008.33},
    institution = {ETH Z\~{A}¼rich},
    issn = {1058-6180},
    journal = {Annals of the History of Computing, IEEE},
    month = jul,
    number = {3},
    pages = {32--39},
    posted-at = {2013-11-20 05:53:30},
    priority = {2},
    publisher = {IEEE},
    title = {A Brief History of Software Engineering},
    url = {http://dx.doi.org/10.1109/mahc.2008.33},
    volume = {30},
    year = {2008}
}

@article{citeulike:12787786,
    abstract = {scene, by recalling the principle technical issues and concerns of the time. These are discussed under the headings Software as a},
    author = {Randell, B.},
    citeulike-article-id = {12787786},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.66.2798},
    posted-at = {2013-11-13 20:21:43},
    priority = {2},
    title = {Commodity, Programming Languages, Multiprogramming and {Time-Sharing}, Modularity and Structuring, and The Problems of Large Systems.},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.66.2798}
}

@article{mahoney_roots_1990,
    author = {Mahoney, Michael S.},
    citeulike-article-id = {12748812},
    journal = {{CWI} Quarterly},
    keywords = {*file-import-13-11-04},
    number = {4},
    pages = {325--334},
    posted-at = {2013-11-04 03:07:15},
    priority = {2},
    title = {The Roots of Software Engineering},
    volume = {3},
    year = {1990}
}

@article{citeulike:833903,
    abstract = {For the last quarter of a century, software technologists have worked to address the \&ldquo;software crisis\&rdquo; identified in the 1960s. Their efforts have focused on a number of different areas, but have often been marked by the search for singular \&ldquo;best\&rdquo; solutions. However, the fundamental nature of software-involving basic and poorly understood problem solving processes combined with unprecedented and multifaceted complexity-weighs heavily against the utility of singular approaches. Examination of the discourse of software technologists in a number of key professional and trade journals over the last 25 years illuminates various disputes central to the development of software engineering and highlights the necessity of a more pluralistic mind set revolving around synthesis and trade-offs},
    address = {Piscataway, NJ, USA},
    author = {Shapiro, Stuart},
    citeulike-article-id = {833903},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=612678},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/85.560729},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=560729},
    doi = {10.1109/85.560729},
    issn = {1058-6180},
    journal = {IEEE Ann. Hist. Comput.},
    month = jan,
    number = {1},
    pages = {20--54},
    posted-at = {2013-11-04 02:56:08},
    priority = {2},
    publisher = {IEEE Educational Activities Department},
    title = {Splitting the Difference: The Historical Necessity of Synthesis in Software Engineering},
    url = {http://dx.doi.org/10.1109/85.560729},
    volume = {19},
    year = {1997}
}

@article{citeulike:12748733,
    author = {Duxbury, Linda},
    citeulike-article-id = {12748733},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/job.4030140209},
    day = {1},
    doi = {10.1002/job.4030140209},
    journal = {J. Organiz. Behav.},
    month = mar,
    number = {2},
    pages = {192--193},
    posted-at = {2013-11-04 02:44:19},
    priority = {2},
    publisher = {John Wiley \& Sons, Ltd.},
    title = {Computer systems development: History, organization, and implementation. No. of pages: 420. Andrew Friedman and Dominic Cornford, Wiley Series in Information Series, New York, {NY}. 1989},
    url = {http://dx.doi.org/10.1002/job.4030140209},
    volume = {14},
    year = {1993}
}

@article{crisis,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Dijkstra, Edsger W.},
    citeulike-article-id = {296323},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=361591},
    citeulike-linkout-1 = {http://dblp.uni-trier.de/rec/bibtex/journals/cacm/Dijkstra72},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/355604.361591},
    doi = {10.1145/355604.361591},
    issn = {0001-0782},
    journal = {Commun. ACM},
    month = oct,
    number = {10},
    pages = {859--866},
    posted-at = {2013-11-03 19:31:14},
    priority = {2},
    publisher = {ACM},
    title = {The humble programmer},
    url = {http://dx.doi.org/10.1145/355604.361591},
    volume = {15},
    year = {1972}
}

@article{citeulike:12747093,
    author = {Fuegi, J. and Francis, J.},
    citeulike-article-id = {12747093},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/mahc.2003.1253887},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1253887},
    doi = {10.1109/mahc.2003.1253887},
    institution = {Maryland Inst. for Technol. in Humanities, MD, USA},
    issn = {1058-6180},
    journal = {Annals of the History of Computing, IEEE},
    month = oct,
    number = {4},
    pages = {16--26},
    posted-at = {2013-11-03 18:07:17},
    priority = {2},
    publisher = {IEEE},
    title = {Lovelace \& Babbage and the creation of the 1843 'notes'},
    url = {http://dx.doi.org/10.1109/mahc.2003.1253887},
    volume = {25},
    year = {2003}
}


@inproceedings{sax,
    abstract = {The problem of efficiently locating previously known patterns in a time series database (i.e., query by content) has received much attention and may now largely be regarded as a solved problem. However, from a knowledge discovery viewpoint, a more interesting problem is the enumeration of previously unknown, frequently occurring patterns. We call such patterns "motifs", because of their close analogy to their discrete counterparts in computation biology. An efficient motif discovery algorithm for time series would be useful as a tool for summarizing and visualizing massive time series databases. In addition it could be used as a subroutine in various other data mining tasks, including the discovery of association rules, clustering and classification. In this paper we carefully motivate, then introduce, a nontrivial definition of time series motifs. We propose an efficient algorithm to discover them, and we demonstrate the utility and efficiency of our approach on several real world datasets.},
    author = {Patel, P. and Keogh, E. and Lin, J. and Lonardi, S.},
    booktitle = {Data Mining, 2002. ICDM 2003. Proceedings. 2002 IEEE International Conference on},
    citeulike-article-id = {3978081},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icdm.2002.1183925},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1183925},
    doi = {10.1109/icdm.2002.1183925},
    institution = {Comput. Sci. \& Eng. Dept., California Univ., Riverside, CA, USA},
    isbn = {0-7695-1754-4},
    journal = {Data Mining, 2002. ICDM 2002. Proceedings. 2002 IEEE International Conference on},
    pages = {370--377},
    posted-at = {2013-11-03 13:31:16},
    priority = {2},
    publisher = {IEEE},
    title = {Mining motifs in massive time series databases},
    url = {http://dx.doi.org/10.1109/icdm.2002.1183925},
    year = {2002}
}

@article{citeulike:2207655,
    abstract = {This paper describes a sound methodology developed at Praxis High Integrity Systems for detecting and exterminating bugs during all stages of a software project. To develop software, the London-based software house uses mathematically based techniques, known as formal methods, which require that programmers begin their work not by writing code but rather by stringing together special symbols that represent the program's logic. Like a mathematical theorem, these symbol strings can be checked to verify that they form logically correct statements. Once the programmer has checked that the program doesn't have logical flaws, it's a relatively simple matter to convert those symbols into programming code. With an average of less than one error in every 10,000 lines of delivered code, Praxis claims a bug rate that is at least 50 times better than the industry standard.},
    author = {Ross, P. E.},
    booktitle = {Spectrum, IEEE},
    citeulike-article-id = {2207655},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/mspec.2005.1502527},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1502527},
    doi = {10.1109/mspec.2005.1502527},
    issn = {0018-9235},
    journal = {Spectrum, IEEE},
    number = {9},
    pages = {36--41},
    posted-at = {2013-11-01 10:25:13},
    priority = {2},
    publisher = {IEEE},
    title = {The exterminators [software bugs]},
    url = {http://dx.doi.org/10.1109/mspec.2005.1502527},
    volume = {42},
    year = {2005}
}

@article{citeulike:2207653,
    abstract = {This paper discusses how the {FBI}'s \$170 million Virtual Case File ({VCF}) {IT} project became one of the most highly publicized software failure in history. According to a report by the {US} Department of Justice's inspector general, {VCF}'s failure may be attributed to several factors including poorly defined and slowly evolving design requirements, overly ambitious schedules, and the lack of a plan to guide hardware purchases, network deployments and software development for the bureau. The paper also includes interviews with people directly involved with the {VCF} to gain a better picture of an enterprise {IT} project that fell into the most basic traps of software development, from poor planning to bad communication.},
    author = {Goldstein, H.},
    booktitle = {Spectrum, IEEE},
    citeulike-article-id = {2207653},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/mspec.2005.1502526},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1502526},
    day = {06},
    doi = {10.1109/mspec.2005.1502526},
    issn = {0018-9235},
    journal = {Spectrum, IEEE},
    month = sep,
    number = {9},
    pages = {24--35},
    posted-at = {2013-11-02 13:35:03},
    priority = {2},
    publisher = {IEEE},
    title = {Who killed the virtual case file? [case management software]},
    url = {http://dx.doi.org/10.1109/mspec.2005.1502526},
    volume = {42},
    year = {2005}
}

@article{citeulike:6580825,
    abstract = {Successful software development and management depends not only on the technologies, methods and processes employed but also on the judgments and decisions of the humans involved. These, in turn, are affected by the basic views and attitudes of the individual engineers. The objective of this paper is to establish if these views and attitudes can be linked to the personalities of software engineers. We summarize the literature on personality and software engineering and then describe an empirical study on 47 professional engineers in ten different Swedish software development companies. The study evaluated the personalities of these engineers via the {IPIP} 50-item five-factor personality test and prompted them on their attitudes towards and basic views on their professional activities. We present extensive statistical analyses of their responses to show that there are multiple, significant associations between personality factors and software engineering attitudes. The tested individuals are 
more homogeneous in personality than a larger sample of individuals from the general population. Taken together, the methodology and personality test we propose and the associated statistical analyses can help find and quantify relations between complex factors in software engineering projects in both research and practice.},
    author = {Feldt, Robert and Angelis, Lefteris and Torkar, Richard and Samuelsson, Maria},
    citeulike-article-id = {6580825},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.infsof.2010.01.001},
    day = {20},
    doi = {10.1016/j.infsof.2010.01.001},
    issn = {09505849},
    journal = {Information and Software Technology},
    month = jun,
    number = {6},
    pages = {611--624},
    posted-at = {2013-11-02 06:28:54},
    priority = {2},
    title = {Links between the personalities, views and attitudes of software engineers},
    url = {http://dx.doi.org/10.1016/j.infsof.2010.01.001},
    volume = {52},
    year = {2010}
}

@inproceedings{citeulike:12743107,
    author = {Demirors, E. and Sarmasik, G. and Demirors, O.},
    booktitle = {EUROMICRO 97. New Frontiers of Information Technology., Proceedings of the 23rd EUROMICRO Conference},
    citeulike-article-id = {12743107},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/eurmic.1997.617239},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=617239},
    doi = {10.1109/eurmic.1997.617239},
    institution = {Dept. of Comput. Eng., Dokuz Eylul Univ., Izmir, Turkey},
    isbn = {0-8186-8129-2},
    issn = {1089-6503},
    pages = {129--133},
    posted-at = {2013-11-01 20:10:15},
    priority = {2},
    publisher = {IEEE},
    title = {The role of teamwork in software development: Microsoft case study},
    url = {http://dx.doi.org/10.1109/eurmic.1997.617239},
    year = {1997}
}

@article{1605185,
    abstract = {People are a critical software development issue, and the human dimension can be even more important than the technical. An important part of human resources management is assigning people to development roles. This process isn't just crucial for generating productive teams; it can also help software organizations develop systematic long-term competence. Despite the importance of identifying the right people for roles, little is known about doing this properly. Integrating managerial experience with a procedure for identifying the person best suited for each role can help improve human resources management and long-term career development. We've defined a human capability-based procedure to supplement managerial activities for supporting personnel development and human resources management. Along with occupational psychologists and software managers, we've applied our procedure in small and medium-sized enterprises ({SMEs}).},
    author = {Acuna, S. T. and Juristo, N. and Moreno, A. M.},
    citeulike-article-id = {12743101},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/MS.2006.47},
    doi = {10.1109/MS.2006.47},
    journal = {Software, IEEE},
    number = {2},
    pages = {94--101},
    posted-at = {2013-11-01 20:04:56},
    priority = {2},
    title = {Emphasizing human capabilities in software development},
    url = {http://dx.doi.org/10.1109/MS.2006.47},
    volume = {23},
    year = {2006}
}

@book{citeulike:149387,
    author = {DeMarco, Tom and Lister, Timothy},
    citeulike-article-id = {149387},
    day = {01},
    edition = {2nd},
    howpublished = {Paperback},
    isbn = {0932633439},
    month = feb,
    posted-at = {2013-11-01 20:03:07},
    priority = {2},
    publisher = {Dorset House Publishing Company, Incorporated},
    title = {Peopleware: Productive Projects and Teams   (Second Edition)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0932633439},
    year = {1999}
}

@article{citeulike:2207657,
    abstract = {Most {IT} experts agree that software failures occur far more often than they should despite the fact that, for the most part, they are predictable and avoidable. It is unfortunate that most organizations don't see preventing failure as an urgent matter, even though that view risks harming the organization and maybe even destroying it. Because software failure has tremendous implications for business and society, it is important to understand why this attitude persists.},
    author = {Charette, R. N.},
    booktitle = {Spectrum, IEEE},
    citeulike-article-id = {2207657},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/mspec.2005.1502528},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1502528},
    day = {06},
    doi = {10.1109/mspec.2005.1502528},
    institution = {ITABHI Corp., VA, USA},
    issn = {0018-9235},
    journal = {Spectrum, IEEE},
    month = sep,
    number = {9},
    pages = {42--49},
    posted-at = {2013-11-01 10:24:21},
    priority = {2},
    publisher = {IEEE},
    title = {Why software fails [software failure]},
    url = {http://dx.doi.org/10.1109/mspec.2005.1502528},
    volume = {42},
    year = {2005}
}

@inproceedings{citeulike:1325189,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Gavrilov, Martin and Anguelov, Dragomir and Indyk, Piotr and Motwani, Rajeev},
    booktitle = {Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining},
    citeulike-article-id = {1325189},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=347090.347189},
    citeulike-linkout-1 = {http://dblp.uni-trier.de/rec/bibtex/conf/kdd/GavrilovAIM00},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/347090.347189},
    doi = {10.1145/347090.347189},
    isbn = {1-58113-233-6},
    location = {Boston, Massachusetts, USA},
    pages = {487--496},
    posted-at = {2013-08-14 15:34:43},
    priority = {2},
    publisher = {ACM},
    series = {KDD '00},
    title = {Mining the stock market (extended abstract): which measure is best?},
    url = {http://dx.doi.org/10.1145/347090.347189},
    year = {2000}
}

@article{citeulike:699487,
    abstract = {
                The newly inaugurated Research Resource for Complex Physiologic Signals, which was created under the
auspices of the National Center for Research Resources of the National Institutes of Health, is intended to stimulate
current research and new investigations in the study of cardiovascular and other complex biomedical signals. The
resource has 3 interdependent components. {PhysioBank} is a large and growing archive of well-characterized digital
recordings of physiological signals and related data for use by the biomedical research community. It currently includes
databases of multiparameter cardiopulmonary, neural, and other biomedical signals from healthy subjects and from
patients with a variety of conditions with major public health implications, including life-threatening arrhythmias,
congestive heart failure, sleep apnea, neurological disorders, and aging. {PhysioToolkit} is a library of open-source
software for physiological signal processing and analysis, the detection of physiologically significant events using
both classic techniques and novel methods based on statistical physics and nonlinear dynamics, the interactive display
and characterization of signals, the creation of new databases, the simulation of physiological and other signals, the
quantitative evaluation and comparison of analysis methods, and the analysis of nonstationary processes. {PhysioNet} is
an on-line forum for the dissemination and exchange of recorded biomedical signals and open-source software for
analyzing them. It provides facilities for the cooperative analysis of data and the evaluation of proposed new
algorithms. In addition to providing free electronic access to {PhysioBank} data and {PhysioToolkit} software via the
World Wide Web (http://www.physionet. org), {PhysioNet} offers services and training via on-line tutorials to assist
users with varying levels of expertise.
            },
    address = {Margret and H.A. Rey Laboratory for Nonlinear Dynamics in Medicine, Beth Israel Deaconess Medical
Center/Harvard Medical School, Boston, MA 02215, USA. ary@astro.bidmc.harvard.edu},
    author = {Goldberger, A. L. and Amaral, L. A. and Glass, L. and Hausdorff, J. M. and Ivanov, P. C. and Mark, R. G.
and Mietus, J. E. and Moody, G. B. and Peng, C. K. and Stanley, H. E.},
    citeulike-article-id = {699487},
    citeulike-linkout-0 = {http://dx.doi.org/10.1161/01.cir.101.23.e215},
    citeulike-linkout-1 = {http://circ.ahajournals.org/content/101/23/e215.abstract},
    citeulike-linkout-2 = {http://circ.ahajournals.org/content/101/23/e215.full.pdf},
    citeulike-linkout-3 = {http://www.circ.ahajournals.org/cgi/content/abstract/101/23/e215},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/10851218},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=10851218},
    day = {13},
    doi = {10.1161/01.cir.101.23.e215},
    issn = {1524-4539},
    journal = {Circulation},
    month = jun,
    number = {23},
    pages = {e215--e220},
    pmid = {10851218},
    posted-at = {2013-08-14 15:31:13},
    priority = {2},
    publisher = {Lippincott Williams \& Wilkins},
    title = {{PhysioBank}, {PhysioToolkit}, and {PhysioNet}: components of a new research resource for complex
physiologic signals.},
    url = {http://dx.doi.org/10.1161/01.cir.101.23.e215},
    volume = {101},
    year = {2000}
}

@article{citeulike:1172599,
    abstract = {Unlabeled document collections are becoming increasingly common and available\&semi; mining such data
sets represents a major contemporary challenge. Using words as features, text documents are often represented as
high-dimensional and sparse vectors–a few thousand dimensions and a sparsity of 95 to 99\% is typical. In this paper, we
study a certain spherical k-means algorithm for clustering such document vectors. The algorithm outputs k disjoint
clusters each with a concept vector that is the centroid of the cluster normalized to have unit Euclidean norm. As our
first contribution, we empirically demonstrate that, owing to the high-dimensionality and sparsity of the text data, the
clusters produced by the algorithm have a certain  ” fractal-like” and  ” self-similar” behavior. As our second
contribution, we introduce concept decompositions to approximate the matrix of document vectors\&semi; these
decompositions are obtained by taking the least-squares approximation onto the linear subspace spanned by all the
concept vectors. We empirically establish that the approximation errors of the concept decompositions are close to the
best possible, namely, to truncated singular value decompositions. As our third contribution, we show that the concept
vectors are localized in the word space, are sparse, and tend towards orthonormality. In contrast, the singular vectors
are global in the word space and are dense. Nonetheless, we observe the surprising fact that the linear subspaces
spanned by the concept vectors and the leading singular vectors are quite close in the sense of small principal angles
between them. In conclusion, the concept vectors produced by the spherical k-means algorithm constitute a powerful
sparse and localized  ” basis” for text data sets.},
    address = {Hingham, MA, USA},
    author = {Dhillon, Inderjit S. and Modha, Dharmendra S.},
    citeulike-article-id = {1172599},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=370660.370699},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/a:1007612920971},
    citeulike-linkout-2 = {http://www.springerlink.com/content/t61745l4031444r5},
    day = {1},
    doi = {10.1023/a:1007612920971},
    issn = {0885-6125},
    journal = {Mach. Learn.},
    month = jan,
    number = {1-2},
    pages = {143--175},
    posted-at = {2013-08-14 15:29:51},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Concept Decompositions for Large Sparse Text Data Using Clustering},
    url = {http://dx.doi.org/10.1023/a:1007612920971},
    volume = {42},
    year = {2001}
}

@article{citeulike:505248,
    abstract = {This paper evaluates the performance of different criterion functions in the context of partitional
clustering algorithms for document datasets. Our study involves a total of seven different criterion functions, three of
which are introduced in this paper and four that have been proposed in the past. We present a comprehensive experimental
evaluation involving 15 different datasets, as well as an analysis of the characteristics of the various criterion
functions and their effect on the clusters they produce. Our experimental results show that there are a set of criterion
functions that consistently outperform the rest, and that some of the newly proposed criterion functions lead to the
best overall results. Our theoretical analysis shows that the relative performance of the criterion functions depends on
(i) the degree to which they can correctly operate when the clusters are of different tightness, and (ii) the degree to
which they can lead to reasonably balanced clusters.},
    address = {Hingham, MA, USA},
    author = {Zhao, Ying and Karypis, George},
    citeulike-article-id = {505248},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=990398},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/b:mach.0000027785.44527.d6},
    citeulike-linkout-2 = {http://www.springerlink.com/content/h1173023372tx718},
    day = {1},
    doi = {10.1023/b:mach.0000027785.44527.d6},
    issn = {0885-6125},
    journal = {Mach. Learn.},
    month = jun,
    number = {3},
    pages = {311--331},
    posted-at = {2013-08-14 15:28:55},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Empirical and Theoretical Comparisons of Selected Criterion Functions for Document Clustering},
    url = {http://dx.doi.org/10.1023/b:mach.0000027785.44527.d6},
    volume = {55},
    year = {2004}
}

@article{citeulike:4195343,
    abstract = {Practical clustering algorithms require multiple data scans to achieve convergence. For large databases,
these scans become prohibitively expensive. We present a scalable clustering framework applicable to a wide class of
iterative clustering. We require at most one scan of the database. In this work, the framework is instantiated and
numerically justified with the popular {K-Means} clustering algorithm. The method is based on identifying regions of the
data that are compressible, regions that must be maintained in memory, and regions that are discardable. The algorithm
operates within the confines of a limited memory buffer. Empirical results demonstrate that the scalable scheme
outperforms a sampling-based approach. In our scheme, data resolution is preserved to the extent possible based upon the
size of the allocated memory buffer and the fit of current clustering model to the data. The framework is naturally
extended to update multiple clustering models simultaneously. We empirically...},
    author = {Bradley, P. S. and Fayyad, Usama and Reina, Cory},
    citeulike-article-id = {4195343},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.28.1963},
    pages = {9--15},
    posted-at = {2013-08-14 15:27:59},
    priority = {2},
    title = {Scaling Clustering Algorithms to Large Databases},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.28.1963},
    year = {1998}
}

@inproceedings{kmeans,
    author = {MacQueen, J. B.},
    booktitle = {Proc. of the fifth Berkeley Symposium on Mathematical Statistics and Probability},
    citeulike-article-id = {12563823},
    editor = {Cam, Le M. L. and Neyman, J.},
    keywords = {kmeans, *file-import-13-08-14},
    pages = {281--297},
    posted-at = {2013-08-14 15:27:09},
    priority = {2},
    publisher = {University of California Press},
    title = {Some Methods for Classification and Analysis of {MultiVariate} Observations},
    volume = {1},
    year = {1967}
}

@article{citeulike:1576606,
    abstract = {Techniques for partitioning objects into optimally homogeneous groups on the basis of empirical measures
of similarity among those objects have received increasing attention in several different fields. This paper develops a
useful correspondence between any hierarchical system of such clusters, and a particular type of distance measure. The
correspondence gives rise to two methods of clustering that are computationally rapid and invariant under monotonic
transformations of the data. In an explicitly defined sense, one method forms clusters that are optimally  ” connected,”
while the other forms clusters that are optimally  ” compact.”},
    author = {Johnson, Stephen C.},
    booktitle = {Psychometrika},
    citeulike-article-id = {1576606},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/bf02289588},
    citeulike-linkout-1 = {http://www.springerlink.com/content/q715667m18256728},
    citeulike-linkout-2 = {http://link.springer.com/article/10.1007/BF02289588},
    day = {27},
    doi = {10.1007/bf02289588},
    issn = {0033-3123},
    journal = {Psychometrika},
    month = sep,
    number = {3},
    pages = {241--254},
    posted-at = {2013-08-14 15:26:03},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Hierarchical clustering schemes},
    url = {http://dx.doi.org/10.1007/bf02289588},
    volume = {32},
    year = {1967}
}

@book{citeulike:12134192,
    author = {Dirr, Michael A.},
    citeulike-article-id = {12134192},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1588748685},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/1588748685},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/1588748685},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/1588748685},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/1588748685/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1588748685},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/1588748685},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN1588748685},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=1588748685\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/1588748685},
    edition = {6 Revised},
    howpublished = {Paperback},
    isbn = {1588748685},
    keywords = {thesis-phd},
    posted-at = {2013-03-11 05:20:43},
    priority = {2},
    publisher = {Stipes Pub Llc},
    title = {Manual of Woody Landscape Plants: Their Identification, Ornamental Characteristics, Culture, Propogation
and Uses},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1588748685}
}

@mastersthesis{citeulike:12563798,
    author = {Gandhi, A.},
    citeulike-article-id = {12563798},
    institution = {Oregon State University},
    posted-at = {2013-08-14 15:22:50},
    priority = {2},
    title = {{Content-Based} Image Retrieval: Plant Species Identification.},
    year = {2002}
}

@inproceedings{Ratanamahatana04makingtime-series,
    author = {Chotirat Ann Ratanamahatana and Eamonn Keogh},
    title = {Making Time-series Classification More Accurate Using Learned Constraints},
    booktitle = {In proc. of SDM Int’l Conf},
    year = {2004},
    pages = {11--22}
}

@phdthesis{citeulike:12563781,
    author = {Saito, N.},
    citeulike-article-id = {12563781},
    institution = {Yale University},
    posted-at = {2013-08-14 15:19:46},
    priority = {2},
    title = {Local feature extraction and its application using a library of bases.},
    year = {1994}
}

@article{citeulike:404286,
    abstract = {A framework is developed to explore the connection between effective optimization algorithms and the
problems they are solving. A number of  ” no free lunch” ({NFL}) theorems are presented which establish that for any
algorithm, any elevated performance over one class of problems is offset by performance over another class. These
theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization
problem. Applications of the {NFL} theorems to information-theoretic aspects of optimization and benchmark measures of
performance are also presented. Other issues addressed include time-varying optimization problems and a priori  ”
head-to-head” minimax distinctions between optimization algorithms, distinctions that result despite the {NFL} theorems'
enforcing of a type of uniformity over all algorithms},
    author = {Wolpert, D. H. and Macready, W. G.},
    citeulike-article-id = {404286},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/4235.585893},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=585893},
    day = {06},
    doi = {10.1109/4235.585893},
    institution = {IBM Almaden Res. Center, San Jose, CA, USA},
    issn = {1089-778X},
    journal = {Evolutionary Computation, IEEE Transactions on},
    month = apr,
    number = {1},
    pages = {67--82},
    posted-at = {2013-08-14 15:17:49},
    priority = {2},
    publisher = {IEEE},
    title = {No free lunch theorems for optimization},
    url = {http://dx.doi.org/10.1109/4235.585893},
    volume = {1},
    year = {1997}
}

@misc{citeulike:12563754,
  title = {{WCCI}, Ford classification challenge dataset},
  howpublished = {\url{http://home.comcast.net/\~{}nn\_classification/}},
  note = {Accessed: 2013-12-01}
}

@misc{citeulike:12563599,
    author = {Keogh, E. and Zhu, Q. and Hu, B. and Hao, Y. and Xi, X. and Wei, L. and Ratanamahatana, C.},
    citeulike-article-id = {12563599},
    howpublished = {http://www.cs.ucr.edu/\~{}eamonn/time\_series\_data/},
    posted-at = {2013-08-14 15:06:17},
    priority = {2},
    title = {The {UCR} Time Series {Classification/Clustering} Homepage}
}

@article{citeulike:4210208,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Jones, D. R. and Perttunen, C. D. and Stuckman, B. E.},
    citeulike-article-id = {4210208},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=173678},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/bf00941892},
    citeulike-linkout-2 = {http://www.springerlink.com/content/kn467t1876721411},
    day = {1},
    doi = {10.1007/bf00941892},
    issn = {0022-3239},
    journal = {J. Optim. Theory Appl.},
    month = oct,
    number = {1},
    pages = {157--181},
    posted-at = {2013-08-14 15:02:02},
    priority = {2},
    publisher = {Plenum Press},
    title = {Lipschitzian optimization without the Lipschitz constant},
    url = {http://dx.doi.org/10.1007/bf00941892},
    volume = {79},
    year = {1993}
}

@misc{jmotif,
    author = {Senin, Pavel},
    citeulike-article-id = {12563560},
    howpublished = {https://code.google.com/p/jmotif/},
    posted-at = {2013-08-14 14:59:21},
    priority = {2},
    title = {{JMotif} project homepage. Reference implementation of {SAX}-{VSM} algorithm.}
}

@article{hamming,
  added-at = {2006-04-05T23:23:26.000+0200},
  author = {Hamming, {R. W.}},
  biburl = {http://www.bibsonomy.org/bibtex/29809707ce47a2c377387500eec90180a/gromgull},
  description = {My Main bibliography file},
  interhash = {6d7d6d0a103f9158ec1a696e27aa6e36},
  intrahash = {9809707ce47a2c377387500eec90180a},
  journal = {Bell System Techincal Journal},
  keywords = {distance-measure},
  pages = {147-160},
  timestamp = {2006-04-05T23:23:26.000+0200},
  title = {Error Detecting and Error Correcting Codes},
  volume = 29,
  year = 1950
}

@book{citeulike:4469058,
    abstract = {Class-tested and coherent, this groundbreaking new textbook teaches web-era information retrieval,
including web search and the related areas of text classification and text clustering from basic concepts. Written from
a computer science perspective by three leading experts in the field, it gives an up-to-date treatment of all aspects of
the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating
systems; and an introduction to the use of machine learning methods on text collections. All the important ideas are
explained using examples and figures, making it perfect for introductory courses in information retrieval for advanced
undergraduates and graduate students in computer science. Based on feedback from extensive classroom experience, the
book has been carefully structured in order to make teaching more natural and effective. Although originally designed as
the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also create a
buzz for researchers and professionals alike.},
    address = {New York, NY, USA},
    author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch\"{u}tze, Hinrich},
    citeulike-article-id = {4469058},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1394399},
    isbn = {0521865719, 9780521865715},
    posted-at = {2013-08-14 14:50:32},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {Introduction to Information Retrieval},
    url = {http://portal.acm.org/citation.cfm?id=1394399},
    year = {2008}
}

@book{citeulike:10141990,
    author = {Larsen, Richard J. and Marx, Morris L.},
    citeulike-article-id = {10141990},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0321693949},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0321693949},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0321693949},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0321693949},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0321693949/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0321693949},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0321693949},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0321693949},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0321693949\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0321693949},
    day = {06},
    edition = {5},
    howpublished = {Hardcover},
    isbn = {0321693949},
    month = jan,
    posted-at = {2013-08-14 14:48:23},
    priority = {2},
    publisher = {Pearson},
    title = {Introduction to Mathematical Statistics and Its Applications (5th Edition)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0321693949},
    year = {2011}
}

@inproceedings{citeulike:12563493, 
    author = {Rakthanamanon, T. and Keogh, E.},
    booktitle = {Proceedings of the SIAM Intl. Conf. on Data Mining},
    citeulike-article-id = {12563493},
    posted-at = {2013-08-14 14:45:29},
    priority = {2},
    title = {{Fast-Shapelets}: A Scalable Algorithm for Discovering Time Series Shapelets},
    year = {2013}
}

@inproceedings{citeulike:3175749,
    abstract = {In this work, we introduce the new problem of finding time series discords. Time series discords are
subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They
thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for
data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection. As we
will show, discords are particularly attractive as anomaly detectors because they only require one intuitive parameter
(the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. We
evaluate our work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with
objective experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry,
and we demonstrate the effectiveness of our discord discovery algorithm with more than one million experiments, on 82
different datasets from diverse domains.},
    address = {Washington, DC, USA},
    author = {Keogh, Eamonn and Lin, Jessica and Fu, Ada},
    booktitle = {Proceedings of the Fifth IEEE International Conference on Data Mining},
    citeulike-article-id = {3175749},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1106352},
    citeulike-linkout-1 = {http://dblp.uni-trier.de/rec/bibtex/conf/icdm/KeoghLF05},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/icdm.2005.79},
    doi = {10.1109/icdm.2005.79},
    isbn = {0-7695-2278-5},
    pages = {226--233},
    posted-at = {2013-08-14 14:40:55},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {ICDM '05},
    title = {{HOT} {SAX}: Efficiently Finding the Most Unusual Time Series Subsequence},
    url = {http://dx.doi.org/10.1109/icdm.2005.79},
    year = {2005}
}

@inproceedings{citeulike:12563460,
    abstract = {In this paper we will discuss the efficiency and implementation details of an algorithm for finding the
global minimum of a multivariate function subject to simple bounds on the variables. The algorithm, {DIRECT}, developed
by D. R. Jones, C. D. Perttunen and B. E. Stuckman is a modification of the standard Lipschitzian approach that
eliminates the need to specify a Lipschitz constant. We have implemented the {DIRECT} algorithm in Matlab and the
efficiency of our implementation is analyzed by comparing it to the result of Jones's implementation on nine standard
test problems for global optimization. In fifteen out of eighteen runs the results is to the favor of our
implementation. For some test problems the differences in the number of function evaluations needed for the algorithm to
converge are small but for others the differences are great enough to be worth a discussion. Our code is integrated in
the {NLPLIB} {TB} Toolbox as part of the optimization environment {TOMLAB}. All tests are perfor...},
    author = {Bj\"{o}rkman, M. and Holmstr\"{o}m, K.},
    booktitle = {in Matlab. Advanced Modeling and Optimization 1(2),17},
    citeulike-article-id = {12563460},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.2.4152},
    posted-at = {2013-08-14 14:39:14},
    priority = {2},
    title = {Global Optimization Using the {DIRECT} Algorithm in Matlab},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.2.4152},
    year = {1999}
}

@techreport{citeulike:300428,
    abstract = {In a document retieval, or other pattern matching environment where stored entities (documents) are
compared with each other, or with incoming patterns (search requests), it appears that the best indexing (property)
space is one where each entity lies as far away from the others as possible; that is, retrieval performance correlates
inversely with space density. This result is used to choose an optimum indexing vocabulary for a collection of
documents. Typical evaluation results are shown demonstrating the usefulness of the model.},
    address = {Ithaca, NY, USA},
    author = {Salton, Gerard and Wong, A. and Yang, C. S.},
    citeulike-article-id = {300428},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=867322},
    posted-at = {2013-08-14 14:37:47},
    priority = {2},
    publisher = {Cornell University},
    title = {A Vector Space Model for Automatic Indexing},
    url = {http://portal.acm.org/citation.cfm?id=867322},
    year = {1974}
}

@article{citeulike:12563424,
    abstract = {An important component of many data mining projects is finding a good classification algorithm, a
process that requires very careful thought about experimental design. If not done very carefully, comparative studies of
classification and other types of algorithms can easily result in statistically invalid conclusions. This is especially
true when one is using data mining techniques to analyze very large databases, which inevitably contain some
statistically unlikely data. This paper describes several phenomena that can, if ignored, invalidate an experimental
comparison. These phenomena and the conclusions that follow apply not only to classification, but to computational
experiments in almost any aspect of data mining. The paper also discusses why comparative analysis is more important in
evaluating some types of algorithms than for others, and provides some suggestions about how to avoid the pitfalls
suffered by many experimental studies.},
    author = {Salzberg, StevenL},
    booktitle = {Data Mining and Knowledge Discovery},
    citeulike-article-id = {12563424},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a\%253a1009752403260},
    citeulike-linkout-1 = {http://link.springer.com/article/10.1023/A\%3A1009752403260},
    doi = {10.1023/a\%253a1009752403260},
    number = {3},
    pages = {317--328},
    posted-at = {2013-08-14 14:33:12},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {On Comparing Classifiers: Pitfalls to Avoid and a Recommended Approach},
    url = {http://dx.doi.org/10.1023/a\%253a1009752403260},
    volume = {1},
    year = {1997}
}

@inproceedings{citeulike:11345338,
    abstract = {The problem of time series classification ({TSC}), where we consider any real-valued ordered data a time
series, presents a specific machine learning challenge as the ordering of variables is often crucial in finding the best
discriminating features. One of the most promising recent approaches is to find shapelets within a data set. A shapelet
is a time series subsequence that is identified as being representative of class membership. The original research in
this field embedded the procedure of finding shapelets within a decision tree. We propose disconnecting the process of
finding shapelets from the classification algorithm by proposing a shapelet transformation. We describe a means of
extracting the k best shapelets from a data set in a single pass, and then use these shapelets to transform data by
calculating the distances from a series to each shapelet. We demonstrate that transformation into this new data space
can improve classification accuracy, whilst retaining the explanatory power provided by shapelets.},
    address = {New York, NY, USA},
    author = {Lines, Jason and Davis, Luke M. and Hills, Jon and Bagnall, Anthony},
    booktitle = {Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining},
    citeulike-article-id = {11345338},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2339530.2339579},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2339530.2339579},
    doi = {10.1145/2339530.2339579},
    isbn = {978-1-4503-1462-6},
    location = {Beijing, China},
    pages = {289--297},
    posted-at = {2013-08-12 14:29:41},
    priority = {2},
    publisher = {ACM},
    series = {KDD '12},
    title = {A shapelet transform for time series classification},
    url = {http://dx.doi.org/10.1145/2339530.2339579},
    year = {2012}
}

@inproceedings{citeulike:12563380,
    abstract = {The problem of indexing time series has attracted much research interest in the database community. Most
algorithms used to index time series utilize the Euclidean distance or some variation thereof. However is has been
forcefully shown that the Euclidean distance is a very brittle distance measure. Dynamic Time Warping ({DTW}) is a much
more robust distance measure for time series, allowing similar shapes to match even if they are out of phase in the time
axis. Because of this flexibility, {DTW} is widely used in science, medicine, industry and finance. Unfortunately
however, {DTW} does not obey the triangular inequality, and thus has resisted attempts at exact indexing. Instead, many
researchers have introduced approximate indexing techniques, or abandoned the idea of indexing and concentrated on
speeding up sequential search. In this work we introduce a novel technique for the exact indexing of {DTW}. We prove
that our method guarantees no false dismissals and we demonstrate its vast superiority over all competing approaches in
the largest and most comprehensive set of time series indexing experiments ever undertaken.},
    author = {Keogh, Eamonn},
    booktitle = {Proceedings of the 28th international conference on Very Large Data Bases},
    citeulike-article-id = {12563380},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1287369.1287405},
    location = {Hong Kong, China},
    pages = {406--417},
    posted-at = {2013-08-14 14:24:33},
    priority = {2},
    publisher = {VLDB Endowment},
    series = {VLDB '02},
    title = {Exact indexing of dynamic time warping},
    url = {http://portal.acm.org/citation.cfm?id=1287369.1287405},
    year = {2002}
}

@article{citeulike:10525778,
    abstract = {For more than a decade, time series similarity search has been given a great deal of attention by data
mining researchers. As a result, many time series representations and distance measures have been proposed. However,
most existing work on time series similarity search relies on shape-based similarity matching. While some of the
existing approaches work well for short time series data, they typically fail to produce satisfactory results when the
sequence is long. For long sequences, it is more appropriate to consider the similarity based on the higher-level
structures. In this work, we present a histogram-based representation for time series data, similar to the "bag of
words" approach that is widely accepted by the text mining and information retrieval communities. We performed extensive
experiments and show that our approach outperforms the leading existing methods in clustering, classification, and
anomaly detection on dozens of real datasets. We further demonstrate that the representation allows rotation-invariant
matching in shape datasets.},
    address = {Hingham, MA, USA},
    author = {Lin, Jessica and Khade, Rohan and Li, Yuan},
    citeulike-article-id = {10525778},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2387443.2387446},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s10844-012-0196-5},
    citeulike-linkout-2 = {http://www.springerlink.com/content/qq824641766728t9},
    day = {1},
    doi = {10.1007/s10844-012-0196-5},
    issn = {0925-9902},
    journal = {J. Intell. Inf. Syst.},
    month = oct,
    number = {2},
    pages = {287--315},
    posted-at = {2013-08-14 14:23:03},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Rotation-invariant similarity in time series using bag-of-patterns representation},
    url = {http://dx.doi.org/10.1007/s10844-012-0196-5},
    volume = {39},
    year = {2012}
}

@inproceedings{citeulike:5094223,
    abstract = {An abstract is not available.},
    address = {London, UK, UK},
    author = {Agrawal, Rakesh and Faloutsos, Christos and Swami, Arun N.},
    booktitle = {Proceedings of the 4th International Conference on Foundations of Data Organization and Algorithms},
    citeulike-article-id = {5094223},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=645415.652239},
    isbn = {3-540-57301-1},
    pages = {69--84},
    posted-at = {2013-08-14 14:22:06},
    priority = {2},
    publisher = {Springer-Verlag},
    series = {FODO '93},
    title = {Efficient Similarity Search In Sequence Databases},
    url = {http://portal.acm.org/citation.cfm?id=645415.652239},
    year = {1993}
}

@article{citeulike:12563361,
    abstract = {Existing distance measures of time series such as the euclidean distance, {DTW}, and {EDR} are
inadequate in handling certain degrees of amplitude shifting and scaling variances of data items. We propose a novel
distance measure of time series, Spatial Assembling Distance ({SpADe}), that is able to handle noisy, shifting, and
scaling in both temporal and amplitude dimensions. We further apply the {SpADe} to the application of streaming pattern
detection, which is very useful in trend-related analysis, sensor networks, and video surveillance. Our experimental
results on real time series data sets show that {SpADe} is an effective distance measure of time series. Moreover, high
accuracy and efficiency are achieved by {SpADe} for continuous pattern detection in streaming time series.},
    address = {Piscataway, NJ, USA},
    author = {Chen, Yueguo and Chen, Ke and Nascimento, Mario A.},
    citeulike-article-id = {12563361},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2122270.2122560},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/tkde.2010.223},
    doi = {10.1109/tkde.2010.223},
    issn = {1041-4347},
    journal = {IEEE Trans. on Knowl. and Data Eng.},
    month = feb,
    number = {2},
    pages = {265--278},
    posted-at = {2013-08-14 14:20:41},
    priority = {2},
    publisher = {IEEE Educational Activities Department},
    title = {Effective and Efficient {Shape-Based} Pattern Detection over Streaming Time Series},
    url = {http://dx.doi.org/10.1109/tkde.2010.223},
    volume = {24},
    year = {2012}
}

@inproceedings{citeulike:4214336,
    abstract = {Many algorithms have been proposed for the problem of time series classification. However, it is clear
that one-nearest-neighbor with Dynamic Time Warping ({DTW}) distance is exceptionally difficult to beat. This approach
has one weakness, however; it is computationally too demanding for many realtime applications. One way to mitigate this
problem is to speed up the {DTW} calculations. Nonetheless, there is a limit to how much this can help. In this work, we
propose an additional technique, numerosity reduction, to speed up one-nearest-neighbor {DTW}. While the idea of
numerosity reduction for nearest-neighbor classifiers has a long history, we show here that we can leverage off an
original observation about the relationship between dataset size and {DTW} constraints to produce an extremely compact
dataset with little or no loss in accuracy. We test our ideas with a comprehensive set of experiments, and show that it
can efficiently produce extremely fast accurate classifiers.},
    address = {New York, NY, USA},
    author = {Xi, Xiaopeng and Keogh, Eamonn and Shelton, Christian and Wei, Li and Ratanamahatana, Chotirat A.},
    booktitle = {Proceedings of the 23rd international conference on Machine learning},
    citeulike-article-id = {4214336},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1143844.1143974},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1143844.1143974},
    doi = {10.1145/1143844.1143974},
    isbn = {1-59593-383-2},
    location = {Pittsburgh, Pennsylvania},
    pages = {1033--1040},
    posted-at = {2013-08-14 14:18:57},
    priority = {2},
    publisher = {ACM},
    series = {ICML '06},
    title = {Fast time series classification using numerosity reduction},
    url = {http://dx.doi.org/10.1145/1143844.1143974},
    year = {2006}
}

@article{citeulike:532340,
    abstract = {In the last decade there has been an explosion of interest in mining time series data. Literally
hundreds of papers have introduced new algorithms to index, classify, cluster and segment time series. In this work we
make the following claim. Much of this work has very little utility because the contribution made (speed in the case of
indexing, accuracy in the case of classification and clustering, model accuracy in the case of segmentation) offer an
amount of  ” improvement” that would have been completely dwarfed by the variance that would have been observed by
testing on many real world datasets, or the variance that would have been observed by changing minor (unstated)
implementation {details.To} illustrate our point, we have undertaken the most exhaustive set of time series experiments
ever attempted, re-implementing the contribution of more than two dozen papers, and testing them on 50 real world,
highly diverse datasets. Our empirical results strongly support our assertion, and suggest the need for a set of time
series benchmarks and more careful empirical evaluation in the data mining community.},
    address = {Hingham, MA, USA},
    author = {Keogh, Eamonn and Kasetty, Shruti},
    booktitle = {Data Mining and Knowledge Discovery},
    citeulike-article-id = {532340},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=861112},
    citeulike-linkout-1 = {http://dblp.uni-trier.de/rec/bibtex/journals/datamine/KeoghK03},
    citeulike-linkout-2 = {http://dx.doi.org/10.1023/a:1024988512476},
    citeulike-linkout-3 = {http://www.springerlink.com/content/g7535342u0781722},
    citeulike-linkout-4 = {http://link.springer.com/article/10.1023/A:1024988512476},
    day = {1},
    doi = {10.1023/a:1024988512476},
    issn = {1384-5810},
    journal = {Data Min. Knowl. Discov.},
    month = oct,
    number = {4},
    pages = {349--371},
    posted-at = {2013-08-14 13:59:56},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {On the Need for Time Series Data Mining Benchmarks: A Survey and Empirical Demonstration},
    url = {http://dx.doi.org/10.1023/a:1024988512476},
    volume = {7},
    year = {2003}
}

@article{citeulike:10249370,
    abstract = {Sequence classification has a broad range of applications such as genomic analysis, information
retrieval, health informatics, finance, and abnormal detection. Different from the classification task on feature
vectors, sequences do not have explicit features. Even with sophisticated feature selection techniques, the
dimensionality of potential features may still be very high and the sequential nature of features is difficult to
capture. This makes sequence classification a more challenging task than classification on feature vectors. In this
paper, we present a brief review of the existing work on sequence classification. We summarize the sequence
classification in terms of methodologies and application domains. We also provide a review on several extensions of the
sequence classification problem, such as early classification on sequences and semi-supervised learning on sequences.},
    address = {New York, NY, USA},
    author = {Xing, Zhengzheng and Pei, Jian and Keogh, Eamonn},
    citeulike-article-id = {10249370},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1882478},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1882471.1882478},
    doi = {10.1145/1882471.1882478},
    issn = {1931-0145},
    journal = {SIGKDD Explor. Newsl.},
    month = nov,
    number = {1},
    pages = {40--48},
    posted-at = {2013-08-14 13:58:48},
    priority = {2},
    publisher = {ACM},
    title = {A brief survey on sequence classification},
    url = {http://dx.doi.org/10.1145/1882471.1882478},
    volume = {12},
    year = {2010}
}

@article{citeulike:10358271,
    abstract = {The previous decade has brought a remarkable increase of the interest in applications that deal with
querying and mining of time series data. Many of the research efforts in this context have focused on introducing new
representation methods for dimensionality reduction or novel similarity measures for the underlying data. In the vast
majority of cases, each individual work introducing a particular method has made specific claims and, aside from the
occasional theoretical justifications, provided quantitative experimental observations. However, for the most part, the
comparative aspects of these experiments were too narrowly focused on demonstrating the benefits of the proposed methods
over some of the previously introduced ones. In order to provide a comprehensive validation, we conducted an extensive
experimental study re-implementing eight different time series representations and nine similarity measures and their
variants, and testing their effectiveness on 38 time series data sets from a wide variety of application domains. In
this article, we give an overview of these different techniques and present our comparative experimental findings
regarding their effectiveness. In addition to providing a unified validation of some of the existing achievements, our
experiments also indicate that, in some cases, certain claims in the literature may be unduly optimistic.},
    author = {Wang, Xiaoyue and Mueen, Abdullah and Ding, Hui and Trajcevski, Goce and Scheuermann, Peter and Keogh,
Eamonn},
    booktitle = {Data Mining and Knowledge Discovery},
    citeulike-article-id = {10358271},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10618-012-0250-5},
    citeulike-linkout-1 = {http://www.springerlink.com/content/vv13924951r3q214},
    citeulike-linkout-2 = {http://link.springer.com/article/10.1007/s10618-012-0250-5},
    day = {10},
    doi = {10.1007/s10618-012-0250-5},
    issn = {1384-5810},
    journal = {Data Mining and Knowledge Discovery},
    month = feb,
    number = {2},
    pages = {275--309},
    posted-at = {2013-08-14 13:57:28},
    priority = {2},
    publisher = {Springer US},
    title = {Experimental comparison of representation methods and distance measures for time series data},
    url = {http://dx.doi.org/10.1007/s10618-012-0250-5},
    volume = {26},
    year = {2013}
}

@inproceedings{citeulike:3977965,
    abstract = {Several important time series data mining problems reduce to the core task of finding approximately
repeated subsequences in a longer time series. In an earlier work, we formalized the idea of approximately repeated
subsequences by introducing the notion of time series motifs. Two limitations of this work were the poor scalability of
the motif discovery algorithm, and the inability to discover motifs in the presence of {noise.Here} we address these
limitations by introducing a novel algorithm inspired by recent advances in the problem of pattern discovery in
biosequences. Our algorithm is probabilistic in nature, but as we show empirically and theoretically, it can find time
series motifs with very high probability even in the presence of noise or "don't care" symbols. Not only is the
algorithm fast, but it is an anytime algorithm, producing likely candidate motifs almost immediately, and gradually
improving the quality of results over time.},
    address = {New York, NY, USA},
    author = {Chiu, Bill and Keogh, Eamonn and Lonardi, Stefano},
    booktitle = {Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining},
    citeulike-article-id = {3977965},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=956808},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/956750.956808},
    doi = {10.1145/956750.956808},
    isbn = {1-58113-737-0},
    location = {Washington, D.C.},
    pages = {493--498},
    posted-at = {2013-08-12 13:54:45},
    priority = {2},
    publisher = {ACM},
    series = {KDD '03},
    title = {Probabilistic discovery of time series motifs},
    url = {http://dx.doi.org/10.1145/956750.956808},
    year = {2003}
}

@inproceedings{citeulike:12552293,
    abstract = {Time series clustering has become an increasingly important research topic over the past decade. Most
existing methods for time series clustering rely on distances calculated from the entire raw data using the Euclidean
distance or Dynamic Time Warping distance as the distance measure. However, the presence of significant noise, dropouts,
or extraneous data can greatly limit the accuracy of clustering in this domain. Moreover, for most real world problems,
we cannot expect objects from the same class to be equal in length. As a consequence, most work on time series
clustering only considers the clustering of individual time series "behaviors," e.g., individual heart beats or
individual gait cycles, and contrives the time series in some way to make them all equal in length. However, contriving
the data in such a way is often a harder problem than the clustering itself. In this work, we show that by using only
some local patterns and deliberately ignoring the rest of the data, we can mitigate the above problems and cluster time
series of different lengths, i.e., cluster one heartbeat with multiple heartbeats. To achieve this we exploit and extend
a recently introduced concept in time series data mining called shapelets. Unlike existing work, our work demonstrates
for the first time the unintuitive fact that shapelets can be learned from unlabeled time series. We show, with
extensive empirical evaluation in diverse domains, that our method is more accurate than existing methods. Moreover, in
addition to accurate clustering results, we show that our work also has the potential to give insights into the domains
to which it is applied.},
    address = {Washington, DC, USA},
    author = {Zakaria, Jesin and Mueen, Abdullah and Keogh, Eamonn},
    booktitle = {Proceedings of the 2012 IEEE 12th International Conference on Data Mining},
    citeulike-article-id = {12552293},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2471881.2472632},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icdm.2012.26},
    doi = {10.1109/icdm.2012.26},
    isbn = {978-0-7695-4905-7},
    pages = {785--794},
    posted-at = {2013-08-12 14:18:57},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {ICDM '12},
    title = {Clustering Time Series Using {Unsupervised-Shapelets}},
    url = {http://dx.doi.org/10.1109/icdm.2012.26},
    year = {2012}
}

@article{citeulike:7344347,
    abstract = {Classification of time series has been attracting great interest over the past decade. While dozens of
techniques have been introduced, recent empirical evidence has strongly suggested that the simple nearest neighbor
algorithm is very difficult to beat for most time series problems, especially for large-scale datasets. While this may
be considered good news, given the simplicity of implementing the nearest neighbor algorithm, there are some negative
consequences of this. First, the nearest neighbor algorithm requires storing and searching the entire dataset, resulting
in a high time and space complexity that limits its applicability, especially on resource-limited sensors. Second,
beyond mere classification accuracy, we often wish to gain some insight into the data and to make the classification
result more explainable, which global characteristics of the nearest neighbor cannot provide. In this work we introduce
a new time series primitive, time series shapelets, which addresses these limitations. Informally, shapelets are time
series subsequences which are in some sense maximally representative of a class. We can use the distance to the
shapelet, rather than the distance to the nearest neighbor to classify objects. As we shall show with extensive
empirical evaluations in diverse domains, classification algorithms based on the time series shapelet primitives can be
interpretable, more accurate, and significantly faster than state-of-the-art classifiers.},
    address = {Hingham, MA, USA},
    author = {Ye, Lexiang and Keogh, Eamonn},
    citeulike-article-id = {7344347},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1937796.1937885},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s10618-010-0179-5},
    citeulike-linkout-2 = {http://www.springerlink.com/content/v4p5747q2m665385},
    day = {18},
    doi = {10.1007/s10618-010-0179-5},
    issn = {1384-5810},
    journal = {Data Min. Knowl. Discov.},
    month = jan,
    number = {1-2},
    pages = {149--182},
    posted-at = {2013-08-12 14:14:55},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Time series shapelets: a novel technique that allows accurate, interpretable and fast classification},
    url = {http://dx.doi.org/10.1007/s10618-010-0179-5},
    volume = {22},
    year = {2011}
}

@inproceedings{citeulike:1959582,
    abstract = {Partial periodicity search, i.e., search for partial periodic
patterns in time-series databases, is an interesting data mining
problem. Previous studies on periodicity search mainly consider finding
full periodic patterns, where every point in time contributes (precisely
or approximately) to the periodicity. However, partial periodicity is
very common in practice since it is more likely that only some of the
time episodes may exhibit periodic patterns. We present several
algorithms for efficient mining of partial periodic patterns, by
exploring some interesting properties related to partial periodicity
such as the Apriori property and the max-subpattern hit set property,
and by shared mining of multiple periods. The max-subpattern hit set
property is a vital new property which allows us to derive the counts of
all frequent patterns from a relatively small subset of patterns
existing in the time series. We show that mining partial periodicity
needs only two scans over the time series database, even for mining
multiple periods. The performance study shows our proposed methods are
very efficient in mining long periodic patterns},
    author = {Han, Jiawei and Dong, Guozhu and Yin, Yiwen},
    booktitle = {Data Engineering, 1999. Proceedings., 15th International Conference on},
    citeulike-article-id = {1959582},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icde.1999.754913},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=754913},
    doi = {10.1109/icde.1999.754913},
    institution = {Sch. of Comput. Sci., Simon Fraser Univ., Burnaby, BC, Canada},
    isbn = {0-7695-0071-4},
    issn = {1063-6382},
    journal = {Data Engineering, 1999. Proceedings., 15th International Conference on},
    month = mar,
    pages = {106--115},
    posted-at = {2013-08-12 13:47:38},
    priority = {2},
    publisher = {IEEE},
    title = {Efficient mining of partial periodic patterns in time series database},
    url = {http://dx.doi.org/10.1109/icde.1999.754913},
    year = {1999}
}

@article{citeulike:5898869,
    abstract = {We consider the problem of finding rules relating patterns  in a time series to other patterns in that
series,  or patterns in one series to patterns in another series.  A simple example is a rule such as "a period  of low
telephone call activity is usually followed by a  sharp rise in call volume". Examples of rules relating  two or more
time series are "if the Microsoft stock  price goes up and Intel falls, then {IBM} goes up the  next day," and "if
Microsoft goes up strongly for one  day, then declines strongly on the next day, and on  the same days Intel stays about
level, then {IBM} stays  about level." Our emphasis is in the discovery of local  patterns in multivariate time series,
in contrast to traditional  time series analysis which largely focuses on  global models. Thus, we search for rules
whose conditions  refer to patterns in time series. However, we do  not want to define beforehand which patterns are to
be  used; rather, we want the patterns to be formed from  the data in t...},
    author = {Das, Gautam and Lin, King-ip and Mannila, Heikki and Renganathan, Gopal and Smyth, Padhraic},
    citeulike-article-id = {5898869},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.3240},
    pages = {16--22},
    posted-at = {2013-08-12 13:39:55},
    priority = {2},
    title = {Rule Discovery From Time Series},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.3240},
    year = {1998}
}

@article{citeulike:12550871,
    abstract = {Software project telemetry facilitates local, in-process decision making. Hackystat, an open source
reference framework for this new approach, offers easy implementation.},
    author = {Johnson, Philip M. and Kou, Hongbing and Paulding, Michael and Zhang, Qin and Kagawa, Aaron},
    citeulike-article-id = {12550871},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.66.3500},
    posted-at = {2013-08-11 16:14:00},
    priority = {2},
    title = {Improving Software Development Management through Software Project Telemetry},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.66.3500}
}

@inproceedings{citeulike:2900542,
    abstract = {Recent initiatives like the Million Book Project and Google Print Library Project have already archived
several million books in digital format, and within a few years a significant fraction of world's books will be online.
While the majority of the data will naturally be text, there will also be tens of millions of pages of images. Many of
these images will defy automation annotation for the foreseeable future, but a considerable fraction of the images may
be amiable to automatic annotation by algorithms that can link the historical image with a modern contemporary, with its
attendant metatags. In order to perform this linking we must have a suitable distance measure which appropriately
combines the relevant features of shape, color, texture and text. However the best combination of these features will
vary from application to application and even from one manuscript to another. In this work we propose a simple technique
to learn the distance measure by perturbing the training set in a principled way. We show the utility of our ideas on
archives of manuscripts containing images from natural history and cultural artifacts.},
    address = {New York, NY, USA},
    author = {Wang, Xiaoyue and Ye, Lexiang and Keogh, Eamonn and Shelton, Christian},
    booktitle = {Proceedings of the 8th ACM/IEEE-CS joint conference on Digital libraries},
    citeulike-article-id = {2900542},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1378889.1378948},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1378889.1378948},
    doi = {10.1145/1378889.1378948},
    isbn = {978-1-59593-998-2},
    location = {Pittsburgh PA, PA, USA},
    pages = {341--350},
    posted-at = {2013-08-11 15:10:06},
    priority = {2},
    publisher = {ACM},
    series = {JCDL '08},
    title = {Annotating historical archives of images},
    url = {http://dx.doi.org/10.1145/1378889.1378948},
    year = {2008}
}

@inproceedings{citeulike:12550835,
    abstract = {The matching of two-dimensional shapes is an important problem with applications in domains as diverse
as biometrics, industry, medicine and anthropology. The distance measure used must be invariant to many distortions,
including scale, offset, noise, partial occlusion, etc. Most of these distortions are relatively easy to handle, either
in the representation of the data or in the similarity measure used. However rotation invariance seems to be uniquely
difficult. Current approaches typically try to achieve rotation invariance in the representation of the data, at the
expense of discrimination ability, or in the distance measure, at the expense of efficiency. In this work we show that
we can take the slow but accurate approaches and dramatically speed them up. On real world problems our technique can
take current approaches and make them four orders of magnitude faster, without false dismissals. Moreover, our technique
can be used with any of the dozens of existing shape representations and with all the most popular distance measures
including Euclidean distance, Dynamic Time Warping and Longest Common Subsequence.},
    author = {Keogh, Eamonn and Wei, Li and Xi, Xiaopeng and Lee, Sang-hee and Vlachos, Michail},
    booktitle = {VLDB, 2006},
    citeulike-article-id = {12550835},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.1534},
    pages = {882--893},
    posted-at = {2013-08-11 15:06:33},
    priority = {2},
    title = {{LB\_Keogh} supports exact indexing of shapes under rotation invariance with arbitrary representations and
distance measures},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.1534},
    year = {2006}
}

@article{citeulike:12550833,
    abstract = {Two species of coffee bean have acquired worldwide economic importance:? these are, Coffea Arabica and
Coffea Canephora variant Robusta. Arabica beans are valued most highly by the trade, as they are considered to have a
finer flavor than Robusta. In this work, Fourier transform infrared spectroscopy is explored as a rapid alternative to
wet chemical methods for authentication and quantification of coffee products. Principal component analysis ({PCA}) is
applied to spectra of freeze-dried instant coffees, acquired by {DRIFT} (diffuse reflection infrared Fourier transform)
and {ATR} (attenuated total reflection) sampling techniques, and reveals clustering according to coffee species. Linear
discriminant analysis of the principal component scores yields 100\% correct classifications for both training and test
samples. The chemical origin of the discrimination is explored through interpretation of the {PCA} loadings. Partial
least squares regression is applied to spectra of Arabica and Robusta blends to determine the relative content of each
species. Internal cross-validation gives a correlation coefficient of 0.99 and a standard error of prediction of 1.20\%
(w/w), illustrating the potential of the method for industrial off-line quality control analysis. Keywords: Coffee;
discrimination; infrared; spectroscopy},
    author = {Briandet, Romain and Kemsley, E. Katherine and Wilson, Reginald H.},
    citeulike-article-id = {12550833},
    citeulike-linkout-0 = {http://dx.doi.org/10.1021/jf950305a},
    citeulike-linkout-1 = {http://pubs.acs.org/doi/abs/10.1021/jf950305a},
    day = {1},
    doi = {10.1021/jf950305a},
    journal = {J. Agric. Food Chem.},
    month = jan,
    number = {1},
    pages = {170--174},
    posted-at = {2013-08-11 15:04:10},
    priority = {2},
    publisher = {American Chemical Society},
    title = {Discrimination of Arabica and Robusta in Instant Coffee by Fourier Transform Infrared Spectroscopy and
Chemometrics},
    url = {http://dx.doi.org/10.1021/jf950305a},
    volume = {44},
    year = {1996}
}

@book{citeulike:12550665,
    author = {Ewusi-Mensah, Kweku},
    citeulike-article-id = {12550665},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262050722},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262050722},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262050722},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262050722},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262050722/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262050722},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262050722},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262050722},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262050722\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262050722},
    day = {01},
    howpublished = {Hardcover},
    isbn = {0262050722},
    month = aug,
    posted-at = {2013-08-11 11:54:01},
    priority = {2},
    publisher = {The MIT Press},
    title = {Software Development Failures},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262050722},
    year = {2003}
}

@article{citeulike:12550640,
    abstract = {Process discovery has been shown to be challenging offering limited results, however, most work has been
conducted in closed source systems. This paper describes a new approach to process discovery that examines the Internet
information spaces of open source software development projects. In searching for an automated solution to the process
discovery problem, we first have simulated it by having a human act as an \^{a}intelligent spider\^{a} searching the
Web space for evidence of process activities and reconstructing process fragments based on the clues discovered. The
purpose of such an approach is to help reveal the details of our manual process discovery approach. In turn, such
knowledge can then be employed to determine the requirements and design of automated process discovery and modeling
mechanisms that can be applied to Web-based software development projects.},
    author = {Jensen, Chris and Scacchi, Walt},
    citeulike-article-id = {12550640},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.127.9283},
    posted-at = {2013-08-11 09:32:31},
    priority = {2},
    title = {Simulating an Automated Approach to Discovery and Modeling of Open Source Software Development Processes},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.127.9283},
    year = {2003}
}

@inproceedings{citeulike:2280690,
    abstract = {Although state-of-the-art software repositories based on versioning system information are useful to
assess the evolution of a software system, the information they contain is limited in several ways. Versioning systems
such as {CVS} or {SubVersion} store only snapshots of text files, leading to a loss of information: The exact sequence
of changes between two versions is hard to recover. In this paper we present an alternative information repository which
stores incremental changes to the system under study, retrieved from the {IDE} used to build the software. We then use
this change-based model of system evolution to assess when refactorings happen in two case studies, and compare our
findings with refactoring detection approaches on classical versioning system repositories.},
    address = {Washington, DC, USA},
    author = {Robbes, Romain},
    booktitle = {Proceedings of the Fourth International Workshop on Mining Software Repositories},
    citeulike-article-id = {2280690},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1268983.1269029},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/msr.2007.18},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228652},
    doi = {10.1109/msr.2007.18},
    isbn = {0-7695-2950-X},
    posted-at = {2013-08-11 08:04:26},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {MSR '07},
    title = {Mining a {Change-Based} Software Repository},
    url = {http://dx.doi.org/10.1109/msr.2007.18},
    year = {2007}
}

@inproceedings{citeulike:9037939,
    abstract = {When software repositories are mined, two distinct sources of information are usually explored: the
history log and snapshots of the system. Results of analyses derived from these two sources are biased by the frequency
with which developers commit their changes. We argue that the usage of mainstream {SCM} systems influences the way that
developers work. For example, since it is tedious to resolve conflicts due to parallel commits, developers tend to
minimize conflicts by not contemporarily modifying the same file. This however defeats one of the purposes of such
systems. We mine repositories created by our Syde tool, which records every change by every developer in multi-developer
projects. This new source of information can augment the accuracy of analyses and breaks new ground in terms of how such
information can assist developers. In this paper we illustrate how the information we mine can help to provide a refined
notion of code ownership. As a case study, we analyze the developers' activities of the development of a commercial
system.},
    address = {Washington, DC, USA},
    author = {Hattori, Lile and Lanza, Michele},
    booktitle = {Proceedings of the 2009 6th IEEE International Working Conference on Mining Software Repositories},
    citeulike-article-id = {9037939},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1591149},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/MSR.2009.5069492},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/msr.2009.5069492},
    doi = {10.1109/msr.2009.5069492},
    isbn = {978-1-4244-3493-0},
    journal = {Mining Software Repositories, International Workshop on},
    pages = {141--150},
    posted-at = {2013-08-11 08:02:59},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {MSR '09},
    title = {Mining the history of synchronous changes to refine code ownership},
    url = {http://dx.doi.org/10.1109/msr.2009.5069492},
    volume = {0},
    year = {2009}
}

@inproceedings{citeulike:12550438,
    abstract = {The Mining Software Repositories ({MSR}) research community has grown significantly since the first
{MSR} workshop was held in 2004. As the community continues to broaden its scope and deepens its expertise, it is
worthwhile to reflect on the best practices that our community has developed over the past decade of research. We
identify these best practices by surveying past {MSR} conferences and workshops. To that end, we review all 117 full
papers published in the {MSR} proceedings between 2004 and 2012. We extract 268 comments from these papers, and
categorize them using a grounded theory methodology. From this evaluation, four high-level themes were identified: data
acquisition and preparation, synthesis, analysis, and sharing/replication. Within each theme we identify several common
recommendations, and also examine how these recommendations have evolved over the past decade. In an effort to make this
survey a living artifact, we also provide a public forum that contains the extracted recommendations in the hopes that
the {MSR} community can engage in a continuing discussion on our evolving best practices.},
    address = {Piscataway, NJ, USA},
    author = {Hemmati, Hadi and Nadi, Sarah and Baysal, Olga and Kononenko, Oleksii and Wang, Wei and Holmes, Reid and
Godfrey, Michael W.},
    booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
    citeulike-article-id = {12550438},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2487150},
    isbn = {978-1-4673-2936-1},
    location = {San Francisco, CA, USA},
    pages = {343--352},
    posted-at = {2013-08-10 21:13:42},
    priority = {2},
    publisher = {IEEE Press},
    series = {MSR '13},
    title = {The {MSR} cookbook: mining a decade of research},
    url = {http://portal.acm.org/citation.cfm?id=2487150},
    year = {2013}
}

@book{citeulike:2759198,
    author = {McBreen, Pete},
    citeulike-article-id = {2759198},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0201733862},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0201733862},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0201733862},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0201733862},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0201733862/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201733862},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0201733862},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0201733862},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0201733862\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0201733862},
    day = {02},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0201733862},
    month = sep,
    posted-at = {2013-08-04 11:12:43},
    priority = {2},
    publisher = {Addison-Wesley Professional},
    title = {Software Craftsmanship: The New Imperative},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201733862},
    year = {2001}
}

@ONLINE{msr2004,
     title  = "MSR 2004: International Workshop on Mining Software Repositories ",
     month  = "May",
     year   = "2004",
     url    = "http://msr.uwaterloo.ca/msr2004/",
     author = "Ahmed E. Hassan"
 }

@ONLINE{promise12,
     title  = "The PROMISE Repository of empirical software engineering data",
     month  = "June",
     year   = "2012",
     url    = "http://promisedata.googlecode.com",
     author = "Tim Menzies and 
               Bora Caglayan and 
               Zhimin He and 
               Ekrem Kocaguneli and 
               Joe Krall and 
               Fayola Peters and 
               Burak Turhan
              "
 }

@inproceedings{citeulike:12480029,
    abstract = {{Free/Libre} and Open Source Software ({FLOSS}) projects are a form of commons where individuals work
collectively to produce software that is a public, rather than a private, good. The famous phrase "Tragedy of the
Commons" describes a situation where a natural resource commons, such as a pasture, or a water supply, gets depleted
because of overuse. The tragedy in {FLOSS} commons is distinctly different -- it occurs when collective action ceases
before a software product is produced or reaches its full potential. This paper builds on previous work about defining
success in {FLOSS} projects by taking a collective action perspective. We first report the results of interviews with
{FLOSS} developers regarding our ideas about success and failure in {FLOSS} projects. Building on those interviews and
previous work, we then describe our criteria for defining success/tragedy in {FLOSS} commons. Finally, we discuss the
results of a preliminary classification of nearly all projects hosted on 
Sourceforge.net as of August 2006.},
    address = {Washington, DC, USA},
    author = {English, Robert and Schweik, Charles M.},
    booktitle = {Proceedings of the First International Workshop on Emerging Trends in FLOSS Research and Development},
    citeulike-article-id = {12480029},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1270277},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/floss.2007.9},
    doi = {10.1109/floss.2007.9},
    isbn = {0-7695-2961-5},
    posted-at = {2013-07-15 14:32:30},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {FLOSS '07},
    title = {Identifying Success and Tragedy of {FLOSS} Commons: A Preliminary Classification of Sourceforge.net
Projects},
    url = {http://dx.doi.org/10.1109/floss.2007.9},
    year = {2007}
}

@book{richter2007critique,
  title={Critique for the Open Source Development Model},
  author={Richter, S.},
  isbn={9783638807173},
  url={http://books.google.fr/books?id=e1jU2SxSgp0C},
  year={2007},
  publisher={GRIN Verlag}
}

@inproceedings{citeulike:12476567,
    author = {McConnell, Steve},
    booktitle = {2009 31st International Conference on Software Engineering - Companion Volume},
    citeulike-article-id = {12476567},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icse-companion.2009.5070958},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5070958},
    doi = {10.1109/icse-companion.2009.5070958},
    isbn = {978-1-4244-3495-4},
    keywords = {thesis-phd},
    location = {Vancouver, BC, Canada},
    pages = {12},
    posted-at = {2013-07-12 14:14:25},
    priority = {2},
    publisher = {IEEE},
    title = {10 most powerful ideas in software engineering},
    url = {http://dx.doi.org/10.1109/icse-companion.2009.5070958},
    year = {2009}
}

@book{citeulike:262020,
    author = {Weinberg, Gerald M. and Weinberg, Gerald M.},
    citeulike-article-id = {262020},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0932633420\&index=books\&linkCode=qs},
    day = {01},
    edition = {Anl Sub},
    howpublished = {Paperback},
    isbn = {0932633420},
    keywords = {thesis-phd},
    month = aug,
    posted-at = {2013-07-12 12:55:20},
    priority = {2},
    publisher = {Dorset House},
    title = {The Psychology of Computer Programming: Silver Anniversary Edition},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0932633420},
    year = {1998}
}

@book{citeulike:6086365,
    author = {Sommerville, Ian},
    citeulike-article-id = {6086365},
    day = {01},
    edition = {9},
    howpublished = {Hardcover},
    isbn = {0137035152},
    month = mar,
    posted-at = {2013-07-12 09:43:10},
    priority = {2},
    publisher = {Pearson},
    title = {Software engineering},
    url = {http://www.worldcat.org/isbn/0137035152},
    year = {2011}
}

@article{naur_crisis_68,
    author = {Naur, Peter and Randell, Brian.},
    keywords = {thesis-phd},
    title = {Software Engineering: Report of a conference sponsored by the {NATO Science Committee}},
    url = {http://homepages.cs.ncl.ac.uk/brian.randell/NATO/nato1968.PDF},
    year = {1968}
}

@article{citeulike:12159215,
    abstract = {It has long been known that Dynamic Time Warping ({DTW}) is superior to Euclidean distance for
classification and clustering of time series. However, until lately, most research has utilized Euclidean distance
because it is more efficiently calculated. A recently introduced technique that greatly mitigates {DTWs} demanding {CPU}
time has sparked a flurry of research activity. However, the technique and its many extensions still only allow {DTW} to
be applied to moderately large datasets. In addition, almost all of the research on {DTW} has focused exclusively on
speeding up its calculation; there has been little work done on improving its accuracy. In this work, we target the
accuracy aspect of {DTW} performance and introduce a new framework that learns arbitrary constraints on the warping path
of the {DTW} calculation. Apart from improving the accuracy of classification, our technique as a side effect speeds up
{DTW} by a wide margin as well. We show the utility of our approach on datasets 
from diverse domains and demonstrate significant gains in accuracy and efficiency.},
    author = {Ann, Chotirat and Keogh, Ratanamahatana E.},
    citeulike-article-id = {12159215},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.134.2280},
    keywords = {thesis-phd},
    posted-at = {2013-03-15 09:03:46},
    priority = {2},
    title = {Making Time-series Classification More Accurate Using Learned Constraints},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.134.2280}
}

@book{citeulike:12134192,
    author = {Dirr, Michael A.},
    citeulike-article-id = {12134192},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1588748685},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/1588748685},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/1588748685},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/1588748685},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/1588748685/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1588748685},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/1588748685},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN1588748685},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=1588748685\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/1588748685},
    edition = {6 Revised},
    howpublished = {Paperback},
    isbn = {1588748685},
    keywords = {thesis-phd},
    posted-at = {2013-03-11 05:20:43},
    priority = {2},
    publisher = {Stipes Pub Llc},
    title = {Manual of Woody Landscape Plants: Their Identification, Ornamental Characteristics, Culture, Propogation
and Uses},
    url = {http://www.worldcat.org/isbn/1588748685}
}

@article{citeulike:12063110,
    abstract = {Classification of time series has been attracting great interest over the past decade. Recent empirical
evidence has strongly suggested that the simple nearest neighbor algorithm is very difficult to beat for most time
series problems. While this may be considered good news, given the simplicity of implementing the nearest neighbor
algorithm, there are some negative consequences of this. First, the nearest neighbor algorithm requires storing and
searching the entire dataset, resulting in a time and space complexity that limits its applicability, especially on
resource-limited sensors. Second, beyond mere classification accuracy, we often wish to gain some insight into the data.
In this work we introduce a new time series primitive, time series shapelets, which addresses these limitations.
Informally, shapelets are time series subsequences which are in some sense maximally representative of a class. As we
shall show with extensive empirical evaluations in diverse domains, algorithms based on 
the time series shapelet primitives can be interpretable, more accurate and significantly faster than state-of-the-art
classifiers.},
    author = {Ye, Lexiang and Keogh, Eamonn},
    citeulike-article-id = {12063110},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.154.6108},
    keywords = {pkdd, thesis-phd},
    posted-at = {2013-02-24 08:00:53},
    priority = {2},
    title = {Time Series Shapelets: A New Primitive for Data Mining},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.154.6108}
}

@article{citeulike:10402667,
    abstract = {. We propose an indexing method for time sequences for processing similarity queries. We use the
Discrete Fourier Transform ({DFT}) to map time sequences to the frequency domain, the crucial observation being that,
for most sequences of practical interest, only the first few frequencies are strong. Another important observation is
Parseval's theorem, which specifies that the Fourier transform preserves the Euclidean distance in the time or frequency
domain. Having thus mapped sequences to a lowerdimensionality space by using only the first few Fourier coefficients, we
use R    - trees to index the sequences and efficiently answer similarity queries. We provide experimental results which
show that our method is superior to search based on sequential scanning. Our experiments show that a few coefficients
(1-3) are adequate to provide good performance. The performance gain of our method increases with the number and length
of sequences.   On sabbatical from the Dept. of Computer Science, Un...},
    author = {Agrawal, Rakesh and Faloutsos, Christos and Swami, Arun},
    citeulike-article-id = {10402667},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.9405},
    keywords = {pkdd, thesis},
    pages = {69--84},
    posted-at = {2013-02-24 07:52:29},
    priority = {2},
    title = {Efficient Similarity Search In Sequence Databases},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.9405},
    year = {1993}
}

@electronic{citeulike:9385098,
    abstract = {Current research in indexing and mining time series data has produced many interesting algorithms and
representations. However, it has not led to algorithms that can scale to the increasingly massive datasets encountered
in science, engineering, and business domains. In this work, we show how a novel multiresolution symbolic representation
can be used to index datasets which are several orders of magnitude larger than anything else considered in the
literature. Our approach allows both fast exact search and ultra fast approximate search. We show how to exploit the
combination of both types of search as sub-routines in data mining algorithms, allowing for the exact mining of truly
massive real world datasets, containing millions of time series.},
    author = {Shieh, Jin and Keogh, Eamonn},
    citeulike-article-id = {9385098},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.155.4531},
    keywords = {thesis-phd},
    pages = {623--631},
    posted-at = {2013-02-03 20:41:27},
    priority = {2},
    title = {{iSAX}: Indexing and Mining Terabyte Sized Time Series, {SIGKDD}. pp},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.155.4531},
    year = {2008}
}

@book{citeulike:113403,
    author = {Cockburn, Alistair},
    citeulike-article-id = {113403},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0201699699},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0201699699},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0201699699},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0201699699},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0201699699/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201699699},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0201699699},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0201699699},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0201699699\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0201699699},
    day = {22},
    howpublished = {Paperback},
    isbn = {0201699699},
    keywords = {thesis, thesis-phd},
    month = oct,
    posted-at = {2013-02-02 12:12:35},
    priority = {2},
    publisher = {Addison-Wesley Professional},
    title = {Agile Software Development},
    url = {http://www.worldcat.org/isbn/0201699699},
    year = {2001}
}

@article{citeulike:270732,
    abstract = {In a document retrieval, or other pattern matching environment where stored entities (documents) are
compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space
is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing
system may be expressible as a function of the density of the object space; in particular, retrieval performance may
correlate inversely with space density. An approach based on space density computations is used to choose an optimum
indexing vocabulary for a collection of documents. Typical evaluation results are shown, demonstating the usefulness of
the model.},
    address = {New York, NY, USA},
    author = {Salton, G. and Wong, A. and Yang, C. S.},
    citeulike-article-id = {270732},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=361220},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/361219.361220},
    doi = {10.1145/361219.361220},
    issn = {0001-0782},
    journal = {Commun. ACM},
    keywords = {pkdd, thesis},
    month = nov,
    number = {11},
    pages = {613--620},
    posted-at = {2013-01-26 17:17:45},
    priority = {2},
    publisher = {ACM},
    title = {A vector space model for automatic indexing},
    url = {http://dx.doi.org/10.1145/361219.361220},
    volume = {18},
    year = {1975}
}

@inproceedings{citeulike:11958025,
    abstract = {Human activity modeling and recognition using wearable sensors is important in pervasive healthcare,
with applications including quantitative assessment of motor function, rehabilitation, and elder care. Previous human
activity recognition techniques use a "whole-motion" model in which continuous sensor streams are divided into windows
with a fixed time duration whose length is chosen such that all the relevant information in each activity signal can be
extracted from each window. In this paper, we present a statistical motion primitive-based framework for human activity
representation and recognition. Our framework is based on {Bag-of-Features} ({BoF}), which builds activity models using
histograms of primitive symbols. We experimentally validate the effectiveness the {BoF}-based framework for recognizing
nine activity classes and evaluate six factors which impact the performance of the framework. The factors include window
size, choices of features, methods to construct motion primitives, 
motion vocabulary size, weighting schemes of motion primitive assignments, and learning machine kernel functions.
Finally, we demonstrate that our statistical {BoF}-based framework can achieve much better performance compared to a
non-statistical string-matching-based approach.},
    address = {New York, NY, USA},
    author = {Zhang, Mi and Sawchuk, Alexander A.},
    booktitle = {Proceedings of the 2nd ACM SIGHIT International Health Informatics Symposium},
    citeulike-article-id = {11958025},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2110433},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2110363.2110433},
    doi = {10.1145/2110363.2110433},
    isbn = {978-1-4503-0781-9},
    keywords = {pkdd, thesis},
    location = {Miami, Florida, USA},
    pages = {631--640},
    posted-at = {2013-01-25 18:19:53},
    priority = {2},
    publisher = {ACM},
    series = {IHI '12},
    title = {Motion primitive-based human activity recognition using a bag-of-features approach},
    url = {http://dx.doi.org/10.1145/2110363.2110433},
    year = {2012}
}

@inproceedings{citeulike:11958022,
    abstract = {Many ubiquitous computing applications involve human activity recognition based on wearable sensors.
Although this problem has been studied for a decade, there are a limited number of publicly available datasets to use as
standard benchmarks to compare the performance of activity models and recognition algorithms. In this paper, we describe
the freely available {USC} human activity dataset ({USC}-{HAD}), consisting of well-defined low-level daily activities
intended as a benchmark for algorithm comparison particularly for healthcare scenarios. We briefly review some existing
publicly available datasets and compare them with {USC}-{HAD}. We describe the wearable sensors used and details of
dataset construction. We use high-precision well-calibrated sensing hardware such that the collected data is accurate,
reliable, and easy to interpret. The goal is to make the dataset and research based on it repeatable and extendible by
others.},
    address = {New York, NY, USA},
    author = {Zhang, Mi and Sawchuk, Alexander A.},
    booktitle = {Proceedings of the 2012 ACM Conference on Ubiquitous Computing},
    citeulike-article-id = {11958022},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2370438},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2370216.2370438},
    doi = {10.1145/2370216.2370438},
    isbn = {978-1-4503-1224-0},
    keywords = {pkdd, thesis},
    location = {Pittsburgh, Pennsylvania},
    pages = {1036--1043},
    posted-at = {2013-01-25 18:19:13},
    priority = {2},
    publisher = {ACM},
    series = {UbiComp '12},
    title = {{USC}-{HAD}: a daily activity dataset for ubiquitous activity recognition using wearable sensors},
    url = {http://dx.doi.org/10.1145/2370216.2370438},
    year = {2012}
}

@article{citeulike:11796594,
    abstract = {The last decade has witnessed a tremendous growths of interests in applications that deal with querying
and mining of time series data. Numerous representation methods for dimensionality reduction and similarity measures
geared towards time series have been introduced. Each individual work introducing a particular method has made specific
claims and, aside from the occasional theoretical justifications, provided quantitative experimental observations.
However, for the most part, the comparative aspects of these experiments were too narrowly focused on demonstrating the
benefits of the proposed methods over some of the previously introduced ones. In order to provide a comprehensive
validation, we conducted an extensive set of time series experiments re-implementing 8 different representation methods
and 9 similarity measures and their variants, and testing their effectiveness on 38 time series data sets from a wide
variety of application domains. In this paper, we give an overview of these 
different techniques and present our comparative experimental findings regarding their effectiveness. Our experiments
have provided both a unified validation of some of the existing achievements, and in some cases, suggested that certain
claims in the literature may be unduly optimistic.},
    author = {Ding, Hui and Trajcevski, Goce and Scheuermann, Peter and Wang, Xiaoyue and Keogh, Eamonn},
    citeulike-article-id = {11796594},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1454226},
    issn = {2150-8097},
    journal = {Proc. VLDB Endow.},
    keywords = {pkdd, thesis},
    month = aug,
    number = {2},
    pages = {1542--1552},
    posted-at = {2013-01-25 18:05:45},
    priority = {2},
    publisher = {VLDB Endowment},
    title = {Querying and mining of time series data: experimental comparison of representations and distance measures},
    url = {http://portal.acm.org/citation.cfm?id=1454226},
    volume = {1},
    year = {2008}
}

@inproceedings{citeulike:11958014,
    abstract = {Classification of time series has been attracting great interest over the past decade. Recent empirical
evidence has strongly suggested that the simple nearest neighbor algorithm is very difficult to beat for most time
series problems. While this may be considered good news, given the simplicity of implementing the nearest neighbor
algorithm, there are some negative consequences of this. First, the nearest neighbor algorithm requires storing and
searching the entire dataset, resulting in a time and space complexity that limits its applicability, especially on
resource-limited sensors. Second, beyond mere classification accuracy, we often wish to gain some insight into the data.
In this work we introduce a new time series primitive, time series shapelets, which addresses these limitations.
Informally, shapelets are time series subsequences which are in some sense maximally representative of a class. As we
shall show with extensive empirical evaluations in diverse domains, algorithms based on 
the time series shapelet primitives can be interpretable, more accurate and significantly faster than state-of-the-art
classifiers.},
    address = {New York, NY, USA},
    author = {Ye, Lexiang and Keogh, Eamonn},
    booktitle = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
    citeulike-article-id = {11958014},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1557122},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1557019.1557122},
    doi = {10.1145/1557019.1557122},
    isbn = {978-1-60558-495-9},
    keywords = {pkdd, thesis},
    location = {Paris, France},
    pages = {947--956},
    posted-at = {2013-01-25 17:57:45},
    priority = {2},
    publisher = {ACM},
    series = {KDD '09},
    title = {Time series shapelets: a new primitive for data mining},
    url = {http://dx.doi.org/10.1145/1557019.1557122},
    year = {2009}
}

@inproceedings{citeulike:11957982,
    abstract = {Time series shapelets are small, local patterns in a time series that are highly predictive of a class
and are thus very useful features for building classifiers and for certain visualization and summarization tasks. While
shapelets were introduced only recently, they have already seen significant adoption and extension in the community.
Despite their immense potential as a data mining primitive, there are two important limitations of shapelets. First,
their expressiveness is limited to simple binary presence/absence questions. Second, even though shapelets are computed
offline, the time taken to compute them is significant. In this work, we address the latter problem by introducing a
novel algorithm that finds shapelets in less time than current methods by an order of magnitude. Our algorithm is based
on intelligent caching and reuse of computations, and the admissible pruning of the search space. Because our algorithm
is so fast, it creates an opportunity to consider more expressive 
shapelet queries. In particular, we show for the first time an augmented shapelet representation that distinguishes the
data based on conjunctions or disjunctions of shapelets. We call our novel representation {Logical-Shapelets}. We
demonstrate the efficiency of our approach on the classic benchmark datasets used for these problems, and show several
case studies where logical shapelets significantly outperform the original shapelet representation and other time series
classification techniques. We demonstrate the utility of our ideas in domains as diverse as gesture recognition,
robotics, and biometrics.},
    address = {New York, NY, USA},
    author = {Mueen, Abdullah and Keogh, Eamonn and Young, Neal},
    booktitle = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining},
    citeulike-article-id = {11957982},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2020587},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2020408.2020587},
    doi = {10.1145/2020408.2020587},
    isbn = {978-1-4503-0813-7},
    keywords = {pkdd, thesis},
    location = {San Diego, California, USA},
    pages = {1154--1162},
    posted-at = {2013-01-25 17:20:18},
    priority = {2},
    publisher = {ACM},
    series = {KDD '11},
    title = {Logical-shapelets: an expressive primitive for time series classification},
    url = {http://dx.doi.org/10.1145/2020408.2020587},
    year = {2011}
}

@inproceedings{citeulike:11862312,
    abstract = {In this paper, we propose a retrieval method using textual information retrieval techniques, such as
vector space model, for images. Many image retrieval systems are proposed. However, these systems are mainly based on
pattern recognition techniques. Therefore, the features of images are also based on these recognition techniques, such
as color histogram, and shape of the object in images. Generally, these systems do not consider weight of features,
which means how important these features are, which are generally used in textual information retrieval systems. In this
paper, we propose a method considering weight, such as {TFIDF}, to identify the importance degree of features. Using our
proposed method, the system can retrieve intuitively similar retrieval target images to user's query images.},
    author = {Suzuki, Yu and Mitsukawa, M. and Kawagoe, K.},
    booktitle = {Database and Expert Systems Application, 2008. DEXA \&\#039;08. 19th International Workshop on},
    citeulike-article-id = {11862312},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/dexa.2008.106},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4624701},
    doi = {10.1109/dexa.2008.106},
    institution = {Coll. of Inf. Sci. \& Technol., Ritsumeikan Univ., Kyoto},
    isbn = {978-0-7695-3299-8},
    issn = {1529-4188},
    keywords = {thesis-phd},
    pages = {112--116},
    posted-at = {2013-01-02 07:59:00},
    priority = {2},
    publisher = {IEEE},
    title = {A Image Retrieval Method Using {TFIDF} Based Weighting Scheme},
    url = {http://dx.doi.org/10.1109/dexa.2008.106},
    year = {2008}
}

@article{citeulike:11325663,
    abstract = {Comparison of different metrics, using three large samples of haplotypes from different populations,
demonstrates that ρ is the most efficient measure of association between pairs of single nucleotide polymorphisms
({SNPs}). Pairwise data can be modeled, using composite likelihood, to describe the decline in linkage disequilibrium
with distance (the Malecot model). The evidence from more isolated populations (Finland, Sardinia) suggests that linkage
disequilibrium extends to 427–893 kb but, even in samples representative of large heterogeneous populations, such as
{CEPH}, the extent is 385 kb or greater. This suggests that isolated populations are not essential for linkage
disequilibrium mapping of common diseases with {SNPs}. The ∈ parameter of the Malecot model (recombination and time),
evaluated at each {SNP}, indicates regions of the genome with extensive and less extensive disequilibrium (low and high
values of ∈ respectively). When plotted against the physical map, the regions with 
extensive and less extensive linkage disequilibrium may correspond to recombination cold and hot spots. This is
discussed in relation to the Xq25 cytogenetic band and the {HFE} gene region. Hum Mutat 17:255–262, 2001. {\copyright}
2001 {Wiley-Liss}, Inc.},
    author = {Collins, A. and Ennis, S. and Taillon-Miller, P. and Kwok, P. Y. and Morton, N. E.},
    citeulike-article-id = {11325663},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/humu.21},
    doi = {10.1002/humu.21},
    journal = {Hum. Mutat.},
    keywords = {biaworks, snp},
    number = {4},
    pages = {255--262},
    posted-at = {2012-09-26 09:22:13},
    priority = {2},
    publisher = {John Wiley \& Sons, Inc.},
    title = {Allelic association with {SNPs}: Metrics, populations, and the linkage disequilibrium map},
    url = {http://dx.doi.org/10.1002/humu.21},
    volume = {17},
    year = {2001}
}

@article{citeulike:10694925,
    abstract = {
                Exome sequencing using next-generation sequencing technologies is a cost efficient approach to
selectively sequencing coding regions of human genome for detection of disease variants. A significant amount of {DNA}
fragments from the capture process fall outside target regions, and sequence data for positions outside target regions
have been mostly ignored after alignment.
                We performed whole exome sequencing on 22 subjects using Agilent {SureSelect} capture reagent and 6
subjects using Illumina {TrueSeq} capture reagent. We also downloaded sequencing data for 6 subjects from the 1000
Genomes Project Pilot 3 study. Using these data, we examined the quality of {SNPs} detected outside target regions by
computing consistency rate with genotypes obtained from {SNP} chips or the Hapmap database, transition-transversion
({Ti/Tv}) ratio, and percentage of {SNPs} inside {dbSNP}. For all three platforms, we obtained high-quality {SNPs}
outside target regions, and some far from target regions. In our Agilent {SureSelect} data, we obtained 84,049
high-quality {SNPs} outside target regions compared to 65,231 {SNPs} inside target regions (a 129\% increase). For our
Illumina {TrueSeq} data, we obtained 222,171 high-quality {SNPs} outside target regions compared to 95,818 {SNPs} inside
target regions (a 232\% increase). For the data from the 1000 Genomes Project, we obtained 7,
139 high-quality {SNPs} outside target regions compared to 1,548 {SNPs} inside target regions (a 461\% increase).
                These results demonstrate that a significant amount of high quality genotypes outside target regions can
be obtained from exome sequencing data. These data should not be ignored in genetic epidemiology studies.
            },
    author = {Guo, Yan and Long, Jirong and He, Jing and Li, Chung-I I. and Cai, Qiuyin and Shu, Xiao-Ou O. and Zheng,
Wei and Li, Chun},
    citeulike-article-id = {10694925},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2164-13-194},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3416685/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/22607156},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=22607156},
    day = {20},
    doi = {10.1186/1471-2164-13-194},
    issn = {1471-2164},
    journal = {BMC genomics},
    keywords = {biaworks, snp},
    month = may,
    number = {1},
    pages = {194+},
    pmcid = {PMC3416685},
    pmid = {22607156},
    posted-at = {2012-09-26 07:49:09},
    priority = {2},
    title = {Exome sequencing generates high quality data in non-target regions.},
    url = {http://dx.doi.org/10.1186/1471-2164-13-194},
    volume = {13},
    year = {2012}
}

@article{citeulike:11308152,
    abstract = {The transcriptome of a cell is represented by a myriad of different {RNA} molecules with and without
protein-coding capacities. In recent years, advances in sequencing technologies have allowed researchers to more fully
appreciate the complexity of whole transcriptomes, showing that the vast majority of the genome is transcribed,
producing a diverse population of non-protein coding {RNAs} ({ncRNAs}). Thus, the biological significance of non-coding
{RNAs} ({ncRNAs}) have been largely underestimated. Amongst these multiple classes of {ncRNAs}, the long non-coding
{RNAs} ({lncRNAs}) are apparently the most numerous and functionally diverse. A small but growing number of {lncRNAs}
have been experimentally studied, and a view is emerging that these are key regulators of epigenetic gene regulation in
mammalian cells. {LncRNAs} have already been implicated in human diseases such as cancer and neurodegeneration,
highlighting the importance of this emergent field. In this article, we review the 
catalogs of annotated {lncRNAs} and the latest advances in our understanding of {lncRNAs}.},
    author = {Derrien, Thomas and Guig\'{o}, Roderic and Johnson, Rory},
    citeulike-article-id = {11308152},
    citeulike-linkout-0 = {http://dx.doi.org/10.3389/fgene.2011.00107},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3266617/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/22303401},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=22303401},
    doi = {10.3389/fgene.2011.00107},
    issn = {1664-8021},
    journal = {Frontiers in genetics},
    keywords = {biaworks},
    pmcid = {PMC3266617},
    pmid = {22303401},
    posted-at = {2012-09-25 09:34:41},
    priority = {2},
    title = {The Long {Non-Coding} {RNAs}: A New (P)layer in the "Dark Matter".},
    url = {http://dx.doi.org/10.3389/fgene.2011.00107},
    volume = {2},
    year = {2011}
}

@article{citeulike:3132770,
    abstract = {
                Transcriptional initiation of each gene is assumed to be independently controlled in mammals. On the
other hand, recent large-scale transcriptome analyses have shown that the genome is pervasively transcribed, such that
the most of its {DNA} gives rise to {RNAs}. This raises the question of whether it is possible to pinpoint and activate
a particular locus without perturbing numerous neighbouring transcripts. Here we show that intensive transcription at
one locus frequently spills over into its physical neighbouring loci. Rapid induction of immediate-early genes ({IEGs})
in response to growth factor stimulations is accompanied by co-upregulation of their neighbouring genes. Profiling the
primary transcripts in the nucleus with whole-genome tiling arrays delineated simultaneous activation of transcription
centred on {IEGs}. Even in surrounding intergenic regions, transcriptional activation took place at the same time.
Acetylation levels of histone H3 and H4 are elevated along with the {IEG} 
induction and neighbouring co-upregulation. Inhibition of the mitogen-activated protein kinase ({MAPK}) pathway or the
transcription factor {SRF} suppresses all transcriptional upregulation. These results suggest that transcriptional
activation has a ripple effect, which may be advantageous for coordinated expression.
            },
    address = {Department of Cell and Developmental Biology, Graduate School of Biostudies, Kyoto University, Sakyo-ku,
Kyoto 606-8502, Japan.},
    author = {Ebisuya, Miki and Yamamoto, Takuya and Nakajima, May and Nishida, Eisuke},
    citeulike-article-id = {3132770},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/ncb1771},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/ncb1771},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18690232},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18690232},
    day = {10},
    doi = {10.1038/ncb1771},
    issn = {1465-7392},
    journal = {Nature cell biology},
    keywords = {biaworks},
    month = sep,
    number = {9},
    pages = {1106--1113},
    pmid = {18690232},
    posted-at = {2012-09-25 09:26:45},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {Ripples from neighbouring transcription.},
    url = {http://dx.doi.org/10.1038/ncb1771},
    volume = {10},
    year = {2008}
}

@article{citeulike:2923021,
    abstract = {Today's data-rich environment creates its own problems since exploring and analysing vast volumes of
spatio\&\#8211;temporal data have become increasingly difficult. It is suggested to approach this problem not only via
location\&\#8211;space or attribute\&\#8211;space as is traditionally done in {GIScience}, but also via
time\&\#8211;space. This time-visualisation approach considers the data, the user tasks and the visualisation
representations, and aims to improve accessibility, exploration and analysis of huge amounts of geo-data to support
geovisual analytics. To reach this objective, the time wave as the temporal visual representation is introduced. The
time wave combines the strengths of both the timeline and the time wheel and as such is able to represent linear and
cyclic time simultaneously, even at different levels of granularity. The time wave can be used in its role as temporal
reference system, as temporal data representation tool, and as temporal interaction tool. It functions 
in combination with other graphic representations that are typical for location\&\#8211;space and
attribute\&\#8211;space.},
    author = {Li, Xia and Kraak, Menno-Jan},
    citeulike-article-id = {2923021},
    citeulike-linkout-0 = {http://dx.doi.org/10.1179/000870408x311387},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/maney/caj/2008/00000045/00000003/art00005},
    doi = {10.1179/000870408x311387},
    issn = {0008-7041},
    journal = {Cartographic Journal, The},
    month = aug,
    number = {3},
    pages = {193--200},
    posted-at = {2012-08-24 13:54:59},
    priority = {2},
    publisher = {Maney Publishing},
    title = {The Time Wave. A New Method of Visual Exploration of Geo-data in Time\&amp;\#8211;space},
    url = {http://dx.doi.org/10.1179/000870408x311387},
    volume = {45},
    year = {2008}
}

@manual{citeulike:11095763,
    author = {Neale, Mark},
    citeulike-article-id = {11095763},
    citeulike-linkout-0 = {http://www.imdb.fr/title/tt0269629/},
    posted-at = {2012-08-20 05:08:07},
    priority = {2},
    title = {No Maps for These Territories},
    url = {http://www.imdb.fr/title/tt0269629/},
    year = {2000}
}

@article{citeulike:6532298,
    abstract = {I anatomize a successful open-source project, fetchmail, that was run as a deliberate test of some
theories about software engineering suggested by the history of Linux. I discuss these theories in terms of two
fundamentally different development styles, the "cathedral" model, representing most of the commercial world, versus the
"bazaar" model of the Linux world. I show that these models derive from opposing assumptions about the nature of the
software-debugging task. I then make a sustained argument from the Linux experience for the proposition that "Given
enough eyeballs, all bugs are shallow," suggest productive analogies with other self-correcting systems of selfish
agents, and conclude with some exploration of the implications of this insight for the future of software.},
    author = {Raymond, Eric},
    citeulike-article-id = {6532298},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s12130-999-1026-0},
    citeulike-linkout-1 = {http://www.springerlink.com/content/r2enc5xnyk358ref},
    day = {7},
    doi = {10.1007/s12130-999-1026-0},
    issn = {0897-1986},
    journal = {Knowledge, Technology \& Policy},
    month = sep,
    number = {3},
    pages = {23--49},
    posted-at = {2012-08-19 05:51:26},
    priority = {2},
    publisher = {Springer Netherlands},
    title = {The cathedral and the bazaar},
    url = {http://dx.doi.org/10.1007/s12130-999-1026-0},
    volume = {12},
    year = {1999}
}

@inproceedings{citeulike:11079867,
    abstract = {Recognized as one of the powerful technologies in software process engineering, Software Process
Modeling ({SPM}) has received significant attention over the last three decades. Although empirical research plays a
critical role in software engineering, the state-of-the-practice of empirical research in {SPM} has not been
systematically reviewed. This paper serves as a status report of the assessment of empirical research in {SPM} by
analyzing all refereed studies that were published in relevant venues from 1987 to 2008 using systematic review
methodology. The primary findings indicate that in current {SPM}-related empirical studies, (1) software process
management and improvement ({SPI}) was not yet the most popular primary research objectives, (2) exploratory empirical
research methods, e.g., case study and action research, were dominantly used, (3) there were common issues in empirical
research reports in terms of following rigorous reporting guidelines. Based on the review results, we also 
suggest the future needs for empirical research in {SPM}, in terms of research topics, {SPM} techniques, the strengths
of research methodology and the rigors of empirical studies.},
    author = {Bai, Xu and Zhang, He and Huang, LiGuo},
    booktitle = {Empirical Software Engineering and Measurement (ESEM), 2011 International Symposium on},
    citeulike-article-id = {11079867},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/esem.2011.43},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6092583},
    doi = {10.1109/esem.2011.43},
    institution = {Dept. of Comput. Sci. \& Eng., Southern Methodist Univ., Dallas, TX, USA},
    isbn = {978-1-4577-2203-5},
    issn = {1938-6451},
    pages = {339--342},
    posted-at = {2012-08-17 16:36:28},
    priority = {2},
    publisher = {IEEE},
    title = {Empirical Research in Software Process Modeling: A Systematic Literature Review},
    url = {http://dx.doi.org/10.1109/esem.2011.43},
    year = {2011}
}

@electronic{citeulike:11077707,
    citeulike-article-id = {11077707},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/9783642281075},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9783642281075},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9783642281075\&index=books\&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/9783642281075},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/779598753},
    isbn = {9783642281075},
    posted-at = {2012-08-17 13:02:02},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Business Process Management Workshops {BPM} 2011 International Workshops, {Clermont-Ferrand}, France,
August 29, 2011, Revised Selected Papers, Part I},
    url = {http://www.worldcat.org/isbn/9783642281075},
    year = {2012}
}

@inproceedings{citeulike:11061107,
    abstract = {Software engineering research has long borrowed and adapted ideas from other disciplines to adapt to the
peculiar context of building software. That context is less and less peculiar, as automation and communication transform
other fields, and it is time for us to consider how approaches developed in software engineering can be transferred and
generalized to other fields. Considering generalization of software engineering to domains outside computer science has
implications for both software engineering research and education.},
    address = {New York, NY, USA},
    author = {Young, Michal and Faulk, Stuart},
    booktitle = {Proceedings of the FSE/SDP workshop on Future of software engineering research},
    citeulike-article-id = {11061107},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1882451},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1882362.1882451},
    doi = {10.1145/1882362.1882451},
    isbn = {978-1-4503-0427-6},
    location = {Santa Fe, New Mexico, USA},
    pages = {439--442},
    posted-at = {2012-08-14 11:39:13},
    priority = {2},
    publisher = {ACM},
    series = {FoSER '10},
    title = {Sharing what we know about software engineering},
    url = {http://dx.doi.org/10.1145/1882362.1882451},
    year = {2010}
}

@book{citeulike:11058784,
    author = {Hoover, Dave H. and Oshineye, Adewale},
    citeulike-article-id = {11058784},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/0596518382},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN0596518382},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=0596518382\&index=books\&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/0596518382},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/465234765},
    isbn = {0596518382},
    posted-at = {2012-08-13 18:07:02},
    priority = {2},
    publisher = {O'Reilly Media},
    title = {Apprenticeship patterns: guidance for the aspiring software craftsman},
    url = {http://www.worldcat.org/isbn/0596518382},
    year = {2009}
}

@book{citeulike:11058561,
    abstract = {Software Craftsmanship presents an alternative--a craft model that focuses on the people involved in
commercial software development. This book illustrates that it is imperative to turn from the
technology-for-its-own-sake model to one that is grounded in delivering value to customers. The author, Pete {McBreen},
presents a method to nurture mastery in the programmer, develop creative collaboration in small developer teams, and
enhance communications with the customer. The end result--skilled developers who can create, extend, and enhance robust
applications.},
    address = {Boston, MA, USA},
    citeulike-article-id = {11058561},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=500816},
    isbn = {0-201-73386-2},
    posted-at = {2012-08-13 17:27:11},
    priority = {2},
    publisher = {Addison-Wesley Longman Publishing Co., Inc.},
    title = {Software craftsmanship: the new imperative},
    url = {http://portal.acm.org/citation.cfm?id=500816},
    year = {2002}
}

@inproceedings{citeulike:11058554,
    abstract = {Art and Science are usually seen as quite distinct tasks and not supportive of each other or similar at
all. Isn't art all about creativity and abstract beauty, while computer sci-ence is about logic, truths and problem
solving? Can these two practices really be related in any way? Our primary objective is to show the benefits of arts to
software development. First we reflect on the concept of how Art and Science are similar. Then we report our thoughts
about the relation of different types of art to Computer Science such as theater, music, painting, and poetry.},
    address = {New York, NY, USA},
    author = {Cukier, Daniel and Yoder, Joseph W.},
    booktitle = {Proceedings of the 10th SIGPLAN symposium on New ideas, new paradigms, and reflections on programming
and software},
    citeulike-article-id = {11058554},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2089134},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2089131.2089134},
    doi = {10.1145/2089131.2089134},
    isbn = {978-1-4503-0941-7},
    location = {Portland, Oregon, USA},
    pages = {129--136},
    posted-at = {2012-08-13 17:26:17},
    priority = {2},
    publisher = {ACM},
    series = {ONWARD '11},
    title = {The artist in the computer scientist: more humanity to our research},
    url = {http://dx.doi.org/10.1145/2089131.2089134},
    year = {2011}
}

@book{citeulike:11045694,
    author = {Brooks, Frederick P.},
    citeulike-article-id = {11045694},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/9780201835953},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9780201835953},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9780201835953\&index=books\&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/9780201835953},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/423457752},
    isbn = {9780201835953},
    posted-at = {2012-08-11 17:51:23},
    priority = {2},
    publisher = {Addison-Wesley Pub. Co.},
    title = {The mythical man-month : essays on software engineering},
    url = {http://www.worldcat.org/isbn/9780201835953},
    year = {1995}
}

@techreport{citeulike:11045517,
    citeulike-article-id = {11045517},
    day = {17},
    howpublished = {Unpublished},
    location = {http://www.acm.org/serving/se\_policy/selep\_main.html},
    month = jul,
    posted-at = {2012-08-11 17:23:51},
    priority = {2},
    title = {A Summary of the {ACM} Position on Software Engineering as a Licensed Profession},
    year = {2000}
}

@inproceedings{citeulike:11045481,
    abstract = {Summary form only given. Many masters-level programs have been created to address the need for more
professional software engineers. A question remains, however, as to the place for software engineering in undergraduate
studies. To date, most work in undergraduate software engineering education has been performed by small clusters of
computer science and engineering faculty, widely dispersed throughout academia. Building on recommendations from the
Software Engineering Institute ({SEI}), the Association for Computing Machinery ({ACM}), and the {IEEE} Computer
Society, these initial efforts have begun to bear fruit. Typically, the result is a set of software engineering courses
arranged according to one of the following formats: (a) an elective or required course sequence; (b) elective noncredit
paracticums; and (c) software engineering topics introduced in existing courses. The paper discusses: (a) What is the
proper relationship between typical engineering programs and those in software 
engineering? (b) How should software engineering education differ from both computer science and computer engineering?
(c) If undergraduate program degrees in software engineering are developed, how should such programs interact with other
engineering programs? and (d) How are minors and concentrations in software engineering affected by the presence of a
baccalaureate in software engineering?},
    author = {Naveda, J. F. and Lutz, M. J. and Hillburn, T. B. and Northrup, L. M. and Stinson, M. C.},
    booktitle = {Frontiers in Education Conference, 1997. 27th Annual Conference. \&\#039;Teaching and Learning in an
Era of Change\&\#039;. Proceedings.},
    citeulike-article-id = {11045481},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/fie.1997.635933},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=635933},
    doi = {10.1109/fie.1997.635933},
    institution = {Dept. of Comput. Sci., Rochester Inst. of Technol., NY},
    isbn = {0-7803-4086-8},
    month = nov,
    pages = {750 vol.2+},
    posted-at = {2012-08-11 17:14:18},
    priority = {2},
    publisher = {IEEE},
    title = {The role of software engineering in undergraduate education},
    url = {http://dx.doi.org/10.1109/fie.1997.635933},
    volume = {2},
    year = {1997}
}

@inproceedings{citeulike:11045472,
    abstract = {An evaluation of the current state of developments in the field of software engineering ({SE})
professionalism is presented including the effect of {ACM} withdrawing from the {IEEE}-{CS}/{ACM} Software Engineering
Coordinating Committee ({SWECC}). An examination is made of two of the projects initiated by {SWECC}: that defining the
Software Engineering Code of Ethics and Professional Practice and that providing a Guide to a Software Engineering Body
of Knowledge. The successes and problems associated with each are highlighted. Details are presented of a project
supported by the International Federation of Information Processing, concerned with the harmonisation of professional
standards, which could now be very relevant to re-establishing progress on the road to a {SE} profession. Efforts
undertaken to promote this work to the {SE} community are also reported. Finally overall conclusions and recommendations
are given that could improve the situation in the future},
    author = {Thompson, J. B.},
    booktitle = {Computer Software and Applications Conference, 2001. COMPSAC 2001. 25th Annual International},
    citeulike-article-id = {11045472},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/cmpsac.2001.960596},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=960596},
    doi = {10.1109/cmpsac.2001.960596},
    institution = {Sch. of Comput., Univ. of Sunderland},
    isbn = {0-7695-1372-7},
    issn = {0730-3157},
    pages = {39--45},
    posted-at = {2012-08-11 17:13:07},
    priority = {2},
    publisher = {IEEE},
    title = {A long and winding road (Progress on the road to a software engineering profession)},
    url = {http://dx.doi.org/10.1109/cmpsac.2001.960596},
    year = {2001}
}

@inproceedings{citeulike:11044022,
    abstract = {The report issued by the Inquiry Board in charge of inspecting the Ariane 5 flight 501 failure concludes
that causes of the failure are rooted in poor {S/W} Engineering practice. From the failure scenario described in the
Inquiry Board report, it is possible to infer what, in our view, are the real causes of the 501 failure. We develop
arguments to demonstrate that the real causes of the 501 failure are neither {S/W} specification errors nor {S/W} design
errors. Real causes of the failure are faults in the capture of the overall Ariane 5 application/environment
requirements, and faults in the design and the dimensioning of the Ariane 5 on-board computing system. These faults
result from not following a rigorous system engineering approach, such as applying a proof-based System Engineering
method. A definition of proof-based System Engineering for Computing Systems is also presented},
    author = {Le Lann, G.},
    booktitle = {Engineering of Computer-Based Systems, 1997. Proceedings., International Conference and Workshop on},
    citeulike-article-id = {11044022},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ecbs.1997.581900},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=581900},
    doi = {10.1109/ecbs.1997.581900},
    institution = {Inst. Nat. de Recherche en Inf. et Autom., Le Chesnay},
    isbn = {0-8186-7889-5},
    month = mar,
    pages = {339--346},
    posted-at = {2012-08-11 12:46:18},
    priority = {2},
    publisher = {IEEE},
    title = {An analysis of the Ariane 5 flight 501 failure-a system engineering perspective},
    url = {http://dx.doi.org/10.1109/ecbs.1997.581900},
    year = {1997}
}

@article{citeulike:11020197,
    abstract = {Software applications developed within the {OSS} community have enjoyed tremendous success and forprofit
organizations are keen to tap into this significant pool of software development talent. These companies seek to benefit
from the talent of a global and sometimes voluntary workforce by paying some employees to contribute to {OSS} projects.
This merging of open and traditional software development may cause developer stress based on conflicting {OSS}
community and traditional software development norms. Specifically, developers must balance company intellectual
property concerns with the reciprocal and community-based norms that drive {OSS} development. When these values are not
in sync, contributors that aim to abide by conflicting values may exhibit dysfunctional attitudes. Employee stress with
respect to their role can be destructive to organizational outcomes. This study develops an {OSS} context specific model
that describes the relationship between clashing software development 
cultures and employee organizational commitment. We leverage the rich {OSS} literature and the research that focuses on
organizational-professional conflict ({OPC}) to develop hypotheses linking clashing cultures and organizational
commitment. These hypotheses are tested using a combination of archival data and a survey of 127 {GNOME} developers. The
findings presented in this paper contribute to {OSS} literature and},
    author = {Daniel, Sherae and Maruping, Likeobe and Cataldo, Marcelo and Herbsleb, James D.},
    citeulike-article-id = {11020197},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.206.3894},
    posted-at = {2012-08-06 04:52:20},
    priority = {2},
    title = {When Cultures Clash: Participation in Open Source Communities and Its Implications For Organizational
Commitment},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.206.3894},
    year = {2011}
}

@article{citeulike:712058,
    abstract = {Between June 1985 and January 1987, the Therac-25 medical electron accelerator was involved in six
massive radiation overdoses. As a result, several people died and others were seriously injured. A detailed
investigation of the factors involved in the software-related overdoses and attempts by users, manufacturers, and
government agencies to deal with the accidents is presented. The authors demonstrate the complex nature of accidents and
the need to investigate all aspects of system development and operation in order to prevent future accidents. The
authors also present some lessons learned in terms of system engineering, software engineering, and government
regulation of safety-critical systems containing software components.>},
    address = {Los Alamitos, CA, USA},
    author = {Leveson, N. G. and Turner, C. S.},
    citeulike-article-id = {712058},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=161477.161479},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/MC.1993.274940},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/mc.1993.274940},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=274940},
    doi = {10.1109/mc.1993.274940},
    institution = {Dept. of Comput. Sci. \& Eng., Washington Univ., Seattle, WA},
    issn = {0018-9162},
    journal = {Computer},
    month = jul,
    number = {7},
    pages = {18--41},
    posted-at = {2012-08-05 07:28:03},
    priority = {2},
    publisher = {IEEE},
    title = {An investigation of the Therac-25 accidents},
    url = {http://dx.doi.org/10.1109/mc.1993.274940},
    volume = {26},
    year = {1993}
}

@inproceedings{csdl2-11-10,
    abstract = {Within the ﬁeld of software repository mining
({MSR}) researchers deal with a problem of discovery of interesting and 
actionable information about software projects. It is
a common practice to perform analyzes on the various levels
of abstraction of change events, for example by aggregating
change-events into time-series. Following this, I investigate
the applicability of {SAX}-based approximation and indexing of
time-series with tf∗idf weights in order to discover recurrent
behaviors within development process. The proposed workﬂow
starts by extracting and aggregating of revision control data
and followed by reduction and transformation of aggregated
data into symbolic space with {PAA} and {SAX}. Resulting {SAX}
words then grouped into dictionaries associated with software
process constraints known to inﬂuence behaviors, such as time,
location, employment, etc. These, in turn, are investigated with
the use of tf∗idf statistics as a dissimilarity measure in order
to discover behavioral patterns.
As a proof of the concept I have applied this technique to
software process artifact trails corresponding to Android {OS}
development, where it was able to discover recurrent behaviors
in the  ” new code lines dynamics” before and after release.
By building a classiﬁer upon these behaviors, I was able to
successfully recognize pre- and post-release behaviors within
the same and similar sub-projects of Android {OS}.},
    author = {Senin, Pavel},
    booktitle = {Software Engineering Research and Practice},
    citeulike-article-id = {10692397},
    citeulike-linkout-0 = {\url{http://www2.hawaii.edu/~senin/assets/papers/Android-senin-draft.pdf}},
    keywords = {hackystat, publications-conferences, trajectory},
    location = {Las Vegas, NV, USA},
    month = may,
    posted-at = {2012-05-22 09:19:25},
    priority = {2},
    title = {Recognizing recurrent development behaviors corresponding to Android {OS} release life-cycle},
    url = {http://www2.hawaii.edu/\~{}senin/papers/serp12.pdf},
    year = {2012}
}

@inproceedings{citeulike:4066024,
    abstract = {The term weighting function known as {IDF} was proposed in 1972, and has since been extremely widely
used, usually as part of a {TF}*{IDF} function. It is often described as a heuristic, and many papers have been written
(some based on Shannon\^{a}s Information Theory) seeking to establish some theoretical basis for it. Some of these
attempts are reviewed, and it is shown that the Information Theory approaches are problematic, but that there are good
theoretical justifications of both {IDF} and {TF}*{IDF} in traditional probabilistic model of information retrieval.},
    author = {Robertson, Stephen},
    booktitle = {Journal of Documentation},
    citeulike-article-id = {4066024},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.97.7340},
    journal = {Journal of Documentation},
    posted-at = {2012-04-22 09:56:20},
    priority = {2},
    title = {Understanding inverse document frequency: On theoretical arguments for {IDF}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.97.7340},
    volume = {60},
    year = {2004}
}

@inproceedings{citeulike:8687811,
    abstract = {The exhaustivity of document descriptions and the specificity of index terms are usually regarded as
independent. It is suggested that specificity should be interpreted statistically, as a function of term use rather than
of term meaning. The effects on retrieval of variations in term specificity are examined, experiments with three test
collections showing, in particular, that frequently-occurring terms are required for good overall performance. It is
argued that terms should be weighted according to collection frequency, so that matches on less frequent, more specific,
terms are of greater value than matches on frequent terms. Results for the test collections show that considerable
improvements in performance are obtained with this very simple procedure. Exhaustivity and specificity We are familiar
with the notions of exhaustivity and specificity: exhaustivity is a property of index descriptions, and specificity one
of index terms. They are most clearly illustrated by a simple keyword or 
descriptor system. In this case the exhaustivity of a document description is the coverage of its various topics given
by the terms assigned to it; and the specificity of an individual term is the level of detail at which a given concept
is represented.},
    author = {Jones, Karen S.},
    booktitle = {Journal of Documentation},
    citeulike-article-id = {8687811},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.115.8343},
    journal = {Journal of Documentation},
    pages = {11--21},
    posted-at = {2012-04-22 09:55:32},
    priority = {2},
    title = {A statistical interpretation of term specificity and its application in retrieval},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.115.8343},
    volume = {28},
    year = {1972}
}

@article{citeulike:1296888,
    abstract = {Previous taxonomies of software change have focused on the purpose of the change (i.e., the why) rather
than the underlying mechanisms. This paper proposes a taxonomy of software change based on characterizing the mechanisms
of change and the factors that influence these mechanisms. The ultimate goal of this taxonomy is to provide a framework
that positions concrete tools, formalisms and methods within the domain of software evolution. Such a framework would
considerably ease comparison between the various mechanisms of change. It would also allow practitioners to identify and
evaluate the relevant tools, methods and formalisms for a particular change scenario. As an initial step towards this
taxonomy, the paper presents a framework that can be used to characterize software change support tools and to identify
the factors that impact on the use of these tools. The framework is evaluated by applying it to three different change
support tools and by comparing these tools based on this analysis. 
Copyright {\copyright} 2005 John Wiley \& Sons, Ltd.},
    address = {New York, NY, USA},
    author = {Buckley, Jim and Mens, Tom and Zenger, Matthias and Rashid, Awais and Kniesel, G\"{u}nter},
    citeulike-article-id = {1296888},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1090747},
    citeulike-linkout-1 = {http://dx.doi.org/10.1002/smr.v17:5},
    doi = {10.1002/smr.v17:5},
    issn = {1532-060X},
    journal = {J. Softw. Maint. Evol.},
    month = sep,
    number = {5},
    pages = {309--332},
    posted-at = {2012-04-05 14:59:54},
    priority = {2},
    publisher = {John Wiley \&amp; Sons, Inc.},
    title = {Towards a taxonomy of software change: Research Articles},
    url = {http://dx.doi.org/10.1002/smr.v17:5},
    volume = {17},
    year = {2005}
}

@article{citeulike:6701412,
    abstract = {Frequent itemset originates from association rule mining. Recently, it has been applied in text mining
such as document categorization, clustering, etc. In this paper, we conduct a study on text clustering using frequent
itemsets. The main contribution of this paper is three manifolds. First, we present a review on existing methods of
document clustering using frequent patterns. Second, a new method called Maximum Capturing is proposed for document
clustering. Maximum Capturing includes two procedures: constructing document clusters and assigning cluster topics. We
develop three versions of Maximum Capturing based on three similarity measures. We propose a normalization process based
on frequency sensitive competitive learning for Maximum Capturing to merge cluster candidates into predefined number of
clusters. Third, experiments are carried out to evaluate the proposed method in comparison with {CFWS}, {CMS}, {FTC} and
{FIHC} methods. Experiment results show that in clustering, Maximum 
Capturing has better performances than other methods mentioned above. Particularly, Maximum Capturing with
representation using individual words and similarity measure using asymmetrical binary similarity achieves the best
performance. Moreover, topics produced by Maximum Capturing distinguished clusters from each other and can be used as
labels of document clusters.},
    author = {Zhang, Wen and Yoshida, Taketoshi and Tang, Xijin and Wang, Qing},
    citeulike-article-id = {6701412},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.knosys.2010.01.011},
    day = {01},
    doi = {10.1016/j.knosys.2010.01.011},
    issn = {09507051},
    journal = {Knowledge-Based Systems},
    month = jul,
    number = {5},
    pages = {379--388},
    posted-at = {2012-04-02 08:08:58},
    priority = {2},
    title = {Text clustering using frequent itemsets},
    url = {http://dx.doi.org/10.1016/j.knosys.2010.01.011},
    volume = {23},
    year = {2010}
}

@article{citeulike:10520047,
    abstract = {A high-performance {FAQ} retrieval system uses query-log clustering to resolve lexical-disagreement
problems. The proposed system outperforms traditional information-retrieval systems in {FAQ} retrieval.},
    author = {Kim, Harksoo and Seo, Jungyun},
    citeulike-article-id = {10520047},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/mis.2008.23},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4475860},
    doi = {10.1109/mis.2008.23},
    issn = {1541-1672},
    journal = {IEEE Intelligent Systems},
    month = mar,
    number = {2},
    pages = {58--65},
    posted-at = {2012-04-02 08:03:44},
    priority = {2},
    title = {{Cluster-Based} {FAQ} Retrieval Using Latent Term Weights},
    url = {http://dx.doi.org/10.1109/mis.2008.23},
    volume = {23},
    year = {2008}
}

@electronic{citeulike:10516186,
    author = {De Carvalho, Andre},
    citeulike-article-id = {10516186},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/9783642148828},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9783642148828},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9783642148828\&index=books\&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/9783642148828},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/698588997},
    isbn = {9783642148828},
    posted-at = {2012-04-01 08:12:38},
    priority = {2},
    publisher = {Springer},
    title = {Distributed computing and artificial intelligence 7th international symposium},
    url = {http://www.worldcat.org/isbn/9783642148828},
    year = {2010}
}

@incollection{citeulike:10516185,
    abstract = {Recently the number of interactions between a company and its customers has been increased and it has
taken a lot of time and cost of help desk operators. Companies construct {FAQ} pages in their web site and try to
provide better services for their customer, however it takes surplus costs to analyze stored inquiries and extract
frequent questions and answers. In this paper the authors propose a classification method of inquiry e-mails for
describing {FAQ} (Frequently Asked Questions). In this method, a dictionary used for classification of inquiries is
generated and updated automatically by statistical information of characteristic words in clusters, and inquiries are
classified correctly to a proper cluster. This method achieved 70 percent precision of inquiry classification in an
experiment with practical data stored in the registration management system for a sports association.},
    address = {Berlin, Heidelberg},
    author = {Iwai, Koichi and Iida, Kaoru and Akiyoshi, Masanori and Komoda, Norihisa},
    booktitle = {Distributed Computing and Artificial Intelligence},
    chapter = {5},
    citeulike-article-id = {10516185},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-14883-5\_5},
    citeulike-linkout-1 = {http://www.springerlink.com/content/962h832280wn6r68},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-642-14883-5\_5},
    doi = {10.1007/978-3-642-14883-5\_5},
    editor = {Leon and Rodr\'{\i}guez-Gonz\'{a}lez, Sara and Paz Santana, JuanF and Rodr\'{\i}guez, JuanM},
    isbn = {978-3-642-14882-8},
    pages = {35--43},
    posted-at = {2012-04-01 08:12:05},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Advances in Intelligent and Soft Computing},
    title = {A Classification Method of Inquiry {e-Mails} for Describing {FAQ} with Self-configured Class Dictionary},
    url = {http://dx.doi.org/10.1007/978-3-642-14883-5\_5},
    volume = {79},
    year = {2010}
}

@article{citeulike:10516174,
    abstract = {Most of existing text clustering algorithms use the vector space model, which treats documents as bags
of words. Thus, word sequences in the documents are ignored, while the meaning of natural languages strongly depends on
them. In this paper, we propose two new text clustering algorithms, named Clustering based on Frequent Word Sequences
({CFWS}) and Clustering based on Frequent Word Meaning Sequences ({CFWMS}). A word is the word form showing in the
document, and a word meaning is the concept expressed by synonymous word forms. A word (meaning) sequence is frequent if
it occurs in more than certain percentage of the documents in the text database. The frequent word (meaning) sequences
can provide compact and valuable information about those text documents. For experiments, we used the Reuters-21578 text
collection, {CISI} documents of the Classic data set [Classic data set, ftp://ftp.cs.cornell.edu/pub/smart/], and a
corpus of the Text Retrieval Conference ({TREC}) [High Accuracy Retrieval 
from Documents ({HARD}) Track of Text Retrieval Conference, 2004]. Our experimental results show that {CFWS} and {CFWMS}
have much better clustering accuracy than Bisecting k-means ({BKM}) [M. Steinbach, G. Karypis, V. Kumar, A Comparison of
Document Clustering Techniques, {KDD}-2000 Workshop on Text Mining, 2000], a modified bisecting k-means using background
knowledge ({BBK}) [A. Hotho, S. Staab, G. Stumme, Ontologies improve text document clustering, in: Proceedings of the
3rd {IEEE} International Conference on Data Mining, 2003, pp. 541–544] and Frequent Itemset-based Hierarchical
Clustering ({FIHC}) [{B.C}.M. Fung, K. Wang, M. Ester, Hierarchical document clustering using frequent itemsets, in:
Proceedings of {SIAM} International Conference on Data Mining, 2003] algorithms.},
    address = {Amsterdam, The Netherlands, The Netherlands},
    author = {Li, Yanjun and Chung, Soon M. and Holt, John D.},
    citeulike-article-id = {10516174},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1321938},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.datak.2007.08.001},
    doi = {10.1016/j.datak.2007.08.001},
    issn = {0169023X},
    journal = {Data \& Knowledge Engineering},
    month = jan,
    number = {1},
    pages = {381--404},
    posted-at = {2012-04-01 07:40:51},
    priority = {2},
    publisher = {Elsevier Science Publishers B. V.},
    title = {Text document clustering based on frequent word meaning sequences},
    url = {http://dx.doi.org/10.1016/j.datak.2007.08.001},
    volume = {64},
    year = {2008}
}

@inproceedings{citeulike:10513234,
    abstract = {Time series discord has proven to be a useful concept for time-series anomaly identification. To search
for discords, various algorithms have been developed. Most of these algorithms rely on pre-building an index (such as a
trie) for subsequences. Users of these algorithms are typically required to choose optimal values for word-length and/or
alphabet-size parameters of the index, which are not intuitive. In this paper, we propose an algorithm to directly
search for the {top-K} discords, without the requirement of building an index or tuning external parameters. The
algorithm exploits quasi-periodicity present in many time series. For quasi-periodic time series, the algorithm gains
significant speedup by reducing the number of calls to the distance function.},
    address = {Berlin, Heidelberg},
    author = {Luo, Wei and Gallagher, Marcus},
    booktitle = {Proceedings of the 15th Pacific-Asia conference on Advances in knowledge discovery and data mining -
Volume Part II},
    citeulike-article-id = {10513234},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2022862},
    isbn = {978-3-642-20846-1},
    location = {Shenzhen, China},
    pages = {135--148},
    posted-at = {2012-03-30 18:00:42},
    priority = {2},
    publisher = {Springer-Verlag},
    series = {PAKDD'11},
    title = {Faster and parameter-free discord search in quasi-periodic time series},
    url = {http://portal.acm.org/citation.cfm?id=2022862},
    year = {2011}
}

@inproceedings{citeulike:7853299,
    abstract = {Source control repositories, bug repositories, archived communications, deployment logs, and code
repositories are examples of software repositories that are commonly available for most software projects. The mining
software repositories ({MSR}) field analyzes and cross-links the rich data available in these repositories to uncover
interesting and actionable information about software systems. By transforming these repositories from static
record-keeping ones into active repositories, we can guide decision processes in modern software projects. For example,
data in source control repositories, traditionally used to archive code, could be linked with data in bug repositories
to help practitioners propagate complex changes and to warn them about risky code based on prior changes and bugs. In
this paper, we present a brief history of the {MSR} field and discuss several recent achievements and results of using
{MSR} techniques to support software research and practice. We then discuss the various 
opportunities and challenges that lie in the road ahead for this important and emerging field.},
    author = {Hassan, Ahmed E.},
    booktitle = {2008 Frontiers of Software Maintenance},
    citeulike-article-id = {7853299},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/fosm.2008.4659248},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4659248},
    doi = {10.1109/fosm.2008.4659248},
    institution = {Sch. of Comput., Queen's Univ., Kingston, ON},
    isbn = {978-1-4244-2654-6},
    location = {Beijing, China},
    month = sep,
    pages = {48--57},
    posted-at = {2012-03-27 15:02:47},
    priority = {2},
    publisher = {IEEE},
    title = {The road ahead for Mining Software Repositories},
    url = {http://dx.doi.org/10.1109/fosm.2008.4659248},
    year = {2008}
}

@article{citeulike:9919804,
    abstract = {Determining the factors that have an influence on software systems development and deployment project
outcomes has been the focus of extensive and ongoing research for more than 30 years. We provide here a survey of the
research literature that has addressed this topic in the period 1996–2006, with a particular focus on empirical
analyses. On the basis of this survey we present a new classification framework that represents an abstracted and
synthesized view of the types of factors that have been asserted as influencing project outcomes.},
    address = {New York, NY, USA},
    author = {McLeod, Laurie and MacDonell, Stephen G.},
    citeulike-article-id = {9919804},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1978803},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1978802.1978803},
    doi = {10.1145/1978802.1978803},
    issn = {0360-0300},
    journal = {ACM Comput. Surv.},
    month = oct,
    number = {4},
    posted-at = {2012-03-27 14:44:32},
    priority = {2},
    publisher = {ACM},
    title = {Factors that affect software systems development project outcomes: A survey of research},
    url = {http://dx.doi.org/10.1145/1978802.1978803},
    volume = {43},
    year = {2011}
}

@article{citeulike:7985580,
    abstract = {The Minimum Quartet Tree Cost problem is to construct an optimal weight tree from the weighted quartet
topologies on n objects, where optimality means that the summed weight of the embedded quartet topologies is optimal (so
it can be the case that the optimal tree embeds all quartets as nonoptimal topologies). We present a Monte Carlo
heuristic, based on randomized hill-climbing, for approximating the optimal weight tree, given the quartet topology
weights. The method repeatedly transforms a dendrogram, with all objects involved as leaves, achieving a monotonic
approximation to the exact single globally optimal tree. The problem and the solution heuristic has been extensively
used for general hierarchical clustering of nontree-like (non-phylogeny) data in various domains and across domains with
heterogeneous data. We also present a greatly improved heuristic, reducing the running time by a factor of order a
thousand to ten thousand. All this is implemented and available, as part of the {
CompLearn} package. We compare performance and running time of the original and improved versions with those of {UPGMA},
{BioNJ}, and {NJ}, as implemented in the {SplitsTree} package on genomic data for which the latter are optimized.},
    author = {Cilibrasi, Rudi L. and Vit\'{a}nyi, Paul M. B.},
    citeulike-article-id = {7985580},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.patcog.2010.08.033},
    day = {06},
    doi = {10.1016/j.patcog.2010.08.033},
    issn = {00313203},
    journal = {Pattern Recognition},
    month = mar,
    number = {3},
    pages = {662--677},
    posted-at = {2012-03-23 09:16:10},
    priority = {2},
    title = {A Fast Quartet tree heuristic for hierarchical clustering},
    url = {http://dx.doi.org/10.1016/j.patcog.2010.08.033},
    volume = {44},
    year = {2011}
}

@article{citeulike:1717609,
    abstract = {Words and phrases acquire meaning from the way they are used in society, from their relative semantics
to other words and phrases. For computers, the equivalent of "society" is "database," and the equivalent of "use" is "a
way to search the database". We present a new theory of similarity between words and phrases based on information
distance and Kolmogorov complexity. To fix thoughts, we use the World Wide Web ({WWW}) as the database, and Google as
the search engine. The method is also applicable to other search engines and databases. This theory is then applied to
construct a method to automatically extract similarity, the Google similarity distance, of words and phrases from the
{WWW} using Google page counts. The {WWW} is the largest database on earth, and the context information entered by
millions of independent users averages out to provide automatic semantics of useful quality. We give applications in
hierarchical clustering, classification, and language translation. We give examples 
to distinguish between colors and numbers, cluster names of paintings by 17th century Dutch masters and names of books
by English novelists, the ability to understand emergencies and primes, and we demonstrate the ability to do a simple
automatic {English-Spanish} translation. Finally, we use the {WordNet} database as an objective baseline against which
to judge the performance of our method. We conduct a massive randomized trial in binary classification using support
vector machines to learn categories based on our Google distance, resulting in an a mean agreement of 87 percent with
the expert crafted {WordNet} categories},
    address = {Piscataway, NJ, USA},
    author = {Cilibrasi, R. L. and Vitanyi, P. M. B.},
    citeulike-article-id = {1717609},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1263333},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/TKDE.2007.48},
    citeulike-linkout-2 = {http://dblp.uni-trier.de/rec/bibtex/journals/tkde/CilibrasiV07},
    citeulike-linkout-3 = {http://dx.doi.org/10.1109/tkde.2007.48},
    citeulike-linkout-4 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4072748},
    doi = {10.1109/tkde.2007.48},
    institution = {CWI, Amsterdam},
    issn = {1041-4347},
    journal = {Knowledge and Data Engineering, IEEE Transactions on},
    month = mar,
    number = {3},
    pages = {370--383},
    posted-at = {2012-03-23 09:14:55},
    priority = {2},
    publisher = {IEEE},
    title = {The Google Similarity Distance},
    url = {http://dx.doi.org/10.1109/tkde.2007.48},
    volume = {19},
    year = {2007}
}

@incollection{citeulike:10490042,
    abstract = {Time series data-mining algorithms usually scale poorly with regard to dimensionality. Symbolic
representations have proven to be a very effective way to reduce the dimensionality of time series even using simple
aggregations over episodes of the same length and a fixed set of symbols. However, computing adaptive symbolic
representations would enable more accurate representations of the dataset without compromising the dimensionality
reduction. Therefore we propose a new generic framework to compute adaptive Segmentation Based Symbolic Representations
({SBSR}) of time series. {SBSR} can be applied to any model but we focus on piecewise constant models ({SBSRL0}) which
are the most commonly used. {SBSR} are built by computing both the episode boundaries and the symbolic alphabet in order
to minimize information loss of the resulting symbolic representation. We also propose a new distance measure for
{SBSRL0} tightly lower bounding the euclidean distance measure.},
    address = {Berlin, Heidelberg},
    author = {Hugueney, Bernard},
    chapter = {54},
    citeulike-article-id = {10490042},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11871637\_54},
    citeulike-linkout-1 = {http://www.springerlink.com/content/q841685q716381hl},
    doi = {10.1007/11871637\_54},
    editor = {F\"{u}rnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
    isbn = {978-3-540-45374-1},
    pages = {545--552},
    posted-at = {2012-03-23 09:13:07},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Adaptive {Segmentation-Based} Symbolic Representations of Time Series for Better Modeling and Lower
Bounding Distance Measures Knowledge Discovery in Databases: {PKDD} 2006},
    url = {http://dx.doi.org/10.1007/11871637\_54},
    volume = {4213},
    year = {2006}
}

@article{citeulike:10490031,
    abstract = {The problem of finding a specified pattern in a time series database (i.e., query by content) has
received much attention and is now a relatively mature field. In contrast, the important problem of enumerating all
surprising or interesting patterns has received far less attention. This problem requires a meaningful definition of  ”
surprise”, and an efficient search technique. All previous attempts at finding surprising patterns in time series use a
very limited notion of surprise, and/or do not scale to massive datasets. To overcome these limitations we propose a
novel technique that defines a pattern surprising if the frequency of its occurrence differs substantially from that
expected by chance, given some previously seen data. This notion has the advantage of not requiring the user to
explicitly define what is a surprising pattern, which may be hard, or perhaps impossible, to elicit from a domain
expert. Instead, the user gives the algorithm a collection of previously observed  ” normal” 
data. Our algorithm uses a suffix tree to efficiently encode the frequency of all observed patterns and allows a Markov
model to predict the expected frequency of previously unobserved patterns. Once the suffix tree has been constructed, a
measure of surprise for all the patterns in a new database can be determined in time and space linear in the size of the
database. We demonstrate the utility of our approach with an extensive experimental evaluation.},
    author = {Lonardi, Stefano and Lin, Jessica and Keogh, Eamonn and Chiu, Bill},
    citeulike-article-id = {10490031},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00354-006-0004-2},
    citeulike-linkout-1 = {http://www.springerlink.com/content/a14r415114673512},
    day = {4},
    doi = {10.1007/s00354-006-0004-2},
    issn = {0288-3635},
    journal = {New Generation Computing},
    month = nov,
    number = {1},
    pages = {61--93},
    posted-at = {2012-03-23 09:11:39},
    priority = {2},
    publisher = {Ohmsha, Ltd.},
    title = {Efficient Discovery of Unusual Patterns in Time Series},
    url = {http://dx.doi.org/10.1007/s00354-006-0004-2},
    volume = {25},
    year = {2006}
}

@article{citeulike:9692670,
    abstract = {Time series of remote sensing imagery or derived vegetation indices and biophysical products have been
shown particularly useful to characterize land ecosystem dynamics. Various methods have been developed based on temporal
trajectory analysis to characterize, classify and detect changes in ecosystem dynamics. Although time series similarity
measures play an important role in these methods, a quantitative comparison of the similarity measures is lacking. The
objective of this study was to provide an overview and quantitative comparison of the similarity measures in function of
varying time series and ecosystem characteristics, such as amplitude, timing and noise effects. For this purpose, the
performance was evaluated for the commonly used similarity measures (D), ranging from Manhattan ({DMan}), Euclidean
({DE}) and Mahalanobis ({DMah}) distance measures, to correlation ({DCC}), Principal Component Analysis ({PCA}; {DPCA})
and Fourier based ({DFFT},{D\^{I}¾,DFk}) similarities. The 
quantitative comparison consists of a series of {Monte-Carlo} simulations based on subsets of global {MODIS} Normalized
Difference Vegetation index ({NDVI}) and Enhanced Vegetation Index ({EVI}) and Leaf Area Index ({LAI}) data. Results of
the simulations reveal four main groups of time series similarity measures with different sensitivities: (i) {DMan},
{DE}, {DPCA}, {DFk} quantify the difference in time series values, (ii) {DMah} accounts for temporal correlation and
non-stationarity of variance, (iii) {DCC} measures the temporal correlation, and (iv) the Fourier based {DFFT} and
D\^{I}¾ show their specific sensitivity based on the selected Fourier components. The difference measures show
relatively the highest sensitivity to amplitude effects, whereas the correlation based measures are highly sensitive to
variations in timing and noise. The Fourier based measures, finally, depend highly on the signal to noise ratio and the
balance between amplitude and phase dominance. The heterogeneity in sensitivity of 
each D stresses the importance of (i) understanding the time series characteristics before applying any classification
of change detection approach and (ii) defining the variability one wants to identify/account for. This requires an
understanding of the ecosystem dynamics and time series characteristics related to the baseline, amplitude, timing,
noise and variability of the ecosystem time series. This is also illustrated in the quantitative comparison, where the
different sensitivities of D for the {NDVI}, {EVI}, and {LAI} data relate specifically to the temporal characteristics
of each data set. Additionally, the effect of noise and intra- and interclass variability is demonstrated in a case
study based on land cover classification. \^{a}º A quantitative comparison of time series similarity measures D is
performed. \^{a}º Four groups of D with different sensitivities are obtained. \^{a}º Time series characteristics,
noise and variability affect the performance of D. \^{a}º The sensitivities stress the 
importance of proper selection of similarity measures. \^{a}º Understanding time series properties is crucial for
classification/change detection.},
    author = {Lhermitte, S. and Verbesselt, J. and Verstraeten, W. W. and Coppin, P.},
    citeulike-article-id = {9692670},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.rse.2011.06.020},
    doi = {10.1016/j.rse.2011.06.020},
    issn = {00344257},
    journal = {Remote Sensing of Environment},
    month = dec,
    number = {12},
    pages = {3129--3152},
    posted-at = {2012-03-23 09:09:47},
    priority = {2},
    title = {A comparison of time series similarity measures for classification and change detection of ecosystem
dynamics},
    url = {http://dx.doi.org/10.1016/j.rse.2011.06.020},
    volume = {115},
    year = {2011}
}

@article{citeulike:300440,
    abstract = {Time series clustering has been shown effective in providing useful information in various domains.
There seems to be an increased interest in time series clustering as part of the effort in temporal data mining
research. To provide an overview, this paper surveys and summarizes previous works that investigated the clustering of
time series data in various application domains. The basics of time series clustering are presented, including
general-purpose clustering algorithms commonly used in time series clustering studies, the criteria for evaluating the
performance of the clustering results, and the measures to determine the similarity/dissimilarity between two time
series being compared, either in the forms of raw data, extracted features, or some model parameters. The past researchs
are organized into three groups depending upon whether they work directly with the raw data either in the time or
frequency domain, indirectly with features extracted from the raw data, or indirectly with 
models built from the raw data. The uniqueness and limitation of previous research are discussed and several possible
topics for future research are identified. Moreover, the areas that time series clustering have been applied to are also
summarized, including the sources of data used. It is hoped that this review will serve as the steppingstone for those
interested in advancing this area of research.},
    address = {New York, NY, USA},
    author = {Warren Liao, T.},
    citeulike-article-id = {300440},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1746700},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.patcog.2005.01.025},
    citeulike-linkout-2 =
{http://www.sciencedirect.com/science/article/B6V14-4G7G4BP-2/2/8e96ce614dd47a4a84c6712bd0c43022},
    doi = {10.1016/j.patcog.2005.01.025},
    issn = {00313203},
    journal = {Pattern Recognition},
    month = nov,
    number = {11},
    pages = {1857--1874},
    posted-at = {2012-03-23 09:07:44},
    priority = {2},
    publisher = {Elsevier Science Inc.},
    title = {Clustering of time series data—a survey},
    url = {http://dx.doi.org/10.1016/j.patcog.2005.01.025},
    volume = {38},
    year = {2005}
}

@article{citeulike:8014315,
    abstract = {Time series is an important class of temporal data objects and it can be easily obtained from scientific
and financial applications. A time series is a collection of observations made chronologically. The nature of time
series data includes: large in data size, high dimensionality and necessary to update continuously. Moreover time series
data, which is characterized by its numerical and continuous nature, is always considered as a whole instead of
individual numerical field. The increasing use of time series data has initiated a great deal of research and
development attempts in the field of data mining. The abundant research on time series data mining in the last decade
could hamper the entry of interested researchers, due to its complexity. In this paper, a comprehensive revision on the
existing time series data mining research is given. They are generally categorized into representation and indexing,
similarity measure, segmentation, visualization and mining. Moreover state-of-the-art 
research issues are also highlighted. The primary objective of this paper is to serve as a glossary for interested
researchers to have an overall picture on the current time series data mining development and identify their potential
research direction to further investigation.},
    address = {Tarrytown, NY, USA},
    author = {Fu, Tak-chung},
    citeulike-article-id = {8014315},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1897378},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.engappai.2010.09.007},
    day = {09},
    doi = {10.1016/j.engappai.2010.09.007},
    issn = {09521976},
    journal = {Engineering Applications of Artificial Intelligence},
    month = feb,
    number = {1},
    pages = {164--181},
    posted-at = {2012-03-23 09:05:54},
    priority = {2},
    publisher = {Pergamon Press, Inc.},
    title = {A review on time series data mining},
    url = {http://dx.doi.org/10.1016/j.engappai.2010.09.007},
    volume = {24},
    year = {2011}
}

@inproceedings{citeulike:3013335,
    abstract = {The process of E-type software development and evolution has
proven most difficult to improve, possibly due to the fact that the
process is a multi-input, multi-output system involving feedback at many
levels. This observation, first recorded in the early 1970s during an
extended study of {OS}/360 evolution, was recently captured in a {FEAST}
(Feedback, Evolution And Software Technology) hypothesis: a hypothesis
being studied in on-going two-year project, {FEAST}/1. Preliminary
conclusions based on a study of a financial transaction {system-Logica}'s
Fastwire ({FW})-are outlined and compared with those reached during the
earlier {OS}/360 study. The new analysis supports, or better does not
contradict, the laws of software evolution, suggesting that the 1970s
approach to metric analysis of software evolution is still relevant
today. It is hoped that {FEAST}/1 will provide a foundation for mastering
the feedback aspects of the software evolution process, opening up new
paths for process modelling and improvement},
    author = {Lehman, M. M. and Ramil, J. F. and Wernick, P. D. and Perry, D. E. and Turski, W. M.},
    booktitle = {Software Metrics Symposium, 1997. Proceedings., Fourth International},
    citeulike-article-id = {3013335},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/metric.1997.637156},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=637156},
    doi = {10.1109/metric.1997.637156},
    institution = {Dept. of Comput., Imperial Coll. of Sci., Technol. \& Med., London},
    isbn = {0-8186-8093-8},
    month = nov,
    pages = {20--32},
    posted-at = {2012-03-21 14:51:07},
    priority = {2},
    publisher = {IEEE},
    title = {Metrics and laws of software evolution-the nineties view},
    url = {http://dx.doi.org/10.1109/metric.1997.637156},
    year = {1997}
}

@article{citeulike:10396459,
    author = {Klepeis, N. E. and Nelson, W. C. and Ott, W. R. and Robinson, J. P. and Tsang, A. M. and Switzer, P. and
Behar, J. V. and Hern, S. C. and Engelmann, W. H.},
    citeulike-article-id = {10396459},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/sj.jea.7500165},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/11477521},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=11477521},
    doi = {10.1038/sj.jea.7500165},
    issn = {1053-4245},
    journal = {Journal of exposure analysis and environmental epidemiology},
    number = {3},
    pages = {231--252},
    pmid = {11477521},
    posted-at = {2012-02-29 10:26:43},
    priority = {2},
    title = {The National Human Activity Pattern Survey ({NHAPS}): a resource for assessing exposure to environmental
pollutants.},
    url = {http://dx.doi.org/10.1038/sj.jea.7500165},
    volume = {11},
    year = {2001}
}

@article{citeulike:10392325,
    abstract = {This study compares two North American time–activity data bases: the National Human Activity Pattern
Survey ({NHAPS}) of 9386 interviewees in 1992–1994 in the continental {USA} with the Canadian Human Activity Pattern
Survey ({CHAPS}) of 2381 interviewees in 1996–1997 in four major Canadian cities. Identical surveys and methodology were
used to collect this data: random sample telephone selection within the identified telephone exchanges,
computer-assisted telephone interviews, overselection of children and weekends in the 24-h recall diary and the same
interviewers. Very similar response rates were obtained: 63\% ({NHAPS}) and 64.5\% ({CHAPS}). Results of comparisons by
age within major activity and location groups suggest activity and location patterns are very similar (most differences
being less than 1\% or 14 min in a 24-h day) with the exception of seasonal differences. Canadians spend less time
outdoors in winter and less time indoors in summer than their {U.S}. counterparts. When 
exposure assessments use time of year or outdoor/indoor exposure gradients, these differences may result in significant
differences in exposure assessments. Otherwise, the 24-h time activity patterns of North Americans are remarkably
similar and use of the combined data set for some exposure assessments may be feasible.},
    author = {Leech, Judith A. and Nelson, William C. and Burnett, Richard T. and Aaron, Shawn and Raizenne, Mark E.},
    citeulike-article-id = {10392325},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/sj.jea.7500244},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/7500244a},
    day = {01},
    doi = {10.1038/sj.jea.7500244},
    issn = {1053-4245},
    journal = {Journal of Exposure Science and Environmental Epidemiology},
    month = nov,
    number = {6},
    pages = {427--432},
    posted-at = {2012-02-28 07:54:19},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {It's about time: A comparison of Canadian and American time–activity patterns},
    url = {http://dx.doi.org/10.1038/sj.jea.7500244},
    volume = {12},
    year = {2002}
}

@article{citeulike:2739216,
    abstract = {By classifying programs according to their relationship to the environment in which they are executed,
the paper identifies the sources of evolutionary pressure on computer applications and programs and shows why this
results in a process of never ending maintenance activity. The resultant life cycle processes are then briefly
discussed. The paper then introduces laws of Program Evolution that have been formulated following quantitative studies
of the evolution of a number of different systems. Finally an example is provided of the application of Evolution
Dynamics models to program release planning.},
    author = {Lehman, M. M.},
    booktitle = {Proceedings of the IEEE},
    citeulike-article-id = {2739216},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/proc.1980.11805},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1456074},
    doi = {10.1109/proc.1980.11805},
    issn = {0018-9219},
    journal = {Proceedings of the IEEE},
    number = {9},
    pages = {1060--1076},
    posted-at = {2012-02-28 07:45:57},
    priority = {2},
    publisher = {IEEE},
    title = {Programs, life cycles, and laws of software evolution},
    url = {http://dx.doi.org/10.1109/proc.1980.11805},
    volume = {68},
    year = {1980}
}

@article{citeulike:10392305,
    abstract = {The use of geographically separated software development groups is proposed as a method for enabling
24-hour software development, or software shift work. The advantages of such an approach are explained, and potential
organizational models for such virtual teams are described. Virtual team co-operation, information requirements and
communication channels are explored. Activities in the software development life-cycle in which virtual teams can be
advantageously utilized are explained, and examples of the successful use of virtual teams are cited. Finally a measure
of the effectiveness of virtual teams known as the distributed working overhead is defined, which will enable project
managers to clearly see the benefits and associated costs of employing virtual teams on a project.},
    author = {Gorton, Ian and Motwani, Sanjeev},
    citeulike-article-id = {10392305},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0950-5849(96)01099-3},
    doi = {10.1016/0950-5849(96)01099-3},
    issn = {09505849},
    journal = {Information and Software Technology},
    month = jan,
    number = {10},
    pages = {647--655},
    posted-at = {2012-02-28 07:43:43},
    priority = {2},
    title = {Issues in co-operative software engineering using globally distributed teams},
    url = {http://dx.doi.org/10.1016/0950-5849(96)01099-3},
    volume = {38},
    year = {1996}
}

@book{citeulike:6095797,
    author = {Yourdon, Edward},
    citeulike-article-id = {6095797},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/013143635X},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/013143635X},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/013143635X},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/013143635X},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/013143635X/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/013143635X},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/013143635X},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN013143635X},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=013143635X\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/013143635X},
    day = {16},
    edition = {2},
    howpublished = {Paperback},
    isbn = {013143635X},
    month = nov,
    posted-at = {2012-02-28 07:40:23},
    priority = {2},
    publisher = {Prentice Hall},
    title = {Death March (2nd Edition)},
    url = {http://www.worldcat.org/isbn/013143635X},
    year = {2003}
}

@inproceedings{citeulike:10392277,
    abstract = {Modern software is often developed over many years with hundreds of thousands of commits. Commit
metadata is a rich source of social characteristics, including the commit's time of day and the experience and commit
frequency of its author. The "bugginess" of a commit is also a critical property of that commit. In this paper, we
investigate the correlation between a commit's social characteristics and its "bugginess"; such results can be very
useful for software developers and software engineering researchers. For instance, developers or code reviewers might be
well-advised to thoroughly verify commits that are more likely to be buggy. In this paper, we study the correlation
between a commit's bugginess and the time of day of the commit, the day of week of the commit, and the experience and
commit frequency of the commit authors. We survey two widely-used open source projects: the Linux kernel and
{PostgreSQL}. Our main findings include: (1) commits submitted between midnight and 4 {AM} (
referred to as late-night commits) are significantly buggier and commits between 7 {AM} and noon are less buggy,
implying that developers may want to double-check their own latenight commits; (2) daily-committing developers produce
less-buggy commits, indicating that we may want to promote the practice of daily-committing developers reviewing other
developers' commits; and (3) the bugginess of commits versus day-of-week varies for different software projects.},
    address = {New York, NY, USA},
    author = {Eyolfson, Jon and Tan, Lin and Lam, Patrick},
    booktitle = {Proceedings of the 8th Working Conference on Mining Software Repositories},
    citeulike-article-id = {10392277},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1985464},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1985441.1985464},
    doi = {10.1145/1985441.1985464},
    isbn = {978-1-4503-0574-7},
    location = {Waikiki, Honolulu, HI, USA},
    pages = {153--162},
    posted-at = {2012-02-28 07:07:49},
    priority = {2},
    publisher = {ACM},
    series = {MSR '11},
    title = {Do time of day and developer experience affect commit bugginess?},
    url = {http://dx.doi.org/10.1145/1985441.1985464},
    year = {2011}
}

@inproceedings{citeulike:3056638,
    abstract = {Interpretations of {TF}-{IDF} are based on binary independence retrieval, Poisson, information theory,
and language modelling. This paper contributes a review of existing interpretations, and then, {TF}-{IDF} is
systematically related to the probabilities P(q|d) and P(d|q). Two approaches are explored: a space of independent, and
a space of disjoint terms. For independent terms, an "extreme" query/non-query term assumption uncovers {TF}-{IDF}, and
an analogy of P(d|q) and the probabilistic odds O(r|d, q) mirrors relevance feedback. For disjoint terms, a relationship
between probability theory and {TF}-{IDF} is established through the integral + 1/x dx = log x. This study uncovers
components such as divergence from randomness and pivoted document length to be inherent parts of a document-query
independence ({DQI}) measure, and interestingly, an integral of the {DQI} over the term occurrence probability leads to
{TF}-{IDF}.},
    address = {New York, NY, USA},
    author = {Roelleke, Thomas and Wang, Jun},
    booktitle = {Proceedings of the 31st annual international ACM SIGIR conference on Research and development in
information retrieval},
    citeulike-article-id = {3056638},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1390334.1390409},
    citeulike-linkout-1 = {http://dblp.uni-trier.de/rec/bibtex/conf/sigir/RoellekeW08},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/1390334.1390409},
    doi = {10.1145/1390334.1390409},
    isbn = {978-1-60558-164-4},
    location = {Singapore, Singapore},
    pages = {435--442},
    posted-at = {2012-02-27 21:07:32},
    priority = {2},
    publisher = {ACM},
    series = {SIGIR '08},
    title = {{TF}-{IDF} uncovered: a study of theories and probabilities},
    url = {http://dx.doi.org/10.1145/1390334.1390409},
    year = {2008}
}

@proceedings{citeulike:3562,
    abstract = {Iterative refinement clustering algorithms (e.g. {K-Means},
{EM}) converge to one of numerous local minima. It is known
that they are especially sensitive to initial conditions. We
present a procedure for computing a refined starting
condition from a given initial one that is based on an
efficient technique for estimating the modes of a distribution.
The refined initial starting condition leads to convergence to

\&quot;better\&quot; local minima. The procedure is applicable to a wide
class of clustering...},
    author = {Fayyad, Usama M. and Reina, Cory and Bradley, Paul S.},
    booktitle = {Knowledge Discovery and Data Mining},
    citeulike-article-id = {3562},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.54.3469},
    pages = {194--198},
    posted-at = {2012-02-26 09:05:43},
    priority = {2},
    title = {Initialization of Iterative Refinement Clustering Algorithms},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.54.3469},
    year = {1998}
}

@misc{citeulike:964346,
    abstract = {Using an open-source, Java toolkit of name-matching

methods, we experimentally compare string distance

metrics on the task of matching entity names. We investigate

a number of different metrics proposed by different

communities, including edit-distance metrics, fast

heuristic string comparators , token-based distance metrics,

and hybrid methods. Overall, the best-performing

method is a hybrid scheme combining a {TFIDF} weighting

scheme, which is widely used in information retrieval,

with ...},
    author = {Cohen, W. and Ravikumar, P. and Fienberg, S.},
    citeulike-article-id = {964346},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.3605},
    posted-at = {2012-02-26 04:10:18},
    priority = {2},
    title = {A comparison of string distance metrics for name-matching tasks},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.3605},
    year = {2003}
}

@inproceedings{citeulike:10377366,
    abstract = {The development of Open Source systems produces a variety of software artifacts such as source code,
version control records, bug reports, and email discussions. Since the development is distributed across different tool
environments and developer practices, any analysis of project behavior must be inferred from whatever common artifacts
happen to be available. In this paper, we propose an approach to characterizing a project's behavior around the time of
major and minor releases; we do this by partitioning the observed activities, such as artifact check-ins, around the
dates of major and minor releases, and then look for recognizable patterns. We validate this approach by means of a case
study on the {MySQL} database system; in this case study, we found patterns which suggested {MySQL} was behaving
consistently within itself. These patterns included testing and documenting that took place more before a release than
after and that the rate of source code changes dipped around release time.},
    address = {Washington, DC, USA},
    author = {Hindle, Abram and Godfrey, Michael W. and Holt, Richard C.},
    booktitle = {Proceedings of the 29th International Conference on Software Engineering Workshops},
    citeulike-article-id = {10377366},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1261202},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icsew.2007.181},
    doi = {10.1109/icsew.2007.181},
    isbn = {0-7695-2830-9},
    posted-at = {2012-02-22 15:40:18},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Release Pattern Discovery via Partitioning: Methodology and Case Study},
    url = {http://dx.doi.org/10.1109/icsew.2007.181},
    year = {2007}
}

@inproceedings{citeulike:3378725,
    abstract = {This paper presents an approach to recover time variant information from software repositories. It is
widely accepted that software evolves due to factors such as defect removal, market opportunity or adding new features.
Software evolution details are stored in software repositories which often contain the changes history. On the other
hand there is a lack of approaches, technologies and methods to efficiently extract and represent time dependent
information. Disciplines such as signal and image processing or speech recognition adopt frequency domain
representations to mitigate differences of signals evolving in time. Inspired by time-frequency duality, this paper
proposes the use of Linear Predictive Coding ({LPC}) and Cepstrum coefficients to model time varying software artifact
histories. {LPC} or Cepstrum allow obtaining very compact representations with linear complexity. These representations
can be used to highlight components and artifacts evolved in the same way or with very similar 
evolution patterns. To assess the proposed approach we applied {LPC} and Cepstral analysis to 211 Linux kernel releases
(i.e., from 1.0 to 1.3.100), to identify files with very similar size histories. The approach, the preliminary results
and the lesson learned are presented in this paper.},
    address = {New York, NY, USA},
    author = {Antoniol, Giuliano and Rollo, Vincenzo F. and Venturi, Gabriele},
    booktitle = {Proceedings of the 2005 international workshop on Mining software repositories},
    citeulike-article-id = {3378725},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1082983.1083156},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1082983.1083156},
    doi = {10.1145/1082983.1083156},
    isbn = {1-59593-123-6},
    issn = {0163-5948},
    journal = {SIGSOFT Softw. Eng. Notes},
    location = {St. Louis, Missouri},
    number = {4},
    pages = {1--5},
    posted-at = {2012-02-22 15:35:53},
    priority = {2},
    publisher = {ACM},
    series = {MSR '05},
    title = {Linear predictive coding and cepstrum coefficients for mining time variant information from software
repositories},
    url = {http://dx.doi.org/10.1145/1082983.1083156},
    volume = {30},
    year = {2005}
}

@inproceedings{citeulike:10377345,
    abstract = {Within the field of software repository mining, it is common practice to extract change-events from
source control systems and then abstract these events to allow for different analyses. One approach is to apply
time-series analysis by aggregating these events into signals. Time-series analysis requires that researchers specify a
period of study; usually ldquonaturalrdquo periods such as days, months, and years are chosen. As yet there has been no
research to validate that these assumptions are reasonable. We address this by applying Fourier analysis to discover the
ldquonaturalrdquo periodicities of software development. Fourier analysis can detect and determine the periodicity of
repeating events. Fourier transforms represent signals as linear combinations of sine-waves that suggest how much
activity occurs at certain frequencies. If behaviors of different frequencies are mixed into one signal, they can be
separated. Thus Fourier transforms can help us identify significant development 
process sub-signals within software projects.},
    author = {Hindle, A. and Godfrey, M. W. and Holt, R. C.},
    booktitle = {Software Engineering - Companion Volume, 2009. ICSE-Companion 2009. 31st International Conference on},
    citeulike-article-id = {10377345},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icse-companion.2009.5071005},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5071005},
    doi = {10.1109/icse-companion.2009.5071005},
    institution = {Univ. of Waterloo, Waterloo, ON},
    isbn = {978-1-4244-3495-4},
    month = may,
    pages = {295--298},
    posted-at = {2012-02-22 15:28:43},
    priority = {2},
    publisher = {IEEE},
    title = {Mining recurrent activities: Fourier analysis of change events},
    url = {http://dx.doi.org/10.1109/icse-companion.2009.5071005},
    year = {2009}
}

@article{citeulike:6954210,
    abstract = {
                Most sequence comparison methods assume that the data being compared are trustworthy, but this is not
the case with raw {DNA} sequences obtained from automatic sequencing machines. Nevertheless, sequence comparisons need
to be done on them in order to remove vector splice sites and contaminants. This step is necessary before other genomic
data processing stages can be carried out, such as fragment assembly or {EST} clustering. A specialized tool is
therefore needed to solve this apparent dilemma.
                We have designed and implemented a program that specifically addresses the problem. This program, called
{LUCY}, has been in use since 1998 at The Institute for Genomic Research ({TIGR}). During this period, many rounds of
experience-driven modifications were made to {LUCY} to improve its accuracy and its ability to deal with extremely
difficult input cases. We believe we have finally obtained a useful program which strikes a delicate balance among the
many issues involved in the raw sequence cleaning problem, and we wish to share it with the research community.
                {LUCY} is available directly from {TIGR} (http://www.tigr.org/softlab). Academic users can download
{LUCY} after accepting a free academic use license. Business users may need to pay a license fee to use {LUCY} for
commercial purposes.
                Questions regarding the quality assessment module of {LUCY} should be directed to Michael Holmes
(mholmes@tigr.org). Questions regarding other aspects of {LUCY} should be directed to {Hui-Hsien} Chou
(hhchou@iastate.edu).
            },
    author = {Chou, H. H. and Holmes, M. H.},
    citeulike-article-id = {6954210},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/bioinformatics/17.12.1093},
    citeulike-linkout-1 = {http://bioinformatics.oxfordjournals.org/content/17/12/1093.abstract},
    citeulike-linkout-2 = {http://bioinformatics.oxfordjournals.org/content/17/12/1093.full.pdf},
    citeulike-linkout-3 = {http://bioinformatics.oxfordjournals.org/cgi/content/abstract/17/12/1093},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/11751217},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=11751217},
    day = {01},
    doi = {10.1093/bioinformatics/17.12.1093},
    issn = {1367-4803},
    journal = {Bioinformatics (Oxford, England)},
    keywords = {de\_paper},
    month = dec,
    number = {12},
    pages = {1093--1104},
    pmid = {11751217},
    posted-at = {2012-01-17 05:08:52},
    priority = {2},
    publisher = {Oxford University Press},
    title = {{DNA} sequence quality trimming and vector removal.},
    url = {http://dx.doi.org/10.1093/bioinformatics/17.12.1093},
    volume = {17},
    year = {2001}
}

@inproceedings{citeulike:8531446,
    abstract = {Delivering increasingly complex software-reliant systems demands better ways to manage the long-term
effects of short-term expedients. The technical debt metaphor is gaining significant traction in the agile development
community as a way to understand and communicate such issues. The idea is that developers sometimes accept compromises
in a system in one dimension (e.g., modularity) to meet an urgent demand in some other dimension (e.g., a deadline), and
that such compromises incur a "debt": on which "interest" has to be paid and which the "principal" should be repaid at
some point for the long-term health of the project. We argue that the software engineering research community has an
opportunity to study and improve this concept. We can offer software engineers a foundation for managing such trade-offs
based on models of their economic impacts. Therefore, we propose managing technical debt as a part of the future
research agenda for the software engineering field.},
    address = {New York, NY, USA},
    author = {Brown, Nanette and Cai, Yuanfang and Guo, Yuepu and Kazman, Rick and Kim, Miryung and Kruchten, Philippe
and Lim, Erin and MacCormack, Alan and Nord, Robert and Ozkaya, Ipek and Sangwan, Raghvinder and Seaman, Carolyn and
Sullivan, Kevin and Zazworka, Nico},
    booktitle = {Proceedings of the FSE/SDP workshop on Future of software engineering research},
    citeulike-article-id = {8531446},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1882373},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1882362.1882373},
    doi = {10.1145/1882362.1882373},
    isbn = {978-1-4503-0427-6},
    keywords = {eseiw12, thesis-phd},
    location = {Santa Fe, New Mexico, USA},
    pages = {47--52},
    posted-at = {2011-12-16 13:22:16},
    priority = {2},
    publisher = {ACM},
    series = {FoSER '10},
    title = {Managing technical debt in software-reliant systems},
    url = {http://dx.doi.org/10.1145/1882362.1882373},
    year = {2010}
}

@article{citeulike:10131869,
    abstract = {
                Indole Acetic Acid 9 ({IAA9}) is a negative auxin response regulator belonging to the {Aux/IAA}
transcription factor gene family whose downregulation triggers fruit set before pollination, thus giving rise to
parthenocarpy. In situ hybridization experiments revealed that a tissue-specific gradient of {IAA9} expression is
established during flower development, the release of which upon pollination triggers the initiation of fruit
development. Comparative transcriptome and targeted metabolome analysis uncovered important features of the molecular
events underlying pollination-induced and pollination-independent fruit set. Comprehensive transcriptomic profiling
identified a high number of genes common to both types of fruit set, among which only a small subset are dependent on
{IAA9} regulation. The fine-tuning of {Aux/IAA} and {ARF} genes and the downregulation of {TAG1} and {TAGL6} {MADS} box
genes are instrumental in triggering the fruit set program. Auxin and ethylene emerged as the most 
active signaling hormones involved in the flower-to-fruit transition. However, while these hormones affected only a
small number of transcriptional events, dramatic shifts were observed at the metabolic and developmental levels. The
activation of photosynthesis and sucrose metabolism-related genes is an integral regulatory component of fruit set
process. The combined results allow a far greater comprehension of the regulatory and metabolic events controlling early
fruit development both in the presence and absence of pollination/fertilization.
            },
    author = {Wang, Hua and Schauer, Nicolas and Usadel, Bjoern and Frasse, Pierre and Zouine, Mohamed and Hernould,
Michel and Latch\'{e}, Alain and Pech, Jean-Claude C. and Fernie, Alisdair R. and Bouzayen, Mondher},
    citeulike-article-id = {10131869},
    citeulike-linkout-0 = {http://dx.doi.org/10.1105/tpc.108.060830},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2700536/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/19435935},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=19435935},
    doi = {10.1105/tpc.108.060830},
    issn = {1040-4651},
    journal = {The Plant cell},
    keywords = {gbf},
    month = may,
    number = {5},
    pages = {1428--1452},
    pmcid = {PMC2700536},
    pmid = {19435935},
    posted-at = {2011-12-15 15:19:57},
    priority = {2},
    title = {Regulatory features underlying pollination-dependent and -independent tomato fruit set revealed by
transcript and primary metabolite profiling.},
    url = {http://dx.doi.org/10.1105/tpc.108.060830},
    volume = {21},
    year = {2009}
}

@article{citeulike:4200367,
    abstract = {Motivation: A new protocol for sequencing the messenger {RNA} in a cell, known as {RNA}-Seq, generates
millions of short sequence fragments in a single run. These fragments, or 'reads', can be used to measure levels of gene
expression and to identify novel splice variants of genes. However, current software for aligning {RNA}-Seq data to a
genome relies on known splice junctions and cannot identify novel ones. {TopHat} is an efficient read-mapping algorithm
designed to align reads from an {RNA}-Seq experiment to a reference genome without relying on known splice sites.},
    author = {Trapnell, Cole and Pachter, Lior and Salzberg, Steven L.},
    citeulike-article-id = {4200367},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/bioinformatics/btp120},
    citeulike-linkout-1 = {http://bioinformatics.oxfordjournals.org/content/25/9/1105.abstract},
    citeulike-linkout-2 = {http://bioinformatics.oxfordjournals.org/content/25/9/1105.full.pdf},
    citeulike-linkout-3 = {http://bioinformatics.oxfordjournals.org/cgi/content/abstract/25/9/1105?etoc},
    citeulike-linkout-4 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2672628/},
    citeulike-linkout-5 = {http://view.ncbi.nlm.nih.gov/pubmed/19289445},
    citeulike-linkout-6 = {http://www.hubmed.org/display.cgi?uids=19289445},
    day = {01},
    doi = {10.1093/bioinformatics/btp120},
    issn = {1460-2059},
    journal = {Bioinformatics},
    keywords = {gbf},
    month = may,
    number = {9},
    pages = {1105--1111},
    pmcid = {PMC2672628},
    pmid = {19289445},
    posted-at = {2011-12-15 12:11:36},
    priority = {0},
    publisher = {Oxford University Press},
    title = {{TopHat}: discovering splice junctions with {RNA}-Seq},
    url = {http://dx.doi.org/10.1093/bioinformatics/btp120},
    volume = {25},
    year = {2009}
}

@inproceedings{citeulike:693466,
    abstract = {George Santayana's statement, "Those who cannot remember the past are condemned to repeat it," is only
half true. The past also includes successful histories. If you haven't been made aware of them, you're often condemned
not to repeat their {successes.In} a rapidly expanding field such as software engineering, this happens a lot. Extensive
studies of many software projects such as the Standish Reports offer convincing evidence that many projects fail to
repeat past {successes.This} paper tries to identify at least some of the major past software experiences that were well
worth repeating, and some that were not. It also tries to identify underlying phenomena influencing the evolution of
software engineering practices that have at least helped the author appreciate how our field has gotten to where it has
been and where it {is.A} counterpart Santayana-like statement about the past and future might say, "In an era of rapid
change, those who repeat the past are condemned to a bleak future." (
Think about the dinosaurs, and think carefully about software engineering maturity models that emphasize
{repeatability.)This} paper also tries to identify some of the major sources of change that will affect software
engineering practices in the next couple of decades, and identifies some strategies for assessing and adapting to these
sources of change. It also makes some first steps towards distinguishing relatively timeless software engineering
principles that are risky not to repeat, and conditions of change under which aging practices will become increasingly
risky to repeat.},
    address = {New York, NY, USA},
    author = {Boehm, Barry},
    booktitle = {Proceedings of the 28th international conference on Software engineering},
    citeulike-article-id = {693466},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1134285.1134288},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1134285.1134288},
    doi = {10.1145/1134285.1134288},
    isbn = {1-59593-375-1},
    keywords = {thesis-phd},
    location = {Shanghai, China},
    pages = {12--29},
    posted-at = {2011-11-22 14:38:50},
    priority = {2},
    publisher = {ACM},
    series = {ICSE '06},
    title = {A view of 20th and 21st century software engineering},
    url = {http://dx.doi.org/10.1145/1134285.1134288},
    year = {2006}
}

@article{citeulike:3716342,
    abstract = {To mark {IEEE} Software's 25th anniversary, Software Technology column editor Christof Ebert presents a
review and road map of major software technologies, starting with the magazine's inauguration, 1984. Learning from the
many hypes and often long introduction cycles, he provides some timeless principles of technology evaluation and
introduction.},
    author = {Ebert, Christof},
    booktitle = {Software, IEEE},
    citeulike-article-id = {3716342},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1477273},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ms.2008.141},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4670707},
    doi = {10.1109/ms.2008.141},
    journal = {Software, IEEE},
    keywords = {thesis-phd},
    number = {6},
    pages = {22--25},
    posted-at = {2011-11-22 14:37:07},
    priority = {2},
    title = {A Brief History of Software Technology},
    url = {http://dx.doi.org/10.1109/ms.2008.141},
    volume = {25},
    year = {2008}
}

@article{citeulike:7679414,
    abstract = {We discuss the 'software crisis' as a social and cultural phenomenon, arguing that it can be viewed as
(one more) manifestation of postmodernism. We illustrate our argument with a range of examples taken from software
engineering, demonstrating software engineering's roots in (and commitment to) modernism and the nature of its fin de
si\`{e}cle predicament. We argue that current attempts within software engineering to respond to the software crisis
have not been adequate and that a new, more humble, approach to software development is required.},
    author = {Robinson, H. and Hall, P. and Hovenden, F. and Rachel, J.},
    citeulike-article-id = {7679414},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/comjnl/41.6.363},
    citeulike-linkout-1 = {http://comjnl.oxfordjournals.org/content/41/6/363.abstract},
    citeulike-linkout-2 = {http://comjnl.oxfordjournals.org/content/41/6/363.full.pdf},
    citeulike-linkout-3 = {http://comjnl.oxfordjournals.org/cgi/content/abstract/41/6/363},
    day = {1},
    doi = {10.1093/comjnl/41.6.363},
    issn = {1460-2067},
    journal = {The Computer Journal},
    keywords = {thesis-phd},
    month = jan,
    number = {6},
    pages = {363--375},
    posted-at = {2011-11-22 14:31:00},
    priority = {2},
    publisher = {Oxford University Press},
    title = {Postmodern Software Development},
    url = {http://dx.doi.org/10.1093/comjnl/41.6.363},
    volume = {41},
    year = {1998}
}

@book{citeulike:10055914,
    citeulike-article-id = {10055914},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/026269087X},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/026269087X},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/026269087X},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/026269087X},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/026269087X/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/026269087X},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/026269087X},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN026269087X},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=026269087X\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/026269087X},
    howpublished = {Paperback},
    isbn = {026269087X},
    keywords = {thesis-phd},
    posted-at = {2011-11-22 09:16:21},
    priority = {2},
    publisher = {MIT Press (MA)},
    title = {Models of Bounded Rationality, Volume 2: Behavioral Economics and Business Organization (v. 2)},
    url = {http://www.worldcat.org/isbn/026269087X}
}

@article{citeulike:6708618,
    abstract = {Based on an invited address, "Behaving Like a Manager," as part of the All Academy
{Centennial/Anniversary} Symposium of the national, annual meeting of the Academy of Management, this paper by Simon
addresses the popular topic of the "rational" and "non-rational" components in the behavior of effective managers.
Previous discussion of this topic has been hampered by the lack of a precise characterization of the nonrational
components--specifically a characterization of the mechanisms of managerial judgment and intuition. Simon provides a
description of intuitive and judgmental processes and a sketch of the evidence that is available to support this
description. Further, his paper shows how intuition and judgment rest on extensive experience and knowledge; how, in
fact, they can be understood in terms of the recognition of cues and the consequent evocation from memory of relevant
experiences. In a final section of the paper, Simon discusses some of the pathologies commonly encountered in 
managerial behavior, both those produced by emotions and stress and those arising from the lack of appropriate
habits--that is to say, of appropriate intuitive responses. This diagnosis leads Simon to some rather specific
conclusions about the kinds of intuitions that need to be cultivated and habituated in organizations, and some of the
ways in which they can be developed.},
    author = {Simon, Herbert A.},
    citeulike-article-id = {6708618},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/4164720},
    citeulike-linkout-1 = {http://www.jstor.org/stable/4164720},
    doi = {10.2307/4164720},
    issn = {08963789},
    journal = {The Academy of Management Executive (1987-1989)},
    keywords = {thesis-phd},
    number = {1},
    pages = {57--64},
    posted-at = {2011-11-22 08:39:37},
    priority = {2},
    publisher = {Academy of Management},
    title = {Making Management Decisions: The Role of Intuition and Emotion},
    url = {http://dx.doi.org/10.2307/4164720},
    volume = {1},
    year = {1987}
}

@book{citeulike:1414171,
    abstract = {Most of Barnard's career was spent in executive practice. A Mount Hermon and
Harvard education, cut off short of the bachelor's degree, was followed by
nearly forty years in the American Telephone \& Telegraph Company. His career
began in the Statistical Department, took him to technical expertness in the
economics of rates and administrative experience in the management of
commercial operations, and culminated in the presidency of the New Jersey Bell
Telephone Company. He was not directly involved in the Western Electric
experiments conducted chiefly at the Hawthorne plant in Cicero, but his
association with Elton Mayo and the latter's colleagues at the Harvard
Business School had an important bearing on his most original ideas.

Barnard's executive experience at {AT}\&T was paralleled and followed by a career
in public service unusual in his own time and hardly routine today. He was at
various times president of the United Services Organization (the {USO} of World
War {II}), head of the General Education Board and later president of the
Rockefeller Foundation (after Raymond Fosdick and before Dean Rusk), chairman
of the National Science Foundation, an assistant to the Secretary of the
Treasury, a consultant to the American representative in the United Nations
Atomic Energy Committee, to name only some of his public interests. He was a
director of a number of companies, a fellow of the American Association for
the Advancement of Science and of the American Academy of Arts and Sciences.
He was a lover of music and a founder of the Bach Society of New Jersey.},
    author = {Barnard, Chester I.},
    citeulike-article-id = {1414171},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0674328035},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0674328035},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0674328035},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0674328035},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0674328035/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0674328035},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0674328035},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0674328035},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0674328035\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0674328035},
    day = {01},
    edition = {30 Anv},
    howpublished = {Paperback},
    isbn = {0674328035},
    keywords = {thesis-phd},
    month = jan,
    posted-at = {2011-11-22 08:17:11},
    priority = {2},
    publisher = {Harvard University Press},
    title = {The Functions of the Executive: 30th Anniversary Edition},
    url = {http://www.worldcat.org/isbn/0674328035},
    year = {1971}
}

@article{citeulike:10055684,
    author = {Simon, Herbert A.},
    citeulike-article-id = {10055684},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/27850429},
    citeulike-linkout-1 = {http://www.jstor.org/stable/27850429},
    doi = {10.2307/27850429},
    issn = {00030996},
    journal = {American Scientist},
    keywords = {thesis-phd},
    number = {3},
    posted-at = {2011-11-22 08:02:18},
    priority = {2},
    publisher = {Sigma Xi, The Scientific Research Society},
    title = {Studying Human Intelligence by Creating Artificial Intelligence: When considered as a physical symbol
system, the human brain can be fruitfully studied by computer simulation of its processes},
    url = {http://dx.doi.org/10.2307/27850429},
    volume = {69},
    year = {1981}
}

@inproceedings{citeulike:6095377,
    abstract = {A core set of concepts for the software process is defined. These concepts are intended to facilitate
communications and to provide a framework for further definitions. The definitions focus on essential concepts; however,
they do not represent a comprehensive glossary of common software process terms. Following an initial overview, the
basic process concepts which underlie the definitions are outlined. The definitions are grouped in four sets: a
framework for process definition, an engineering of process, an enactment of process, and process properties. The use of
these concepts in several domains is illustrated. Some observations on the definition process are offered},
    author = {Feiler, P. H. and Humphrey, W. S.},
    booktitle = {Software Process, 1993. Continuous Software Process Improvement, Second International Conference on
the},
    citeulike-article-id = {6095377},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/spcon.1993.236824},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=236824},
    day = {06},
    doi = {10.1109/spcon.1993.236824},
    institution = {Software Eng. Inst., Carnegie Mellon Univ., Pittsburgh, PA},
    isbn = {0-8186-3600-9},
    journal = {Software Process, 1993. Continuous Software Process Improvement, Second International Conference on the},
    keywords = {thesis-phd},
    month = feb,
    pages = {28--40},
    posted-at = {2011-11-15 13:38:50},
    priority = {2},
    publisher = {IEEE},
    title = {Software process development and enactment: concepts and definitions},
    url = {http://dx.doi.org/10.1109/spcon.1993.236824},
    year = {1993}
}

@article{citeulike:10004032,
    abstract = {The paper is adapted from a presentation at a symposium on advanced programming methods for digital
computers sponsored by the Navy Mathematical Computing Advisory Panel and the Office of Naval Research in June 1956. The
author describes the techniques used to produce the programs for the {Semi-Automatic} Ground Environment ({SAGE})
system.},
    author = {Benington, Herbert D.},
    citeulike-article-id = {10004032},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/mahc.1983.10102},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4640770},
    doi = {10.1109/mahc.1983.10102},
    issn = {0164-1239},
    journal = {Annals of the History of Computing},
    keywords = {thesis-phd},
    month = oct,
    number = {4},
    pages = {350--361},
    posted-at = {2011-11-08 08:47:16},
    priority = {2},
    publisher = {IEEE},
    title = {Production of Large Computer Programs},
    url = {http://dx.doi.org/10.1109/mahc.1983.10102},
    volume = {5},
    year = {1983}
}

@article{citeulike:10004037,
    abstract = {The paper is adapted from a presentation at the 1957 Eastern Joint Computer Conference. The authors give
details of the {Semi-Automatic} Ground Environment ({SAGE}) system and how it developed.},
    address = {Los Alamitos, CA, USA},
    author = {Everett, Robert R. and Zraket, Charles A. and Benington, Herbert D.},
    citeulike-article-id = {10004037},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/MAHC.1983.10096},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/mahc.1983.10096},
    doi = {10.1109/mahc.1983.10096},
    issn = {1058-6180},
    journal = {IEEE Annals of the History of Computing},
    keywords = {thesis-phd},
    pages = {330--339},
    posted-at = {2011-11-08 08:44:05},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {{SAGE}-A Data Processing System for Air Defense},
    url = {http://dx.doi.org/10.1109/mahc.1983.10096},
    volume = {5},
    year = {1983}
}

@article{citeulike:10004001,
    abstract = {Events leading to the adoption of voice telephone lines for air-defense operational messages are
described. This process paved the way for the use of operational data lines in the {SAGE} ({Semi-Automatic} Ground
Environment) system. The paper describes the early considerations leading to the use of a digital computer in {SAGE},
and how Whirlwind was chosen to be that computer. The context of the development of magnetic core memory is illuminated.
The attitudes of engineering professionals toward digital equipment are reviewed. The author reveals how the name
"Ground Environment" was created.},
    author = {Valley, George E.},
    citeulike-article-id = {10004001},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/mahc.1985.10030},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4640733},
    doi = {10.1109/mahc.1985.10030},
    issn = {0164-1239},
    journal = {Annals of the History of Computing},
    keywords = {thesis-phd},
    month = jul,
    number = {3},
    pages = {196--226},
    posted-at = {2011-11-08 08:16:43},
    priority = {2},
    publisher = {IEEE},
    title = {How the {SAGE} Development Began},
    url = {http://dx.doi.org/10.1109/mahc.1985.10030},
    volume = {7},
    year = {1985}
}

@article{citeulike:10002165,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Sommerville, Ian},
    citeulike-article-id = {10002165},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=234420},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/234313.234420},
    doi = {10.1145/234313.234420},
    issn = {0360-0300},
    journal = {ACM Comput. Surv.},
    keywords = {thesis-phd},
    month = mar,
    pages = {269--271},
    posted-at = {2011-11-07 21:12:03},
    priority = {2},
    publisher = {ACM},
    title = {Software process models},
    url = {http://dx.doi.org/10.1145/234313.234420},
    volume = {28},
    year = {1996}
}

@article{citeulike:3996892,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {McCracken, Daniel D. and Jackson, Michael A.},
    citeulike-article-id = {3996892},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1005937.1005943},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1005937.1005943},
    doi = {10.1145/1005937.1005943},
    issn = {0163-5948},
    journal = {SIGSOFT Softw. Eng. Notes},
    keywords = {thesis-phd},
    month = apr,
    number = {2},
    pages = {29--32},
    posted-at = {2011-11-07 21:09:21},
    priority = {2},
    publisher = {ACM},
    title = {Life cycle concept considered harmful},
    url = {http://dx.doi.org/10.1145/1005937.1005943},
    volume = {7},
    year = {1982}
}

@misc{Boehm95anchoringthe,
    author = {Boehm, Barry and Usc, Barry B.},
    citeulike-article-id = {10002136},
    keywords = {*file-import-11-11-07},
    posted-at = {2011-11-07 21:02:07},
    priority = {2},
    title = {Anchoring the Software Process},
    year = {1995}
}

@article{citeulike:10002126,
    abstract = {A short description is given of software process models and the issues they address. An outline is given
of the process steps involved in the spiral model, an evolving risk-driven approach that provides a framework for
guiding the software process, and its application to a software project is shown. A summary is given of the primary
advantages and implications involved in using the spiral model and the primary difficulties in using it at its current
incomplete level of elaboration.},
    address = {Los Alamitos, CA, USA},
    author = {Boehm, Barry W.},
    citeulike-article-id = {10002126},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=45801},
    issn = {0018-9162},
    journal = {Computer},
    keywords = {thesis-phd},
    month = may,
    pages = {61--72},
    posted-at = {2011-11-07 20:59:41},
    priority = {2},
    publisher = {IEEE Computer Society Press},
    title = {A Spiral Model of Software Development and Enhancement},
    url = {http://portal.acm.org/citation.cfm?id=45801},
    volume = {21},
    year = {1988}
}

@article{citeulike:1986013,
    abstract = {First Page of the Article},
    address = {Los Alamitos, CA, USA},
    author = {Brooks, Frederick P.},
    booktitle = {Computer},
    citeulike-article-id = {1986013},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=26441},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/MC.1987.1663532},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/mc.1987.1663532},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1663532},
    day = {07},
    doi = {10.1109/mc.1987.1663532},
    issn = {0018-9162},
    journal = {Computer},
    keywords = {thesis-phd},
    month = apr,
    number = {4},
    pages = {10--19},
    posted-at = {2011-11-03 05:48:23},
    priority = {2},
    publisher = {IEEE Computer Society Press},
    title = {No Silver Bullet Essence and Accidents of Software Engineering},
    url = {http://dx.doi.org/10.1109/mc.1987.1663532},
    volume = {20},
    year = {1987}
}

@article{citeulike:4384552,
    abstract = {New myths about formal methods are gaining tacit acceptance both
outside and inside the system-development community. The authors address
and dispel these myths based on their observations of industrial
projects. The myths include: formal methods delay the development
process; they lack tools; they replace traditional engineering design
methods; they only apply to software; are unnecessary; not supported;
and formal methods people always use formal methods},
    address = {Los Alamitos, CA, USA},
    author = {Bowen, J. P. and Hinchey, M. G.},
    booktitle = {Software, IEEE},
    citeulike-article-id = {4384552},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=625488},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/52.391826},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=391826},
    doi = {10.1109/52.391826},
    issn = {0740-7459},
    journal = {Software, IEEE},
    keywords = {thesis-phd},
    month = jul,
    number = {4},
    pages = {34--41},
    posted-at = {2011-11-03 05:45:42},
    priority = {2},
    publisher = {IEEE},
    title = {Seven more myths of formal methods},
    url = {http://dx.doi.org/10.1109/52.391826},
    volume = {12},
    year = {1995}
}

@inproceedings{citeulike:9982731,
    author = {Royce, Winson W.},
    booktitle = {IEEE WESCON},
    citeulike-article-id = {9982731},
    citeulike-linkout-0 = {http://citeseer.ist.psu.edu/showciting?cid=68128},
    keywords = {thesis-phd},
    location = {New York},
    month = aug,
    posted-at = {2011-11-03 05:26:03},
    priority = {2},
    title = {Managing The Development Of A Large Software System},
    url = {http://citeseer.ist.psu.edu/showciting?cid=68128},
    year = {1970}
}

@book{citeulike:900855,
    author = {Kernighan, Brian W. and Plauger, P. J.},
    citeulike-article-id = {900855},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0070342075},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0070342075},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0070342075},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0070342075},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0070342075/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0070342075},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0070342075},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0070342075},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0070342075\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0070342075},
    day = {01},
    edition = {2nd},
    howpublished = {Paperback},
    isbn = {0070342075},
    month = jan,
    posted-at = {2011-10-29 22:08:11},
    priority = {2},
    publisher = {McGraw-Hill},
    title = {The Elements of Programming Style, 2nd Edition},
    url = {http://www.worldcat.org/isbn/0070342075},
    year = {1978}
}

@book{citeulike:9962027,
    author = {Kirchmer, Mathias},
    citeulike-article-id = {9962027},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/3540655751},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/3540655751},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/3540655751},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/3540655751},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/3540655751/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3540655751},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/3540655751},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN3540655751},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=3540655751\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/3540655751},
    day = {14},
    edition = {2nd},
    howpublished = {Hardcover},
    isbn = {3540655751},
    month = apr,
    posted-at = {2011-10-29 21:59:42},
    priority = {2},
    publisher = {Springer},
    title = {Business Process Oriented Implementation of Standard Software: How to Achieve Competitive Advantage
Efficiently and Effectively},
    url = {http://www.worldcat.org/isbn/3540655751},
    year = {1999}
}

@book{citeulike:9962022,
    author = {Bpo0999},
    citeulike-article-id = {9962022},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0769509991},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0769509991},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0769509991},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0769509991},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0769509991/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0769509991},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0769509991},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0769509991},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0769509991\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0769509991},
    day = {27},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0769509991},
    month = nov,
    posted-at = {2011-10-29 21:56:39},
    priority = {2},
    publisher = {Wiley-IEEE Computer Society Pr},
    title = {Software Process Improvement},
    url = {http://www.worldcat.org/isbn/0769509991},
    year = {2001}
}

@book{citeulike:9962021,
    author = {Humphrey, Watts S.},
    citeulike-article-id = {9962021},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0201180952},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0201180952},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0201180952},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0201180952},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0201180952/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201180952},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0201180952},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0201180952},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0201180952\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0201180952},
    day = {11},
    howpublished = {Hardcover},
    isbn = {0201180952},
    month = jan,
    posted-at = {2011-10-29 21:53:54},
    priority = {2},
    publisher = {Addison-Wesley Professional},
    title = {Managing the Software Process},
    url = {http://www.worldcat.org/isbn/0201180952},
    year = {1989}
}

@article{citeulike:5203446,
    abstract = {Certain principles long considered fundamental to software engineering are examined and found wanting.},
    address = {Los Alamitos, CA, USA},
    author = {DeMarco, Tom},
    booktitle = {Software, IEEE},
    citeulike-article-id = {5203446},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/MS.2009.101},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ms.2009.101},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5076468},
    doi = {10.1109/ms.2009.101},
    issn = {0740-7459},
    journal = {Software, IEEE},
    keywords = {thesis-phd},
    month = jul,
    number = {4},
    pages = {96},
    posted-at = {2011-10-29 05:12:27},
    priority = {2},
    publisher = {IEEE},
    title = {Software Engineering: An Idea Whose Time Has Come and Gone?},
    url = {http://dx.doi.org/10.1109/ms.2009.101},
    volume = {26},
    year = {2009}
}

@book{citeulike:9958822,
    author = {Carpenter, Gaylene and Blandy, Doug},
    citeulike-article-id = {9958822},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0736065644},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0736065644},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0736065644},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0736065644},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0736065644/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0736065644},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0736065644},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0736065644},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0736065644\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0736065644},
    day = {03},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0736065644},
    keywords = {thesis-phd},
    month = mar,
    posted-at = {2011-10-28 21:53:19},
    priority = {2},
    publisher = {Human Kinetics},
    title = {Arts and Cultural Programming: A Leisure Perspective},
    url = {http://www.worldcat.org/isbn/0736065644},
    year = {2008}
}

@article{citeulike:9928907,
    abstract = {Is computer programming an art requiring craftsmanship, or is it a science requiring the disciplined
application of best practices? This letter argues in favor of craftsmanship without ignoring best practices. Discussion
includes the progression of a programmer from apprentice to journeyman to master craftsman within the telecommunications
domain. {\copyright} 2003 Lucent Technologies Inc.},
    author = {Pyritz, Bill},
    citeulike-article-id = {9928907},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/bltj.10079},
    doi = {10.1002/bltj.10079},
    journal = {Bell Labs Tech. J.},
    keywords = {thesis},
    number = {3},
    pages = {101--104},
    posted-at = {2011-10-20 21:13:26},
    priority = {2},
    publisher = {Wiley Subscription Services, Inc., A Wiley Company},
    title = {Craftsmanship versus engineering: Computer {programming -- An} art or a science?},
    url = {http://dx.doi.org/10.1002/bltj.10079},
    volume = {8},
    year = {2003}
}

@book{citeulike:9758924,
    author = {van der Aalst, Wil M. P.},
    citeulike-article-id = {9758924},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/3642193447},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/3642193447},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/3642193447},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/3642193447},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/3642193447/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3642193447},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/3642193447},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN3642193447},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=3642193447\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/3642193447},
    day = {12},
    edition = {1st Edition.},
    howpublished = {Hardcover},
    isbn = {3642193447},
    keywords = {thesis-phd},
    month = apr,
    posted-at = {2011-10-09 17:55:13},
    priority = {2},
    publisher = {Springer},
    title = {Process Mining: Discovery, Conformance and Enhancement of Business Processes},
    url = {http://www.worldcat.org/isbn/3642193447},
    year = {2011}
}

@article{citeulike:3112209,
    abstract = {Understanding the molecular mechanisms responsible for the regulation of the transcriptome present in
eukaryotic cells is one of the most challenging tasks in the postgenomic era. In this regard, alternative splicing
({AS}) is a key phenomenon contributing to the production of different mature transcripts from the same primary {RNA}
sequence. As a plethora of different transcript forms is available in databases, a first step to uncover the biology
that drives {AS} is to identify the different types of reflected splicing variation. In this work, we present a general
definition of the {AS} event along with a notation system that involves the relative positions of the splice sites. This
nomenclature univocally and dynamically assigns a specific  ” {AS} code” to every possible pattern of splicing
variation. On the basis of this definition and the corresponding codes, we have developed a computational tool
({AStalavista}) that automatically characterizes the complete landscape of {AS} events in a 
given transcript annotation of a genome, thus providing a platform to investigate the transcriptome diversity across
genes, chromosomes, and species. Our analysis reveals that a substantial part—in human more than a quarter—of the
observed splicing variations are ignored in common classification pipelines. We have used {AStalavista} to investigate
and to compare the {AS} landscape of different reference annotation sets in human and in other metazoan species and
found that proportions of {AS} events change substantially depending on the annotation protocol, species-specific
attributes, and coding constraints acting on the transcripts. The {AStalavista} system therefore provides a general
framework to conduct specific studies investigating the occurrence, impact, and regulation of {AS}. The genome sequence
is said to be an organism's blueprint, a set of instructions driving the organism's biology. The unfolding of these
instructions—the so-called genes—is initiated by the transcription of {DNA} into {RNA} 
molecules, which subsequently are processed before they can take their functional role. During this processing step,
initially identical {RNA} molecules may result in different products through a process known as alternative splicing
({AS}). {AS} therefore allows for widening the diversity from the limited repertoire of genes, and it is often
postulated as an explanation for the apparent paradox that complex and simple organisms resemble in their number of
genes; it characterizes species, individuals, and developmental and cellular conditions. Comparing the differences of
{AS} products between cells may help to reveal the broad molecular basis underlying phenotypic differences—for instance,
between a cancer and a normal cell. An obstacle for such comparisons has been that, so far, no paradigm existed to
delineate each single quantum of {AS}, so-called {AS} events. Here, we describe a possibility of exhaustively
decomposing {AS} complements into qualitatively different groups of events and a nomenclature to 
unequivocally denote them. This typological catalogue of {AS} events along with their observed frequencies represent the
{AS} landscape, and we propose a procedure to automatically identify such landscapes. We use it to describe the human
{AS} landscape and to investigate how it has changed throughout evolution.},
    author = {Sammeth, Michael and Foissac, Sylvain and Guig\'{o}, Roderic},
    citeulike-article-id = {3112209},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pcbi.1000147},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2467475/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18688268},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18688268},
    day = {8},
    doi = {10.1371/journal.pcbi.1000147},
    issn = {1553-7358},
    journal = {PLoS Comput Biol},
    keywords = {assembly},
    month = aug,
    number = {8},
    pages = {e1000147+},
    pmcid = {PMC2467475},
    pmid = {18688268},
    posted-at = {2011-08-31 12:56:39},
    priority = {2},
    publisher = {Public Library of Science},
    title = {A General Definition and Nomenclature for Alternative Splicing Events},
    url = {http://dx.doi.org/10.1371/journal.pcbi.1000147},
    volume = {4},
    year = {2008}
}

@article{citeulike:9379777,
    abstract = {Although Manduca sexta has significantly contributed to our knowledge on a variety of insect
physiological processes, the lack of its genome sequence hampers the large-scale gene discovery, transcript profiling,
and proteomic analysis in this biochemical model species. Here we report our implementation of the {RNA}-Seq {cDNA}
sequencing approach based on massively parallel pyrosequencing, which allows us to categorize transcripts based on their
relative abundances and to discover process- or tissue-specifically regulated genes simultaneously. We obtained
1,821,652 reads with an average length of 289 bp per read from fat body and hemocytes of na\"{i}ve and microbe-injected
M. sexta larvae. After almost all (92.1\%) of these reads were assembled into 19,020 contigs, we identified 528 contigs
whose relative abundances increased at least 5- and 8-fold in fat body and hemocytes, respectively, after the microbial
challenge. Polypeptides encoded by these contigs include pathogen recognition 
receptors, extracellular and intracellular signal mediators and regulators, antimicrobial peptides, and proteins with no
known sequence but likely participating in defense in novel ways. We also found 250 and 161 contigs that were
preferentially expressed in fat body and hemocytes, respectively. Furthermore, we integrated data from our previous
study and generated a sequence database to support future gene annotation and proteomic analysis in M. sexta. In
summary, we have successfully established a combined approach for gene discovery and expression profiling in organisms
lacking known genome sequences.},
    author = {Zhang, Shuguang and Gunaratna, Ramesh T. and Zhang, Xiufeng and Najar, Fares and Wang, Yang and Roe, Bruce
and Jiang, Haobo},
    citeulike-article-id = {9379777},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.ibmb.2011.05.005},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3142711/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/21641996},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=21641996},
    day = {27},
    doi = {10.1016/j.ibmb.2011.05.005},
    issn = {1879-0240},
    journal = {Insect biochemistry and molecular biology},
    month = sep,
    number = {9},
    pages = {733--746},
    pmcid = {PMC3142711},
    pmid = {21641996},
    posted-at = {2011-08-23 10:43:23},
    priority = {2},
    title = {Pyrosequencing-based expression profiling and identification of differentially regulated genes from Manduca
sexta, a lepidopteran model insect.},
    url = {http://dx.doi.org/10.1016/j.ibmb.2011.05.005},
    volume = {41},
    year = {2011}
}

@inproceedings{citeulike:3064729,
    abstract = {Versioned and bug-tracked software systems provide a huge amount of historical data regarding source
code changes and issues management. In this paper we deal with impact analysis of a change request and show that data
stored in software repositories are a good descriptor on how past change requests have been resolved. A fine grained
analysis method of software repositories is used to index code at different levels of granularity, such as lines of code
and source files, with free text contained in software repositories. The method exploits information retrieval
algorithms to link the change request description and code entities impacted by similar past change requests. We
evaluate such approach on a set of three open-source projects.},
    address = {New York, NY, USA},
    author = {Canfora, Gerardo and Cerulo, Luigi},
    booktitle = {Proceedings of the 2006 international workshop on Mining software repositories},
    citeulike-article-id = {3064729},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1138009},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1137983.1138009},
    doi = {10.1145/1137983.1138009},
    isbn = {1-59593-397-2},
    keywords = {thesis-phd},
    location = {Shanghai, China},
    pages = {105--111},
    posted-at = {2011-06-20 07:24:39},
    priority = {2},
    publisher = {ACM},
    series = {MSR '06},
    title = {Fine grained indexing of software repositories to support impact analysis},
    url = {http://dx.doi.org/10.1145/1137983.1138009},
    year = {2006}
}

@article{citeulike:6699577,
    abstract = {
                High-throughput sequencing technologies, such as the Illumina Genome Analyzer, are powerful new tools
for investigating a wide range of biological and medical questions. Statistical and computational methods are key for
drawing meaningful and accurate conclusions from the massive and complex datasets generated by the sequencers. We
provide a detailed evaluation of statistical methods for normalization and differential expression ({DE}) analysis of
Illumina transcriptome sequencing ({mRNA}-Seq) data.
                We compare statistical methods for detecting genes that are significantly {DE} between two types of
biological samples and find that there are substantial differences in how the test statistics handle low-count genes. We
evaluate how {DE} results are affected by features of the sequencing platform, such as, varying gene lengths,
base-calling calibration method (with and without phi X control lane), and flow-cell/library preparation effects. We
investigate the impact of the read count normalization method on {DE} results and show that the standard approach of
scaling by total lane counts (e.g., {RPKM}) can bias estimates of {DE}. We propose more general quantile-based
normalization procedures and demonstrate an improvement in {DE} detection.
                Our results have significant practical and methodological implications for the design and analysis of
{mRNA}-Seq experiments. They highlight the importance of appropriate statistical methods for normalization and {DE}
inference, to account for features of the sequencing platform that could impact the accuracy of results. They also
reveal the need for further research in the development of statistical and computational methods for {mRNA}-Seq.
            },
    author = {Bullard, James H. and Purdom, Elizabeth and Hansen, Kasper D. and Dudoit, Sandrine},
    citeulike-article-id = {6699577},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2105-11-94},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2838869/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/20167110},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=20167110},
    day = {18},
    doi = {10.1186/1471-2105-11-94},
    issn = {1471-2105},
    journal = {BMC bioinformatics},
    month = feb,
    number = {1},
    pages = {94+},
    pmcid = {PMC2838869},
    pmid = {20167110},
    posted-at = {2011-06-08 09:45:12},
    priority = {2},
    title = {Evaluation of statistical methods for normalization and differential expression in {mRNA}-Seq
experiments.},
    url = {http://dx.doi.org/10.1186/1471-2105-11-94},
    volume = {11},
    year = {2010}
}

@inproceedings{citeulike:9114115,
    abstract = {The development of Open Source systems produces a variety of software artifacts such as source code,
version control records, bug reports, and email discussions. Since the development is distributed across different tool
environments and developer practices, any analysis of project behavior must be inferred from whatever common artifacts
happen to be available. In this paper, we propose an approach to characterizing a project's behavior around the time of
major and minor releases; we do this by partitioning the observed activities, such as artifact check-ins, around the
dates of major and minor releases, and then look for recognizable patterns. We validate this approach by means of a case
study on the {MySQL} database system; in this case study, we found patterns which suggested {MySQL} was behaving
consistently within itself. These patterns included testing and documenting that took place more before a release than
after and that the rate of source code changes dipped around release time.},
    address = {Washington, DC, USA},
    author = {Hindle, Abram and Godfrey, Michael W. and Holt, Richard C.},
    booktitle = {Proceedings of the Fourth International Workshop on Mining Software Repositories},
    citeulike-article-id = {9114115},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1269033},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/msr.2007.28},
    doi = {10.1109/msr.2007.28},
    isbn = {0-7695-2950-X},
    posted-at = {2011-04-07 18:25:23},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {MSR '07},
    title = {Release Pattern Discovery via Partitioning: Methodology and Case Study},
    url = {http://dx.doi.org/10.1109/msr.2007.28},
    year = {2007}
}

@book{citeulike:7706819,
    citeulike-article-id = {7706819},
    day = {01},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0803913710},
    keywords = {thesis-phd},
    month = nov,
    posted-at = {2011-04-07 16:27:01},
    priority = {2},
    publisher = {Sage Publications, Inc},
    title = {Reliability and Validity Assessment (Quantitative Applications in the Social Sciences)},
    url = {http://www.worldcat.org/isbn/0803913710},
    year = {1979}
}

@inproceedings{citeulike:9112798,
    abstract = {In this paper, we present the method we have developed to analyze socio-technical  aspects of software
problem management in {F/OSS} communities, based on large  corpora of problem reports; and we report on early results we
obtained using our  framework. Given the amount of data available, computational techniques to  scalably extract event
data and model the collectives\&\#039; behaviors are needed. We are  using a variety of techniques that couple
human-based qualitative analysis with  computational extraction and modeling to generate models of the processes
involved  in software problem management.},
    author = {Oss, For U. and Ripoche, Gabriel and Gasser, Les},
    booktitle = {in Proceedings of the 16 th International Conference on Software \&amp; Systems Engineering and their
Applications},
    citeulike-article-id = {9112798},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.4.2887},
    keywords = {thesis-phd},
    pages = {2--4},
    posted-at = {2011-04-07 14:03:33},
    priority = {2},
    title = {Scalable Automatic Extraction of Process Models},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.4.2887},
    year = {2003}
}

@article{citeulike:421438,
    abstract = {Many successful free/open source software ({FOSS}) projects start with the premise that their
contributors are rarely colocated, and as a consequence, these projects are cases of global software development
({GSD}). This article describes how the {GNOME} Project, a large {FOSS} project, has tried to overcome the disadvantages
of {GSD}. The main goal of {GNOME} is to create a {GUI} desktop for Unix systems, and encompasses close to two million
lines of code. More than 500 individuals (distributed across the world) have contributed to the project. This article
also describes the software development methods and practices used by the members of the project, and its organizational
structure. The article ends by proposing a list of practices that could benefit other global software development
projects, both {FOSS} and commercial. Copyright \&copy; 2004 John Wiley \&amp; Sons, Ltd.},
    author = {German, Daniel M.},
    citeulike-article-id = {421438},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/spip.189},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/109630255/ABSTRACT},
    day = {22},
    doi = {10.1002/spip.189},
    issn = {1077-4866},
    journal = {Software Process: Improvement and Practice},
    keywords = {thesis-phd},
    month = oct,
    number = {4},
    pages = {201--215},
    posted-at = {2011-04-07 10:21:54},
    priority = {2},
    title = {The {GNOME} project: a case study of open source, global software development},
    url = {http://dx.doi.org/10.1002/spip.189},
    volume = {8},
    year = {2004}
}

@inproceedings{citeulike:227033,
    abstract = {Moments before the launch of every space vehicle, engineering discipline specialists must make a
critical go/no-go decision. The cost of a false positive, allowing a launch in spite of a fault, or a false negative,
stopping a potentially successful launch, can be measured in the tens of millions of dollars, not including the cost in
morale and other more intangible detriments. The Aerospace Corporation is responsible for providing engineering
assessments critical to the go/no-go decision for every Department of Defense space vehicle. These assessments are made
by constantly monitoring streaming telemetry data in the hours before launch. We will introduce {VizTree}, a novel
time-series visualization tool to aid the Aerospace analysts who must make these engineering assessments. {VizTree} was
developed at the University of California, Riverside and is unique in that the same tool is used for mining archival
data and monitoring incoming live telemetry. The use of a single tool for both aspects 
of the task allows a natural and intuitive transfer of mined knowledge to the monitoring task. Our visualization
approach works by transforming the time series into a symbolic representation, and encoding the data in a modified
suffix tree in which the frequency and other properties of patterns are mapped onto colors and other visual properties.
We demonstrate the utility of our system by comparing it with state-of-the-art batch algorithms on several real and
synthetic datasets.},
    address = {New York, NY, USA},
    author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano and Lankford, Jeffrey P. and Nystrom, Donna M.},
    booktitle = {Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
    citeulike-article-id = {227033},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1014104},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1014052.1014104},
    doi = {10.1145/1014052.1014104},
    isbn = {1-58113-888-1},
    keywords = {thesis-phd},
    location = {Seattle, WA, USA},
    pages = {460--469},
    posted-at = {2011-03-28 18:15:17},
    priority = {2},
    publisher = {ACM},
    series = {KDD '04},
    title = {Visually mining and monitoring massive time series},
    url = {http://dx.doi.org/10.1145/1014052.1014104},
    year = {2004}
}

@inproceedings{citeulike:9007622,
    abstract = {Often stakeholders, such as developers, managers, or buyers, want to find out what software development
processes are being followed within a software project. Their reasons include: {CMM} and {ISO} 9000 compliance, process
validation, management, acquisitions, and business intelligence. Recovering the software development processes from an
existing project is expensive if one must rely upon manual inspection of artifacts and interviews of developers and
their managers. Researchers have suggested live observation and instrumentation of a project to allow for more
measurement, but this is costly, invasive, and also requires a live running project. Instead, we propose an after the
fact analysis: software process recovery. This approach analyzes version control systems, bug trackers and mailing list
archives using a variety of supervised and unsupervised techniques from machine learning, topic analysis, natural
language processing and statistics. We can combine all of these methods to recover 
process events that we map back to software development processes like the Unified Process. We can produce diagrams
called Recovered Unified Process Views ({RUPV}) that are similar to the Unified Process diagram, a time-line of effort
per parallel discipline occurring across time. We then validate these methods using case studies of multiple open source
software systems.},
    author = {Hindle, Abram},
    citeulike-article-id = {9007622},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/wcre.2010.46},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5645491},
    doi = {10.1109/wcre.2010.46},
    keywords = {thesis-phd},
    location = {Beverly, MA, USA},
    month = oct,
    pages = {305--308},
    posted-at = {2011-03-17 10:58:07},
    priority = {2},
    title = {Software Process Recovery: Recovering Process from Artifacts},
    url = {http://dx.doi.org/10.1109/wcre.2010.46},
    year = {2010}
}

@inproceedings{citeulike:9006886,
    abstract = {We have mined the Eclipse bug and version databases to map failures to Eclipse components. The resulting
data set lists the defect density of all Eclipse components. As we demonstrate in three simple experiments, the bug data
set can be easily used to relate code, process, and developers to defects. The data set is publicly avail-able for
download.},
    author = {Schr\"{o}ter, Adrian and Zimmermann, Thomas and Premraj, Rahul and Zeller, Andreas},
    booktitle = {In Proceedings of the 5th International Symposium on Empirical Software Engineering, Volume II: Short
Papers and Posters},
    citeulike-article-id = {9006886},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.114.7244},
    keywords = {thesis-phd},
    pages = {18--20},
    posted-at = {2011-03-17 07:47:22},
    priority = {2},
    title = {If your bug database could talk},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.114.7244},
    volume = {2006},
    year = {2006}
}

@electronic{citeulike:9004378,
    abstract = {Version control systems ({VCSs}) are used to store and reconstruct past versions of program source code.
As a by-product they also capture a great deal of contextual information about each change. We will illustrate some ways
to use this information to better understand a program\&\#039;s development history. 1},
    author = {Ball, Thomas and Kim, Jung-min and Porter, Adam A. and Siy, Harvey P.},
    citeulike-article-id = {9004378},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.8653},
    keywords = {thesis-phd},
    posted-at = {2011-03-16 19:46:51},
    priority = {2},
    title = {Abstract If Your Version Control System Could Talk...},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.8653}
}

@article{citeulike:6185797,
    abstract = {Modulators of G protein-coupled receptors ({GPCRs}) form a key area for the pharmaceutical industry,
representing approximately 27\% of all Food and Drug Administration ({FDA})-approved drugs. Consequently, there are a
wide variety of in vitro plate-based screening technologies that enable the measurement of compound affinity, potency,
and efficacy for almost every type of {GPCR}. However, to maximize success it is prudent to ensure that (i) the most
suitable assay formats are identified, (ii) they are configured optimally to detect the desired compound activity, and
(iii) that they form a basis for predicting clinical effects. To achieve this, an understanding of the pathways and
mechanisms of receptor activation relevant to the disease mechanism, as well as the benefits and/or limitations of the
specific techniques, is key.},
    address = {Totowa, NJ},
    author = {Williams, Christine and Hill, Stephen J.},
    booktitle = {G Protein-Coupled Receptors in Drug Discovery},
    chapter = {3},
    citeulike-article-id = {6185797},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-1-60327-317-6\_3},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19513640},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19513640},
    citeulike-linkout-3 = {http://www.springerlink.com/content/k6626211005lq75r},
    doi = {10.1007/978-1-60327-317-6\_3},
    isbn = {978-1-60327-316-9},
    issn = {1064-3745},
    journal = {Methods in molecular biology (Clifton, N.J.)},
    pages = {39--50},
    pmid = {19513640},
    posted-at = {2011-03-15 09:25:53},
    priority = {2},
    publisher = {Humana Press},
    series = {Methods in Molecular Biology™},
    title = {{GPCR} signaling: understanding the pathway to successful drug discovery.},
    url = {http://dx.doi.org/10.1007/978-1-60327-317-6\_3},
    volume = {552},
    year = {2009}
}

@incollection{citeulike:8979205,
    address = {Berlin, Heidelberg},
    author = {Schultz, G\"{u}nter and Schaefer, Michael},
    booktitle = {Encyclopedia of Molecular Pharmacology},
    chapter = {143},
    citeulike-article-id = {8979205},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-38918-7\_143},
    citeulike-linkout-1 = {http://www.springerlink.com/content/m55x7682590qm896},
    doi = {10.1007/978-3-540-38918-7\_143},
    editor = {Offermanns, Stefan and Rosenthal, Walter},
    isbn = {978-3-540-38916-3},
    pages = {1236--1242},
    posted-at = {2011-03-11 10:29:49},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Transmembrane Signaling},
    url = {http://dx.doi.org/10.1007/978-3-540-38918-7\_143},
    year = {2008}
}

@electronic{citeulike:5058462,
    abstract = {All analyses of version archives have one phase in common: the preprocessing of data. Preprocessing has
a direct impact on the quality of the results returned by an analysis. In this paper we discuss four essential
preprocessing tasks necessary for a fine-grained analysis of {CVS} archives: (a) data extraction, (b) transaction
recovery, (c) mapping of changes to fine-grained entities, and (d) data cleaning. We formalize the concept of sliding
time windows and show how commit mails can relate revisions to transactions. We also present two approaches that map
changes to the affected building blocks of a file, e.g. functions or sections.},
    author = {Zimmermann, Thomas},
    citeulike-article-id = {5058462},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.9987},
    keywords = {th, thesis-phd},
    pages = {2--6},
    posted-at = {2011-03-02 19:13:54},
    priority = {2},
    title = {Preprocessing {CVS} data for fine-grained analysis},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.9987},
    year = {2004}
}

@article{Masse:2009p34032,
    abstract = {In both insect and vertebrate olfactory systems only two synapses separate the sensory periphery from
brain areas required for memory formation and the organisation of behaviour. In the Drosophila olfactory system, which
is anatomically very similar to its vertebrate counterpart, there has been substantial recent progress in understanding
the flow of information from experiments using molecular genetic, electrophysiological and optical imaging techniques.
In this review, we shall focus on how olfactory information is processed and transformed in order to extract
behaviourally relevant information. We follow the progress from olfactory receptor neurons, through the first processing
area, the antennal lobe, to higher olfactory centres. We address both the underlying anatomy and mechanisms that govern
the transformation of neural activity. We emphasise our emerging understanding of how different elementary computations,
including signal averaging, gain control, decorrelation and integration, may 
be mapped onto different circuit elements.},
    author = {Masse, Nicolas Y. and Turner, Glenn C. and Jefferis, Gregory S. X. E.},
    citeulike-article-id = {7248783},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cub.2009.06.026},
    citeulike-linkout-1 = {http://www.cell.com/current-biology/retrieve/pii/S0960982209013013},
    doi = {10.1016/j.cub.2009.06.026},
    journal = {Curr Biol},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors, odorants},
    local-url = {file://localhost/Users/Walton/Dropbox/Libraries/Papers/Curr\%20Biol\%202009\%20Masse.pdf},
    month = aug,
    number = {16},
    pages = {R700--13},
    posted-at = {2011-02-25 17:03:07},
    priority = {2},
    title = {Olfactory information processing in Drosophila},
    url = {http://www.cell.com/current-biology/retrieve/pii/S0960982209013013},
    volume = {19},
    year = {2009}
}

@article{citeulike:8861859,
    abstract = {Ants rely heavily on olfaction for communication and orientation. Here we provide the first detailed
structure–function analyses within an ant's central olfactory system asking whether in the carpenter ant, Camponotus
floridanus, the olfactory pathway exhibits adaptations to processing many pheromonal and general odors. Using
fluorescent tracing, confocal microscopy, and {3D}-analyses we demonstrate that the antennal lobe ({AL}) contains up to
≈460 olfactory glomeruli organized in seven distinct clusters innervated via seven antennal sensory tracts. The {AL} is
divided into two hemispheres regarding innervation of glomeruli by either projection neurons ({PNs}) with axons leaving
via the medial (m) or lateral (l) antennocerebral tract ({ACT}). M- and {l-ACT} {PNs} differ in their target areas in
the mushroom-body calyx and lateral horn. Three additional {ACTs} project to the lateral protocerebrum only. We analyzed
odor processing in {AL} glomeruli by retrograde loading of {PNs} with Fura-2 
dextran and fluorimetric calcium imaging. Odor responses were reproducible and comparable across individuals. Calcium
responses to pheromonal and nonpheromonal odors were very sensitive (10−11 dilution) and patterns were partly
overlapping, indicating that processing of both odor classes is not spatially segregated within the {AL}. Response
patterns to the main trail-pheromone component nerolic acid remained stable over a wide range of intensities (7–8 log
units), while response durations increased indicating that odor quality is maintained by a stable pattern and intensity
is mainly encoded in response durations. The structure–function analyses contribute new insights into important aspects
of odor processing in a highly advanced insect olfactory system. J. Comp. Neurol. 506:425–441, 2008. {\copyright} 2007
{Wiley-Liss}, Inc.},
    author = {Zube, Christina and Kleineidam, Christoph J. and Kirschner, Sebastian and Neef, Jakob and R\"{o}ssler,
Wolfgang},
    citeulike-article-id = {8861859},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/cne.21548},
    doi = {10.1002/cne.21548},
    journal = {J. Comp. Neurol.},
    keywords = {odorants},
    number = {3},
    pages = {425--441},
    posted-at = {2011-02-21 15:58:12},
    priority = {2},
    publisher = {Wiley Subscription Services, Inc., A Wiley Company},
    title = {Organization of the olfactory pathway and odor processing in the antennal lobe of the ant Camponotus
floridanus},
    url = {http://dx.doi.org/10.1002/cne.21548},
    volume = {506},
    year = {2008}
}

@article{citeulike:2680015,
    abstract = {In insects, each olfactory sensory neuron expresses between one and three ligand-binding members of the
olfactory receptor ({OR}) gene family, along with the highly conserved and broadly expressed Or83b co-receptor1, 2, 3,
4, 5, 6, 7, 8, 9. The functional insect {OR} consists of a heteromeric complex of unknown stoichiometry but comprising
at least one variable odorant-binding subunit and one constant Or83b family subunit10, 11, 12, 13, 14, 15, 16. Insect
{ORs} lack homology to G-protein-coupled chemosensory receptors in vertebrates17 and possess a distinct
seven-transmembrane topology with the amino terminus located intracellularly10, 18. Here we provide evidence that
heteromeric insect {ORs} comprise a new class of ligand-activated non-selective cation channels. Heterologous cells
expressing silkmoth, fruitfly or mosquito heteromeric {OR} complexes showed extracellular Ca2+ influx and
cation-non-selective ion conductance on stimulation with odorant. Odour-evoked {OR} currents are 
independent of known G-protein-coupled second messenger pathways. The fast response kinetics and {OR}-subunit-dependent
K+ ion selectivity of the insect {OR} complex support the hypothesis that the complex between {OR} and Or83b itself
confers channel activity. Direct evidence for odorant-gated channels was obtained by outside-out patch-clamp recording
of Xenopus oocyte and {HEK293T} cell membranes expressing insect {OR} complexes. The ligand-gated ion channel formed by
an insect {OR} complex seems to be the basis for a unique strategy that insects have acquired to respond to the
olfactory environment.},
    author = {Sato, Koji and Pellegrino, Maurizio and Nakagawa, Takao and Nakagawa, Tatsuro and Vosshall, Leslie B. and
Touhara, Kazushige},
    citeulike-article-id = {2680015},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature06850},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature06850},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18408712},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18408712},
    day = {13},
    doi = {10.1038/nature06850},
    issn = {0028-0836},
    journal = {Nature},
    keywords = {odorant},
    month = apr,
    number = {7190},
    pages = {1002--1006},
    pmid = {18408712},
    posted-at = {2011-02-21 14:16:39},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {Insect olfactory receptors are heteromeric ligand-gated ion channels},
    url = {http://dx.doi.org/10.1038/nature06850},
    volume = {452},
    year = {2008}
}

@article{citeulike:2680014,
    abstract = {From worm to man, many odorant signals are perceived by the binding of volatile ligands to odorant
receptors1 that belong to the G-protein-coupled receptor ({GPCR}) family2. They couple to heterotrimeric G-proteins,
most of which induce {cAMP} production3. This second messenger then activates cyclic-nucleotide-gated ion channels to
depolarize the olfactory receptor neuron, thus providing a signal for further neuronal processing. Recent findings,
however, have challenged this concept of odorant signal transduction in insects, because their odorant receptors, which
lack any sequence similarity to other {GPCRs4}, are composed of conventional odorant receptors (for example, Or22a),
dimerized with a ubiquitously expressed chaperone protein5, such as Or83b in Drosophila6. Or83b has a structure akin to
{GPCRs}, but has an inverted orientation in the plasma membrane4, 7. However, G proteins are expressed in insect
olfactory receptor neurons8, and olfactory perception is modified by mutations 
affecting the {cAMP} transduction pathway9. Here we show that application of odorants to mammalian cells co-expressing
Or22a and Or83b results in non-selective cation currents activated by means of an ionotropic and a metabotropic pathway,
and a subsequent increase in the intracellular Ca2+ concentration. Expression of Or83b alone leads to functional ion
channels not directly responding to odorants, but being directly activated by intracellular {cAMP} or {cGMP}. Insect
odorant receptors thus form ligand-gated channels as well as complexes of odorant-sensing units and
cyclic-nucleotide-activated non-selective cation channels. Thereby, they provide rapid and transient as well as
sensitive and prolonged odorant signalling.},
    author = {Wicher, Dieter and Schafer, Ronny and Bauernfeind, Rene and Stensmyr, Marcus C. and Heller, Regine and
Heinemann, Stefan H. and Hansson, Bill S.},
    citeulike-article-id = {2680014},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature06861},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature06861},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18408711},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18408711},
    day = {13},
    doi = {10.1038/nature06861},
    issn = {0028-0836},
    journal = {Nature},
    keywords = {odorants},
    month = apr,
    number = {7190},
    pages = {1007--1011},
    pmid = {18408711},
    posted-at = {2011-02-21 14:15:42},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {Drosophila odorant receptors are both ligand-gated and cyclic-nucleotide-activated cation channels},
    url = {http://dx.doi.org/10.1038/nature06861},
    volume = {452},
    year = {2008}
}

@article{citeulike:6296216,
    abstract = {We have taken advantage of the availability of a large amount of Drosophila genomic {DNA} sequence in
the Berkeley Drosophila Genome Project database ( approximately 1/5 of the genome) to identify a family of novel seven
transmembrane domain encoding genes that are putative Drosophila olfactory receptors. Members of the family are
expressed in distinct subsets of olfactory neurons, and certain family members are restricted to distinct portions of
the olfactory system. This pattern of expression has interesting similarities to and differences from the expression
patterns observed for olfactory receptors in vertebrates. The Drosophila olfactory system is simpler than mammalian
systems, yet it is complex enough to present a fascinating system in which to study neural information processing.
Moreover, the powerful genetic manipulations available in Drosophila, when combined with electrophysiological and
behavioral analyses, make this an attractive model system in which to study olfactory 
discrimination.},
    author = {Gao, Q. and Chess, A.},
    citeulike-article-id = {6296216},
    citeulike-linkout-0 = {http://dx.doi.org/10.1006/geno.1999.5894},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/10458908},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=10458908},
    day = {15},
    doi = {10.1006/geno.1999.5894},
    issn = {0888-7543},
    journal = {Genomics},
    keywords = {odorant},
    month = aug,
    number = {1},
    pages = {31--39},
    pmid = {10458908},
    posted-at = {2011-02-21 14:10:32},
    priority = {2},
    title = {Identification of candidate Drosophila olfactory receptors from genomic {DNA} sequence.},
    url = {http://dx.doi.org/10.1006/geno.1999.5894},
    volume = {60},
    year = {1999}
}

@article{citeulike:6287036,
    abstract = {By analogy to mammals, odorant receptors ({ORs}) in insects, such as Drosophila melanogaster, have long
been thought to belong to the G-protein coupled receptor ({GPCR}) superfamily. However, recent work has cast doubt on
this assumption and has tentatively suggested an inverted topology compared to the canonical Nout − Cin 7 transmembrane
({TM}) {GPCR} topology, at least for some Drosophila {ORs}. Here, we report a detailed topology mapping of the
Drosophila {OR83b} receptor using engineered glycosylation sites as topology markers. Our results are inconsistent with
a classical {GPCR} topology and show that {OR83b} has an intracellular N-terminus, an extracellular C-terminus, and
{7TM} helices.},
    author = {Lundin, C. and Kall, L. and Kreher, S. and Kapp, K. and Sonnhammer, E. and Carlson, J. and Vonheijne, G.
and Nilsson, I.},
    citeulike-article-id = {6287036},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.febslet.2007.11.007},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/18005664},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=18005664},
    day = {11},
    doi = {10.1016/j.febslet.2007.11.007},
    issn = {00145793},
    journal = {FEBS Letters},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors},
    month = dec,
    number = {29},
    pages = {5601--5604},
    pmid = {18005664},
    posted-at = {2011-01-24 16:09:27},
    priority = {2},
    title = {Membrane topology of the Drosophila {OR83b} odorant receptor},
    url = {http://dx.doi.org/10.1016/j.febslet.2007.11.007},
    volume = {581},
    year = {2007}
}

@article{citeulike:2446040,
    abstract = {The contributions of measurement and experimentation to the state of the art in software engineering are
reviewed. The role of measurement in developing theoretical models is discussed, and concerns for reliability and
validity are stressed. Current approaches to measuring software characteristics are presented as examples. In
particular, software complexity metrics related to control flow, module interconnectedness, and Halstead's Software
Science are discussed. The use of experimental methods in evaluating cause-effect relationships is also discussed.
Example programs of experimental research which investigated conditional statements and control flow are reviewed. The
conclusion argues that many advances in software engineering will be related to improvements in the measurement and
experimental evaluation of software techniques and practices.},
    author = {Curtis, B.},
    booktitle = {Proceedings of the IEEE},
    citeulike-article-id = {2446040},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/proc.1980.11813},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1456082},
    doi = {10.1109/proc.1980.11813},
    issn = {0018-9219},
    journal = {Proceedings of the IEEE},
    keywords = {msr, msr-2011},
    number = {9},
    pages = {1144--1157},
    posted-at = {2011-01-18 18:58:30},
    priority = {2},
    title = {Measurement and experimentation in software engineering},
    url = {http://dx.doi.org/10.1109/proc.1980.11813},
    volume = {68},
    year = {1980}
}

@article{citeulike:5969736,
    author = {Benton, Richard and Vannice, Kirsten S. and Gomez-Diaz, Carolina and Vosshall, Leslie B.},
    citeulike-article-id = {5969736},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cell.2008.12.001},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19135896},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19135896},
    day = {09},
    doi = {10.1016/j.cell.2008.12.001},
    issn = {00928674},
    journal = {Cell},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors, g\_proteins},
    month = jan,
    number = {1},
    pages = {149--162},
    pmid = {19135896},
    posted-at = {2011-01-18 11:47:56},
    priority = {2},
    title = {Variant Ionotropic Glutamate Receptors as Chemosensory Receptors in Drosophila},
    url = {http://dx.doi.org/10.1016/j.cell.2008.12.001},
    volume = {136},
    year = {2009}
}

@article{citeulike:5969737,
    abstract = { In the fruit fly Drosophila, not all olfactory sensory neurons express a seven transmembrane odorant
receptor, suggesting that other types of odorant receptors might exist. Benton et al. (2009) now present evidence that a
family of proteins related to ionotropic glutamate receptors is a previously unrecognized class of odorant receptors.
Main {TextOdor} detection is accomplished by odorant receptors, originally identified in rodents as a large family of
seven transmembrane G protein-coupled receptors ({GPCRs}). Odorant receptors have subsequently been found in fish and
nematodes, and eventually in the fruit fly Drosophila (Bargmann, 2006). Surprisingly, Drosophila seven transmembrane
odorant receptors ({ORs}) were recently found to have inverted membrane topology compared to typical {GPCRs}, with their
N terminus facing the cytoplasm rather than the extracellular space (Benton et al., 2006). Additionally, Drosophila
{ORs} require Or83b, another seven transmembrane protein highly conserved in 
insects, as an obligate coreceptor (Larsson et al., 2004). Indeed, evidence suggests that {OR}/Or83b complexes form
ligand-gated ion channels ([Sato et al., 2008] and [Wicher et al., 2008]), a striking difference to {GPCRs} in worms and
vertebrates that rely on second messengers to activate ion channels. In this issue, Benton et al. (2009) report the
identification of a new class of odorant receptors that are related to ionotropic glutamate receptors, thus expanding
the known repertoire of odorant receptors beyond the classical family of seven transmembrane {receptors.In} the
Drosophila olfactory system, olfactory sensory neurons ({OSNs}, also known as olfactory receptor neurons or {ORNs})
located in the antennae and maxillary palps send axons to the antennal lobe in the central brain. {OSN} dendrites are
present in sensory organs called sensilla, where they are exposed to the environment, and the different types of
sensilla (basiconic, coeloconic, and trichoid) respond to different types of odorants (Figure 
1). Just as in the mammalian olfactory system, most Drosphila {OSNs} express a single {OR}, and {OSN} axons expressing
the same {OR} converge on the same glomerulus in the antennal lobe (Vosshall and Stocker, 2007). Nearly every {OR} has
been genetically mapped for its expression in specific sensilla and for its corresponding {OSN} axon projection to a
specific glomerulus (Couto et al., 2005). With one exception, all {ORs} are expressed in basiconic and trichoid {OSNs}.
Or35a is expressed in coeloconic {OSNs} which project to only one of eight glomeruli predicted to be targets of
coeloconic {OSNs}. Exhaustive study of {ORs} and gustatory receptors (two gustatory receptors are coexpressed in
{CO2}-sensing {OSNs}, see Figure 1) still leaves most coeloconic {OSNs} unaccounted for with regard to the identity of
the odorant receptors they express (Couto et al., 2005). This indicated that an unidentified class of odorant receptors
could be present in most coeloconic {OSNs}. Benton et al. (2009) now present 
convincing evidence that a family of proteins related to ionotropic glutamate receptors fill this role. Benton et al.
identified this family of receptors, which they named ionotropic receptors ({IRs}), in a bioinformatic screen for genes
expressed in the fly antennae. Subsequent {BLAST} searches revealed a family of 61 genes in Drosophila. Despite having a
similar modular organization to the ionotropic glutamate receptors extensively studied for their role in synaptic
transmission, such as {AMPA} and {NMDA} receptors, the {IRs} show wide divergence at the sequence level and in
particular show considerable variations in residues known to be important for glutamate binding. Thus, these {IRs} are
unlikely to be glutamate receptors, but may instead bind other {ligands.Multiple} lines of evidence indicate that {IRs}
are indeed the missing coeloconic odorant receptors. First, {mRNAs} of 15 {IRs} are specifically expressed in neurons of
the adult antenna. Second, an antibody that specifically recognized one {IR} 
protein stained the dendrites of {OSNs}, consistent with a role in odor detection. Third, the {IR}-positive {OSNs} are
distinct from Or83b-expressing {OSNs}, as assayed by double in situ analysis (with the exception of coeloconic {OSNs}
coexpressing {Or35a/Or83b}/Ir76b). Fourth, in mutants that disrupt coeloconic sensilla development, {IR} expression is
lost. Fifth, {IR} expression maps into four clusters of neurons corresponding to the four coeloconic sensilla types
previously characterized physiologically (Yao et al., 2005). Sixth, just as {OSNs} expressing a common {OR} project
their axons to a single glomerulus, axons labeled by {Ir76a-GAL4} converge to a single glomerulus previously identified
as having coeloconic input. Finally, misexpression of {IRs} is sufficient to bestow new odor sensitivity to coeloconic
{OSNs}, indicating that {IRs} determine odor {specificity.There} appear to be important organizational differences
between {OSNs} that express {IRs} and those that express {ORs}. Multiple {IRs} 
can be coexpressed per neuron, which is strikingly different than {OR} expression, which generally follows a one
neuron-one receptor rule. This may reflect a functional requirement for more than one {IR} to form a functional channel.
{NMDA} receptors, for instance, are a tetramer composed of different subunits. Although Ir76a axons target a single
glomerulus, this may not be a general rule, as Ir76a is one of the few {IRs} expressed in a single class of coeloconic
{OSNs}. The odor responses of {IR}-expressing {OSNs} may be defined by expression of a particular set of {IRs} rather
than a single {IR} gene, so a given {IR} may label axons projecting to multiple {glomeruli.These} important results by
Benton et al. lend themselves to several lines of future study. Biologically, the identification of {IRs} should allow
comprehensive mapping of odor specificity and glomerular projection of specific {IR}-expressing {OSNs}. It is already
known that a division of labor exists between the trichoid sensilla that 
putatively sense pheromones and the basiconic sensilla that sense food odorants, and this division is even propagated to
higher olfactory centers (Jefferis et al., 2007). Future studies will determine whether coeloconic {OSNs} have
particular odor specialties and how this information is represented in the brain. Mechanistically, it is important to
extend the sufficiency test beyond ectopic expression of {IRs} in other coeloconic {OSNs}. For instance, reconstituting
the odor response in ectopic cells such as Xenopus oocytes would allow the dissection of biochemical and biophysical
properties of the {IR} receptor/channel {complex.The} identification of {IRs} as odorant receptors also raises
interesting evolutionary questions. Ionotropic glutamate receptors at synapses and {IRs} in odor detection both function
by sensing molecules in the extracellular environment, an ancient faculty dating back to prokaryotes (Bargmann, 2006).
Various families of  ” chemosensors” may have been coopted numerous times through 
evolution for purposes as diverse as olfaction, immunity, and neurotransmission. A second consideration is the
difference between olfaction in insects and other animals, namely that insect odorant receptors could function
independently from second messengers. Whether this distinction allows some evolutionary advantage, such as a more rapid
signaling, is yet to be determined. One thing is certain: insights from Drosophila olfaction continue to yield surprises
while deepening our understanding of general biological principles. },
    author = {Spletter, Maria L. and Luo, Liqun},
    citeulike-article-id = {5969737},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cell.2008.12.031},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19135885},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19135885},
    day = {09},
    doi = {10.1016/j.cell.2008.12.031},
    issn = {00928674},
    journal = {Cell},
    keywords = {g\_proteins, odorant\_binding\_protein, pheromone},
    month = jan,
    number = {1},
    pages = {23--25},
    pmid = {19135885},
    posted-at = {2011-01-18 11:45:35},
    priority = {2},
    title = {A New Family of Odorant Receptors in Drosophila},
    url = {http://dx.doi.org/10.1016/j.cell.2008.12.031},
    volume = {136},
    year = {2009}
}

@article{citeulike:620314,
    abstract = {G protein-coupled receptors ({GPCRs}) constitute a large superfamily involved in various types of signal
transduction pathways triggered by hormones, odorants, peptides, proteins, and other types of ligands. The superfamily
is so diverse that many members lack sequence similarity, although they all span the cell membrane seven times with an
extracellular N and a cytosolic C terminus. We analyzed a divergent set of {GPCRs} and found distinct loop length
patterns and differences in amino acid composition between cytosolic loops, extracellular loops, and membrane regions.
We configured {GPCRHMM}, a hidden Markov model, to fit those features and trained it on a large dataset representing the
entire superfamily. {GPCRHMM} was benchmarked to profile {HMMs} and generic transmembrane detectors on sets of known
{GPCRs} and {non-GPCRs}. In a cross-validation procedure, profile {HMMs} produced an error rate nearly twice as high as
{GPCRHMM}. In a sensitivity-selectivity test, {GPCRHMM}'s sensitivity was 
about 15\% higher than that of the best transmembrane predictors, at comparable false positive rates. We used {GPCRHMM}
to search for novel members of the {GPCR} superfamily in five proteomes. All in all we detected 120 sequences that
lacked annotation and are potentially novel {GPCRs}. Out of those 102 were found in Caenorhabditis elegans, four in
human, and seven in mouse. Many predictions (65) belonged to Pfam domains of unknown function. {GPCRHMM} strongly
rejected a family of arthropod-specific odorant receptors believed to be {GPCRs}. A detailed analysis showed that these
sequences are indeed very different from other {GPCRs}. {GPCRHMM} is available at http://gpcrhmm.cgb.ki.se.},
    address = {Center for Genomics and Bioinformatics, Karolinska Institutet, S-17177 Stockholm, Sweden.},
    author = {Wistrand, Markus and K\"{a}ll, Lukas and Sonnhammer, Erik L.},
    citeulike-article-id = {620314},
    citeulike-linkout-0 = {http://dx.doi.org/10.1110/ps.051745906},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/16452613},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=16452613},
    doi = {10.1110/ps.051745906},
    issn = {0961-8368},
    journal = {Protein science : a publication of the Protein Society},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors, g\_proteins},
    month = mar,
    number = {3},
    pages = {509--521},
    pmid = {16452613},
    posted-at = {2011-01-18 08:09:29},
    priority = {2},
    title = {A general model of G protein-coupled receptor sequences and its application to detect remote homologs.},
    url = {http://dx.doi.org/10.1110/ps.051745906},
    volume = {15},
    year = {2006}
}

@article{citeulike:6286506,
    abstract = {Drosophila olfactory sensory neurons ({OSNs}) each express two odorant receptors ({ORs}): a divergent
member of the {OR} family and the highly conserved, broadly expressed receptor {OR83b}. {OR83b} is essential for
olfaction in vivo and enhances {OR} function in vitro, but the molecular mechanism by which it acts is unknown. Here we
demonstrate that {OR83b} heterodimerizes with conventional {ORs} early in the endomembrane system in {OSNs}, couples
these complexes to the conserved ciliary trafficking pathway, and is essential to maintain the {OR}/{OR83b} complex
within the sensory cilia, where odor signal transduction occurs. The {OR}/{OR83b} complex is necessary and sufficient to
promote functional reconstitution of odor-evoked signaling in sensory neurons that normally respond only to carbon
dioxide. Unexpectedly, unlike all known vertebrate and nematode chemosensory receptors, we find that Drosophila {ORs}
and {OR83b} adopt a novel membrane topology with their N-termini and the most 
conserved loops in the cytoplasm. These loops mediate direct association of {ORs} with {OR83b}. Our results reveal that
{OR83b} is a universal and integral part of the functional {OR} in Drosophila . This atypical heteromeric and
topological design appears to be an insect-specific solution for odor recognition, making the {OR}/{OR83b} complex an
attractive target for the development of highly selective insect repellents to disrupt olfactory-mediated host-seeking
behaviors of insect disease vectors.},
    author = {Benton, Richard and Sachse, Silke and Michnick, Stephen W. and Vosshall, Leslie B.},
    citeulike-article-id = {6286506},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pbio.0040020},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/16402857},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=16402857},
    day = {17},
    doi = {10.1371/journal.pbio.0040020},
    issn = {1545-7885},
    journal = {PLoS Biol},
    keywords = {g\_protein\_coupled\_receptors, g\_proteins, odorant\_binding\_protein},
    month = jan,
    number = {2},
    pages = {e20+},
    pmid = {16402857},
    posted-at = {2011-01-18 08:08:14},
    priority = {2},
    publisher = {Public Library of Science},
    title = {Atypical Membrane Topology and Heteromeric Function of Drosophila Odorant Receptors In Vivo},
    url = {http://dx.doi.org/10.1371/journal.pbio.0040020},
    volume = {4},
    year = {2006}
}

@article{citeulike:423054,
    abstract = {
                The mammalian olfactory system can recognize and discriminate a large number of different odorant
molecules. The detection of chemically distinct odorants presumably results from the association of odorous ligands with
specific receptors on olfactory sensory neurons. To address the problem of olfactory perception at a molecular level, we
have cloned and characterized 18 different members of an extremely large multigene family that encodes seven
transmembrane domain proteins whose expression is restricted to the olfactory epithelium. The members of this novel gene
family are likely to encode a diverse family of odorant receptors.
            },
    address = {Department of Biochemistry and Molecular Biophysics, College of Physicians and Surgeons, Columbia
University, New York, New York 10032.},
    author = {Buck, L. and Axel, R.},
    citeulike-article-id = {423054},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/1840504},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=1840504},
    day = {5},
    issn = {0092-8674},
    journal = {Cell},
    keywords = {g\_protein\_coupled\_receptors, g\_proteins, odorant, odorant\_binding\_protein},
    month = apr,
    number = {1},
    pages = {175--187},
    pmid = {1840504},
    posted-at = {2011-01-14 12:57:32},
    priority = {2},
    title = {A novel multigene family may encode odorant receptors: a molecular basis for odor recognition.},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/1840504},
    volume = {65},
    year = {1991}
}

@article{citeulike:1642785,
    abstract = {Insects have an enormous impact on global public health as disease vectors and as agricultural enablers
as well as pests and olfaction is an important sensory input to their behavior. As such it is of great value to
understand the interplay of the molecular components of the olfactory system which, in addition to fostering a better
understanding of insect neurobiology, may ultimately aid in devising novel intervention strategies to reduce disease
transmission or crop damage. Since the first discovery of odorant receptors in vertebrates over a decade ago, much of
our view on how the insect olfactory system might work has been derived from observations made in vertebrates and other
invertebrates, such as lobsters or nematodes. Together with the advantages of a wide range of genetic tools, the
identification of the first insect odorant receptors in Drosophila melanogaster in 1999 paved the way for rapid progress
in unraveling the question of how olfactory signal transduction and processing 
occurs in the fruitfly. This review intends to summarize much of this progress and to point out some areas where
advances can be expected in the near future.},
    author = {R\"{u}tzler, M. and Zwiebel, L. J.},
    citeulike-article-id = {1642785},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00359-005-0044-y},
    citeulike-linkout-1 = {http://www.springerlink.com/content/g37492k14117774k},
    day = {1},
    doi = {10.1007/s00359-005-0044-y},
    issn = {0340-7594},
    journal = {Journal of Comparative Physiology A: Neuroethology, Sensory, Neural, and Behavioral Physiology},
    keywords = {g\_protein\_coupled\_receptors, g\_proteins, odorant, odorant\_binding\_protein, or},
    month = sep,
    number = {9},
    pages = {777--790},
    posted-at = {2011-01-14 12:23:46},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {Molecular biology of insect olfaction:recent progress and conceptual models},
    url = {http://dx.doi.org/10.1007/s00359-005-0044-y},
    volume = {191},
    year = {2005}
}

@article{citeulike:6890081,
    abstract = {An international, peer-reviewed genome sciences journal featuring outstanding original research that
offers novel insights into the biology of all organisms},
    author = {Borchert, Nadine and Dieterich, Christoph and Krug, Karsten and Sch\"{u}tz, Wolfgang and Jung, Stephan and
Nordheim, Alfred and Sommer, Ralf J. and Macek, Boris},
    citeulike-article-id = {6890081},
    citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.103119.109},
    citeulike-linkout-1 = {http://genome.cshlp.org/content/early/2010/04/21/gr.103119.109.abstract},
    citeulike-linkout-2 = {http://genome.cshlp.org/content/early/2010/04/21/gr.103119.109.full.pdf},
    citeulike-linkout-3 = {http://genome.cshlp.org/cgi/content/abstract/20/6/837},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/20237107},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=20237107},
    day = {01},
    doi = {10.1101/gr.103119.109},
    issn = {1549-5469},
    journal = {Genome Research},
    keywords = {odorant, odorant\_binding\_protein},
    month = jun,
    number = {6},
    pages = {837--846},
    pmid = {20237107},
    posted-at = {2011-01-14 09:47:37},
    priority = {2},
    publisher = {Cold Spring Harbor Laboratory Press},
    title = {Proteogenomics of Pristionchus pacificus reveals distinct proteome structure of nematode models},
    url = {http://dx.doi.org/10.1101/gr.103119.109},
    volume = {20},
    year = {2010}
}

@article{citeulike:8031121,
    abstract = {{BACKGROUND}:Roche 454 pyrosequencing has become a method of choice for generating transcriptome data
from non-model organisms. Once the tens to hundreds of thousands of short (250-450 base) reads have been produced, it is
important to correctly assemble these to estimate the sequence of all the transcripts. Most transcriptome assembly
projects use only one program for assembling 454 pyrosequencing reads, but there is no evidence that the programs used
to date are optimal. We have carried out a systematic comparison of five assemblers ({CAP3}, {MIRA}, Newbler, {SeqMan}
and {CLC}) to establish best practices for transcriptome assemblies, using a new dataset from the parasitic nematode
Litomosoides {sigmodontis.RESULTS}:Although no single assembler performed best on all our criteria, Newbler 2.5 gave
longer contigs, better alignments to some reference sequences, and was fast and easy to use. {SeqMan} assemblies
performed best on the criterion of recapitulating known transcripts, and had more 
novel sequence than the other assemblers, but generated an excess of small, redundant contigs. The remaining assemblers
all performed almost as well, with the exception of Newbler 2.3 (the version currently used by most assembly projects),
which generated assemblies that had significantly lower total length. As different assemblers use different underlying
algorithms to generate contigs, we also explored merging of assemblies and found that the merged datasets not only
aligned better to reference sequences than individual assemblies, but were also more consistent in the number and size
of {contigs.CONCLUSIONS}:Transcriptome assemblies are smaller than genome assemblies and thus should be more
computationally tractable, but are often harder because individual contigs can have highly variable read coverage.
Comparing single assemblers, Newbler 2.5 performed best on our trial data set, but other assemblers were closely
comparable. Combining differently optimal assemblies from different programs however gave a 
more credible final product, and this strategy is recommended.},
    author = {Kumar, Sujai and Blaxter, Mark},
    citeulike-article-id = {8031121},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2164-11-571},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/20950480},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=20950480},
    doi = {10.1186/1471-2164-11-571},
    issn = {1471-2164},
    journal = {BMC Genomics},
    keywords = {g\_protein\_coupled\_receptors, odorant, odorant\_binding\_protein},
    number = {1},
    pages = {571+},
    pmid = {20950480},
    posted-at = {2011-01-14 09:47:18},
    priority = {2},
    title = {Comparing de novo assemblers for 454 transcriptome data},
    url = {http://dx.doi.org/10.1186/1471-2164-11-571},
    volume = {11},
    year = {2010}
}

@article{citeulike:8604053,
    abstract = {Male moths are endowed with odorant receptors ({ORs}) to detect species-specific sex pheromones with
remarkable sensitivity and selectivity. We serendipitously discovered that an endogenous {OR} in the fruit fly,
Drosophila melanogaster, is highly sensitive to the sex pheromone of the silkworm moth, bombykol. Intriguingly, the
fruit fly detectors are more sensitive than the receptors of the silkworm moth, although its ecological significance is
unknown. By expression in the  ” empty neuron” system, we identified the fruit fly bombykol-sensitive {OR} as {DmelOR7a}
(= {DmOR7a}). The profiles of this receptor in response to bombykol in the native sensilla (ab4) or expressed in the
empty neuron system (ab3 sensilla) are indistinguishable. Both {WT} and transgenic flies responded with high
sensitivity, in a dose-dependent manner, and with rapid signal termination. In contrast, the same empty neuron
expressing the moth bombykol receptor, {BmorOR1}, demonstrated low sensitivity and slow signal 
inactivation. When expressed in the trichoid sensilla T1 of the fruit fly, the neuron housing {BmorOR1} responded with
sensitivity comparable to that of the native trichoid sensilla in the silkworm moth. By challenging the native bombykol
receptor in the fruit fly with high doses of another odorant to which the receptor responds with the highest
sensitivity, we demonstrate that slow signal termination is induced by overdose of a stimulus. As opposed to the empty
neuron system in the basiconic sensilla, the structural, biochemical, and/or biophysical features of the sensilla make
the T1 trichoid system of the fly a better surrogate for the moth receptor.},
    author = {Syed, Zainulabeuddin and Kopp, Artyom and Kimbrell, Deborah A. and Leal, Walter S.},
    citeulike-article-id = {8604053},
    citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.1003881107},
    citeulike-linkout-1 = {http://www.pnas.org/content/early/2010/04/28/1003881107.abstract},
    citeulike-linkout-2 = {http://www.pnas.org/content/early/2010/04/28/1003881107.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/20439725},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=20439725},
    doi = {10.1073/pnas.1003881107},
    journal = {Proceedings of the National Academy of Sciences},
    keywords = {odorant, odorant\_binding\_protein, pheromone},
    pmid = {20439725},
    posted-at = {2011-01-14 07:46:04},
    priority = {2},
    title = {Bombykol receptors in the silkworm moth and the fruit fly},
    url = {http://dx.doi.org/10.1073/pnas.1003881107}
}

@article{citeulike:8599306,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Bryant, A. and Kirkham, J. A.},
    citeulike-article-id = {8599306},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1010897},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1010891.1010897},
    doi = {10.1145/1010891.1010897},
    issn = {0163-5948},
    journal = {SIGSOFT Softw. Eng. Notes},
    keywords = {msr-2011},
    month = jul,
    pages = {44--60},
    posted-at = {2011-01-13 20:11:51},
    priority = {2},
    publisher = {ACM},
    title = {B. W. Boehm software engineering economics: a review essay},
    url = {http://dx.doi.org/10.1145/1010891.1010897},
    volume = {8},
    year = {1983}
}

@article{citeulike:8596983,
    abstract = {The article examines a statistical analysis of a productivity
variation, involving a unique database containing 206 business software
projects from 26 Finnish companies. The authors examine differences in
the factors, explaining productivity in the banking, insurance,
manufacturing, wholesale/retail, and public administration sectors. The
authors provide productivity benchmarking equations that are useful both
for estimating expected productivity at the start of a new project and
for benchmarking a completed project for each business sector},
    author = {Maxwell, K. D. and Forselius, P.},
    citeulike-article-id = {8596983},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/52.820015},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=820015},
    doi = {10.1109/52.820015},
    issn = {07407459},
    journal = {IEEE Software},
    keywords = {msr-2011},
    month = jan,
    number = {1},
    pages = {80--88},
    posted-at = {2011-01-13 14:18:52},
    priority = {2},
    title = {Benchmarking software development productivity},
    url = {http://dx.doi.org/10.1109/52.820015},
    volume = {17},
    year = {2000}
}

@article{citeulike:7019087,
    abstract = {Time is an essential measure of performance in software
development because time delays tend to fall directly to the bottom
line. To address this issue, this research seeks to distinguish
time-based software development practices: those managerial actions that
result in faster development speed and higher productivity. This study
is based upon a survey of software management practices in Western
Europe and builds upon an earlier study we carried out in the United
States and Japan (Integrated Manufacturing Systems, vol. 7, no. 2,
1996). We measure the extent to which managers in the {USA}, Japan and
Europe differ in their management of software projects and also
determine the tools, technology and practices that separate fast and
slow developers in Western Europe},
    author = {Blackburn, J. D. and Scudder, G. D. and Van Wassenhove, L. N.},
    citeulike-article-id = {7019087},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/32.553636},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=553636},
    doi = {10.1109/32.553636},
    issn = {00985589},
    journal = {IEEE Transactions on Software Engineering},
    keywords = {msr-2011},
    month = dec,
    number = {12},
    pages = {875--885},
    posted-at = {2011-01-13 14:17:37},
    priority = {2},
    title = {Improving speed and productivity of software development: a global survey of software developers},
    url = {http://dx.doi.org/10.1109/32.553636},
    volume = {22},
    year = {1996}
}

@article{citeulike:938392,
    abstract = {The identification, combination, and interaction of the many
factors which influence software development productivity makes the
measurement, estimation, comparison and tracking of productivity rates
very difficult. Through the analysis of a European Space Agency database
consisting of 99 software development projects from 37 companies in a
European countries, the paper seeks to provide significant and useful
Information about the major factors which influence the productivity of
European space, military, and industrial applications, as well as to
determine the best metric for measuring the productivity of these
projects. Several key findings emerge from the study. The results
indicate that some organizations are obtaining significantly higher
productivity than others. Some of this variation is due to the
differences in the application category and programming language of
projects in each company; however, some differences must also be due to
the ways in which these companies manage their software development
projects. The use of tools and modern programming practices were found
to be major controllable factors in productivity improvement. Finally,
the lines-of-code productivity metric is shown to be superior to the
process productivity metric for projects in the authors' database},
    author = {Maxwell, K. D. and Van Wassenhove, L. and Dutta, S.},
    citeulike-article-id = {938392},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/32.544349},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=544349},
    doi = {10.1109/32.544349},
    issn = {00985589},
    journal = {IEEE Transactions on Software Engineering},
    keywords = {msr-2011},
    month = oct,
    number = {10},
    pages = {706--718},
    posted-at = {2011-01-13 14:08:20},
    priority = {2},
    title = {Software development productivity of European space, military, and industrial applications},
    url = {http://dx.doi.org/10.1109/32.544349},
    volume = {22},
    year = {1996}
}

@inproceedings{citeulike:8596894,
    abstract = {Various measures and methods have been developed to measure the sizes of different software entities
produced throughout the software life cycle. Understanding the nature of the relationship between the sizes of these
products has become significant due to various reasons. One major reason is the ability to predict the size of the later
phase products by using the sizes of early life cycle products. For example, we need to predict the Source Lines of Code
({SLOC}) from Function Points ({FP}) since {SLOC} is being used as the main input for most of the estimation models when
this measure is not available yet. {SLOC}/{FP} ratios have been used by the industry for such purposes even though the
assumed linear relationship has not been validated yet. Similarly, {FP} has recently started to be used to predict the
Bytes of code for estimating the amount of spare memory needed in systems. In this paper, we aim to investigate further
the nature of the relationship between the software functional size 
and the code size by conducting a series of empirical studies.},
    author = {Gencel, Cigdem and Heldal, Rogardt and Lind, Kenneth},
    citeulike-article-id = {8596894},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/apsec.2009.51},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5358475},
    doi = {10.1109/apsec.2009.51},
    keywords = {msr-2011},
    location = {Batu Ferringhi, Penang, Malaysia},
    month = dec,
    pages = {19--26},
    posted-at = {2011-01-13 14:06:07},
    priority = {2},
    title = {On the Relationship between Different Size Measures in the Software Life Cycle},
    url = {http://dx.doi.org/10.1109/apsec.2009.51},
    year = {2009}
}

@article{citeulike:8596749,
    abstract = {A simple method measuring new effective lines of code showed that between 19 and 40 percent of code
written on three projects wasn't in the final release. Generally, productivity is a function of input effort and output
size. A strong understanding of software productivity, coupled with a good estimate of software size, is key to
predicting project effort and, ultimately, producing reliable project duration estimates, schedules, and resource needs.
Project managers and engineers often measure or predict the size of released software-the volume of software in the
marketed product. However, the final release doesn't include reworked code-code that was changed or deleted during
development.},
    author = {Morozoff, E.},
    citeulike-article-id = {8596749},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ms.2009.160},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5232799},
    doi = {10.1109/ms.2009.160},
    issn = {0740-7459},
    journal = {IEEE Software},
    keywords = {msr-2011},
    month = jan,
    number = {1},
    pages = {72--77},
    posted-at = {2011-01-13 14:04:33},
    priority = {2},
    title = {Using a Line of Code Metric to Understand Software Rework},
    url = {http://dx.doi.org/10.1109/ms.2009.160},
    volume = {27},
    year = {2010}
}

@inproceedings{citeulike:6346098,
    abstract = {Source lines of code ({SLOC}) is perhaps the oldest of software
metrics, and still a benchmark for evaluating new ones. Despite the
extensive experience with the {SLOC} metric, there are still a number of
misconceptions about it. The paper addresses three of them: (1) that the
format of {SLOC} is relevant to how to properly count it (a simple
experiment shows that, in fact, it does not matter), (2) that {SLOC} is
most useful as a predictor of software quality (in fact it is most
useful as a covariate of other predictors), and (3) that there is an
important inverse relationship between defect density and code size (in
fact, this is an arithmetic artifact of plotting {bugs-per-SLOC} against
{SLOC})},
    address = {Los Alamitos, CA, USA},
    author = {Rosenberg, J.},
    citeulike-article-id = {6346098},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/METRIC.1997.637174},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/metric.1997.637174},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=637174},
    day = {7},
    doi = {10.1109/metric.1997.637174},
    isbn = {0-8186-8093-8},
    journal = {Software Metrics Symposium, 1997. Proceedings., Fourth International},
    keywords = {msr-2011},
    location = {Albuquerque, NM, USA},
    month = nov,
    pages = {137--142},
    posted-at = {2011-01-13 13:23:13},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Some misconceptions about lines of code},
    url = {http://dx.doi.org/10.1109/metric.1997.637174},
    volume = {0},
    year = {1997}
}

@article{citeulike:8484508,
    abstract = {Odorant receptors comprise a unique family of G-protein-coupled seven-transmembrane receptors both in
mammals and insects. In the fruit fly Drosophila melanogaster, all 61 candidate odorant receptor genes have been
identified based on the complete genome sequence, and their expression patterns have been examined. A given odorant
receptor is expressed in the antenna or maxillary palp, or not expressed at all. Here we have applied a set of
statistical analyses to the length of the extra- and intracellular loops and terminals ({LTs}) of Drosophila odorant
receptors to examine possible inter- and intramolecular relations at the population level. We have first provided some
useful statistical information such as mean length values and length histograms to depict a general nature of Drosophila
odorant receptors at the population level, after focusing on discrepancy on assigning transmembrane domains between
researchers. In a preferable transmembrane assignment, all extracellular {LTs}, especially 
the second extracellular loops, were relatively large in length, suggesting their functional significance. Somewhat
surprisingly, principle component analysis ({PCA}) indicated that the maxillary palp receptors were almost as diverse as
the antenna receptors despite their much smaller population size. {PCA} together with histograms also revealed that
receptors with an abnormal length configuration tended not to be expressed, suggesting that {LT} length deviations are
related to transcriptional silencing of odorant receptor genes. Rank transformation tests pointed out possible {LTs}
that could have different length between differently expressed receptors at the population level. Taken together, length
analyses provide us with a general picture, i.e.  ” length configuration,” of Drosophila odorant receptors at the
population level that could point out putatively important functional sites for experimental studies.},
    author = {Otaki, J.},
    citeulike-article-id = {8484508},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0022-5193(03)00068-7},
    day = {07},
    doi = {10.1016/s0022-5193(03)00068-7},
    issn = {00225193},
    journal = {Journal of Theoretical Biology},
    keywords = {odorant, odorant\_binding\_protein, pheromone},
    month = jul,
    number = {1},
    pages = {27--37},
    posted-at = {2010-12-25 18:18:07},
    priority = {2},
    title = {Length analyses of Drosophila odorant receptors},
    url = {http://dx.doi.org/10.1016/s0022-5193(03)00068-7},
    volume = {223},
    year = {2003}
}

@article{citeulike:8484507,
    abstract = { In 1999, three groups independently identified a large family of candidate Drosophila odorant receptor
genes ([2, 3 and 5]). These genes encode novel seven transmembrane domain receptor proteins that are selectively
expressed in subsets of olfactory receptor neurons in the fruit fly. A total of 19 candidate odorant receptors were
described in the initial reports, and these were named according to three different nomenclature systems, resulting in
multiple names for a given receptor. With the recent completion of the euchromatic genome sequence of Drosophila ([1 and
4]), the number of identified genes with homology to the candidate odorant receptors has increased to a total of 60.
These have been annotated by Celera Genomics in collaboration with the Berkeley Drosophila Genome Project using a fourth
nomenclature system. To address this nomenclature problem, representatives of several laboratories met at the
Association for Chemoreception Sciences meeting held in Sarasota, Florida, in April, 
2000. Subsequently, representatives of {FlyBase} were consulted for their assistance in unifying the nomenclature. As a
result of these discussions, a Drosophila Odorant Receptor Nomenclature Committee was formed to systematize and unify
the Drosophila odorant receptor nomenclature. Table 1 presents a summary of the proposed nomenclature, which has
recently been endorsed by a number of scientists working in the field. Rationale of the {SystemGenes} in Drosophila are
typically named to convey functional information, usually reflecting a mutant phenotype. When mutants are not available,
the gene name instead often conveys information about chromosomal position. The Drosophila genome has been divided into
102 numbered segments, based on characteristic banding patterns visible on polytene chromosomes. The cytogenetic
positions of the 60 odorant receptors have been inferred by linkage to known mapped genes, but have not been precisely
determined. Recognizing this inherent uncertainty, yet desiring to convey 
positional information in the unified nomenclature, the Committee proposes that each Drosophila odorant receptor be
named according to its location within the primary numbered cytogenetic units. Where there is only one candidate
receptor within a given numbered region, it is appended with the small letter  ” a.” In cases where there are multiple
receptors within a numbered region, these are supplied with a small letter as a unique identifier according to relative
position on the cytogenetic map. For instance, the two odorant receptors in division 43 on the second chromosome are
named Or43a and Or43b, corresponding to map positions {43A1} and {43F5}, respectively. In accordance with nomenclature
standards developed by {FlyBase}, the letter  ” D” for Drosophila has been eliminated from the name and the generic
symbol  ” Or,” for odorant receptor substituted. The benefit of this naming scheme is that general cytogenetic
information is conveyed, thereby localizing receptors to within approximately 1\% of the 
genome. The omission of more specific number and letter subdivisions in the nomenclature insulates the new names from
readjustments of cytological positions of Drosophila genes that will undoubtedly occur as more accurate alignments
between the cytogenetic map and genomic sequence are {made.Naming} New {SequencesA} total of 60 Drosophila odorant
receptors have been identified and named by members of the Committee. In the eventuality that additional genes are
discovered, these should be named according to the scheme described above. Where possible, the assistance of {FlyBase}
(flybase-help@morgan.harvard.edu) should be sought. Additional information on the odorant receptors in the fly genome is
available at web sites maintained by {FlyBase} (http://flybase.bio.indiana.edu), the Berkeley Drosophila Genome Project
(http://www.fruitfly.org), and the National Center for Biotechnology Information (http://www.ncbi.nlm.nih.gov). We
recommend that this nomenclature be used in future publications. },
    citeulike-article-id = {8484507},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0092-8674(00)00020-9},
    doi = {10.1016/s0092-8674(00)00020-9},
    issn = {00928674},
    journal = {Cell},
    keywords = {odorant\_binding\_protein, protein\_coupled\_receptors, receptor\_type, receptors},
    month = jul,
    number = {2},
    pages = {145--146},
    posted-at = {2010-12-25 18:16:41},
    priority = {2},
    title = {A Unified Nomenclature System for the Drosophila Odorant Receptors},
    url = {http://dx.doi.org/10.1016/s0092-8674(00)00020-9},
    volume = {102},
    year = {2000}
}

@article{citeulike:8484504,
    abstract = {For most organisms, chemosensation is critical for survival and is mediated by large families of
chemoreceptor proteins, whose expression must be tuned appropriately to changes in the chemical environment. We asked
whether expression of chemoreceptor genes that are clustered in the genome would be regulated independently; whether
expression of certain chemoreceptor genes would be especially sensitive to environmental changes; whether groups of
chemoreceptor genes undergo coordinated rexpression; and how plastic the expression of chemoreceptor genes is with
regard to sex, development, reproductive state, and social context. To answer these questions we used Drosophila
melanogaster , because its chemosensory systems are well characterized and both the genotype and environment can be
controlled precisely. Using customized {cDNA} microarrays, we showed that chemoreceptor genes that are clustered in the
genome undergo independent transcriptional regulation at different developmental stages and 
between sexes. Expression of distinct subgroups of chemoreceptor genes is sensitive to reproductive state and social
interactions. Furthermore, exposure of flies only to odor of the opposite sex results in altered transcript abundance of
chemoreceptor genes. These genes are distinct from those that show transcriptional plasticity when flies are allowed
physical contact with same or opposite sex members. We analyzed covariance in transcript abundance of chemosensory genes
across all environmental conditions and found that they segregated into 20 relatively small, biologically relevant
modules of highly correlated transcripts. This finely pixilated modular organization of the chemosensory subgenome
enables fine tuning of the expression of the chemoreceptor repertoire in response to ecologically relevant environmental
and physiological conditions.},
    author = {Zhou, Shanshan and Stone, Eric A. and Mackay, Trudy F. C. and Anholt, Robert R. H.},
    citeulike-article-id = {8484504},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pgen.1000681},
    day = {9},
    doi = {10.1371/journal.pgen.1000681},
    journal = {PLoS Genet},
    keywords = {odorant, odorant\_binding\_protein, protein\_coupled\_receptors},
    month = oct,
    number = {10},
    pages = {e1000681+},
    posted-at = {2010-12-25 18:11:57},
    priority = {2},
    publisher = {Public Library of Science},
    title = {Plasticity of the Chemoreceptor Repertoire in Drosophila melanogaster},
    url = {http://dx.doi.org/10.1371/journal.pgen.1000681},
    volume = {5},
    year = {2009}
}

@article{citeulike:8484501,
    abstract = {We identified a large family of putative odorant-binding protein ({OBP}) genes in the genome of
Drosophila melanogaster. Some of these genes are present in large clusters in the genome. Most members are expressed in
various taste organs, including gustatory sensilla in the labellum, the pharyngeal labral sense organ, dorsal and
ventral cibarial organs, as well as taste bristles located on the wings and tarsi. Some of the gustatory {OBPs} are
expressed exclusively in taste organs, but most are expressed in both olfactory and gustatory sensilla. Multiple binding
proteins can be coexpressed in the same gustatory sensillum. Cells in the tarsi that express {OBPs} are required for
normal chemosensation mediated through the leg, as ablation of these cells dramatically reduces the sensitivity of the
proboscis extension reflex to sucrose. Finally, we show that {OBP} genes expressed in the pharyngeal taste sensilla are
still expressed in the poxneuro genetic background while {OBPs} expressed in the 
labellum are not. These findings support a broad role for members of the {OBP} family in gustation and olfaction and
suggest that poxneuro is required for cell fate determination of labellar but not pharyngeal taste organs.},
    author = {Galindo, K. and Smith, D. P.},
    citeulike-article-id = {8484501},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/11729153},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=11729153},
    issn = {0016-6731},
    journal = {Genetics},
    keywords = {pheromone, protein\_coupled\_receptors},
    month = nov,
    number = {3},
    pages = {1059--1072},
    pmid = {11729153},
    posted-at = {2010-12-25 18:08:49},
    priority = {2},
    title = {A large family of divergent Drosophila odorant-binding proteins expressed in gustatory and olfactory
sensilla.},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/11729153},
    volume = {159},
    year = {2001}
}

@article{citeulike:8484488,
    abstract = {Olfaction is of considerable importance to many insects in behaviors critical for survival and
reproduction, including location of food sources, selection of mates, recognition of colony con-specifics, and
determination of oviposition sites. An ubiquitous, but poorly understood, component of the insect's olfactory system is
a group of odorant-binding proteins ({OBPs}) that are present at high concentrations in the aqueous lymph surrounding
the dendrites of olfactory receptor neurons. {OBPs} are believed to shuttle odorants from the environment to the
underlying odorant receptors, for which they could potentially serve as odorant presenters. Here we show that the
Drosophila genome carries 51 potential {OBP} genes, a number comparable to that of its odorant-receptor genes. We find
that the majority (73\%) of these {OBP}-like genes occur in clusters of as many as nine genes, in contrast to what has
been observed for the Drosophila odorant-receptor genes. Two of the presumptive {OBP} gene 
clusters each carries an odorant-receptor gene. We also report an intriguing subfamily of 12 putative {OBPs} that share
a unique C-terminal structure with three conserved cysteines and a conserved proline. Members of this subfamily have not
previously been described for any insect. We have performed phylogenetic analyses of the {OBP}-related proteins in
Drosophila as well as other insects, and we discuss the duplication and divergence of the genes for this large family.
[The sequence data from this study have been submitted to {FlyBase}. Annotations for these sequences are available as
supplementary material at http://www.genome.org.]},
    author = {Hekmat-Scafe, Daria S. and Scafe, Charles R. and McKinney, Aimee J. and Tanouye, Mark A.},
    citeulike-article-id = {8484488},
    citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.239402},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/12213773},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=12213773},
    doi = {10.1101/gr.239402},
    issn = {1088-9051},
    journal = {Genome research},
    keywords = {odorant, odorant\_binding\_protein, pheromone, receptors},
    month = sep,
    number = {9},
    pages = {1357--1369},
    pmid = {12213773},
    posted-at = {2010-12-25 17:57:42},
    priority = {2},
    title = {Genome-wide analysis of the odorant-binding protein gene family in Drosophila melanogaster.},
    url = {http://dx.doi.org/10.1101/gr.239402},
    volume = {12},
    year = {2002}
}

@article{citeulike:8420112,
    abstract = {A better understanding of the individual developers' performance has been shown to result in benefits
such as improved project estimation accuracy and enhanced software quality assurance. However, new challenges of
distinguishing the individual activities involved in software evolution arise when considering collaborative development
environments. Since Software repositories such as version control systems ({VCS}) and bug tracking systems ({BTS}) are
available for most software projects and hold a detailed and rich record of the historical development information, this
paper presents our experiences mining individual performance indicators in collaborative development environments by
using these repositories. The base of our key idea is to identify the complexity metrics (in the code base) and field
defects(from bug tracking system) at individual-level by incorporating the historical data from version control system.
We also remotely measure and analyze these indicators mined from a libre 
project {jEdit}, which involves around one hundred developer. The results show that these indicators are feasible and
instructive in the understanding of the individual performance.},
    address = {Los Alamitos, CA, USA},
    author = {Zhang, Shen and Wang, Yongji and Xiao, Junchao},
    citeulike-article-id = {8420112},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/APSEC.2008.12},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/apsec.2008.12},
    doi = {10.1109/apsec.2008.12},
    issn = {1530-1362},
    journal = {Asia-Pacific Software Engineering Conference},
    keywords = {msr},
    pages = {247--254},
    posted-at = {2010-12-13 10:02:53},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Mining Individual Performance Indicators in Collaborative Development Using Software Repositories},
    url = {http://dx.doi.org/10.1109/apsec.2008.12},
    volume = {0},
    year = {2008}
}

@inproceedings{citeulike:797370,
    abstract = {Over 200 {CVS} repositories representing the assignments of students in a second year undergraduate
computer science course have been assembled. This unique data set represents many individuals working separately on
identical projects, presenting the opportunity to evaluate the effects of the work habits captured by {CVS} on
performance. This paper outlines our experiences mining and analyzing these repositories. We extracted various
quantitative measures of student behaviour and code quality, and attempted to correlate these features with grades.
Despite examining 166 features, we find that grade performance cannot be accurately predicted; certainly no predictors
stronger than simple lines-of-code were found.},
    address = {New York, NY, USA},
    author = {Mierle, Keir and Laven, Kevin and Roweis, Sam and Wilson, Greg},
    booktitle = {Proceedings of the 2005 international workshop on Mining software repositories},
    citeulike-article-id = {797370},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1083150},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1083142.1083150},
    doi = {10.1145/1083142.1083150},
    isbn = {1-59593-123-6},
    keywords = {msr},
    location = {St. Louis, Missouri},
    pages = {1--5},
    posted-at = {2010-12-13 09:33:41},
    priority = {2},
    publisher = {ACM},
    series = {MSR '05},
    title = {Mining student {CVS} repositories for performance indicators},
    url = {http://dx.doi.org/10.1145/1083142.1083150},
    year = {2005}
}

@article{citeulike:8383204,
    abstract = {Abstract The insect chemoreceptor superfamily, consisting of the odorant receptor (Or) and gustatory
receptor (Gr) families, exhibits patterns of evolution ranging from highly conserved proteins to lineage-specific gene
subfamily expansions when compared across insect suborders and orders. Here their evolution across the timespan of 25
million years is examined which yield orthologous divergences ranging from 5?50\%. They also reveal the beginnings of
lineage-specific gene subfamilies as multiple duplications of particular gene lineages in either or both Drosophila
melanogaster and D. pseudoobscura (Frolova and Astaurov) (Diptera: Drosophilidae). Gene losses and pseudogenes are
similarly evident in both lineages, and even in closer comparisons of D. melanogaster with D. yakuba, leaving these
species with roughly similar numbers of chemoreceptors despite considerable gene turnover. The large range of
divergences and gene duplications provide abundant raw material for studies of structure and 
function in this novel superfamily, which contains proteins that evolved to bind specific ligands that mediate much of
the ecology and mating behavior of insects. Abstract The insect chemoreceptor superfamily, consisting of the odorant
receptor (Or) and gustatory receptor (Gr) families, exhibits patterns of evolution ranging from highly conserved
proteins to lineage-specific gene subfamily expansions when compared across insect suborders and orders. Here their
evolution across the timespan of 25 million years is examined which yield orthologous divergences ranging from 5?50\%.
They also reveal the beginnings of lineage-specific gene subfamilies as multiple duplications of particular gene
lineages in either or both Drosophila melanogaster and D. pseudoobscura (Frolova and Astaurov) (Diptera: Drosophilidae).
Gene losses and pseudogenes are similarly evident in both lineages, and even in closer comparisons of D. melanogaster
with D. yakuba, leaving these species with roughly similar numbers of chemoreceptors 
despite considerable gene turnover. The large range of divergences and gene duplications provide abundant raw material
for studies of structure and function in this novel superfamily, which contains proteins that evolved to bind specific
ligands that mediate much of the ecology and mating behavior of insects.},
    author = {Robertson, Hugh M.},
    citeulike-article-id = {8383204},
    citeulike-linkout-0 = {http://www.bioone.org/doi/abs/10.1673/031.009.1801},
    citeulike-linkout-1 = {http://dx.doi.org/10.1673/031.009.1801},
    day = {8},
    doi = {10.1673/031.009.1801},
    journal = {Journal of Insect Science},
    keywords = {lepidopteran, protein\_coupled\_receptors, receptor\_type, receptors},
    month = dec,
    number = {18},
    pages = {1--14},
    posted-at = {2010-12-08 10:37:30},
    priority = {2},
    publisher = {University of Wisconsin Library},
    title = {The Insect Chemoreceptor Superfamily in Drosophila pseudoobscura: Molecular Evolution of
{Ecologically-Relevant} Genes Over 25 Million Years},
    url = {http://dx.doi.org/10.1673/031.009.1801},
    volume = {9},
    year = {2010}
}

@article{citeulike:8383133,
    abstract = {Candidate olfactory receptors of the moth Heliothis virescens were found to be extremely diverse from
receptors of the fruitfly Drosophila melanogaster and the mosquito Anopheles gambiae, but there is one exception. The
moth receptor type {HR2} shares a rather high degree of sequence identity with one olfactory receptor type both from
Drosophila (Dor83b) and from Anopheles ({AgamGPRor7}); moreover, in contrast to all other receptors, this unique
receptor type is expressed in numerous antennal neurons. Here we describe the identification of {HR2} homologues in two
further lepidopteran species, the moths Antheraea pernyi and Bombyx mori, which share 86–88\% of their amino acids. In
addition, based on {RT}-{PCR} experiments {HR2} homologues were discovered in antennal {cDNA} of the honey bee (Apis
mellifera; Hymenoptera), the blowfly (Calliphora erythrocephala; Diptera) and the mealworm (Tenebrio molitor;
Coleoptera). Comparison of all {HR2}-related receptors revealed a high degree of sequence 
conservation across insect orders. In situ hybridization of antennal sections from the bee and the blowfly support the
notion that {HR2}-related receptors are generally expressed in a very large number of antennal cells. This, together
with the high degree of conservation suggests that this unique receptor subtype may fulfill a special function in
chemosensory neurons of insects.},
    author = {Krieger, J. and Klink, O. and Mohl, C. and Raming, K. and Breer, H.},
    booktitle = {Journal of Comparative Physiology A},
    citeulike-article-id = {8383133},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00359-003-0427-x},
    citeulike-linkout-1 = {http://www.springerlink.com/content/pcmvpay37891grk1},
    citeulike-linkout-2 = {http://link.springer.com/article/10.1007/s00359-003-0427-x},
    day = {1},
    doi = {10.1007/s00359-003-0427-x},
    issn = {0340-7594},
    journal = {Journal of Comparative Physiology A: Neuroethology, Sensory, Neural, and Behavioral Physiology},
    keywords = {lepidopteran, mellifera, receptor\_type, receptors},
    month = jul,
    number = {7},
    pages = {519--526},
    posted-at = {2010-12-08 10:22:38},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {A candidate olfactory receptor subtype highly conserved across different insect orders},
    url = {http://dx.doi.org/10.1007/s00359-003-0427-x},
    volume = {189},
    year = {2003}
}

@inproceedings{citeulike:8347594,
    abstract = {Understanding a program and its evolution is not satisfied only by looking at a current snapshot of its
source code. Thus, a developer often examines a sequence of its snapshots stored in repositories of versioning systems,
and identifies differences between two successive snapshots. Unfortunately, such differences do not represent individual
changes of the source code. This paper proposes a mechanism for recording all editing operations a developer has applied
to source code on an integrated development environment. The paper also shows a running implementation of the mechanism
built as an Eclipse plug-in, which is called {OperationRecorder}. The experimental results with a small-scale program
substantiate that it has a practical use from the viewpoint of its performance.},
    address = {New York, NY, USA},
    author = {Omori, Takayuki and Maruyama, Katsuhisa},
    booktitle = {Proceedings of the 2008 international working conference on Mining software repositories},
    citeulike-article-id = {8347594},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1370750.1370758},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1370750.1370758},
    doi = {10.1145/1370750.1370758},
    isbn = {978-1-60558-024-1},
    keywords = {msr, spi, thesis},
    location = {Leipzig, Germany},
    pages = {31--34},
    posted-at = {2010-12-02 10:13:39},
    priority = {2},
    publisher = {ACM},
    series = {MSR '08},
    title = {A change-aware development environment by recording editing operations of source code},
    url = {http://dx.doi.org/10.1145/1370750.1370758},
    year = {2008}
}

@inproceedings{citeulike:8347569,
    abstract = {Software engineering process information extracted from version control systems and bug tracking
databases are widely used in empirical software engineering. In prior work, we showed that these data are plagued by
quality deficiencies, which vary in its characteristics across projects. In addition, we showed that those deficiencies
in the form of bias do impact the results of studies in empirical software engineering. While these findings affect
software engineering researchers the impact on practitioners has not yet been substantiated. In this paper we,
therefore, explore (i) if the process data quality and characteristics have an influence on the bug fixing process and
(ii) if the process quality as measured by the process data has an influence on the product (i.e., software) quality.
Specifically, we analyze six Open Source as well as two Closed Source projects and show that process data quality and
characteristics have an impact on the bug fixing process: the high rate of empty commit 
messages in Eclipse, for example, correlates with the bug report quality. We also show that the product quality -
measured by number of bugs reported - is affected by process data quality measures. These findings have the potential to
prompt practitioners to increase the quality of their software process and its associated data quality.},
    author = {Bachmann, Adrian and Bernstein, Abraham},
    citeulike-article-id = {8347569},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/msr.2010.5463286},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5463286},
    doi = {10.1109/msr.2010.5463286},
    keywords = {msr, psi, thesis},
    location = {Cape Town, South Africa},
    month = may,
    pages = {62--71},
    posted-at = {2010-12-02 09:55:40},
    priority = {2},
    title = {When process data quality affects the number of bugs: Correlations in software engineering datasets},
    url = {http://dx.doi.org/10.1109/msr.2010.5463286},
    year = {2010}
}

@inproceedings{citeulike:7465518,
    abstract = {Reliably predicting software defects is one of software engineering's holy grails. Researchers have
devised and implemented a plethora of bug prediction approaches varying in terms of accuracy, complexity and the input
data they require. However, the absence of an established benchmark makes it hard, if not impossible, to compare
approaches. We present a benchmark for defect prediction, in the form of a publicly available data set consisting of
several software systems, and provide an extensive comparison of the explanative and predictive power of well-known bug
prediction approaches, together with novel approaches we devised. Based on the results, we discuss the performance and
stability of the approaches with respect to our benchmark and deduce a number of insights on bug prediction models.},
    author = {D'Ambros, M. and Lanza, M. and Robbes, R.},
    booktitle = {Mining Software Repositories (MSR), 2010 7th IEEE Working Conference on},
    citeulike-article-id = {7465518},
    citeulike-linkout-0 = {http://dblp.uni-trier.de/rec/bibtex/conf/msr/DAmbrosLR10},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/msr.2010.5463279},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5463279},
    doi = {10.1109/msr.2010.5463279},
    institution = {Fac. of Inf., Univ. of Lugano, Lugano, Switzerland},
    isbn = {978-1-4244-6802-7},
    keywords = {msr, psi, thesis},
    location = {Cape Town, South Africa},
    month = may,
    pages = {31--41},
    posted-at = {2010-12-02 09:46:30},
    priority = {2},
    publisher = {IEEE},
    title = {An extensive comparison of bug prediction approaches},
    url = {http://dx.doi.org/10.1109/msr.2010.5463279},
    year = {2010}
}

@incollection{citeulike:8347443,
    address = {New York},
    author = {Humphrey, Watts and Konrad, Michael},
    booktitle = {Software Process Modeling},
    chapter = {6},
    citeulike-article-id = {8347443},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/0-387-24262-7\_6},
    citeulike-linkout-1 = {http://www.springerlink.com/content/rx5035w62g170m7w},
    doi = {10.1007/0-387-24262-7\_6},
    editor = {Basili, Victor R. and Acu\~{n}a, Silvia T. and Juristo, Natalia},
    isbn = {0-387-24261-9},
    keywords = {spi, thesis},
    pages = {141--161},
    posted-at = {2010-12-02 08:14:15},
    priority = {2},
    publisher = {Springer US},
    series = {International Series in Software Engineering},
    title = {Motivation and Process Improvement},
    url = {http://dx.doi.org/10.1007/0-387-24262-7\_6},
    volume = {10},
    year = {2005}
}

@incollection{citeulike:8347363,
    abstract = {The success of software process improvement ({SPI}) implementation initiatives depends fundamentally of
the strategies adopted to support the execution of such initiatives. Therefore, it is essential to define adequate {SPI}
implementation strategies aiming to facilitate the achievement of organizational business goals and to increase the
benefits of process improvements. The objective of this work is to present an approach to support the execution of {SPI}
implementation initiatives. We also describe a methodology applied to capture knowledge related to critical success
factors that influence {SPI} initiatives. This knowledge was used to define effective {SPI} strategies aiming to
increase the success of {SPI} initiatives coordinated by a specific {SPI} consultancy organization. This work also
presents the functionalities of a set of tools integrated in a process-centered knowledge management environment, named
{CORE}-{KM}, customized to support the presented approach.},
    address = {Berlin, Heidelberg},
    author = {Montoni, Mariano A. and Cerdeiral, Cristina and Zanetti, David and Cavalcanti da Rocha, Ana R.},
    booktitle = {Software Process Improvement},
    chapter = {15},
    citeulike-article-id = {8347363},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-85936-9\_15},
    citeulike-linkout-1 = {http://www.springerlink.com/content/q425133441912512},
    doi = {10.1007/978-3-540-85936-9\_15},
    editor = {O'Connor, Rory V. and Baddoo, Nathan and Smolander, Kari and Messnarz, Richard},
    isbn = {978-3-540-85934-5},
    issn = {1865-0929},
    keywords = {spi, thesis},
    pages = {164--175},
    posted-at = {2010-12-02 07:55:47},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Communications in Computer and Information Science},
    title = {A Knowledge Management Approach to Support Software Process Improvement Implementation Initiatives},
    url = {http://dx.doi.org/10.1007/978-3-540-85936-9\_15},
    volume = {16},
    year = {2008}
}

@incollection{citeulike:8347349,
    abstract = {Continuous improvement of software development capability is fundamental for organizations to thrive in
competitive markets. Nevertheless, Software Process Improvement ({SPI}) initiatives have demonstrated limited results
because {SPI} managers usually fail to cope with factors that have influence on the success of {SPI}. In this paper, we
present the results of a multi-strategy approach aiming to identify critical success factors ({CSF}) that have influence
on {SPI}. The study results were confirmed by the literature review. The {CSF} were identified through a combination of
qualitative and quantitative analyses of the results of a survey we conducted with {SPI} practitioners involved in
Brazilian software industry experiences. We also identified the relationships of major factors that emerged from the
survey. We expect that the major {CSF} presented in this paper can be used by {SPI} managers in the definition of {SPI}
strategies aiming to enhance {SPI} initiatives success.},
    address = {Berlin, Heidelberg},
    author = {Montoni, Mariano and Rocha, Ana},
    booktitle = {Software Process Improvement},
    chapter = {16},
    citeulike-article-id = {8347349},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-75381-0\_16},
    citeulike-linkout-1 = {http://www.springerlink.com/content/hg76q55232134234},
    doi = {10.1007/978-3-540-75381-0\_16},
    editor = {Abrahamsson, Pekka and Baddoo, Nathan and Margaria, Tiziana and Messnarz, Richard},
    isbn = {978-3-540-74765-9},
    issn = {0302-9743},
    keywords = {spi, thesis},
    pages = {175--186},
    posted-at = {2010-12-02 07:54:35},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {A Methodology for Identifying Critical Success Factors That Influence Software Process Improvement
Initiatives: An Application in the Brazilian Software Industry},
    url = {http://dx.doi.org/10.1007/978-3-540-75381-0\_16},
    volume = {4764},
    year = {2007}
}

@incollection{citeulike:8347324,
    abstract = {In small software companies the resources available for {SPI} are often limited. With limited resources,
the motivation of the employees becomes one of the key factors for {SPI}. In this article, the motivational factors
affecting a small company's {SPI} efforts are discussed. In the research, we carried out interviews and a survey in a
small Finnish software company considering the motivation towards {SPI}. The results are presented here and compared
with earlier motivation research. There were differences revealed while comparing the motivating factors of smaller
companies to those of larger ones. In large companies the focus seems to be on the business related motivators and in
small ones the motivators related to comfortability of work are emphasized. Motivation survey and the interviews proved
to be useful tools in planning the future {SPI} strategy. A lot of valuable information was discovered for planning and
implementing the next steps of {SPI}.},
    address = {Berlin, Heidelberg},
    author = {Valtanen, Anu and Sihvonen, Hanna-Miina},
    booktitle = {Software Process Improvement},
    chapter = {14},
    citeulike-article-id = {8347324},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-85936-9\_14},
    citeulike-linkout-1 = {http://www.springerlink.com/content/w51225422g2521v3},
    doi = {10.1007/978-3-540-85936-9\_14},
    editor = {O'Connor, Rory V. and Baddoo, Nathan and Smolander, Kari and Messnarz, Richard},
    isbn = {978-3-540-85934-5},
    issn = {1865-0929},
    keywords = {spi, thesis},
    pages = {152--163},
    posted-at = {2010-12-02 07:46:42},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Communications in Computer and Information Science},
    title = {Employees' Motivation for {SPI}: Case Study in a Small Finnish Software Company},
    url = {http://dx.doi.org/10.1007/978-3-540-85936-9\_14},
    volume = {16},
    year = {2008}
}

@article{citeulike:8347320,
    abstract = {Software organizations can significantly improve the quality of their output if they have a defined and
documented software process, together with the appropriate techniques and tools to measure its effectiveness. Without a
defined process it is impossible to measure success or focus on how development capability can be enhanced. To date, a
number of software process improvement frameworks have been developed and implemented. However, most of these models
have been targeted at large-scale producers. Furthermore, they have applied to companies who use traditional development
techniques. Smaller companies and those operating in development areas where speed of delivery is paramount have not, as
yet, had process improvement paradigms available for adoption.},
    author = {Coleman, Gerry and Verbruggen, Renaat},
    citeulike-article-id = {8347320},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a:1008856624790},
    citeulike-linkout-1 = {http://www.springerlink.com/content/m4314n53861651p7},
    day = {1},
    doi = {10.1023/a:1008856624790},
    issn = {09639314},
    journal = {Software Quality Journal},
    keywords = {spi, thesis},
    month = jul,
    number = {2},
    pages = {107--122},
    posted-at = {2010-12-02 07:45:42},
    priority = {2},
    publisher = {Springer Netherlands},
    title = {A Quality Software Process for Rapid Application Development},
    url = {http://dx.doi.org/10.1023/a:1008856624790},
    volume = {7},
    year = {1998}
}

@article{citeulike:8347315,
    abstract = {This paper provides the author's personal views and perspectives on software process improvement.
Starting with his first work on technology assessment in IBM over 20 years ago, Watts Humphrey describes the process
improvement work he has been directly involved in. This includes the development of the early process assessment
methods, the original design of the CMM, and the introduction of the Personal Software Process (PSP)SM and Team Software
Process (TSP){SM}. In addition to describing the original motivation for this work, the author also reviews many of the
problems he and his associates encountered and why they solved them the way they did. He also comments on the
outstanding issues and likely directions for future work. Finally, this work has built on the experiences and
contributions of many people. Mr. Humphrey only describes work that he was personally involved in and he names many of
the key contributors. However, so many people have been involved in this work that a full list of 
the important participants would be impractical.},
    author = {Humphrey, Watts S.},
    citeulike-article-id = {8347315},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a:1020593305601},
    citeulike-linkout-1 = {http://www.springerlink.com/content/g52105122328w558},
    day = {1},
    doi = {10.1023/a:1020593305601},
    issn = {10227091},
    journal = {Annals of Software Engineering},
    keywords = {spi, thesis},
    month = dec,
    number = {1},
    pages = {39--72},
    posted-at = {2010-12-02 07:44:03},
    priority = {2},
    publisher = {Springer Netherlands},
    title = {Three Process Perspectives: Organizations, Teams, and People},
    url = {http://dx.doi.org/10.1023/a:1020593305601},
    volume = {14},
    year = {2002}
}

@article{citeulike:5969719,
    abstract = {Olfaction, the sense of smell, depends on large, divergent families of odorant receptors that detect
odour stimuli in the nose and transform them into patterns of neuronal activity that are recognised in the brain. The
olfactory circuits in mammals and insects display striking similarities in their sensory physiology and neuroanatomy,
which has suggested that odours are perceived by a conserved mechanism. Here I review recent revelations of significant
structural and functional differences between the Drosophila and mammalian odorant receptor proteins and discuss the
implications for our understanding of the evolutionary and molecular biology of the insect odorant receptors.},
    author = {Benton, R.},
    citeulike-article-id = {5969719},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00018-006-6130-7},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/16786219},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=16786219},
    doi = {10.1007/s00018-006-6130-7},
    issn = {1420-682X},
    journal = {Cellular and molecular life sciences : CMLS},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors},
    month = jul,
    number = {14},
    pages = {1579--1585},
    pmid = {16786219},
    posted-at = {2010-11-10 09:24:27},
    priority = {2},
    title = {On the {ORigin} of smell: odorant receptors in insects.},
    url = {http://dx.doi.org/10.1007/s00018-006-6130-7},
    volume = {63},
    year = {2006}
}

@article{citeulike:8227474,
    abstract = {Abstract Insect odorant receptors are a large family of seven transmembrane proteins believed to be
G-protein coupled receptors. The peptide sequences of two odorant receptors within a given species may share as little
as 17\% identity, and there is limited similarity between receptors of divergent species. One exception is {DmOr83b},
which is found in Drosophila melanogaster and is highly conserved in at least ten other insect species. {DmOr83b} is
broadly expressed in most of the olfactory sensory neurons of D. melanogaster at most developmental stages, while other
odorant receptors tend to have more restricted and specific expression patterns. {DmOr83b} is critical for D.
melanogaster olfaction, and it is involved in properly localizing other odorant receptors possibly by forming
heterodimers with these receptors. The C-terminal region has been implicated as sites for such heterodimer formation.
Multiple em for motif elicitation ({MEME}), a hidden markov model based program, was used to 
uncover three conserved motifs in the C-termini of a vast majority of the odorant receptor peptides from Anopheles
gambiae, D. melanogaster, and Apis mellifera. These motifs are also found in {DmOr83b} and its orthologs and the order
of these motifs is conserved as well. The conservation of these motifs among divergent odorant receptors in divergent
species suggests functional importance. We propose that these motifs are involved in receptor- receptor protein
interactions, contributing to the heterodimer formation between {DmOr83b} (or its orthologs) and other odorant
receptors.},
    author = {Miller, Raymond and Tu, Zhijian},
    citeulike-article-id = {8227474},
    citeulike-linkout-0 = {http://www.bioone.org/doi/abs/10.1673/031.008.5301},
    citeulike-linkout-1 = {http://dx.doi.org/10.1673/031.008.5301},
    day = {1},
    doi = {10.1673/031.008.5301},
    journal = {Journal of Insect Science},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors, g\_proteins},
    month = sep,
    number = {53},
    pages = {1--10},
    posted-at = {2010-11-10 09:22:51},
    priority = {2},
    publisher = {University of Wisconsin Library},
    title = {Odorant Receptor {C-Terminal} Motifs in Divergent Insect Species},
    url = {http://dx.doi.org/10.1673/031.008.5301},
    volume = {8},
    year = {2008}
}

@article{citeulike:8161676,
    abstract = {{BACKGROUND}: The olfactory system plays an important role in the recognition of leaf volatiles during
the search of folivore insects for a suitable plant host. For example, volatiles emitted by mulberry leaves trigger
chemotaxis behavior in the silkworms Bombyx mori, and as a consequence, they preferentially reside on and consume
mulberry leaves. Here, we aimed to identify natural chemoattractants and their corresponding olfactory receptors (Ors)
involved in silkworm behavior to mulberry leaves. {RESULTS}: Chemotaxis behavioral assays for headspace volatiles
detected by gas chromatography-mass spectroscopy analysis revealed that among the volatiles that were emitted by
mulberry leaves, cis-jasmone was the most potent attractant for silkworms, working at a threshold of 0.3 pg from a 20 cm
distance. Among a total of 66 Ors identified in the B. mori genome, we found that 23 were expressed in the olfactory
organs during larval stages. Functional analysis of all the larvae-expressed Ors in 
Xenopus oocytes revealed that one Or, termed {BmOr}-56, showed a high sensitivity to cis-jasmone. In addition, the
ligand-receptor activity of {BmOr}-56 reflected the chemotaxis behavioral response of silkworms. {CONCLUSIONS}: We
identified cis-jasmone as a potent attractant in mulberry leaves for silkworms and provide evidence that a highly tuned
receptor, {BmOr}-56, may mediate this behavioral attraction. The current study sheds light on the mechanism of the
correlation between olfactory perception in folivore insects and chemotaxis behavior to a natural volatile emitted by
green leaves.},
    author = {Tanaka, Kana and Uda, Yusuke and Ono, Yukiteru and Nakagawa, Tatsuro and Suwa, Makiko and Yamaoka, Ryohei
and Touhara, Kazushige},
    citeulike-article-id = {8161676},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cub.2009.04.035},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19427209},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19427209},
    day = {9},
    doi = {10.1016/j.cub.2009.04.035},
    issn = {1879-0445},
    journal = {Current biology : CB},
    keywords = {bombyx\_mori, odorant, pheromone},
    month = jun,
    number = {11},
    pages = {881--890},
    pmid = {19427209},
    posted-at = {2010-11-01 10:15:36},
    priority = {2},
    title = {Highly selective tuning of a silkworm olfactory receptor to a key mulberry leaf volatile.},
    url = {http://dx.doi.org/10.1016/j.cub.2009.04.035},
    volume = {19},
    year = {2009}
}

@article{citeulike:1072363,
    abstract = {Abstract Olfaction plays an important role in the life history of insects, including key behaviours such
as host selection, oviposition and mate recognition. Odour perception by insects is primarily mediated by the large
diverse family of odourant receptors (Ors) that are expressed on the dendrites of olfactory neurones housed within
chemosensilla. However, few Or sequences have been identified from the Lepidoptera, an insect order that includes some
of the most important pest species worldwide. We have identified 41 Or gene sequences from the silkworm (Bombyx mori)
genome, more than double the number of published Or sequences from the Lepidoptera. Many silkworm Ors appear to be
orthologs of the 17 published tobacco budworm (Heliothis virescens) Ors indicating that many Or lineages may be
conserved within the Lepidoptera. The majority of the Or genes are expressed in adult female and male antennae
(determined by quantitative real-time {PCR} analysis), supporting their probable roles in adult 
olfaction. Several Or genes are expressed at high levels in both male and female antennae, suggesting they mediate the
perception of common host or conspecific volatiles important to both sexes. {BmOrs} 45–47 group together in the same
phylogenetic branch and all three are expressed at moderate female-biased ratios, six to eight times higher in female
compared to male moth antennae. Interestingly, {BmOrs19} and 30 appear to be expressed predominantly in female antennae,
opposite to that of the published silkworm pheromone receptors {BmOrs} 1 and 3 that are specific to male antennae. These
results suggest that {BmOr19} and 30 may detect odours critical to female behaviour, such as oviposition cues or
male-produced courtship pheromones.},
    author = {Wanner, K. W. and Anderson, A. R. and Trowell, S. C. and Theilmann, D. A. and Robertson, H. M. and
Newcomb, R. D.},
    citeulike-article-id = {1072363},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1365-2583.2007.00708.x},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/bsc/imb/2007/00000016/00000001/art00011},
    doi = {10.1111/j.1365-2583.2007.00708.x},
    issn = {0962-1075},
    journal = {Insect Molecular Biology},
    keywords = {odorant, pheromone},
    month = feb,
    number = {1},
    pages = {107--119},
    posted-at = {2010-10-31 14:38:26},
    priority = {2},
    publisher = {Blackwell Publishing Ltd},
    title = {Female-biased expression of odourant receptor genes in the adult antennae of the silkworm, Bombyx mori},
    url = {http://dx.doi.org/10.1111/j.1365-2583.2007.00708.x},
    volume = {16},
    year = {2007}
}

@article{Robertson:2006p8313,
    abstract = {The honey bee genome sequence reveals a remarkable expansion of the insect odorant receptor (Or) family
relative to the repertoires of the flies Drosophila melanogaster and Anopheles gambiae, which have 62 and 79 Ors
respectively. A total of 170 Or genes were annotated in the bee, of which seven are pseudogenes. These constitute five
bee-specific subfamilies in an insect Or family tree, one of which has expanded to a total of 157 genes encoding
proteins with 15\%-99 amino acid identity. Most of the Or genes are in tandem arrays, including one with 60 genes. This
bee-specific expansion of the Or repertoire presumably underlies their remarkable olfactory abilities, including
perception of several pheromone blends, kin recognition signals, and diverse floral odors. The number of Apis mellifera
Ors is approximately equal to the number of glomeruli in the bee antennal lobe (160-170), consistent with a general
one-receptor/one-neuron/one-glomerulus relationship. The bee genome encodes just 10 
gustatory receptors (Grs) compared with the D. melanogaster and A. gambiae repertoires of 68 and 76 Grs, respectively. A
lack of Gr gene family expansion primarily accounts for this difference. A nurturing hive environment and a mutualistic
relationship with plants may explain the lack of Gr family expansion. The Or family is the most dramatic example of gene
family expansion in the bee genome, and characterizing their caste- and sex-specific gene expression may provide clues
to their specific roles in detection of pheromone, kin, and floral odors.},
    author = {Robertson, Hugh M. and Wanner, Kevin W.},
    citeulike-article-id = {7247598},
    citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.5057506},
    doi = {10.1101/gr.5057506},
    journal = {Genome Res},
    keywords = {g\_protein\_coupled\_receptor, odorant, protein\_coupled\_receptors},
    local-url = {file://localhost/Users/Walton/Dropbox/Libraries/Papers/Genome\%20Res\%202006\%20Robertson.pdf},
    month = nov,
    number = {11},
    pages = {1395--403},
    posted-at = {2010-10-31 14:14:33},
    priority = {2},
    title = {The chemoreceptor superfamily in the honey bee, Apis mellifera: expansion of the odorant, but not
gustatory, receptor family},
    url = {http://dx.doi.org/10.1101/gr.5057506},
    volume = {16},
    year = {2006}
}

@article{citeulike:8151104,
    abstract = {The European corn borer ({ECB}), Ostrinia nubilalis (Hubner), exists as two separate sex pheromone
races. {ECB}(Z) females produce a 97:3 blend of Z11- and E11-tetradecenyl acetate whereas {ECB}(E) females produce an
opposite 1:99 ratio of the Z and E isomers. Males of each race respond specifically to their conspecific female's blend.
A closely related species, the Asian corn borer ({ACB}), O. furnacalis , uses a 3:2 blend of Z12- and E12-tetradecenyl
acetate, and is believed to have evolved from an {ECB}-like ancestor. To further knowledge of the molecular mechanisms
of pheromone detection and its evolution among closely related species we identified and characterized sex pheromone
receptors from {ECB}(Z).},
    author = {Wanner, Kevin W. and Nichols, Andrew S. and Allen, Jean E. and Bunger, Peggy L. and Garczynski, Stephen F.
and Linn, Charles E. and Robertson, Hugh M. and Luetje, Charles W.},
    citeulike-article-id = {8151104},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0008685},
    day = {13},
    doi = {10.1371/journal.pone.0008685},
    journal = {PLoS ONE},
    keywords = {g\_protein\_coupled\_receptors, g\_proteins, pheromone, protein\_coupled\_receptors},
    month = jan,
    number = {1},
    pages = {e8685+},
    posted-at = {2010-10-31 12:46:30},
    priority = {2},
    publisher = {Public Library of Science},
    title = {Sex Pheromone Receptor Specificity in the European Corn Borer Moth, Ostrinia nubilalis},
    url = {http://dx.doi.org/10.1371/journal.pone.0008685},
    volume = {5},
    year = {2010}
}

@article{citeulike:8130921,
    abstract = {This article discusses seven chiral odorants that demonstrate the enantioselectivity of odor sensation:
carvone, Celery Ketone, camphor, Florhydral, 3-methyl-3-sulfanylhexan-1-ol, muscone, and methyl jasmonate. After a
general introduction of the odorant−receptor interaction and the combinatorial code of olfaction, the olfactory
properties of the enantiomers of these seven odorants, their occurrence in nature, industrial production, and
application in perfumery are discussed. Finally, practical aspects of chirality and odor sensation are set forth and
these odorants are proposed as examples for introductory courses on stereochemistry, natural products, or bioorganic
chemistry.},
    author = {Kraft, Philip and Mannschreck, Albrecht},
    citeulike-article-id = {8130921},
    citeulike-linkout-0 = {http://dx.doi.org/10.1021/ed100128v},
    citeulike-linkout-1 = {http://pubs.acs.org/doi/abs/10.1021/ed100128v},
    day = {1},
    doi = {10.1021/ed100128v},
    journal = {Journal of Chemical Education},
    keywords = {general\_introduction, gpcr},
    month = jun,
    number = {6},
    pages = {598--603},
    posted-at = {2010-10-27 09:59:24},
    priority = {2},
    title = {The Enantioselectivity of Odor Sensation: Some Examples for Undergraduate Chemistry Courses},
    url = {http://dx.doi.org/10.1021/ed100128v},
    volume = {87},
    year = {2010}
}

@article{citeulike:515227,
    abstract = {{PMID}: 12627966 The α-factor receptor of the yeast Saccharomyces cerevisiae encoded by the {STE2} gene
is a member of the large family of G protein-coupled receptors ({GPCRs}) that mediate multiple signal transduction
pathways. The third intracellular loop of {GPCRs} has been identified as a likely site of interaction with G proteins.
To determine the extent of allowed substitutions within this loop, we subjected a stretch of 21 amino acids
({Leu228−Leu248}) to intensive random mutagenesis and screened multiply substituted alleles for receptor function. The
91 partially functional mutant alleles that were recovered contained 96 unique amino acid substitutions. Every position
in this region can be replaced with at least two other types of amino acids without a significant effect on function.
The tolerance for nonconservative substitutions indicates that activation of the G protein by ligand-bound receptors
involves multiple intramolecular interactions that do not strongly depend on particular 
sequence elements. Many of the functional mutant alleles exhibit greater than normal levels of signaling, consistent
with an inhibitory role for the third intracellular loop. Removal of increasing numbers of positively charged residues
from the loop by site-directed mutagenesis causes a progressive loss of signaling function, indicating that the overall
net charge of the loop is important for receptor function. Introduction of negatively charged residues also leads to a
reduced level of signaling. The defects in signaling caused by substitution of charged amino acids are not caused by
changes in the abundance of receptors at the cell surface.},
    address = {Department of Biochemistry and Biophysics, P.O. Box 712, University of Rochester School of Medicine and
Dentistry, Rochester, New York 14642, USA.},
    author = {\'{C}eli\'{c}, Andjelka and Martin, Negin P. and Son, Cagdas D. and Becker, Jeffrey M. and Naider, Fred
and Dumont, Mark E.},
    citeulike-article-id = {515227},
    citeulike-linkout-0 = {http://dx.doi.org/10.1021/bi0269308},
    citeulike-linkout-1 = {http://pubs.acs.org/doi/abs/10.1021/bi0269308},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/12627966},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=12627966},
    day = {1},
    doi = {10.1021/bi0269308},
    issn = {0006-2960},
    journal = {Biochemistry},
    keywords = {g\_proteins, gpcr, pheromone},
    month = mar,
    number = {10},
    pages = {3004--3017},
    pmid = {12627966},
    posted-at = {2010-10-27 09:54:26},
    priority = {2},
    title = {Sequences in the Intracellular Loops of the Yeast Pheromone Receptor Ste2p Required for G Protein
Activation{\dag}},
    url = {http://dx.doi.org/10.1021/bi0269308},
    volume = {42},
    year = {2003}
}

@article{citeulike:8130912,
    abstract = {{PMID}: 15667221 The α-factor receptor (Ste2p) stimulates mating of the yeast Saccharomyces cerevisiae.
Ste2p belongs to the large family of G protein-coupled receptors that are characterized by seven transmembrane
α-helices. Receptor activation is thought to involve changes in the packing of the transmembrane helix bundle. To
identify residues that contribute to Ste2p activation, second-site suppressor mutations were isolated that restored
function to defective receptors carrying either an {F204S} or {Y266C} substitution which affect residues at the
extracellular ends of transmembrane domains 5 and 6, respectively. Thirty-five different suppressor mutations were
identified. On their own, these mutations caused a range of phenotypes, including hypersensitivity, constitutive
activity, altered ligand binding, and loss of function. The majority of the mutations affected residues in the
transmembrane segments that are predicted to face the helix bundle. Many of the suppressor mutations caused 
constitutive receptor activity, suggesting they improved receptor function by partially restoring the balance between
the active and inactive states. Analysis of mutations in transmembrane domain 7 implicated residues Ala281 and Thr282 in
receptor activation. The {A281T} and {T282A} mutants were supersensitive to S. cerevisiae α-factor, but were defective
in responding to a variant of α-factor produced by another species, Saccharomyces kluyveri. The {A281T} mutant also
displayed 8.7-fold enhanced basal signaling. Interestingly, Ala281 and Thr282 are situated in approximately the same
position as Lys296 in rhodopsin, which is covalently linked to retinal. These results suggest that transmembrane domain
7 plays a role in receptor activation in a wide range of G protein-coupled receptors from yeast to humans.},
    author = {Lin, Jennifer C. and Duell, Ken and Saracino, Misty and Konopka, James B.},
    citeulike-article-id = {8130912},
    citeulike-linkout-0 = {http://dx.doi.org/10.1021/bi048050u},
    citeulike-linkout-1 = {http://pubs.acs.org/doi/abs/10.1021/bi048050u},
    day = {1},
    doi = {10.1021/bi048050u},
    journal = {Biochemistry},
    keywords = {gpcr, protein\_coupled\_receptors},
    month = feb,
    number = {4},
    pages = {1278--1287},
    posted-at = {2010-10-27 09:53:04},
    priority = {2},
    title = {Identification of Residues that Contribute to Receptor Activation through the Analysis of Compensatory
Mutations in the G {Protein-Coupled} {α-Factor} Receptor{\dag}},
    url = {http://dx.doi.org/10.1021/bi048050u},
    volume = {44},
    year = {2005}
}

@article{citeulike:6964143,
    abstract = {{PMID}: 15966721 All G protein-coupled receptors ({GPCRs}) share a common seven {TM} helix architecture
and the ability to activate heterotrimeric G proteins. Nevertheless, these receptors have widely divergent sequences
with no significant homology. We present a detailed structure−function comparison of the very divergent Class A and D
receptors to address whether there is a common activation mechanism across the {GPCR} superfamily. The Class A and D
receptors are represented by the vertebrate visual pigment rhodopsin and the yeast α-factor pheromone receptor Ste2,
respectively. Conserved amino acids within each specific receptor class and amino acids where mutation alters receptor
function were located in the structures of rhodopsin and Ste2 to assess whether there are functionally equivalent
positions or regions within these receptors. We find several general similarities that are quite striking. First,
strongly polar amino acids mediate helix interactions. Their mutation generally leads 
to loss of function or constitutive activity. Second, small and weakly polar amino acids facilitate tight helix packing.
Third, proline is essential at similar positions in transmembrane helices 6 and 7 of both receptors. Mapping the
specific location of the conserved amino acids and sites of constitutively active mutations identified conserved
microdomains on transmembrane helices H3, H6, and H7, suggesting that there are underlying similarities in the mechanism
of the widely divergent Class A and Class D receptors.},
    author = {Eilers, Markus and Hornak, Viktor and Smith, Steven O. and Konopka, James B.},
    citeulike-article-id = {6964143},
    citeulike-linkout-0 = {http://dx.doi.org/10.1021/bi047316u},
    citeulike-linkout-1 = {http://pubs.acs.org/doi/abs/10.1021/bi047316u},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/15966721},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=15966721},
    day = {1},
    doi = {10.1021/bi047316u},
    issn = {0006-2960},
    journal = {Biochemistry},
    keywords = {g\_protein\_coupled\_receptors, gpcr},
    month = jun,
    number = {25},
    pages = {8959--8975},
    pmid = {15966721},
    posted-at = {2010-10-27 09:51:31},
    priority = {2},
    title = {Comparison of Class A and D G {Protein-Coupled} Receptors:  Common Features in Structure and
Activation{\dag}},
    url = {http://dx.doi.org/10.1021/bi047316u},
    volume = {44},
    year = {2005}
}

@article{citeulike:1137370,
    abstract = {Odorant receptors belong to class A of the G protein-coupled receptors ({GPCRs}) and detect a large
number of structurally diverse odorant molecules. A recent structural bioinformatic analysis suggests that structural
features are conserved across class A of {GPCRs} in spite of their low sequence identity. Based on this work, we have
aligned the sequences of 29 {ORs} for which ligand binding data are available. Recent site-directed mutagenesis
experiments on one such receptor ({MOR174}-9) provide information that helped to identify nine amino-acid residues
involved in ligand binding. Our modeling provides a rationale for amino acids in equivalent positions in most of the
odorant receptors considered and helps to identify other amino acids that could be important for ligand binding. Our
findings are consistent with most of the previous models and allow predictions for site-directed mutagenesis
experiments, which could also validate our model.},
    author = {Khafizov, Kamil and Anselmi, Claudio and Menini, Anna and Carloni, Paolo},
    citeulike-article-id = {1137370},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00894-006-0160-9},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/klu/894/2007/00000013/00000003/00000160},
    citeulike-linkout-2 = {http://www.springerlink.com/content/j30m651831ku77q2},
    day = {1},
    doi = {10.1007/s00894-006-0160-9},
    issn = {1610-2940},
    journal = {Journal of Molecular Modeling},
    keywords = {gpcr, ligand, or},
    month = mar,
    number = {3},
    pages = {401--409},
    posted-at = {2010-10-27 09:36:58},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {Ligand specificity of odorant receptors},
    url = {http://dx.doi.org/10.1007/s00894-006-0160-9},
    volume = {13},
    year = {2007}
}

@inproceedings{csdl2-10-09,
    abstract = {A process defines a set of routines which allow one to organize, manage and improve activities in order
to reach a goal. With expert intuition and a-priori knowledge, software processes have been modeled for a long time,
resulting in the Waterfall, Spiral and other development models. Later, with the wide use of {SCM} systems and the
public availability of primitive software process artifact trails, formal methods such as Petri Nets, State Machines and
others have been applied to the problem of recurrent process discovery and control. Recent advances in metrics effort,
increased use of continuous integration, and extensive documentation of the performed process make information-rich
fine-grained software process artifacts trails available for analysis. This fine-grained data has the potential to shed
new light on the software process. In this work I propose to investigate an automated technique for the discovery and
characterization of recurrent behaviors in software development - "
programming habits" either on an individual or a team level.},
    address = {Bolzano-Bozen, Italy},
    author = {Senin, Pavel},
    booktitle = {Proceedings of the Fifth International Doctoral Symposium on Empirical Software Engineering},
    citeulike-article-id = {7805992},
    citeulike-linkout-0 = {http://csdl.ics.hawaii.edu/techreports/10-09/10-09.pdf},
    month = sep,
    posted-at = {2010-09-23 08:56:42},
    priority = {2},
    title = {Software Trajectory Analysis: An empirically based method for automated software process discovery},
    url = {http://csdl.ics.hawaii.edu/techreports/10-09/10-09.pdf},
    year = {2010}
}

@inbook{citeulike:7691059,
    abstract = {Software process improvement has been a focus of industry for many years. To assist with the
implementation of process improvement, we provide an approach to recover process enactment data. The goal of our method
is to uncover the actual process used and thereby provide evidence for improving the quality of a planned software
process that is followed by an organization in the future. The recovered process model (or patterns) is presented at the
same level of abstraction as the planned process model. This allows an easy and clear method to identify the distance
between a planned process model and the actual project enactment. We investigate the enactment of a defined software
process model from the view of understanding the opportunity for process model improvement from the viewpoint of the
project managers in the context of a small software development organization. We collected data from one of our
collaboration organizations and then applied our method to a case study. The consistencies 
between a planned process model and the project enactment were measured. The outcomes of our method provide precise
information including qualitative and quantitative data to assist project managers with process improvement in future
practice. The main contribution of our work is to provide a novel approach to assist software process improvement by
recovering a model from process enactment data.},
    address = {Berlin, Heidelberg},
    author = {Huo, Ming and Zhang, He and Jeffery, Ross},
    booktitle = {Making Globally Distributed Software Development a Success Story},
    chapter = {16},
    citeulike-article-id = {7691059},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-79588-9\_16},
    citeulike-linkout-1 = {http://www.springerlink.com/content/5144745744446878},
    doi = {10.1007/978-3-540-79588-9\_16},
    editor = {Wang, Qing and Pfahl, Dietmar and Raffo, David M.},
    isbn = {978-3-540-79587-2},
    pages = {173--185},
    posted-at = {2010-08-23 14:49:13},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Detection of Consistent Patterns from Process Enactment Data},
    url = {http://dx.doi.org/10.1007/978-3-540-79588-9\_16},
    volume = {5007},
    year = {2008}
}

@inproceedings{citeulike:7690766,
    abstract = {Software process improvement has been a focus of industry for many years. To assist the procedure and
implementation of process improvement we provide a software process recovery method based on mining project enactment
data. The goal of the method is to uncover the actual process used in order to provide input to improve the quality of a
defined software process. The recovered model (or patterns) is at the same level of abstraction as the predefined
process model. This provides an easy and clear way to identify the gap between the planned process model and the real
enactment. We investigate the enactment of a defined software process from the view of understanding the appropriateness
and fitness for purpose of the process model from the viewpoint of the project managers in the context of a small
software development organization. We collected data from organizations and applied our method to a pilot case study.
The main contribution of our work is to provide a software process model recovery 
method which supports software process change and improvement.},
    author = {Huo, Ming and Zhang, He and Jeffery, Ross},
    booktitle = {2006 13th Asia Pacific Software Engineering Conference (APSEC'06)},
    citeulike-article-id = {7690766},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/apsec.2006.14},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4137443},
    doi = {10.1109/apsec.2006.14},
    isbn = {0-7695-2685-3},
    location = {Bangalore, India},
    month = dec,
    pages = {401--410},
    posted-at = {2010-08-23 10:59:07},
    priority = {2},
    publisher = {IEEE},
    title = {A Systematic Approach to Process Enactment Analysis as Input to Software Process Improvement or Tailoring},
    url = {http://dx.doi.org/10.1109/apsec.2006.14},
    year = {2006}
}

@article{citeulike:7622907,
    abstract = {Olfactory stimulation induces an odor-guided crawling behavior of Drosophila melanogaster larvae
characterized by either an attractive or a repellent reaction. In order to understand the underlying processes leading
to these orientations we stimulated single olfactory receptor neurons ({ORNs}) through photo-activation within an intact
neuronal network. Using the {Gal4-UAS} system two light inducible proteins, the light-sensitive cation channel
channelrhodopsin-2 ({ChR}-2) or the light-sensitive adenylyl cyclase (Pacalpha) were expressed in all or in individual
{ORNs} of the larval olfactory system. Blue light stimulation caused an activation of these neurons, ultimately
producing the illusion of an odor stimulus. Larvae were tested in a phototaxis assay for their orientation toward or
away from the light source. Here we show that activation of Pacalpha expressing {ORNs} bearing the receptors Or33b or
Or45a in blind {norpA} mutant larvae induces a repellent behavior away from the light. 
Conversely, photo-activation of the majority of {ORNs} induces attraction towards the light. Interestingly, in wild type
larvae two ligands of Or33b and Or45a, octyl acetate and propionic ethylester, respectively, have been found to cause an
escape reaction. Therefore, we combined light and odor stimulation to analyze the function of Or33b and Or45a expressing
{ORNs}. We show that the larval olfactory system contains a designated neuronal pathway for repellent odorants and that
activation of a specific class of {ORNs} already determines olfactory avoidance behavior.},
    author = {Bellmann, Dennis and Richardt, Arnd and Freyberger, Robert and Nuwal, Nidhi and Schw\"{a}rzel, Martin and
Fiala, Andr\'{e} and St\"{o}rtkuhl, Klemens F.},
    citeulike-article-id = {7622907},
    citeulike-linkout-0 = {http://dx.doi.org/10.3389/fnbeh.2010.00027},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2889724/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/20577637},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=20577637},
    doi = {10.3389/fnbeh.2010.00027},
    issn = {1662-5153},
    journal = {Frontiers in behavioral neuroscience},
    pmcid = {PMC2889724},
    pmid = {20577637},
    posted-at = {2010-08-12 12:37:29},
    priority = {2},
    title = {Optogenetically Induced Olfactory Stimulation in Drosophila Larvae Reveals the Neuronal Basis of
{Odor-Aversion} behavior.},
    url = {http://dx.doi.org/10.3389/fnbeh.2010.00027},
    volume = {4},
    year = {2010}
}

@inproceedings{citeulike:4934205,
    abstract = {The number of moves required to solve any state of Rubik's cube has been a matter of long-standing
conjecture for over 25 years -- since Rubik's cube appeared. This number is sometimes called "God's number". An upper
bound of 29 (in the face-turn metric) was produced in the early 1990's, followed by an upper bound of 27 in 2006.},
    address = {New York, NY, USA},
    author = {Kunkle, Daniel and Cooperman, Gene},
    booktitle = {ISSAC '07: Proceedings of the 2007 international symposium on Symbolic and algebraic computation},
    citeulike-article-id = {4934205},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1277581},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1277548.1277581},
    doi = {10.1145/1277548.1277581},
    isbn = {978-1-59593-743-8},
    location = {Waterloo, Ontario, Canada},
    pages = {235--242},
    posted-at = {2010-08-09 19:15:27},
    priority = {2},
    publisher = {ACM},
    title = {Twenty-six moves suffice for Rubik's cube},
    url = {http://dx.doi.org/10.1145/1277548.1277581},
    year = {2007}
}

@article{citeulike:4483310,
    abstract = {{BACKGROUND}:Olfactory Receptors ({ORs}) form the largest multigene family in vertebrates. Their
evolution and their expansion in the vertebrate genomes was the subject of many studies. In this paper we apply a
motif-based approach to this problem in order to uncover evolutionary {characteristics.RESULTS}:We extract deterministic
motifs from {ORs} belonging to ten species using the {MEX} (Motif Extraction) algorithm, thus defining Common Peptides
({CPs}) characteristic to {ORs}. We identify species-specific {CPs} and show that their relative abundance is high only
in fish and frog, suggesting relevance to water-soluble odorants. We estimate the origins of {CPs} according to the tree
of life and track the gains and losses of {CPs} through evolution. We identify major {CP} gain in tetrapods and major
losses in reptiles. Although the number of human {ORs} is less than half of the number of {ORs} in other mammals, the
fraction of lost {CPs} is only {11\%.By} examining the positions of {CPs} along 
the {OR} sequence, we find two regions that expanded only in tetrapods. Using {CPs} we are able to establish remote
homology relations between {ORs} and {non-OR} {GPCRs}.Selecting {CPs} according to their evolutionary age, we bicluster
{ORs} and {CPs} for each species. Clean biclustering emerges when using relatively novel {CPs}. Evolutionary age is used
to track the history of {CP} acquisition in the collection of mammalian {OR} families within {HORDE} (Human Olfactory
Receptor Data {Explorer).CONCLUSION}:The {CP} method provides a novel perspective that reveals interesting traits in the
evolution of olfactory receptors. It is consistent with previous knowledge, and provides finer details. Using available
phylogenetic trees, evolution can be rephrased in terms of {CP} {origins.Supplementary} information is also available at
{http://adios.tau.ac.il/ORPS}},
    author = {Gottlieb, Assaf and Olender, Tsviya and Lancet, Doron and Horn, David},
    citeulike-article-id = {4483310},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2148-9-91},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19416542},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19416542},
    day = {05},
    doi = {10.1186/1471-2148-9-91},
    issn = {1471-2148},
    journal = {BMC Evolutionary Biology},
    keywords = {irisa},
    month = may,
    number = {1},
    pages = {91+},
    pmid = {19416542},
    posted-at = {2010-08-02 09:21:34},
    priority = {2},
    title = {Common peptides shed light on evolution of Olfactory Receptors},
    url = {http://dx.doi.org/10.1186/1471-2148-9-91},
    volume = {9},
    year = {2009}
}

@article{citeulike:964046,
    abstract = {The main goal of the motif finding problem is to detect novel, over-represented unknown signals in a set
of sequences (e.g. transcription factor binding sites in a genome). The most widely used algorithms for finding motifs
obtain a generative probabilistic representation of these over-represented signals and try to discover profiles that
maximize the information content score. Although these profiles form a very powerful representation of the signals, the
major difficulty arises from the fact that the best motif corresponds to the global maximum of a non-convex continuous
function. Popular algorithms like Expectation Maximization ({EM}) and Gibbs sampling tend to be very sensitive to the
initial guesses and are known to converge to the nearest local maximum very quickly. In order to improve the quality of
the results, {EM} is used with multiple random starts or any other powerful stochastic global methods that might yield
promising initial guesses (like projection algorithms). Global methods 
do not necessarily give initial guesses in the convergence region of the best local maximum but rather suggest that a
promising solution is in the neighborhood region. In this paper, we introduce a novel optimization framework that
searches the neighborhood regions of the initial alignment in a systematic manner to explore the multiple local optimal
solutions. This effective search is achieved by transforming the original optimization problem into its corresponding
dynamical system and estimating the practical stability boundary of the local maximum. Our results show that the
popularly used {EM} algorithm often converges to sub-optimal solutions which can be significantly improved by the
proposed neighborhood profile search. Based on experiments using both synthetic and real datasets, our method
demonstrates significant improvements in the information content scores of the probabilistic models. The proposed method
also gives the flexibility in using different local solvers and global methods depending on 
their suitability for some specific datasets.},
    author = {Reddy, Chandan K. and Weng, Yao-Chung C. and Chiang, Hsiao-Dong D.},
    citeulike-article-id = {964046},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1748-7188-1-23},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/17129371},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=17129371},
    day = {27},
    doi = {10.1186/1748-7188-1-23},
    issn = {1748-7188},
    journal = {Algorithms for molecular biology : AMB},
    month = nov,
    number = {1},
    pages = {23+},
    pmid = {17129371},
    posted-at = {2010-07-03 14:34:43},
    priority = {2},
    title = {Refining motifs by improving information content scores using neighborhood profile search.},
    url = {http://dx.doi.org/10.1186/1748-7188-1-23},
    volume = {1},
    year = {2006}
}

@article{citeulike:2678511,
    abstract = {Many of today's information systems are driven by explicit process models. Workflow management systems,
but also {ERP}, {CRM}, {SCM}, and {B2B}, are configured on the basis of a workflow model specifying the order in which
tasks need to be executed. Creating a workflow design is a complicated time-consuming process and typically there are
discrepancies between the actual workflow processes and the processes as perceived by the management. To support the
design of workflows, we propose the use of workflow mining. Starting point for workflow mining is a so-called  ”
workflow log” containing information about the workflow process as it is actually being executed. In this paper, we
introduce the concept of workflow mining and present a common format for workflow logs. Then we discuss the most
challenging problems and present some of the workflow mining approaches available today.},
    address = {Amsterdam, The Netherlands, The Netherlands},
    author = {Vanderaalst, W. and Vandongen, B. and Herbst, J. and Maruster, L. and Schimm, G. and Weijters, A.},
    citeulike-article-id = {2678511},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=961808.961812},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/s0169-023x(03)00066-1},
    doi = {10.1016/s0169-023x(03)00066-1},
    issn = {0169023X},
    journal = {Data \& Knowledge Engineering},
    month = nov,
    number = {2},
    pages = {237--267},
    posted-at = {2010-07-03 12:06:38},
    priority = {2},
    publisher = {Elsevier Science Publishers B. V.},
    title = {Workflow mining: A survey of issues and approaches},
    url = {http://dx.doi.org/10.1016/s0169-023x(03)00066-1},
    volume = {47},
    year = {2003}
}

@article{citeulike:4122657,
    abstract = {The overall mean recognition probability (mean accuracy) of a pattern classifier is calculated and
numerically plotted as a function of the pattern measurement complexity n and design data set size},
    author = {Hughes, G.},
    booktitle = {Information Theory, IEEE Transactions on},
    citeulike-article-id = {4122657},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tit.1968.1054102},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1054102},
    doi = {10.1109/tit.1968.1054102},
    issn = {0018-9448},
    journal = {Information Theory, IEEE Transactions on},
    month = jan,
    number = {1},
    pages = {55--63},
    posted-at = {2010-06-30 20:16:49},
    priority = {2},
    publisher = {IEEE},
    title = {On the mean accuracy of statistical pattern recognizers},
    url = {http://dx.doi.org/10.1109/tit.1968.1054102},
    volume = {14},
    year = {1968}
}

@article{citeulike:7370527,
    abstract = {{Abstract\&nbsp;\&nbsp;Accurate} thematic classification is one of the most commonly desired outputs
from remote sensing images. Recent research efforts to improve the reliability and accuracy of image classification have
led to the introduction of the Support Vector Classification ({SVC}) scheme. {SVC} is a new generation of supervised
learning method based on the principle of statistical learning theory, which is designed to decrease uncertainty in the
model structure and the fitness of data. We have presented a comparative analysis of {SVC} with the Maximum Likelihood
Classification ({MLC}) method, which is the most popular conventional supervised classification technique. {SVC} is an
optimization technique in which the classification accuracy heavily relies on identifying the optimal parameters. Using
a case study, we verify a method to obtain these optimal parameters such that {SVC} can be applied efficiently. We use
multispectral and hyperspectral images to develop thematic classes of 
known lithologic units in order to compare the classification accuracy of both the methods. We have varied the training
to testing data proportions to assess the relative robustness and the optimal training sample requirement of both the
methods to achieve comparable levels of accuracy. The results of our study illustrated that {SVC} improved the
classification accuracy, was robust and did not suffer from dimensionality issues such as the Hughes Effect.},
    author = {Oommen, Thomas and Misra, Debasmita and Twarakavi, Navin and Prakash, Anupma and Sahoo, Bhaskar and
Bandopadhyay, Sukumar},
    citeulike-article-id = {7370527},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11004-008-9156-6},
    citeulike-linkout-1 = {http://www.springerlink.com/content/88j1306hp6386216},
    day = {1},
    doi = {10.1007/s11004-008-9156-6},
    issn = {1874-8961},
    journal = {Mathematical Geosciences},
    keywords = {dissertation, support\_vector\_machine},
    month = may,
    number = {4},
    pages = {409--424},
    posted-at = {2010-06-30 20:04:51},
    priority = {2},
    title = {An Objective Analysis of Support Vector Machine Based Classification for Remote Sensing},
    url = {http://dx.doi.org/10.1007/s11004-008-9156-6},
    volume = {40},
    year = {2008}
}

@proceedings{citeulike:1630245,
    abstract = {In this work, we introduce the new problem of finding time series discords. Time series discords are
subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They
thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for
data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection.
Discords are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length
of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. We evaluate our
work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with objective
experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry, and we
demonstrate the effectiveness of our discord discovery algorithm with more than one 
million experiments, on 82 different datasets from diverse domains.},
    author = {Keogh, E. and Lin, J. and Fu, A.},
    booktitle = {Data Mining, Fifth IEEE International Conference on},
    citeulike-article-id = {1630245},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1565683},
    journal = {Data Mining, Fifth IEEE International Conference on},
    pages = {8 pp.+},
    posted-at = {2010-06-30 19:33:27},
    priority = {2},
    title = {{HOT} {SAX}: efficiently finding the most unusual time series subsequence},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1565683},
    year = {2005}
}

@article{citeulike:692,
    abstract = {
                In a previous paper, we introduced {MUSCLE}, a new program for creating multiple alignments of protein
sequences, giving a brief summary of the algorithm and showing {MUSCLE} to achieve the highest scores reported to date
on four alignment accuracy benchmarks. Here we present a more complete discussion of the algorithm, describing several
previously unpublished techniques that improve biological accuracy and / or computational complexity. We introduce a new
option, {MUSCLE}-fast, designed for high-throughput applications. We also describe a new protocol for evaluating
objective functions that align two profiles.
                We compare the speed and accuracy of {MUSCLE} with {CLUSTALW}, Progressive {POA} and the {MAFFT} script
{FFTNS1}, the fastest previously published program known to the author. Accuracy is measured using four benchmarks:
{BAliBASE}, {PREFAB}, {SABmark} and {SMART}. We test three variants that offer highest accuracy ({MUSCLE} with default
settings), highest speed ({MUSCLE}-fast), and a carefully chosen compromise between the two ({MUSCLE}-prog). We find
{MUSCLE}-fast to be the fastest algorithm on all test sets, achieving average alignment accuracy similar to {CLUSTALW}
in times that are typically two to three orders of magnitude less. {MUSCLE}-fast is able to align 1,000 sequences of
average length 282 in 21 seconds on a current desktop computer.
                {MUSCLE} offers a range of options that provide improved speed and / or alignment accuracy compared with
currently available programs. {MUSCLE} is freely available at http://www.drive5.com/muscle.
            },
    address = {Department of Plant and Microbial Biology, 461 Koshland Hall, University of California, Berkeley, CA
94720-3102, USA. bob@drive5.com},
    author = {Edgar, Robert C.},
    citeulike-article-id = {692},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2105-5-113},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC517706/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/15318951},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=15318951},
    day = {19},
    doi = {10.1186/1471-2105-5-113},
    issn = {1471-2105},
    journal = {BMC bioinformatics},
    month = aug,
    number = {1},
    pages = {113+},
    pmcid = {PMC517706},
    pmid = {15318951},
    posted-at = {2010-06-30 19:22:58},
    priority = {2},
    title = {{MUSCLE}: a multiple sequence alignment method with reduced time and space complexity.},
    url = {http://dx.doi.org/10.1186/1471-2105-5-113},
    volume = {5},
    year = {2004}
}

@article{citeulike:1586554,
    abstract = {Abstract\&nbsp;\&nbsp; Drosophila melanogaster has proven to be a useful model system to probe the
mechanisms underlying the detection, discrimination, and perception of volatile odorants. The relatively small receptor
repertoire of 62 odorant receptors makes the goal of understanding odor responses from the total receptor repertoire
approachable in this system, and recent work has been directed toward this goal. In addition, new work not only sheds
light but also raises more questions about the initial steps in odor perception in this system. Odorant receptor genes
in Drosophila are predicted to encode seven transmembrane receptors, but surprising data suggest that these receptors
may be inverted in the plasma membrane compared to classical G-protein coupled receptors. Finally, although some
Drosophila odorant receptors are activated directly by odorant molecules, detection of a volatile pheromone, 11-cis
vaccenyl acetate requires an extracellular adapter protein called {LUSH} for activation 
of pheromone sensitive neurons. Because pheromones are used by insects to trigger mating and other behaviors, these
insights may herald new approaches to control behavior in pathogenic and agricultural pest insects.},
    author = {Smith, Dean},
    citeulike-article-id = {1586554},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00424-006-0190-2},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/klu/424/2007/00000454/00000005/00000190},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/17205355},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=17205355},
    citeulike-linkout-4 = {http://www.springerlink.com/content/h626234424151873},
    day = {1},
    doi = {10.1007/s00424-006-0190-2},
    issn = {0031-6768},
    journal = {Pfl\"{u}gers Archiv European Journal of Physiology},
    month = aug,
    number = {5},
    pages = {749--758},
    pmid = {17205355},
    posted-at = {2010-06-30 09:58:48},
    priority = {2},
    publisher = {Springer},
    title = {Odor and pheromone detection in Drosophila melanogaster},
    url = {http://dx.doi.org/10.1007/s00424-006-0190-2},
    volume = {454},
    year = {2007}
}

@incollection{citeulike:7369108,
    abstract = {A methodology is presented to quantitatively model the expected relationships between investments in
process improvements and improvements in business measures. Such a predictive model can be used as an auxiliary in
process improvement planning in addition to established models like {CMMI}. Different from a generic model like {CMMI},
the proposed methodology allows for creating a fully customized model focusing on the context or product at hand. To
manage the inherent parameter uncertainty of quantitative modelling of software processes a novel approach in this
context is used by explicitly handling the parameter variations using interval arithmetic. The paper outlines the
methodology and presents results from a study at Siemens.},
    address = {Berlin, Heidelberg},
    author = {Birkh\"{o}lzer, Thomas and Dickmann, Christoph and Klein, Harald and Vaupel, J\"{u}rgen and Ast, Stefan
and Meyer, Ludger},
    booktitle = {Product-Focused Software Process Improvement },
    chapter = {25},
    citeulike-article-id = {7369108},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-69566-0\_25},
    citeulike-linkout-1 = {http://www.springerlink.com/content/r83552w14vr26248},
    doi = {10.1007/978-3-540-69566-0\_25},
    editor = {Jedlitschka, Andreas and Salo, Outi},
    isbn = {978-3-540-69564-6},
    issn = {0302-9743},
    pages = {304--316},
    posted-at = {2010-06-30 09:55:08},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Customized Predictive Models for Process Improvement Projects},
    url = {http://dx.doi.org/10.1007/978-3-540-69566-0\_25},
    volume = {5089},
    year = {2008}
}

@incollection{citeulike:7366077,
    abstract = {Commercial software firms are increasingly using and contributing to open source software. Thus, they
need to understand and work with open source software development processes. This paper investigates whether the
practice of continuous integration of agile software development methods has had an impact on open source software
projects. Using fine-granular data from more than 5000 active open source software projects we analyze the size of code
contributions over a project's life-span. Code contribution size has stayed flat. We interpret this to mean that open
source software development has not changed its code integration practices. In particular, within the limits of this
study, we claim that the practice of continuous integration has not yet significantly influenced the behavior of open
source software developers.},
    address = {Boston, MA},
    author = {Deshpande, Amit and Riehle, Dirk},
    booktitle = {Open Source Development, Communities and Quality},
    chapter = {23},
    citeulike-article-id = {7366077},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-0-387-09684-1\_23},
    citeulike-linkout-1 = {http://www.springerlink.com/content/hj223l05x53l70v1},
    doi = {10.1007/978-0-387-09684-1\_23},
    editor = {Russo, Barbara and Damiani, Ernesto and Hissam, Scott and Lundell, Bj\"{o}rn and Succi, Giancarlo},
    isbn = {978-0-387-09683-4},
    issn = {1571-5736},
    pages = {273--280},
    posted-at = {2010-06-29 13:56:37},
    priority = {2},
    publisher = {Springer Boston},
    series = {IFIP International Federation for Information Processing},
    title = {Continuous Integration in Open Source Software Development},
    url = {http://dx.doi.org/10.1007/978-0-387-09684-1\_23},
    volume = {275},
    year = {2008}
}

@article{citeulike:7351135,
    author = {Gibbs, Wayt W.},
    citeulike-article-id = {7351135},
    journal = {Scientific American},
    month = sep,
    posted-at = {2010-06-23 11:35:18},
    priority = {2},
    title = {Software's Chronic Crisis},
    year = {1994}
}

@inbook{citeulike:7349861,
    abstract = {This paper presents a value-based software process framework that has been derived from the 4+1 theory
of value-based software engineering ({VBSE}). The value-based process framework integrates the four component theories –
dependency, utility, decision, and control, to the central theory W, and orients itself as a 7-step process guide to
practice value-based software engineering. We also illustrate applying the process framework to a supply chain
organization through a case study analysis.},
    address = {Berlin, Heidelberg},
    author = {Boehm, Barry and Jain, Apurva},
    booktitle = {Software Process Change },
    chapter = {1},
    citeulike-article-id = {7349861},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11754305\_1},
    citeulike-linkout-1 = {http://www.springerlink.com/content/hqn78653116517k6},
    doi = {10.1007/11754305\_1},
    editor = {Wang, Qing and Pfahl, Dietmar and Raffo, David M. and Wernick, Paul},
    isbn = {978-3-540-34199-4},
    pages = {1--10},
    posted-at = {2010-06-22 23:44:49},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {A {Value-Based} Software Process Framework},
    url = {http://dx.doi.org/10.1007/11754305\_1},
    volume = {3966},
    year = {2006}
}

@article{citeulike:7349857,
    abstract = {As a recognized discipline, software engineering traces its roots back to the 1968 {NATO} conference
where the term was first used extensively to highlight the need for an engineering approach to the development of
software. In the 30 years since that first  ” software engineering” conference, significant attempts have been made to
improve the overall effectiveness of the software development process, and thus reduce the frequency and severity of
software project failures. A major part of this improvement effort has been the attempt to develop quantitative measures
which can be used to more accurately describe and better understand and manage the software development life cycle.
Thus, many software metrics and models have been introduced during this period. In this article, we briefly trace the
history of the development of software metrics and models, and then summarize the current state of the field. For
discussion purposes, this entire development period is then arbitrarily divided into an 
Introductory Period (1971–1985), Growth Period (1985–1997) and the Current Period (1997–?). The development of metrics
during each of these periods is then related to the treatment of software metrics and models in software engineering
curricula during that same period. Our conclusion is that software engineering curricula have indeed reflected the state
of software engineering as the work in software metrics and models has progressed. Furthermore, software engineering
curricula of the future should reflect the relatively mature state that software metrics have attained, by covering the
basic concepts of metrics in appropriate core courses, and more advanced metrics topics in a specialized, elective
metrics course.},
    author = {Mills, Everald E.},
    citeulike-article-id = {7349857},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a:1018909531948},
    citeulike-linkout-1 = {http://www.springerlink.com/content/l3398645k187285g},
    day = {1},
    doi = {10.1023/a:1018909531948},
    issn = {10227091},
    journal = {Annals of Software Engineering},
    month = mar,
    number = {1},
    pages = {181--200},
    posted-at = {2010-06-22 23:44:27},
    priority = {2},
    title = {Metrics in the software engineering curriculum},
    url = {http://dx.doi.org/10.1023/a:1018909531948},
    volume = {6},
    year = {1998}
}

@incollection{citeulike:7349055,
    abstract = {The {U.S}. Department of Defense and other parts of the {U.S}. government use the Capability Maturity
Model Integrated ({CMMI}) for process improvement to reduce the risk of poor performance by its major contractors.
Acquisition officials have reported that many of its major programs suffer from cost, schedule, and technical
performance problems even though those programs are being implemented by companies which rate high with respect to the
{CMMI}. This paper explores possible reasons why companies with high {CMMI} ratings can still have significant
performance problems and suggests possible remedies.},
    address = {Berlin, Heidelberg},
    author = {Pyster, Arthur},
    booktitle = {Unifying the Software Process Spectrum },
    chapter = {8},
    citeulike-article-id = {7349055},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11608035\_8},
    citeulike-linkout-1 = {http://www.springerlink.com/content/p634738l5t05874t},
    doi = {10.1007/11608035\_8},
    editor = {Li, Mingshu and Boehm, Barry and Osterweil, Leon J.},
    isbn = {978-3-540-31112-6},
    pages = {75--82},
    posted-at = {2010-06-22 15:24:55},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {What Beyond {CMMI} Is Needed to Help Assure Program and Project Success?},
    url = {http://dx.doi.org/10.1007/11608035\_8},
    volume = {3840},
    year = {2006}
}

@incollection{citeulike:2050908,
    abstract = {A process defines the way activities are organized, managed, measured, supported and improved to reach a
goal. It has been shown, 15 years ago [1] that processes are software too; more precisely that their description can
also be software. We hypothesize that a system can be characterized by its goal and by answering the questions: why,
what and how.},
    address = {Berlin, Heidelberg},
    author = {Estublier, Jacky},
    booktitle = {Unifying the Software Process Spectrum },
    chapter = {3},
    citeulike-article-id = {2050908},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11608035\_3},
    citeulike-linkout-1 = {http://www.springerlink.com/content/f8r4580p3016r025},
    doi = {10.1007/11608035\_3},
    editor = {Li, Mingshu and Boehm, Barry and Osterweil, Leon J.},
    isbn = {978-3-540-31112-6},
    journal = {Unifying the Software Process Spectrum},
    pages = {25--34},
    posted-at = {2010-06-22 15:20:36},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Software are Processes Too},
    url = {http://dx.doi.org/10.1007/11608035\_3},
    volume = {3840},
    year = {2006}
}

@inproceedings{citeulike:7349026,
    abstract = {Sound methods of analysis and comparison of software processes are crucial for such tasks as process
understanding, process correctness verification, evolution management, process classification, process improvement, and
choosing the appropriate process for a certain project. The purpose of our research is to lay the foundations for a
systematic and rigorous comparison of processes by establishing fixed methods and conceptual frameworks that are able to
assure that comparison efforts will yield predictable, reproducible results. The analysis framework presented here
assumes that the comparison will be done relative to a fixed standard feature classification schema for the processes
used, and with the use of a fixed formalism for modeling the processes. The aspect of the system described in this paper
is focused on functional analysis of processes according to the predefined comparison topics, well formedness
constraints, and instrumented agents. The paper describes our experience using our 
analysis system and its application to a logistics software process from the telecommunication domain. 1},
    author = {Podorozhny, Rodion M. and Perry, Dewayne E. and Osterweil, Leon J.},
    booktitle = {International Software Process Workshop},
    citeulike-article-id = {7349026},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.74.4930},
    pages = {482--497},
    posted-at = {2010-06-22 15:17:50},
    priority = {2},
    title = {Automatically Analyzing Software Processes: Experience Report},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.74.4930}
}

@book{citeulike:6169037,
    abstract = {"This book presents international practices in the development and use of applied {e-Learning} and
{e-Teaching} in the classroom in order to enhance student experience, add value to teaching practices, and illuminate
best practices in the area of {e-Assessment}. This book provides insight into {e-Learning} and {e-Teaching} practices
while exploring the roles of academic staff in adoption and {application"--Provided} by publisher.},
    author = {McShea, Daniel W. and Brandon, Robert N.},
    citeulike-article-id = {6169037},
    citeulike-linkout-0 = {http://www.worldcat.org/oclc/55600801},
    isbn = {978},
    journal = {GIS Proc. ACM Int. Symp. Adv. Geogr. Inf. Syst. GIS: Proceedings of the ACM International Symposium on
Advances in Geographic Information Systems},
    posted-at = {2010-06-22 15:17:00},
    priority = {2},
    publisher = {University of Chicago Press},
    series = {Springer series in synergetics, 18},
    title = {Biology's first law : the tendency for diversity and complexity to increase in evolutionary systems},
    url = {http://www.worldcat.org/oclc/55600801},
    year = {2010}
}

@article{citeulike:7239889,
    author = {Magn\'{u}sson, Kjartan and Sigurdsson, Sven and Babak, Petro and Gudmundsson, Stef\'{a}n and
Dereksd\'{o}ttir, Eva H.},
    citeulike-article-id = {7239889},
    citeulike-linkout-0 = {http://dx.doi.org/10.3934/dcdsb.2004.4.695},
    doi = {10.3934/dcdsb.2004.4.695},
    issn = {1531-3492},
    journal = {Discrete and Continuous Dynamical Systems - Series B},
    keywords = {inna},
    month = may,
    number = {3},
    pages = {695--704},
    posted-at = {2010-06-03 16:14:00},
    priority = {2},
    title = {A continuous density Kolmogorov type model for a migrating fish stock},
    url = {http://dx.doi.org/10.3934/dcdsb.2004.4.695},
    volume = {4},
    year = {2004}
}

@article{citeulike:7239881,
    abstract = {Uncertainty in estimates of survival of dispersing animals is a vexing difficulty in conservation
biology. The current notion is that this uncertainty decreases the usefulness of spatially explicit population models in
particular. We examined this problem by comparing dispersal models of three levels of complexity: (1) an event-based
binomial model that considers only the occurrence of mortality or arrival, (2) a temporally explicit exponential model
that employs mortality and arrival rates, and (3) a spatially explicit gridwalk model that simulates the movement of
animals through an artificial landscape. Each model was fitted to the same set of field data. A first objective of the
paper is to illustrate how the maximum-likelihood method can be used in all three cases to estimate the means and
confidence limits for the relevant model parameters, given a particular set of data on dispersal survival. Using this
framework we show that the structure of the uncertainty for all three models is 
strikingly similar. In fact, the results of our unified approach imply that spatially explicit dispersal models, which
take advantage of information on landscape details, suffer less from uncertainly than do simpler models. Moreover, we
show that the proposed strategy of model development safeguards one from error propagation in these more complex models.
Finally, our approach shows that all models related to animal dispersal, ranging from simple to complex, can be related
in a hierarchical fashion, so that the various approaches to modeling such dispersal can be viewed from a unified
perspective.},
    author = {Mooij, Wolf M. and DeAngelis, Donald L.},
    citeulike-article-id = {7239881},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/4134696},
    citeulike-linkout-1 = {http://www.jstor.org/stable/4134696},
    doi = {10.2307/4134696},
    issn = {10510761},
    journal = {Ecological Applications},
    keywords = {inna},
    number = {3},
    pages = {794--805},
    posted-at = {2010-06-03 16:12:20},
    priority = {2},
    publisher = {Ecological Society of America},
    title = {Uncertainty in Spatially Explicit Animal Dispersal Models},
    url = {http://dx.doi.org/10.2307/4134696},
    volume = {13},
    year = {2003}
}

@incollection{citeulike:7131605,
    abstract = {We describe in this paper the experiments done to compare two algorithms that identify the family of
regular languages in the limit, the algorithm of Trakhenbrot and {Barzdin/Gold} by one hand and the {RPNI}/Lang
algorithm by the other. As a previous step, for a better comparison, we formulate the algorithm of Gold as a merging
states in the prefix tree acceptor scheme.},
    author = {Garc\'{\i}a, P. and Cano, A. and Ruiz, J.},
    booktitle = {Grammatical Inference: Algorithms and Applications },
    citeulike-article-id = {7131605},
    citeulike-linkout-0 = {http://www.springerlink.com/content/p49nx01ev9ux8pfy},
    keywords = {inference},
    pages = {257--258},
    posted-at = {2010-05-06 07:05:00},
    priority = {2},
    title = {A Comparative Study of Two Algorithms for Automata Identification},
    url = {http://www.springerlink.com/content/p49nx01ev9ux8pfy},
    year = {2000}
}

@incollection{citeulike:7131602,
    abstract = {We propose 10 different open problems in the field of grammatical inference. In all cases, problems are
theoretically oriented but correspond to practical questions. They cover the areas of polynomial learning models,
learning from ordered alphabets, learning deterministic Pomdps, learning negotiation processes, learning from
context-free background knowledge.},
    address = {Berlin, Heidelberg},
    author = {de la Higuera, Colin},
    booktitle = {Grammatical Inference: Algorithms and Applications },
    chapter = {4},
    citeulike-article-id = {7131602},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11872436\_4},
    citeulike-linkout-1 = {http://www.springerlink.com/content/06301k441267gj32},
    doi = {10.1007/11872436\_4},
    editor = {Sakakibara, Yasubumi and Kobayashi, Satoshi and Sato, Kengo and Nishino, Tetsuro and Tomita, Etsuji},
    isbn = {978-3-540-45264-5},
    keywords = {inference},
    pages = {32--44},
    posted-at = {2010-05-06 07:04:05},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {Ten Open Problems in Grammatical Inference},
    url = {http://dx.doi.org/10.1007/11872436\_4},
    volume = {4201},
    year = {2006}
}

@incollection{citeulike:7130326,
    abstract = {We present a method for modeling user navigation on a web site using grammatical inference of stochastic
regular grammars. With this method we achieve better models than the previously used first order Markov chains, in terms
of predictive accuracy and utility of recommendations. In order to obtain comparable results, we apply the same
grammatical inference algorithms on Markov chains, modeled as probabilistic automata. The automata induced in this way
perform better than the original Markov chains, as models for user navigation, but they are considerably inferior to the
automata induced by the traditional grammatical inference methods. The evaluation of our method was based on two web
usage data sets from two very dissimilar web sites. It consisted in producing, for each user, a personalized list of
recommendations and then measuring its recall and expected utility.},
    author = {Karampatziakis, Nikolaos and Paliouras, Georgios and Pierrakos, Dimitrios and Stamatopoulos, Panagiotis},
    booktitle = {Grammatical Inference: Algorithms and Applications },
    citeulike-article-id = {7130326},
    citeulike-linkout-0 = {http://www.springerlink.com/content/n8cbh619bv6415bh},
    keywords = {inference},
    pages = {187--198},
    posted-at = {2010-05-06 06:18:30},
    priority = {2},
    title = {Navigation Pattern Discovery Using Grammatical Inference},
    url = {http://www.springerlink.com/content/n8cbh619bv6415bh},
    year = {2004}
}

@incollection{citeulike:7024475,
    abstract = {We study determinization of weighted finite-state automata ({WFAs}), which has important applications in
automatic speech recognition ({ASR}). We provide the first polynomial-time algorithm to test for the twins property,
which determines if a {WFA} admits a deterministic equivalent. We also provide a rigorous analysis of a determinization
algorithm of Mohri, with tight bounds for acyclic {WFAs}. Given that {WFAs} can expand exponentially when determinized,
we explore why those used in {ASR} tend to shrink. The folklore explanation is that {ASR} {WFAs} have an acyclic,
multi-partite structure. We show, however, that there exist such {WFAs} that always incur exponential expansion when
determinized. We then introduce a class of {WFAs}, also with this structure, whose expansion depends on the weights:
some weightings cause them to shrink, while others, including random weightings, cause them to expand {exponentially.We}
provide experimental evidence that {ASR} {WFAs} exhibit this weight 
dependence. That they shrink when determinized, therefore, is a result of favorable weightings in addition to special
topology.},
    author = {Buchsbaum, Adam L. and Giancarlo, Raffaele and Westbrook, Jeffery R.},
    booktitle = {Automata, Languages and Programming },
    citeulike-article-id = {7024475},
    citeulike-linkout-0 = {http://www.springerlink.com/content/yeclvf54qqlr8aaw},
    keywords = {irisa},
    pages = {482+},
    posted-at = {2010-04-16 09:34:15},
    priority = {2},
    title = {On the Determinization of Weighted Finite Automata},
    url = {http://www.springerlink.com/content/yeclvf54qqlr8aaw},
    year = {1998}
}

@article{citeulike:6622689,
    abstract = {The mosquito Anopheles gambiae is the major vector of malaria in {sub-Saharan} Africa. It locates its
human hosts primarily through olfaction, but little is known about the molecular basis of this process. Here we
functionally characterize the Anopheles gambiae odorant receptor ({AgOr}) repertoire. We identify receptors that respond
strongly to components of human odour and that may act in the process of human recognition. Some of these receptors are
narrowly tuned, and some salient odorants elicit strong responses from only one or a few receptors, suggesting a central
role for specific transmission channels in human host-seeking behaviour. This analysis of the Anopheles gambiae
receptors permits a comparison with the corresponding Drosophila melanogaster odorant receptor repertoire. We find that
odorants are differentially encoded by the two species in ways consistent with their ecological needs. Our analysis of
the Anopheles gambiae repertoire identifies receptors that may be useful targets 
for controlling the transmission of malaria.},
    author = {Carey, Allison F. and Wang, Guirong and Su, Chih-Ying Y. and Zwiebel, Laurence J. and Carlson, John R.},
    citeulike-article-id = {6622689},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature08834},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature08834},
    citeulike-linkout-2 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2833235/},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/20130575},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=20130575},
    day = {4},
    doi = {10.1038/nature08834},
    issn = {1476-4687},
    journal = {Nature},
    keywords = {irisa},
    month = mar,
    number = {7285},
    pages = {66--71},
    pmcid = {PMC2833235},
    pmid = {20130575},
    posted-at = {2010-03-08 13:50:08},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {Odorant reception in the malaria mosquito Anopheles gambiae.},
    url = {http://dx.doi.org/10.1038/nature08834},
    volume = {464},
    year = {2010}
}

@article{citeulike:6776942,
    abstract = {{BACKGROUND}:Insect odorant binding proteins ({OBPs}) and chemosensory proteins ({CSPs}) play an
important role in chemical communication of insects. Gene discovery of these proteins is a time-consuming task. In
recent years, expressed sequence tags ({ESTs}) of many insect species have accumulated, thus providing a useful resource
for gene {discovery.RESULTS}:We have developed a computational pipeline to identify {OBP} and {CSP} genes from insect
{ESTs}. In total, 752,841 insect {ESTs} were examined from 54 species covering eight Orders of Insecta. From these
{ESTs}, 142 {OBPs} and 177 {CSPs} were identified, of which 117 {OBPs} and 129 {CSPs} are new. The complete open reading
frames ({ORFs}) of 88 {OBPs} and 123 {CSPs} were obtained by electronic elongation. We randomly chose 26 {OBPs} from
eight species of insects, and 21 {CSPs} from four species for {RT}-{PCR} validation. Twenty two {OBPs} and 16 {CSPs}
were confirmed by {RT}-{PCR}, proving the efficiency and reliability of the algorithm. 
Together with all family members obtained from the {NCBI} ({OBPs}) or the {UniProtKB} ({CSPs}), 850 {OBPs} and 237
{CSPs} were analyzed for their structural characteristics and evolutionary {relationship.CONCLUSIONS}:A large number of
new {OBPs} and {CSPs} were found, providing the basis for deeper understanding of these proteins. In addition, the
conserved motif and evolutionary analysis provide some new insights into the evolution of insect {OBPs} and {CSPs}.
Motif pattern fine-tune the functions of {OBPs} and {CSPs}, leading to the minor difference in binding sex pheromone or
plant volatiles in different insect Orders.},
    author = {Xu, Ya L. and He, Peng and Zhang, Lan and Fang, Shao Q. and Dong, Shuang L. and Zhang, Yong J. and Li,
Fei},
    citeulike-article-id = {6776942},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2164-10-632},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/20034407},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=20034407},
    doi = {10.1186/1471-2164-10-632},
    issn = {1471-2164},
    journal = {BMC Genomics},
    keywords = {irisa},
    number = {1},
    pages = {632+},
    pmid = {20034407},
    posted-at = {2010-03-08 13:49:13},
    priority = {2},
    title = {Large-scale identification of odorant-binding proteins and chemosensory proteins from expressed sequence
tags in insects},
    url = {http://dx.doi.org/10.1186/1471-2164-10-632},
    volume = {10},
    year = {2009}
}

@article{citeulike:6776936,
    abstract = {{BACKGROUND}:Dogs and rats have a highly developed capability to detect and identify odorant molecules,
even at minute concentrations. Previous analyses have shown that the olfactory receptors ({ORs}) that specifically bind
odorant molecules are encoded by the largest gene family sequenced in mammals so {far.RESULTS}:We identified five amino
acid patterns characteristic of {ORs} in the recently sequenced boxer dog and brown Norway rat genomes. Using these
patterns, we retrieved 1,094 dog genes and 1,493 rat genes from these shotgun sequences. The retrieved sequences
constitute the olfactory receptor repertoires of these two animals. Subsets of 20.3\% (for the dog) and 19.5\% (for the
rat) of these genes were annotated as pseudogenes as they had one or several mutations interrupting their open reading
frames. We performed phylogenetic studies and organized these two repertoires into classes, families and
{subfamilies.CONCLUSION}:We have established a complete or almost complete list of {OR} 
genes in the dog and the rat and have compared the sequences of these genes within and between the two species. Our
results provide insight into the evolutionary development of these genes and the local amplifications that have led to
the specific amplification of many subfamilies. We have also compared the human and rat {ORs} with the human and mouse
{OR} repertoires.},
    author = {Quignon, Pascale and Giraud, Mathieu and Rimbault, Maud and Lavigne, Patricia and Tacher, Sandrine and
Morin, Emmanuelle and Retout, Elodie and Valin, Anne S. and Toh, Kerstin L. and Nicolas, Jacques and Galibert, Francis},
    citeulike-article-id = {6776936},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/gb-2005-6-10-r83},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/16207354},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=16207354},
    doi = {10.1186/gb-2005-6-10-r83},
    issn = {1465-6906},
    journal = {Genome Biology},
    keywords = {irisa},
    number = {10},
    pages = {R83+},
    pmid = {16207354},
    posted-at = {2010-03-08 13:48:20},
    priority = {2},
    title = {The dog and rat olfactory receptor repertoires},
    url = {http://dx.doi.org/10.1186/gb-2005-6-10-r83},
    volume = {6},
    year = {2005}
}

@article{citeulike:6655701,
    abstract = {During a circumnavigation of the Svalbard archipelago in May 2006, simultaneous marine environmental
(meteorology, heat flux, ocean turbulence, irradiance) and biological (phytoplankton and zooplankton biomass/species)
data were sampled at selected stations. The zooplankton data were supplemented by high-resolution, high-speed {VPR}
sampling down to 100 m depth at most stations. We were able to sample different phases of the phytoplankton spring bloom
in Arctic as well as in Atlantic waters, and the stations represented different situations with respect to irradiance,
turbulence and water-column stability. Phytoplankton growth and depth distribution were physically controlled, while
zooplankton distributions were affected by biological parameters and turbulence. Development of the zooplankton followed
the phytoplankton bloom phase, which was progressing in a direction from west to east in the waters north of Svalbard,
and southwards in the Barents Sea. Our results also showed that the 
zooplankton did not avoid  Phaeocystis pouchetii  colonies, which have earlier been described as toxic. Despite an early
retreat of the ice this year there was no apparent mismatch between the phytoplankton bloom and the dominant
mesozooplankton,  Calanus  spp.},
    author = {Norrbin, Fredrika and Eilertsen, Hans C. and Degerlund, Maria},
    citeulike-article-id = {6655701},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.dsr2.2008.11.006},
    doi = {10.1016/j.dsr2.2008.11.006},
    issn = {09670645},
    journal = {Deep Sea Research Part II: Topical Studies in Oceanography},
    month = oct,
    number = {21-22},
    pages = {1945--1958},
    posted-at = {2010-02-11 21:58:44},
    priority = {2},
    title = {Vertical distribution of primary producers and zooplankton grazers during different phases of the Arctic
spring bloom},
    url = {http://dx.doi.org/10.1016/j.dsr2.2008.11.006},
    volume = {56},
    year = {2009}
}

@article{citeulike:6655694,
    abstract = {doi: {10.1515/BOT}.2009.073 Abstract Polar algae have a striking ability to photosynthesize and grow
under very low light and temperatures. In seaweeds, minimum light demands for photosynthetic saturation and compensation
can be as low as 10 and 2 μmol photons m-2 s-1, respectively. For benthic microalgae, these values can be even lower
because of the limited irradiance reaching deep sea floors. The extreme shade adaptation of these organisms sets their
distributional limits at depths close to 40 m and enables them to tolerate long periods of extended darkness. In
addition to their capability for efficient photosynthesis at extremely low light levels, polar algae possess metabolic
adaptations to persist at low temperatures, which permit them to complete their life cycles at year-round temperatures
close to {0°C}. Seaweeds with the lowest temperature demands are the species endemic to the Antarctic while Arctic algae
are comparatively less cold-adapted. These adaptive characteristics allow 
benthic marine algae to make high contributions to high latitude coastal primary productivity and energy fluxes,
exceeding or equaling the production of primary producers in more temperate systems. The studies summarized here give
important insights into the major physiological adaptations allowing marine benthic microalgae and seaweeds to colonize
these extreme habitats.},
    author = {G\'{o}mez, Iv\'{a}n and Wulff, Angela and Roleda, Michael Y. and Huovinen, Pirjo and Karsten, Ulf and
Quartino, Mar\'{\i}a L. and Dunton, Ken and Wiencke, Christian},
    citeulike-article-id = {6655694},
    citeulike-linkout-0 = {http://www.reference-global.com/doi/abs/10.1515/BOT.2009.073},
    citeulike-linkout-1 = {http://dx.doi.org/10.1515/bot.2009.073},
    day = {1},
    doi = {10.1515/bot.2009.073},
    journal = {Botanica Marina},
    month = dec,
    number = {6},
    pages = {593--608},
    posted-at = {2010-02-11 21:55:09},
    priority = {2},
    title = {Light and temperature demands of marine benthic microalgae and seaweeds in polar regions},
    url = {http://dx.doi.org/10.1515/bot.2009.073},
    volume = {52},
    year = {2009}
}

@article{citeulike:6655690,
    abstract = {Pronounced seasonality is a characteristic feature of polar ecosystems, but seasonal studies in the
{high-Arctic} pack-ice zone are still scarce because of logistical constraints. During six expeditions (1994–2003) to
the Fram Strait area between Greenland and Svalbard in winter, spring, early summer, late summer and autumn, the sub-ice
habitat and fauna below the pack ice (0–1 m depth) were analyzed for seasonal patterns. Both environmental variables
such as ice cover, temperature, salinity and chlorophyll  a  (chl  a ), as well as species composition, abundance and
biomass of the sub-ice fauna showed distinct seasonal dynamics. Most species of the sub-ice fauna were found in early
summer, followed by autumn, spring and late summer; the lowest number occurred in winter. The sub-ice fauna was
dominated by copepod nauplii during all seasons. Next numerous was the small pelagic copepod  Oithona similis,  followed
by occassional swarms of  Pseudocalanus minutus  and  Calanus  spp. Abundances of 
the sympagic fauna in the sub-ice water layer were much lower, with ectinosomatid copepods being usually the most
numerous sympagic group. In the course of the year, total abundances of the sub-ice fauna showed a steep increase from
the earliest sampling dates towards the end of winter/beginning of spring reaching maximum numbers then, and a decrease
to minimum numbers in early summer. A second peak occurred in late summer, followed by a decrease towards autumn. This
significant trend was due to the abundances of copepod nauplii and  Oithona similis . Sympagic species were virtually
absent during winter, and increased significantly in spring and early and late summer. A factor analysis revealed the
variables ice cover and thickness, water temperature and salinity, as well as chl  a  as the major controlling factors
for the seasonal patterns in different groups and species of the sub-ice fauna. Because of the special environmental
conditions in the sub-ice habitat, and the unique species composition 
characterized by small taxa, young stages, and sympagic species, the seasonal dynamics of the Arctic sub-ice fauna
differ substantially from those of the epipelagic zooplankton community in the Arctic Ocean.},
    author = {Werner, Iris},
    citeulike-article-id = {6655690},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.dsr.2005.11.001},
    doi = {10.1016/j.dsr.2005.11.001},
    issn = {09670637},
    journal = {Deep Sea Research Part I: Oceanographic Research Papers},
    month = feb,
    number = {2},
    pages = {294--309},
    posted-at = {2010-02-11 21:49:22},
    priority = {2},
    title = {Seasonal dynamics of sub-ice fauna below pack ice in the Arctic (Fram Strait)},
    url = {http://dx.doi.org/10.1016/j.dsr.2005.11.001},
    volume = {53},
    year = {2006}
}

@article{citeulike:6655689,
    abstract = {Alterations in sea ice and primary production are expected to have cascading influences on the food web
in high Arctic marine ecosystems. This study spanned four years and examined the spring phytoplankton production bloom
in Disko Bay, West Greenland ({69°N}, {53°W}) (using chlorophyll  a  concentrations as a proxy) under contrasting sea
ice conditions in 2001 and 2003 (heavy sea ice) and 2002 and 2004 (light sea ice). Satellite-based observations of
chlorophyll  a , sea ice and sea surface temperature were used together with in situ depth profiles of chlorophyll  a 
fluorescence collected at 24 sampling stations along the south coast of Disko Island (5–30 km offshore) in May 2003 and
2004. Chlorophyll  a  and sea surface temperatures were also obtained from the Moderate Resolution Imaging
Spectroradiometer ({MODIS}: {EOS}-Terra and {AQUA} satellites) between March 2001 and July 2004. Daily {SMMR}/{SSMI} sea
ice data were obtained in the same years. An empirical regional algorithm was 
developed to calibrate ratios of remotely sensed measurements of water leaving radiance with in situ chlorophyll  a 
fluorescence. The optimal integration depth was 0–4 m, explaining between 70\% and 91\% of the variance. The spatial
development of the phytoplankton bloom showed that the southwestern corner of the study area had the earliest and the
largest spring phytoplankton bloom. The eastern part of Disko Bay, influenced by meltwater outflow from the glaciers,
shows no signs of an early phytoplankton bloom and followed the general pattern of an accelerated bloom soon after the
disappearance of sea ice. In all four years the coupling between phytoplankton and sea ice was bounded by average open
water between 50\% and 80\%, likely due to the combined availability of light and stable open water. The daily
incremental growth in both mean chlorophyll  a  density (chlorophyll  a  per volume water, μg l −1 ) and abundance
(density of chlorophyll  a  extrapolated to ice free areas, tons) estimated by linear 
regression (chlorophyll  a  vs. day) between 1 April and 15 May was highest in 2002 and 2004 (light ice years) and
lowest in 2001 and 2003 (heavy ice years). In years with late sea ice retreat the chlorophyll  a  attained only slightly
lower densities than in years with early sea ice retreat. However, the abundance of chlorophyll  a  in light ice years
was considerably larger than in heavy ice years, and there was an obvious effect of more open water for light-induced
stimulation of primary production. This observation demonstrates the importance of estimating chlorophyll  a  abundance
rather than density in sea ice covered areas. This study also presents the first regional calibration of {MODIS}
chlorophyll  a  data for Arctic waters.},
    author = {Heidejorgensen, M. and Laidre, K. and Logsdon, M. and Nielsen, T.},
    citeulike-article-id = {6655689},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.pocean.2007.01.006},
    doi = {10.1016/j.pocean.2007.01.006},
    issn = {00796611},
    journal = {Progress In Oceanography},
    month = apr,
    number = {1},
    pages = {79--95},
    posted-at = {2010-02-11 21:47:21},
    priority = {2},
    title = {Springtime coupling between chlorophyll a, sea ice and sea surface temperature in Disko Bay, West
Greenland},
    url = {http://dx.doi.org/10.1016/j.pocean.2007.01.006},
    volume = {73},
    year = {2007}
}

@article{citeulike:6655688,
    abstract = {A rise in global temperatures could potentially lead to less ice in the Arctic, including a reduction in
the ice-covered period. The consequence of a changing ice cover on the food web structure and production in Disko Bay,
Western Greenland, is analysed through application of a dynamical model for the planktonic food web. The model is
successfully calibrated and tested for sensitivity, using a detailed data set for 1996–1997. Model scenarios are (1)
extended ice cover and (2) no ice. These scenarios are compared to model runs with measured ice cover in two normal
years. In the extended ice scenario, assuming unchanged copepod behaviour, copepods are starving or feeding in the
ice/water interface from the time they ascend to the surface layer from over-wintering depths until the ice break-up in
June. The total annual primary production reaches the same level as it does in the average year, but copepod ingestion
and, as a consequence, vertical carbon export is reduced by app. 40\%. In the ice-
free situation, an early diatom bloom is initiated by stratification of the water in March, before the copepods ascend.
The diatom bloom is grazed upon by protozooplankton, which reach a high biomass before the copepods ascend in April.
Annual primary production increases by 52\% while copepod ingestion and vertical loss of carbon is reduced by 57\%. This
study illustrates how a change in the ice cover in Arctic areas can potentially create a mismatch between spring primary
production and copepod grazers. The result may be a planktonic food web dominated by protozooplankton, resulting in
lower export of organic material out of the photic zone despite increased primary productivity, or alternatively lead to
changes in species composition or behaviour.},
    author = {Hansen, A. and Nielsen, T. and Levinsen, H. and Madsen, S. and Thingstad, T. and Hansen, B.},
    citeulike-article-id = {6655688},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0967-0637(02)00133-4},
    doi = {10.1016/s0967-0637(02)00133-4},
    issn = {09670637},
    journal = {Deep Sea Research Part I: Oceanographic Research Papers},
    month = jan,
    number = {1},
    pages = {171--187},
    posted-at = {2010-02-11 21:45:36},
    priority = {2},
    title = {Impact of changing ice cover on pelagic productivity and food web structure in Disko Bay, West Greenland: a
dynamic model approach},
    url = {http://dx.doi.org/10.1016/s0967-0637(02)00133-4},
    volume = {50},
    year = {2003}
}

@article{citeulike:6655687,
    abstract = {The contribution from small and large cells to biomass and primary production was investigated during
three cruises to the marginal ice zone in the northern Barents Sea in 2003, 2004 and 2005. Chlorophyll  a  biomass and
primary production were size-fractionated at 10 μm. Particulate primary production was measured using  14 C and 24 h  in
situ  incubations. Twelve stations were successfully sampled and the stations were grouped into three different stages
of a phytoplankton bloom. No pre- or post-bloom situations were observed. The highest integrated chl  a  biomass and
primary production were 588 mg chl  a  m −2  and 1475 mg C m −2  d −1  measured during peak bloom situations in May
2005. In the early and late bloom groups the chl  a  biomass and primary production were dominated by small cells, while
large cells dominated in the peak bloom group. Most of the carbon was produced during the peak bloom dominated by large
cells. When seen over the stations that were size-fractionated the small 
cells contributed with 46\% of the total carbon production (large+small cells). The importance of small cells in the
carbon production is emphasized and small cells should not be neglected during phytoplankton blooms in marginal ice
zones.},
    author = {Hodal, H. and Kristiansen, S.},
    citeulike-article-id = {6655687},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.dsr2.2008.05.012},
    doi = {10.1016/j.dsr2.2008.05.012},
    issn = {09670645},
    journal = {Deep Sea Research Part II: Topical Studies in Oceanography},
    month = oct,
    number = {20-21},
    pages = {2176--2185},
    posted-at = {2010-02-11 21:42:14},
    priority = {2},
    title = {The importance of small-celled phytoplankton in spring blooms at the marginal ice zone in the northern
Barents Sea},
    url = {http://dx.doi.org/10.1016/j.dsr2.2008.05.012},
    volume = {55},
    year = {2008}
}

@article{citeulike:6655683,
    abstract = {The findings of a cruise to study the phytoplankton bloom dynamics associated with the marginal ice zone
({MIZ}) in the Bellingshausen Sea during Austral spring ({November-December}) 1992 are reported. Biomass and rate
process measurements were carried out at stations located in the ice, ice edge and open water along the {85°W} meridian
in order to establish the productivity of the microalgae associated with sea-ice and in the water column. In addition, a
series of transects along {85°W} from sea-ice to open water conditions enabled an assessment of the development of
phytoplankton populations. Low phytoplankton biomass and production were noted at ice-covered and ice-edge stations and
in the open water close to the ice edge. Observations from the transects indicated no development of a classical ice
edge bloom despite evidence that sea-ice had retreated more than 100 km during the study period. Survey data along the
{85°W} line revealed a region of high chlorophyll, centred on {67.5°S}, 
which was initially observed during brash ice conditions. This feature, which remained geographically consistent,
persisted for at least 25 days and was thought to be associated with a frontal region. Water column primary production (
14 C) in this high chlorophyll region was ca 0.8 g C m −2  day − , more than 8 times higher than noted in the {MIZ}.
Phytoplankton photosynthetic characteristics within this region indicated that cells were adapted to a low light regime.
A critical depth of 80 m, estimated directly from oxygen flux measurements, was sufficient to permit the initiation and
net growth of phytoplankton standing stocks in a mixed layer of  ca  70 m. A modelling approach using  14 C observations
suggested that phytoplankton growth was less than the sum of the algal loss terms within this feature. An advective
supply of cells therefore would be required to sustain the observed high and constant algal biomass. In addition,
although this high chlorophyll feature was initially observed during brash-ice 
conditions, the available data suggest that it was initiated under open water conditions.},
    author = {Boyd, P.},
    citeulike-article-id = {6655683},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0967-0645(95)00070-7},
    doi = {10.1016/0967-0645(95)00070-7},
    issn = {09670645},
    journal = {Deep Sea Research Part II:  Topical Studies in Oceanography},
    number = {4-5},
    pages = {1177--1200},
    posted-at = {2010-02-11 21:39:00},
    priority = {2},
    title = {[duplicate] Water column and sea-ice primary production during Austral spring in the Bellingshausen Sea},
    url = {http://dx.doi.org/10.1016/0967-0645(95)00070-7},
    volume = {42},
    year = {1995}
}

@article{citeulike:6655681,
    abstract = {In shelf waters of the western Antarctic Peninsula ({wAP}), with abundant macro- and micronutrients,
water-column stability has been suggested as the main factor controlling primary production; freshwater input from
sea-ice melting stabilizes the upper water column by forming a shallow summer mixed layer. Retreating sea ice in the
spring and summer thus defines the area of influence, the sea-ice zone ({SIZ}) and the marginal ice zone ({MIZ}). A
12-year time series (1995–2006) was analyzed to address two main questions: (1) what are the spatial and temporal
patterns in primary production; and (2) to what extent and in what ways is primary production related to sea-ice
dynamics. Data were collected on cruises performed during January of each year, at the height of the growth season,
within the region bounded by {64°S} and {64°W} to the north and {68°S} and {66°W} to the south. Average daily integrated
primary production varied by an order of magnitude, from  250 to  1100 mg C m −2  d −1 , with 
an average cruise primary production of 745 mg C m −2  d −1 . A strong onshore–offshore gradient was evident along the
shelf with higher production observed inshore. Inter-annual regional production varied by a factor of 7: maximum rates
were measured in 2006 (1788 mg C m −2  d −1 ) and minimum in 1999 (248 mg C m −2  d −1 ). The results support the
hypothesis that primary production in the {wAP} shelf is related to sea-ice dynamics. To first order, shallower summer
mixed-layer depths in the shelf correlated with late sea retreat and primary production. Principal component analysis
showed that high primary production in January was associated with enhanced shelf production toward the coast and in the
south, explaining 63\% of the variability in space and time. This first mode captured the inter-annual variability in
regional production. Temporal variability in primary production (time series of anomalies defined for each location)
showed spatial dependence: higher primary production correlated with shallow 
mixed-layer depths only at mid-shelf; in coastal and offshore waters, primary production correlated with deeper mixed
layers. Thus, coastal primary production can show a non-linear relationship with summer mixed layers. Under conditions
of large biomass (>20 mg chl  a  m −3 ) and shallow mixed-layer depth (e.g., 5 m) phytoplankton production becomes light
limited. This limitation is reduced with a deepening of the summer mixed layer (e.g., 20 m). Dominance of diatoms and
the ability to adapt and photosynthesize at higher light levels characterized the large phytoplankton blooms. No
significant regional trend in primary production was detected within the 12-year series. We conclude that the regional
average primary production on the {wAP} shelf is associated with shallow summer mixed layers in conjunction with late
sea-ice retreat. An opposite relationship is observed for the highest production rates in coastal waters, associated
with large biomass, where a deepening of the summer mixed layer relieves light 
limitation.},
    author = {Vernet, M. and Martinson, D. and Iannuzzi, R. and Stammerjohn, S. and Kozlowski, W. and Sines, K. and
Smith, R. and Garibotti, I.},
    citeulike-article-id = {6655681},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.dsr2.2008.05.021},
    doi = {10.1016/j.dsr2.2008.05.021},
    issn = {09670645},
    journal = {Deep Sea Research Part II: Topical Studies in Oceanography},
    month = sep,
    number = {18-19},
    pages = {2068--2085},
    posted-at = {2010-02-11 21:37:39},
    priority = {2},
    title = {Primary production within the sea-ice zone west of the Antarctic Peninsula: {I—Sea} ice, summer mixed
layer, and irradiance},
    url = {http://dx.doi.org/10.1016/j.dsr2.2008.05.021},
    volume = {55},
    year = {2008}
}

@article{citeulike:6655679,
    abstract = {The findings of a cruise to study the phytoplankton bloom dynamics associated with the marginal ice zone
({MIZ}) in the Bellingshausen Sea during Austral spring ({November-December}) 1992 are reported. Biomass and rate
process measurements were carried out at stations located in the ice, ice edge and open water along the {85°W} meridian
in order to establish the productivity of the microalgae associated with sea-ice and in the water column. In addition, a
series of transects along {85°W} from sea-ice to open water conditions enabled an assessment of the development of
phytoplankton populations. Low phytoplankton biomass and production were noted at ice-covered and ice-edge stations and
in the open water close to the ice edge. Observations from the transects indicated no development of a classical ice
edge bloom despite evidence that sea-ice had retreated more than 100 km during the study period. Survey data along the
{85°W} line revealed a region of high chlorophyll, centred on {67.5°S}, 
which was initially observed during brash ice conditions. This feature, which remained geographically consistent,
persisted for at least 25 days and was thought to be associated with a frontal region. Water column primary production (
14 C) in this high chlorophyll region was ca 0.8 g C m −2  day − , more than 8 times higher than noted in the {MIZ}.
Phytoplankton photosynthetic characteristics within this region indicated that cells were adapted to a low light regime.
A critical depth of 80 m, estimated directly from oxygen flux measurements, was sufficient to permit the initiation and
net growth of phytoplankton standing stocks in a mixed layer of  ca  70 m. A modelling approach using  14 C observations
suggested that phytoplankton growth was less than the sum of the algal loss terms within this feature. An advective
supply of cells therefore would be required to sustain the observed high and constant algal biomass. In addition,
although this high chlorophyll feature was initially observed during brash-ice 
conditions, the available data suggest that it was initiated under open water conditions.},
    author = {Boyd, P.},
    citeulike-article-id = {6655679},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0967-0645(95)00070-7},
    doi = {10.1016/0967-0645(95)00070-7},
    issn = {09670645},
    journal = {Deep Sea Research Part II:  Topical Studies in Oceanography},
    number = {4-5},
    pages = {1177--1200},
    posted-at = {2010-02-11 21:35:41},
    priority = {2},
    title = {Water column and sea-ice primary production during Austral spring in the Bellingshausen Sea},
    url = {http://dx.doi.org/10.1016/0967-0645(95)00070-7},
    volume = {42},
    year = {1995}
}

@article{citeulike:6655677,
    author = {Malone, T.},
    citeulike-article-id = {6655677},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0198-0149(87)90127-0},
    doi = {10.1016/0198-0149(87)90127-0},
    issn = {01980149},
    journal = {Deep Sea Research Part A. Oceanographic Research Papers},
    month = jan,
    number = {1},
    pages = {139},
    posted-at = {2010-02-11 21:33:47},
    priority = {2},
    title = {Primary production of the ocean water column as a function of surface light intensity},
    url = {http://dx.doi.org/10.1016/0198-0149(87)90127-0},
    volume = {34},
    year = {1987}
}

@inproceedings{citeulike:6544724,
    abstract = {Libre (free, open source) software is one of the paradigmatic cases where heavy use of telematic tools
and userdriven software development are key points. This paper proposes a methodology for measuring and analyzing
remotely big libre software projects using publicly-available data from their version control repositories. By means of
a tool called {CVSAnalY} that has been implemented following this methodology, measurements and analyses can be made in
an automatic and non-intrusive way, providing real-time and historical data about the project and its contributors.},
    author = {Robles, Gregorio and Koch, Stefan and Gonz\'{a}lez-Barahona, Jes\'{u}s M. and Carlos, Juan},
    booktitle = {In Proceedings of the 2nd ICSE Workshop on Remote Analysis and Measurement of Software Systems (RAMSS},
    citeulike-article-id = {6544724},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.58.6959},
    keywords = {thesis-phd},
    pages = {51--55},
    posted-at = {2010-01-15 18:23:15},
    priority = {2},
    title = {Remote Analysis and Measurement of Libre Software Systems By Means of the {CVSAnalY} tool},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.58.6959},
    year = {2004}
}

@proceedings{citeulike:6544685,
    abstract = {In order to predict the number of changes in the following months for the project Eclipse, we have
applied a statistical (non-explanatory) model based on time series analysis. We have obtained the monthly number of
changes in the {CVS} repository of Eclipse, using the {CVSAnalY} tool. The input to our model was the filtered series of
the number of changes per month, and the output was the number of changes per month for the next three months. Then we
aggregated the results of the three months to obtain the total number of changes in the given period in the challenge.},
    author = {Herraiz, I. and Gonzalez-Barahona, J. M. and Robles, G.},
    citeulike-article-id = {6544685},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/msr.2007.10},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228669},
    day = {26},
    doi = {10.1109/msr.2007.10},
    journal = {Mining Software Repositories, 2007. ICSE Workshops MSR '07. Fourth International Workshop on},
    keywords = {thesis-phd},
    month = may,
    pages = {32},
    posted-at = {2010-01-15 17:25:22},
    priority = {2},
    title = {Forecasting the Number of Changes in Eclipse Using Time Series Analysis},
    url = {http://dx.doi.org/10.1109/msr.2007.10},
    year = {2007}
}

@proceedings{citeulike:6350422,
    abstract = {We present the results of a study in which author entropy was used to characterize author contributions
per file. Our analysis reveals three patterns: banding in the data, uneven distribution of data across bands, and file
size dependent distributions within bands. Our results suggest that when two authors contribute to a file, large files
are more likely to have a dominant author than smaller files.},
    author = {Casebolt, J. R. and Krein, J. L. and MacLean, A. C. and Knutson, C. D. and Delorey, D. P.},
    booktitle = {Mining Software Repositories, 2009. MSR '09. 6th IEEE International Working Conference on},
    citeulike-article-id = {6350422},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/msr.2009.5069484},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5069484},
    day = {17},
    doi = {10.1109/msr.2009.5069484},
    keywords = {msr},
    month = may,
    pages = {91--94},
    posted-at = {2009-12-10 18:18:02},
    priority = {2},
    title = {Author entropy vs. file size in the gnome suite of applications},
    url = {http://dx.doi.org/10.1109/msr.2009.5069484},
    year = {2009}
}

@article{citeulike:3837636,
    abstract = {Our variant ascertainment algorithm, {VAAL}, uses massively parallel {DNA} sequence data to identify
differences between bacterial genomes with high sensitivity and specificity. {VAAL} detected 98\% of differences
(including large insertion-deletions) between pairs of strains from three species while calling no false positives.
{VAAL} also pinpointed a single mutation between Vibrio cholerae genomes, identifying an antibiotic's site of action by
identifying sequence differences between drug-sensitive strains and drug-resistant derivatives.},
    author = {Nusbaum, Chad and Ohsumi, Toshiro K. and Gomez, James and Aquadro, John and Victor, Thomas C. and Warren,
Robert M. and Hung, Deborah T. and Birren, Bruce W. and Lander, Eric S. and Jaffe, David B.},
    citeulike-article-id = {3837636},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nmeth.1286},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nmeth.1286},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/19079253},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=19079253},
    day = {14},
    doi = {10.1038/nmeth.1286},
    issn = {1548-7091},
    journal = {Nature Methods},
    keywords = {short\_reads},
    month = dec,
    number = {1},
    pages = {67--69},
    pmid = {19079253},
    posted-at = {2009-11-23 12:49:54},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {Sensitive, specific polymorphism discovery in bacteria using massively parallel sequencing},
    url = {http://dx.doi.org/10.1038/nmeth.1286},
    volume = {6},
    year = {2008}
}

@article{citeulike:3158518,
    abstract = {An international, peer-reviewed genome sciences journal featuring outstanding original research that
offers novel insights into the biology of all organisms},
    address = {Sanger Institute;},
    author = {Li, Heng and Ruan, Jue and Durbin, Richard},
    citeulike-article-id = {3158518},
    citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.078212.108},
    citeulike-linkout-1 = {http://genome.cshlp.org/content/18/11/1851.abstract},
    citeulike-linkout-2 = {http://genome.cshlp.org/content/18/11/1851.full.pdf},
    citeulike-linkout-3 = {http://genome.cshlp.org/cgi/content/abstract/18/11/1851},
    citeulike-linkout-4 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2577856/},
    citeulike-linkout-5 = {http://view.ncbi.nlm.nih.gov/pubmed/18714091},
    citeulike-linkout-6 = {http://www.hubmed.org/display.cgi?uids=18714091},
    day = {01},
    doi = {10.1101/gr.078212.108},
    issn = {1549-5469},
    journal = {Genome Research},
    keywords = {short\_reads},
    month = nov,
    number = {11},
    pages = {1851--1858},
    pmcid = {PMC2577856},
    pmid = {18714091},
    posted-at = {2009-11-23 12:48:46},
    priority = {2},
    publisher = {Cold Spring Harbor Laboratory Press},
    title = {Mapping short {DNA} sequencing reads and calling variants using mapping quality scores},
    url = {http://dx.doi.org/10.1101/gr.078212.108},
    volume = {18},
    year = {2008}
}

@article{citeulike:5801584,
    abstract = {
                Genome resequencing with short reads generally relies on alignments against a single reference.
{GenomeMapper} supports simultaneous mapping of short reads against multiple genomes by integrating related genomes
(e.g., individuals of the same species) into a single graph structure. It constitutes the first approach for handling
multiple references and introduces representations for alignments against complex structures. Demonstrated benefits
include access to polymorphisms that cannot be identified by alignments against the reference alone. Download
{GenomeMapper} at http://1001genomes.org.
            },
    author = {Schneeberger, Korbinian and Hagmann, J\"{o}rg and Ossowski, Stephan and Warthmann, Norman and Gesing,
Sandra and Kohlbacher, Oliver and Weigel, Detlef},
    citeulike-article-id = {5801584},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/gb-2009-10-9-r98},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2768987/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/19761611},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=19761611},
    day = {17},
    doi = {10.1186/gb-2009-10-9-r98},
    issn = {1465-6914},
    journal = {Genome biology},
    keywords = {short\_reads},
    month = sep,
    number = {9},
    pages = {R98+},
    pmcid = {PMC2768987},
    pmid = {19761611},
    posted-at = {2009-11-23 12:46:43},
    priority = {2},
    title = {Simultaneous alignment of short reads against multiple genomes.},
    url = {http://dx.doi.org/10.1186/gb-2009-10-9-r98},
    volume = {10},
    year = {2009}
}

@article{citeulike:3658666,
    abstract = {
                Whole-genome hybridization studies have suggested that the nuclear genomes of accessions (natural
strains) of Arabidopsis thaliana can differ by several percent of their sequence. To examine this variation, and as a
first step in the 1001 Genomes Project for this species, we produced 15- to 25-fold coverage in Illumina
sequencing-by-synthesis ({SBS}) reads for the reference accession, Col-0, and two divergent strains, Bur-0 and Tsu-1. We
aligned reads to the reference genome sequence to assess data quality metrics and to detect polymorphisms. Alignments
revealed 823,325 unique single nucleotide polymorphisms ({SNPs}) and 79,961 unique 1- to 3-bp indels in the divergent
accessions at a specificity of >99\%, and over 2000 potential errors in the reference genome sequence. We also
identified >3.4 Mb of the Bur-0 and Tsu-1 genomes as being either extremely dissimilar, deleted, or duplicated relative
to the reference genome. To obtain sequences for these regions, we incorporated the Velvet 
assembler into a targeted de novo assembly method. This approach yielded 10,921 high-confidence contigs that were
anchored to flanking sequences and harbored indels as large as 641 bp. Our methods are broadly applicable for
polymorphism discovery in moderate to large genomes even at highly diverged loci, and we established by subsampling the
Illumina {SBS} coverage depth required to inform a broad range of functional and evolutionary studies. Our pipeline for
aligning reads and predicting {SNPs} and indels, {SHORE}, is available for download at http://1001genomes.org.
            },
    author = {Ossowski, Stephan and Schneeberger, Korbinian and Clark, Richard M. and Lanz, Christa and Warthmann,
Norman and Weigel, Detlef},
    citeulike-article-id = {3658666},
    citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.080200.108},
    citeulike-linkout-1 = {http://genome.cshlp.org/content/18/12/2024.abstract},
    citeulike-linkout-2 = {http://genome.cshlp.org/content/18/12/2024.full.pdf},
    citeulike-linkout-3 = {http://genome.cshlp.org/cgi/content/abstract/18/12/2024},
    citeulike-linkout-4 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2593571/},
    citeulike-linkout-5 = {http://view.ncbi.nlm.nih.gov/pubmed/18818371},
    citeulike-linkout-6 = {http://www.hubmed.org/display.cgi?uids=18818371},
    day = {1},
    doi = {10.1101/gr.080200.108},
    issn = {1088-9051},
    journal = {Genome research},
    keywords = {short\_reads},
    month = dec,
    number = {12},
    pages = {2024--2033},
    pmcid = {PMC2593571},
    pmid = {18818371},
    posted-at = {2009-11-23 12:45:32},
    priority = {2},
    title = {Sequencing of natural strains of Arabidopsis thaliana with short reads.},
    url = {http://dx.doi.org/10.1101/gr.080200.108},
    volume = {18},
    year = {2008}
}

@article{citeulike:2289016,
    abstract = {Massively parallel sequencing instruments enable rapid and inexpensive {DNA} sequence data production.
Because these instruments are new, their data require characterization with respect to accuracy and utility. To address
this, we sequenced a Caernohabditis elegans N2 Bristol strain isolate using the Solexa Sequence Analyzer, and compared
the reads to the reference genome to characterize the data and to evaluate coverage and representation. Massively
parallel sequencing facilitates strain-to-reference comparison for genome-wide sequence variant discovery. Owing to the
short-read-length sequences produced, we developed a revised approach to determine the regions of the genome to which
short reads could be uniquely mapped. We then aligned Solexa reads from C. elegans strain {CB4858} to the reference, and
screened for single-nucleotide polymorphisms ({SNPs}) and small indels. This study demonstrates the utility of massively
parallel short read sequencing for whole genome resequencing and for 
accurate discovery of genome-wide polymorphisms.},
    address = {[1] Washington University School of Medicine, Department of Genetics and Genome Sequencing Center, 4444
Forest Park Blvd., St. Louis, Missouri 63108, USA. [2] These authors contributed equally to this work.},
    author = {Hillier, LaDeana W. and Marth, Gabor T. and Quinlan, Aaron R. and Dooling, David and Fewell, Ginger and
Barnett, Derek and Fox, Paul and Glasscock, Jarret I. and Hickenbotham, Matthew and Huang, Weichun and Magrini, Vincent
J. and Richt, Ryan J. and Sander, Sacha N. and Stewart, Donald A. and Stromberg, Michael and Tsung, Eric F. and Wylie,
Todd and Schedl, Tim and Wilson, Richard K. and Mardis, Elaine R.},
    citeulike-article-id = {2289016},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nmeth.1179},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nmeth.1179},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18204455},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18204455},
    citeulike-linkout-4 = {http://www.wormbase.org/db/misc/paper?name=WBPaper00031443},
    day = {20},
    doi = {10.1038/nmeth.1179},
    issn = {1548-7091},
    journal = {Nature Methods},
    keywords = {short\_reads},
    month = jan,
    number = {2},
    pages = {183--188},
    pmid = {18204455},
    posted-at = {2009-11-23 12:43:51},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {Whole-genome sequencing and variant discovery in C. elegans},
    url = {http://dx.doi.org/10.1038/nmeth.1179},
    volume = {5},
    year = {2008}
}

@incollection{citeulike:5973585,
    abstract = {The problem of discovering frequent subgraphs of graph data can be solved by constructing a candidate
set of subgraphs first, and then, identifying within this candidate set those subgraphs that meet the frequent subgraph
requirement. In Apriori-based graph mining, to determine candidate subgraphs from a huge number of generated adjacency
matrices is usually the dominating factor for the overall graph mining performance since it requires to perform many
graph isomorphism tests. To address this issue, we develop an effective algorithm for the candidate set generation. It
is a hash-based algorithm and was confirmed effective through experiments on both real-world and synthetic graph data.},
    author = {Nguyen, Phu C. and Washio, Takashi and Ohara, Kouzou and Motoda, Hiroshi},
    citeulike-article-id = {5973585},
    citeulike-linkout-0 = {http://www.springerlink.com/content/5qq5ctje4akhef2y},
    journal = {Knowledge Discovery in Databases: PKDD 2004},
    keywords = {algorithm, apriori\_algorithm},
    pages = {349--361},
    posted-at = {2009-10-20 11:49:59},
    priority = {2},
    title = {Using a {Hash-Based} Method for {Apriori-Based} Graph Mining},
    url = {http://www.springerlink.com/content/5qq5ctje4akhef2y},
    year = {2004}
}

@proceedings{citeulike:5972696,
    abstract = {Searching for the longest common subsequence (LCS) of biosequences is one of the most important problems
in bioinformatics. A fast algorithm for LCS problem FAST\_LCS is presented. The algorithm first seeks the successors of
the initial identical character pairs according to a successor table to obtain all the identical pairs and their levels.
By tracing back from the identical character pair at the highest level, strong pruning rules are developed. For two
sequences X and Y with length n and m, respectively, the memory required for FAST\_LCS is max{4*(n+1)+4*(m+1), L}, where
L is the number of identical character pairs. The time complexity of parallel computing is O(|LCS(X,Y)|), where
|LCS(X,Y)| is the length of the LCS of X, Y. Experimental result on the gene sequences of tigr database using MPP
parallel computer Shenteng 1800 shows that our algorithm can find the exact solutions significantly more efficiently
than other LCS algorithms},
    author = {Liu, Wei},
    citeulike-article-id = {5972696},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/imsccs.2006.6},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4673521},
    day = {17},
    doi = {10.1109/imsccs.2006.6},
    journal = {Computer and Computational Sciences, 2006. IMSCCS '06. First International Multi-Symposiums on},
    keywords = {algorithm, lcs},
    month = nov,
    pages = {27--34},
    posted-at = {2009-10-19 23:04:25},
    priority = {2},
    title = {A Fast Parallel Longest Common Subsequence Algorithm Based on Pruning Rules},
    url = {http://dx.doi.org/10.1109/imsccs.2006.6},
    volume = {1},
    year = {2008}
}

@proceedings{citeulike:5972687,
    abstract = {Apriori is one of the most important algorithms used in rule association mining. In this paper, we first
discuss the limitations of the Apriori algorithm and then propose an enhancement for improving its efficiency. The
improved algorithm is based on the combination of forward scan and reverse scan of a given database. If certain
conditions are satisfied, the improved algorithm can greatly reduce the scanning times required for the discovery of
candidate itemsets. Theoretical proof and analysis are given for the rationality of our algorithm. A simulation instance
is given in order to show the advantages of this algorithm compared with Apriori.},
    author = {Sun, Dongme and Teng, Shaohua and Zhang, Wei and Zhu, Haibin},
    citeulike-article-id = {5972687},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/coginf.2007.4341914},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4341914},
    day = {08},
    doi = {10.1109/coginf.2007.4341914},
    journal = {Cognitive Informatics, 6th IEEE International Conference on},
    keywords = {algorithm, apriori\_algorithm},
    month = oct,
    pages = {385--390},
    posted-at = {2009-10-19 23:00:58},
    priority = {2},
    title = {An Algorithm to Improve the Effectiveness of Apriori},
    url = {http://dx.doi.org/10.1109/coginf.2007.4341914},
    year = {2007}
}

@article{citeulike:5971661,
    abstract = {People evidence significant inaccuracies when predicting their response to many emotional life events.
One unanswered question is whether such affective forecasting errors are due to participants' poor estimation of their
initial emotional reactions (an  initial intensity bias ), poor estimation of the rate at which these emotional
reactions diminish over time (a  decay bias ), or both. The present research used intensive longitudinal procedures to
explore this question in the wake of an upsetting life event: the dissolution of a romantic relationship. Results
revealed that the affective forecasting error is entirely accounted for by an initial intensity bias, with no
contribution by a decay bias. In addition, several moderators of the affective forecasting error emerged: participants
who were more in love with their partners, who thought it was unlikely they would soon enter a new relationship, and who
played less of a role in initiating the breakup made especially inaccurate forecasts.},
    author = {Eastwick, Paul W. and Finkel, Eli J. and Krishnamurti, Tamar and Loewenstein, George},
    citeulike-article-id = {5971661},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jesp.2007.07.001},
    doi = {10.1016/j.jesp.2007.07.001},
    issn = {00221031},
    journal = {Journal of Experimental Social Psychology},
    keywords = {divorce, psychology},
    month = may,
    number = {3},
    pages = {800--807},
    posted-at = {2009-10-19 18:07:41},
    priority = {2},
    title = {Mispredicting distress following romantic breakup: Revealing the time course of the affective forecasting
error☆},
    url = {http://dx.doi.org/10.1016/j.jesp.2007.07.001},
    volume = {44},
    year = {2008}
}

@incollection{citeulike:5956826,
    abstract = {This paper presents an association rule mining system that is capable of handling set-valued attributes.
Our previous research has exposed us to a variety of real-world biological datasets that contain attributes whose values
are sets of elements, instead of just individual elements. However, very few data mining tools accept datasets that
contain these set-valued attributes, and none of them allow the mining of association rules directly from this type of
data. We introduce in this paper two algorithms for mining (classification) association rules directly from set-valued
data and compare their performance. We have implemented a system based on one of these algorithms and have applied it to
a number of biological datasets. We describe here our system and highlight its merits by means of comparing the results
achieved with it and the failed attempts to mine association rules from those datasets using standard tools. Our system
makes the creation of input files containing set-valued data much 
easier, and makes the mining of association rules directly from these data possible.},
    author = {Shoemaker, Christopher and Ruiz, Carolina},
    citeulike-article-id = {5956826},
    citeulike-linkout-0 = {http://www.springerlink.com/content/nt6mb8x3yekhxa8t},
    journal = {Intelligent Data Engineering and Automated Learning},
    keywords = {algorithm, mining\_system},
    pages = {669--676},
    posted-at = {2009-10-17 19:41:14},
    priority = {2},
    title = {Association Rule Mining Algorithms for {Set-Valued} Data},
    url = {http://www.springerlink.com/content/nt6mb8x3yekhxa8t},
    year = {2003}
}

@article{citeulike:2939267,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has
opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Tichy, Walter F.},
    citeulike-article-id = {2939267},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=357404},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/357401.357404},
    doi = {10.1145/357401.357404},
    issn = {0734-2071},
    journal = {ACM Trans. Comput. Syst.},
    keywords = {algorithm},
    month = nov,
    number = {4},
    pages = {309--321},
    posted-at = {2009-10-02 17:07:59},
    priority = {2},
    publisher = {ACM},
    title = {The string-to-string correction problem with block moves},
    url = {http://dx.doi.org/10.1145/357401.357404},
    volume = {2},
    year = {1984}
}

@article{citeulike:878244,
    abstract = {The string-to-string correction problem is to determine the distance between two strings as measured by
the minimum cost sequence of  ” edit operations” needed to change the one string into the other. The edit operations
investigated allow changing one symbol of a string into another single symbol, deleting one symbol from a string, or
inserting a single symbol into a string. An algorithm is presented which solves this problem in time proportional to the
product of the lengths of the two strings. Possible applications are to the problems of automatic spelling correction
and determining the longest subsequence of characters common to two strings.},
    address = {New York, NY, USA},
    author = {Wagner, Robert A. and Fischer, Michael J.},
    citeulike-article-id = {878244},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=321811},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/321796.321811},
    doi = {10.1145/321796.321811},
    issn = {0004-5411},
    journal = {J. ACM},
    keywords = {algorithm},
    month = jan,
    number = {1},
    pages = {168--173},
    posted-at = {2009-10-02 17:07:06},
    priority = {2},
    publisher = {ACM},
    title = {The {String-to-String} Correction Problem},
    url = {http://dx.doi.org/10.1145/321796.321811},
    volume = {21},
    year = {1974}
}

@incollection{citeulike:5868601,
    abstract = {The longest common {subsequence(LCS}) problem is one of the classical and well-studied problems in
computer science. The computation of the {LCS} is a frequent task in {DNA} sequence analysis, and has applications to
genetics and molecular biology. In this paper we define new variants, introducing the notion of gap-constraints in {LCS}
problem and present efficient algorithms to solve them.},
    author = {Rahman, M. and Iliopoulos, Costas},
    citeulike-article-id = {5868601},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11940128\_41},
    citeulike-linkout-1 = {http://www.springerlink.com/content/t2p026348775823r},
    doi = {10.1007/11940128\_41},
    journal = {Algorithms and Computation},
    keywords = {algorithm},
    pages = {399--408},
    posted-at = {2009-10-01 16:29:08},
    priority = {2},
    title = {Algorithms for Computing Variants of the Longest Common Subsequence Problem},
    url = {http://dx.doi.org/10.1007/11940128\_41},
    year = {2006}
}

@inproceedings{citeulike:3025832,
    abstract = {Efficient and accurate similarity searching for a large amount of time series data set is an important
but non-trivial problem. Many dimensionality reduction techniques have been proposed for effective representation of
time series data in order to realize such similarity searching, including Singular Value Decomposition ({SVD}), the
Discrete Fourier transform ({DFT}), the Adaptive Piecewise Constant Approximation ({APCA}), and the recently proposed
Symbolic Aggregate Approximation ({SAX}).},
    address = {Washington, DC, USA},
    author = {Lkhagva, Battuguldur and Suzuki, Yu and Kawagoe, Kyoji},
    booktitle = {ICDEW '06: Proceedings of the 22nd International Conference on Data Engineering Workshops},
    citeulike-article-id = {3025832},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1130158},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/ICDEW.2006.99},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/icdew.2006.99},
    doi = {10.1109/icdew.2006.99},
    isbn = {0-7695-2571-7},
    journal = {icdew},
    keywords = {dissertation, litreview, sax},
    pages = {115+},
    posted-at = {2009-08-29 16:29:55},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {New Time Series Data Representation {ESAX} for Financial Applications},
    url = {http://dx.doi.org/10.1109/icdew.2006.99},
    volume = {0},
    year = {2006}
}

@book{citeulike:5410331,
    abstract = {"It premieres the most adept researchers in the field who have bravely and
soundly followed mixed methodology approaches."

-{NACADA} (National {ACademic} {ADvising} Association)


In recent years, researchers have begun to combine quantitative and
qualitative approaches within single study research designs. As such, the
literature on mixed methods research has grown at a rapid pace. While more
methodological books addressing mixed methods are becoming available, the
foundational writings of this field are still scattered across diverse
disciplines and their wide range of publications outlets, leaving students and
researchers at a disadvantage to find the exemplary or model studies to help
them understand how to conduct their own mixed methods research.


In light of the dispersed nature of the mixed methods literature, **The Mixed
Methods Reader **editors have organized a collection of key methodological
mixed methods discussions and exemplar mixed methods research studies in one
easy-to-access location. This integrative collection draws from the
international literature appearing across diverse research disciplines over
the past thirty years. **The Mixed Methods Reader **is divided into two parts:
Part I – Methodological Selections and Part {II} – Exemplar Research Studies.
Part I includes a collection of 14 foundational writings from the mixed
methods research literature. These readings convey the overall development and
evolution of mixed methods research and address essential topics for
researchers new to the field of mixed methods research. These topics include
its foundations; design types; implementation issues such as sampling, data
analysis, and validity; rhetorical devices for reporting mixed methods
studies; and critiques about the current thinking in the field. Part {II}
includes 9 exemplar mixed methods research studies drawn from a range of
disciplines and international scholars. The studies were intentionally
selected to illustrate four major types of mixed methods designs. As with the
methodological chapters, the editors organize the exemplar research studies so
that the reader can see a natural progression of the different approaches to
conducting mixed methods research.


**The Mixed Methods Reader**, edited by two leading researchers in mixed
methods research, offers students and researchers a rich balance of
foundational works and exemplary studies across a range of disciplines. This
reader is an invaluable primary or supplementary resource for courses that
address mixed methods research.


**Key Features**

  * Each of the 14 foundational readings offers a brief introduction by the
editors, discussing the reading's overall importance to mixed methods research
and explaining what aspect of the research process is addressed.

  * The foundational readings are organized around the research process to
facilitate its use as a text or supplement for research courses emphasizing
mixed methods approaches. They cover research design types and purposes, data
collection, data analysis, reporting of mixed methods studies, and future
directions.

  * Each of the 9 exemplary studies include a brief commentary from the
editors, highlighting the noteworthy features of the article. These exemplary
studies range in discipline and setting yet focus intently on the research
process and the various ways of conducting mixed methods studies.

  * Visual diagrams accompany each exemplary study: These visual diagrams will
convey the overall structure and approach used in each of the studies.

  * Discussion questions accompanying each selection further call attention to
the key points and help a student or individual researcher to tie together the
core concepts presented in the commentaries and articles.},
    citeulike-article-id = {5410331},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1412951453},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/1412951453},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/1412951453},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/1412951453},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/1412951453/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1412951453},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/1412951453},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN1412951453},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=1412951453\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/1412951453},
    day = {10},
    howpublished = {Paperback},
    isbn = {1412951453},
    keywords = {proposal},
    month = dec,
    posted-at = {2009-08-11 01:10:27},
    priority = {2},
    publisher = {Sage Publications, Inc},
    title = {The Mixed Methods Reader},
    url = {http://www.worldcat.org/isbn/1412951453},
    year = {2007}
}

@book{citeulike:447180,
    abstract = {Once again, editors Norman K. Denzin and Yvonna S Lincoln have put together a
volume that represents the state of the art for the theory and practice of
qualitative inquiry. Built on the foundation of the landmark first edition,
published in 1994, the second edition is both the bridge and the roadmap to
the territory that lies ahead for researchers across the disciplines.

The Second Edition is a significant revision; in fact, it is virtually a new
work. It features six new chapter topics, including, among others, auto-
ethnography, critical race theory, applied ethnography, queer theory, and
testimonies. Another fifteen chapters are written by new contributors. And
every chapter in the book has been thoroughly revised and updated.

At the beginning of the twenty-first century, it is necessary to re-engage the
promise of qualitative research as a generative form of inquiry. The Second
Edition of the Handbook reveals how the discourses of qualitative research can
be used to imagine and create a free and democratic society. Ground-breaking,
thought-provoking, comprehensive and featuring the contributions of a virtual
"Who's Who" in the human sciences, Handbook of Qualitative Research, Second
Edition is absolutely an essential text for the library of any scholar
interested in the art and science of research.},
    citeulike-article-id = {447180},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0761915125},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0761915125},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0761915125},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0761915125},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0761915125/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0761915125},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0761915125},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0761915125},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0761915125\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0761915125},
    day = {18},
    edition = {2nd},
    howpublished = {Hardcover},
    isbn = {0761915125},
    keywords = {proposal},
    month = mar,
    posted-at = {2009-08-11 01:08:30},
    priority = {2},
    publisher = {Sage Publications, Inc},
    title = {Handbook of Qualitative Research},
    url = {http://www.worldcat.org/isbn/0761915125},
    year = {2000}
}

@incollection{GubaLincoln-CompetingParadigms,
    author = {Guba, Egon G. and Lincoln, Yvonna S.},
    booktitle = {The Landscape of Qualitative Research},
    citeulike-article-id = {5410307},
    citeulike-linkout-0 = {http://www.fosonline.org/MCI/DB/view.cfm?ENID=294},
    comment = {Beschreiben Paradigmen qualitativer sozialforschung: Positivismus, Postpositivismus, Kritische Theorie
und Konstruktivismus. Eventuell relevant, f\"{u}r einen Methodenartikel},
    editor = {Denzin, Norman K. and Lincoln, Yvonna S.},
    keywords = {proposal},
    pages = {195--220},
    posted-at = {2009-08-11 00:31:17},
    priority = {0},
    publisher = {Sage},
    title = {Competing paradigms in qualitative research},
    url = {http://www.fosonline.org/MCI/DB/view.cfm?ENID=294},
    year = {1998}
}

@article{citeulike:2132242,
    abstract = {In recent years evaluators of educational and social programs have expanded their methodological
repertoire with designs that include the use of both qualitative and quantitative methods. Such practice, however, needs
to be grounded in a theory that can meaningfully guide the design and implementation of mixed-method evaluations. In
this study, a mixed-method conceptual framework was developed from the theoretical literature and then refined through
an analysis of 57 empirical mixed-method evaluations. Five purposes for mixed-method evaluations are identified in this
conceptual framework: triangulation, complementarity, development, initiation, and expansion. For each of the five
purposes, a recommended design is also presented in terms of seven relevant design characteristics. These design
elements encompass issues about methods, the phenomena under investigation, paradigmatic framework, and criteria for
implementation. In the empirical review, common misuse of the term triangulation was 
apparent in evaluations that stated such a purpose but did not employ an appropriate design. In addition, relatively few
evaluations in this review integrated the different method types at the level of data analysis. Strategies for
integrated data analysis are among the issues identified as priorities for further mixed-method work.},
    author = {Greene, Jennifer C. and Caracelli, Valerie J. and Graham, Wendy F.},
    citeulike-article-id = {2132242},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/1163620},
    citeulike-linkout-1 = {http://www.jstor.org/stable/1163620},
    doi = {10.2307/1163620},
    issn = {01623737},
    journal = {Educational Evaluation and Policy Analysis},
    keywords = {proposal},
    number = {3},
    pages = {255--274},
    posted-at = {2009-08-11 00:18:11},
    priority = {2},
    publisher = {American Educational Research Association},
    title = {Toward a Conceptual Framework for {Mixed-Method} Evaluation Designs},
    url = {http://dx.doi.org/10.2307/1163620},
    volume = {11},
    year = {1989}
}

@article{citeulike:5410299,
    abstract = {Four integrative data analysis strategies for mixed-method evaluation designs are derived from and
illustrated by empirical practice: data transformation, typology development, extreme case analysis, and data
consolidation/merging. The appropriateness of these strategies for different kinds of mixed-method intents is then
discussed. Where appropriate, such integrative strategies are encouraged as ways to realize the full potential of
mixed-methodological approaches.},
    author = {Caracelli, Valerie J. and Greene, Jennifer C.},
    citeulike-article-id = {5410299},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/1164421},
    citeulike-linkout-1 = {http://www.jstor.org/stable/1164421},
    doi = {10.2307/1164421},
    issn = {01623737},
    journal = {Educational Evaluation and Policy Analysis},
    keywords = {proposal},
    number = {2},
    pages = {195--207},
    posted-at = {2009-08-11 00:17:52},
    priority = {2},
    publisher = {American Educational Research Association},
    title = {Data Analysis Strategies for {Mixed-Method} Evaluation Designs},
    url = {http://dx.doi.org/10.2307/1164421},
    volume = {15},
    year = {1993}
}

@article{citeulike:5410262,
    abstract = {Health care research includes many studies that combine quantitative and qualitative methods. In this
paper, we revisit the quantitative-qualitative debate and review the arguments for and against using mixed-methods. In
addition, we discuss the implications stemming from our view, that the paradigms upon which the methods are based have a
different view of reality and therefore a different view of the phenomenon under study. Because the two paradigms do not
study the same phenomena, quantitative and qualitative methods cannot be combined for cross-validation or triangulation
purposes. However, they can be combined for complementary purposes. Future standards for mixed-methods research should
clearly reflect this recommendation.},
    author = {Sale, Joanna E. M. and Lohfeld, Lynne H. and Brazil, Kevin},
    citeulike-article-id = {5410262},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a:1014301607592},
    citeulike-linkout-1 = {http://www.springerlink.com/content/reptjmhej4la023r},
    day = {1},
    doi = {10.1023/a:1014301607592},
    issn = {00335177},
    journal = {Quality and Quantity},
    keywords = {proposal},
    month = feb,
    number = {1},
    pages = {43--53},
    posted-at = {2009-08-10 23:57:15},
    priority = {2},
    title = {Revisiting the {Quantitative-Qualitative} Debate: Implications for {Mixed-Methods} Research},
    url = {http://dx.doi.org/10.1023/a:1014301607592},
    volume = {36},
    year = {2002}
}

@book{citeulike:209817,
    abstract = {\_ \_

"Creswell's **Research Design** is an accessible and useful book that
stimulates students through walk through experiences, use of exercises, and
production of actual writing samples. It is a book that models the types of
issues that best suit different approaches and allows students to understand
when to use mixed methods. Furthermore, its focus on theory and paradigms is
done in a way that helps students decode their meaning."

--{MARTHA} {MONTERO}-{SIEBURTH}, {\_University} of Massachusetts, Boston \_

"One of the most formidable challenges of research design is stating your
purpose. Creswell's approach takes the guesswork out of the process."

--{STEVE} {GUERRIERO}, {\_Organization} \& Management, Antioch New England Graduate
School \_

The **Second Edition **of the bestselling **Research Design: Qualitative,
Quantitative, and Mixed Methods Approaches **offers a unique comparison of
three key approaches to inquiry. This comparison begins with preliminary
consideration of knowledge claims for all three approaches, a review of the
literature, and reflections about the importance of writing and ethics in
scholarly inquiry. The book also addresses the key elements of the process of
research: writing an introduction; stating a purpose for the study;
identifying research questions and hypotheses; using theory; defining,
delimiting and stating the significance of the study; and advancing methods
and procedures for data collection and analysis.

**

Key Features:**

  * Provides a clear presentation of how to implement a mixed methods design
in your proposal or plan as well as show how to implement qualitative and
quantitative approaches

  * Presents the ethical issues that may arise in quantitative, qualitative
and mixed methods studies

  * Offers extensive writing tips to help get your research plan started in
the right direction

  * Contains the latest developments in qualitative inquiry-including
advocacy, participatory, and emancipatory approaches

This book is ideal for readers who seek assistance in designing a full
research study or planning a proposal for a scholarly journal article,
dissertation or thesis. The book is an invaluable reference on the basics of
research design as well as an effective text for graduate courses in Research
Methods, Research Design, and related topics. The book serves a broad audience
of social and human scientists in fields of marketing, management, criminal
justice, psychology, sociology, K-12 education, higher and post-secondary
education, nursing, health sciences, urban studies, and family research.

\^{A} 

(20080208)},
    author = {Creswell, John W.},
    citeulike-article-id = {209817},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0761924426},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0761924426},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/49558924},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0761924426},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0761924426},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0761924426/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0761924426},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0761924426},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0761924426},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0761924426\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0761924426},
    day = {15},
    edition = {2nd},
    howpublished = {Paperback},
    isbn = {0761924426},
    keywords = {proposal},
    month = jul,
    posted-at = {2009-08-10 02:25:17},
    priority = {2},
    publisher = {Sage Publications, Inc},
    title = {Research Design: Qualitative, Quantitative, and Mixed Methods Approaches (2nd Edition)},
    url = {http://www.worldcat.org/isbn/0761924426},
    year = {2002}
}

@phdthesis{csdl2-06-05,
    abstract = {Software development is slow, expensive and error prone, often resulting in products with a large number
of defects which cause serious problems in usability, reliability, and performance. To combat this problem, software
measurement provides a systematic and empirically-guided approach to control and improve software development processes
and final products. However, due to the high cost associated with ``metrics collection'' and difficulties in ``metrics
decision-making,'' measurement is not widely adopted by software organizations. This dissertation proposes a novel
metrics-based program called ``software project telemetry'' to address the problems. It uses software sensors to collect
metrics automatically and unobtrusively. It employs a domain-specific language to represent telemetry trends in software
product and process metrics. Project management and process improvement decisions are made by detecting changes in
telemetry trends and comparing trends between different periods of the 
same project. Software project telemetry avoids many problems inherent in traditional metrics models, such as the need
to accumulate a historical project database and ensure that the historical data remain comparable to current and future
projects. The claim of this dissertation is that software project telemetry provides an effective approach to (1)
automated metrics collection and analysis, and (2) in-process, empirically-guided software development process problem
detection and diagnosis. Two empirical studies were carried out to evaluate the claim: one in software engineering
classes, and the other in the Collaborative Software Development Lab. The results suggested that software project
telemetry had acceptably-low metrics collection and analysis overhead, and that it provided decision-making value at
least in the exploratory context of the two studies.},
    author = {Zhang, Qin},
    citeulike-article-id = {5402133},
    citeulike-linkout-0 = {http://csdl.ics.hawaii.edu/techreports/06-05/06-05.pdf},
    keywords = {hackystat, thesis-phd},
    month = dec,
    posted-at = {2009-08-10 00:05:48},
    priority = {2},
    school = {University of Hawaii, Department of Information and Computer Sciences},
    title = {Improving Software Development Process and Product Management with Software Project Telemetry},
    type = {{Ph.D.} Thesis},
    url = {http://csdl.ics.hawaii.edu/techreports/06-05/06-05.pdf},
    year = {2006}
}

@inproceedings{citeulike:5398684,
    abstract = {this paper we propose {DynaMine}, a tool that analyzes source code check-ins to find highly correlated
method calls as well as common bug fixes in order to automatically discover application-specific coding patterns.
Potential patterns discovered through mining are passed to a dynamic analysis tool for validation; finally, the results
of dynamic analysis are presented to the user},
    author = {Livshits, Benjamin and Zimmermann, Thomas},
    booktitle = {In ESEC/FSE},
    citeulike-article-id = {5398684},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.9759},
    keywords = {proposal},
    pages = {296--305},
    posted-at = {2009-08-08 19:57:04},
    priority = {2},
    title = {{DynaMine}: Finding Common Error Patterns by Mining Software Revision Histories},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.9759},
    year = {2005}
}

@inproceedings{citeulike:3929070,
    abstract = {Modern source-control systems, such as Subversion, preserve change-sets of files as atomic commits.
However, the specific ordering information in which files were changed is typically not found in these source-code
repositories. In this paper, a set of heuristics for grouping change-sets (i.e., log-entries) found in source-code
repositories is presented. Given such groups of change-sets, sequences of files that frequently change together are
uncovered. This approach not only gives the (unordered) sets of files but supplements them with (partial temporal)
ordering information. The technique is demonstrated on a subset of {KDE} source-code repository. The results show that
the approach is able to find sequences of changed-files.},
    address = {New York, NY, USA},
    author = {Kagdi, Huzefa and Yusuf, Shehnaaz and Maletic, Jonathan I.},
    booktitle = {Proceedings of the 2006 international workshop on Mining software repositories},
    citeulike-article-id = {3929070},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1137983.1137996},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1137983.1137996},
    doi = {10.1145/1137983.1137996},
    isbn = {1-59593-397-2},
    location = {Shanghai, China},
    pages = {47--53},
    posted-at = {2009-08-08 17:46:58},
    priority = {2},
    publisher = {ACM},
    series = {MSR '06},
    title = {Mining sequences of changed-files from version histories},
    url = {http://dx.doi.org/10.1145/1137983.1137996},
    year = {2006}
}

@electronic{citeulike:5397994,
    abstract = {During the evolution of a large software system there are requirements to extend  the system since the
demands of the customer and the environment grow or  change constantly. Such large systems reach often a high level of
complexity. Any  additional extension would take many changes and adaptations in the system. At  that point it is
necessary to examine the system and its components concerning  the structural behaviour with respect to the need for
restructuring. This master  \&\#039;s thesis evaluates the software evolution of a Telecommunication Switching  System.
All investigations and results are based on release histories of different  decomposition levels and modules stored in a
database. The major goal was to  identify \&\#034;logical coupling\&\#034; among modules and to determine whether or not
this  coupling represents real module dependencies. The author developed a methodology  named \&\#{034;CAESAR}.\&\#034;
It consists of two main processes: 1.) The Change  Sequence Analysis ({
CSA}) represents all changes of a...},
    author = {Univ and Gall, Harald and Hajek, Karin},
    citeulike-article-id = {5397994},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.5101},
    posted-at = {2009-08-08 16:39:49},
    priority = {2},
    title = {Detection of Logical Coupling Based on Product Release History},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.5101},
    year = {1998}
}

@inproceedings{citeulike:4406375,
    abstract = {Files, classes, or methods have frequently been investigated in recent research on co-change. In this
paper, we present a first study at the level of lines. To identify line changes across several versions, we define the
annotation graph which captures how lines evolve over time. The annotation graph provides more fine-grained software
evolution information such as life cycles of each line and related changes: "Whenever a developer changed line 1 of
version.txt she also changed line 25 of Library.java."},
    address = {New York, NY, USA},
    author = {Zimmermann, Thomas and Kim, Sunghun and Zeller, Andreas and Whitehead, E. James},
    booktitle = {Proceedings of the 2006 international workshop on Mining software repositories},
    citeulike-article-id = {4406375},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1137983.1138001},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1137983.1138001},
    doi = {10.1145/1137983.1138001},
    isbn = {1-59593-397-2},
    location = {Shanghai, China},
    pages = {72--75},
    posted-at = {2009-08-06 02:39:47},
    priority = {2},
    publisher = {ACM},
    series = {MSR '06},
    title = {Mining version archives for co-changed lines},
    url = {http://dx.doi.org/10.1145/1137983.1138001},
    year = {2006}
}

@article{citeulike:4534888,
    abstract = {A comprehensive literature survey on approaches for mining software repositories ({MSR}) in the context
of software evolution is presented. In particular, this survey deals with those investigations that examine multiple
versions of software artifacts or other temporal information. A taxonomy is derived from the analysis of this literature
and presents the work via four dimensions: the type of software repositories mined (what), the purpose (why), the
adopted/invented methodology used (how), and the evaluation method (quality). The taxonomy is demonstrated to be
expressive (i.e., capable of representing a wide spectrum of {MSR} investigations) and effective (i.e., facilitates
similarities and comparisons of {MSR} investigations). Lastly, a number of open research issues in {MSR} that require
further investigation are identified.},
    address = {New York, NY, USA},
    author = {Kagdi, Huzefa and Collard, Michael L. and Maletic, Jonathan I.},
    citeulike-article-id = {4534888},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1345056.1345057},
    citeulike-linkout-1 = {http://dx.doi.org/10.1002/smr.344},
    doi = {10.1002/smr.344},
    issn = {1532-060X},
    journal = {J. Softw. Maint. Evol.},
    keywords = {proposal},
    month = mar,
    number = {2},
    pages = {77--131},
    posted-at = {2009-08-06 02:39:18},
    priority = {2},
    publisher = {John Wiley \&amp; Sons, Inc.},
    title = {A survey and taxonomy of approaches for mining software repositories in the context of software evolution},
    url = {http://dx.doi.org/10.1002/smr.344},
    volume = {19},
    year = {2007}
}

@inproceedings{citeulike:5213050,
    abstract = {The thesis proposes a software-change prediction approach that is based on mining fine-grained
evolutionary couplings from source code repositories. Here, fine-grain refers to identifying couplings between source
code entities such as methods, control structures, or even comments. This differs from current source code mining
techniques that typically only identify couplings between files or fairly high-level entities. Furthermore, the model
combines the mined evolutionary couplings with the estimated changes identified by traditional impact analysis
techniques (e.g., static analysis of call and program-dependency graphs). The research hypothesis is that
software-change prediction using the proposed synergistic approach results in an overall improved expressiveness (i.e.,
granularity and context given to a developer) and effectiveness (i.e., accuracy of the prediction)},
    address = {New York, NY, USA},
    author = {Kagdi, Huzefa},
    booktitle = {Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering},
    citeulike-article-id = {5213050},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1321742},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1321631.1321742},
    doi = {10.1145/1321631.1321742},
    isbn = {978-1-59593-882-4},
    location = {Atlanta, Georgia, USA},
    pages = {559--562},
    posted-at = {2009-08-06 02:34:18},
    priority = {2},
    publisher = {ACM},
    series = {ASE '07},
    title = {Improving change prediction with fine-grained source code mining},
    url = {http://dx.doi.org/10.1145/1321631.1321742},
    year = {2007}
}

@article{citeulike:983796,
    abstract = {Software developers are often faced with modification tasks that involve source which is spread across a
code base. Some dependencies between source code, such as those between source code written in different languages, are
difficult to determine using existing static and dynamic analyses. To augment existing analyses and to help developers
identify relevant source code during a modification task, we have developed an approach that applies data mining
techniques to determine change patterns - sets of files that were changed together frequently in the past - from the
change history of the code base. Our hypothesis is that the change patterns can be used to recommend potentially
relevant source code to a developer performing a modification task. We show that this approach can reveal valuable
dependencies by applying the approach to the Eclipse and Mozilla open source projects and by evaluating the
predictability and interestingness of the recommendations produced for actual modification tasks 
on these systems.},
    address = {Los Alamitos, CA, USA},
    author = {Ying, A. T. T. and Murphy, G. C. and Ng, R. and Chu-Carroll, M. C.},
    booktitle = {Software Engineering, IEEE Transactions on},
    citeulike-article-id = {983796},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1018388},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/TSE.2004.52},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/tse.2004.52},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1324645},
    doi = {10.1109/tse.2004.52},
    issn = {0098-5589},
    journal = {Software Engineering, IEEE Transactions on},
    keywords = {proposal},
    month = sep,
    number = {9},
    pages = {574--586},
    posted-at = {2009-08-06 01:57:50},
    priority = {2},
    publisher = {IEEE},
    title = {Predicting source code changes by mining change history},
    url = {http://dx.doi.org/10.1109/tse.2004.52},
    volume = {30},
    year = {2004}
}

@inproceedings{citeulike:5375867,
    abstract = {Understanding function signature change properties and evolution patterns is important for researchers
concerned with alleviating signature change impacts, understanding software evolution, and predicting future evolution
patterns. We provide detailed signature change properties by analyzing seven software project histories to reveal
multiple properties of signature changes, including their kind, frequency, correlation with other changes, number of
parameter changes, and evolution patterns of signature change kinds. We show that signature changes can be used as
measurement aid for software evolution analysis.},
    address = {Washington, DC, USA},
    author = {Kim, Sunghun and Whitehead, E. James and Jennifer Bevan},
    booktitle = {ICSM '06: Proceedings of the 22nd IEEE International Conference on Software Maintenance},
    citeulike-article-id = {5375867},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1172973},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icsm.2006.47},
    doi = {10.1109/icsm.2006.47},
    isbn = {0-7695-2354-4},
    keywords = {proposal},
    pages = {4--13},
    posted-at = {2009-08-06 01:45:46},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Properties of Signature Change Patterns},
    url = {http://dx.doi.org/10.1109/icsm.2006.47},
    year = {2006}
}

@proceedings{citeulike:5375823,
    abstract = {Understanding software change patterns during evolution is important for researchers concerned with
alleviating change impacts. It can provide insight to understand the software evolution, predict future changes, and
develop new refactoring algorithms. However, most of the current research focus on the procedural programs like C, or
object-oriented programs like Java; seldom effort has been made for aspect-oriented software. In this paper, we propose
an approach for mining change patterns in {AspectJ} software evolution. Our approach first decomposes the software
changes into a set of atomic change representations, then employs the apriori data mining algorithm to generate the most
frequent itemsets. The patterns we found reveal multiple properties of software changes, including their kind,
frequency, and correlation with other changes. In our empirical evaluation on several non-trivial {AspectJ} benchmarks,
we demonstrate that those change patterns can be used as measurement aid and fault 
predication for {AspectJ} software evolution analysis.},
    author = {Qian, Yin and Zhang, Sai and Qi, Zhengwei},
    booktitle = {Computer Science and Software Engineering, 2008 International Conference on},
    citeulike-article-id = {5375823},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/csse.2008.802},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4722012},
    doi = {10.1109/csse.2008.802},
    journal = {Computer Science and Software Engineering, 2008 International Conference on},
    keywords = {proposal},
    pages = {108--111},
    posted-at = {2009-08-06 01:38:01},
    priority = {2},
    title = {Mining Change Patterns in {AspectJ} Software Evolution},
    url = {http://dx.doi.org/10.1109/csse.2008.802},
    volume = {2},
    year = {2008}
}

@incollection{citeulike:5361927,
    abstract = {The workshop addresses practitioners and/or researchers who are interested in empirical software
engineering, software process improvement, and quality {management.Practitioners} are being addressed specifically,
since this workshop is also intended to find out what kind of information practitioners need, which kind of support they
expect from research regarding the aggregation of information, and how they select software engineering technology.},
    author = {Ciolkowski, Marcus and Jedlitschka, Andreas},
    citeulike-article-id = {5361927},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-73460-4\_34},
    citeulike-linkout-1 = {http://www.springerlink.com/content/p027315160r04l51},
    doi = {10.1007/978-3-540-73460-4\_34},
    journal = {Product-Focused Software Process Improvement},
    keywords = {methodology, proposal, research},
    pages = {402--404},
    posted-at = {2009-08-04 21:33:37},
    priority = {2},
    title = {Experience on Applying Quantitative and Qualitative Empiricism to Software Engineering},
    url = {http://dx.doi.org/10.1007/978-3-540-73460-4\_34},
    year = {2007}
}

@article{citeulike:5361919,
    abstract = {In this paper, we argue that the gap between  empirical software engineering and software  engineering
practice might be lessened if more attention  were paid to two important aspects of evidence. The  first is that
evidence from case or field studies of actual  software engineering practice is essential in order to  understand and
inform that practice. The second is that  the nature of evidence should fit the purpose to which  the evidence is going
to be put. One type of evidence is  not per se better than another. For example, the  evidence required to persuade a
manager to change an  aspect of practice might be totally different in nature  from that required to deepen the academic
community's  understanding of such practice.},
    address = {Los Alamitos, CA, USA},
    author = {Segal, Judith},
    citeulike-article-id = {5361919},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/STEP.2003.33},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/step.2003.33},
    doi = {10.1109/step.2003.33},
    isbn = {0-7695-2218-1},
    journal = {Software Technology and Engineering Practice, International Workshop on},
    keywords = {methodology, proposal, research},
    pages = {40--47},
    posted-at = {2009-08-04 21:32:44},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {The Nature of Evidence in Empirical Software Engineering},
    url = {http://dx.doi.org/10.1109/step.2003.33},
    volume = {0},
    year = {2003}
}

@inproceedings{citeulike:5361802,
    abstract = {In this paper, we argue that the gap between empirical software engineering and software engineering
practice might be lessened if more attention were paid to two important aspects of evidence. The first is that evidence
from case or field studies of actual software engineering practice is essential in order to understand and inform that
practice. The second is that the nature of evidence should fit the purpose to which the evidence is going to be put. One
type of evidence is not per se better than another. For example, the evidence required to persuade a manager to change
an aspect of practice might be totally different in nature from that required to deepen the academic community's
understanding of such practice.},
    address = {Washington, DC, USA},
    author = {Segal, Judith},
    booktitle = {STEP '03: Proceedings of the Eleventh Annual International Workshop on Software Technology and
Engineering Practice},
    citeulike-article-id = {5361802},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1034388},
    isbn = {0-7695-2218-1},
    keywords = {methodology, proposal, research},
    pages = {40--47},
    posted-at = {2009-08-04 21:31:06},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {The Nature of Evidence in Empirical Software Engineering},
    url = {http://portal.acm.org/citation.cfm?id=1034388},
    year = {2003}
}

@article{citeulike:5361791,
    author = {Sim, Susan E. and Singer, Janice and Storey, Margaret-Anne},
    citeulike-article-id = {5361791},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a:1009809824225},
    citeulike-linkout-1 = {http://www.springerlink.com/content/m22746122r2t13h8},
    day = {1},
    doi = {10.1023/a:1009809824225},
    journal = {Empirical Software Engineering},
    keywords = {methodology, proposal, research},
    month = mar,
    number = {1},
    pages = {85--93},
    posted-at = {2009-08-04 21:11:35},
    priority = {2},
    title = {Beg, Borrow, or Steal: Using Multidisciplinary Approaches in Empirical Software Engineering Research},
    url = {http://dx.doi.org/10.1023/a:1009809824225},
    volume = {6},
    year = {2001}
}

@article{citeulike:1396399,
    author = {Tichy, Walter F.},
    citeulike-article-id = {1396399},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a:1009844119158},
    citeulike-linkout-1 = {http://www.springerlink.com/content/rr70j282h2k01960},
    day = {1},
    doi = {10.1023/a:1009844119158},
    issn = {13823256},
    journal = {Empirical Software Engineering},
    keywords = {methodology, proposal, research},
    month = dec,
    number = {4},
    pages = {309--312},
    posted-at = {2009-08-04 21:10:13},
    priority = {2},
    title = {Hints for Reviewing Empirical Work in Software Engineering},
    url = {http://dx.doi.org/10.1023/a:1009844119158},
    volume = {5},
    year = {2000}
}

@inproceedings{citeulike:4712996,
    abstract = {This paper reports on the research published between the years 1997 and 2003 inclusive in the journal of
Empirical Software Engineering, drawing on the taxonomy developed by Glass et al. in [3]. We found that the research was
somewhat narrow in topic with about half the papers focusing on measurement/metrics, review and inspection; that
researchers were almost as interested in formulating as in evaluating; that hypothesis testing and laboratory
experiments dominated evaluations; that research was not very likely to focus on people and extremely unlikely to refer
to other disciplines. We discuss our findings in the context of making empirical software engineering more relevant to
practitioners.},
    address = {New York, NY, USA},
    author = {Segal, Judith and Grinyer, Antony and Sharp, Helen},
    booktitle = {REBSE '05: Proceedings of the 2005 workshop on Realising evidence-based software engineering},
    citeulike-article-id = {4712996},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1083174.1083176},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1083174.1083176},
    doi = {10.1145/1083174.1083176},
    isbn = {1-59593-121-X},
    keywords = {methodology, proposal, research},
    location = {St. Louis, Missouri},
    pages = {1--4},
    posted-at = {2009-08-04 21:09:09},
    priority = {2},
    publisher = {ACM},
    title = {The type of evidence produced by empirical software engineers},
    url = {http://dx.doi.org/10.1145/1083174.1083176},
    year = {2005}
}

@article{citeulike:1421943,
    abstract = {While empirical studies in software engineering are beginning to gain recognition in the research
community, this subarea is also entering a new level of maturity by beginning to address the human aspects of software
development. This added focus has added a new layer of complexity to an already challenging area of research. Along with
new research questions, new research methods are needed to study nontechnical aspects of software engineering. In many
other disciplines, qualitative research methods have been developed and are commonly used to handle the complexity of
issues involving human behavior. This paper presents several qualitative methods for data collection and analysis and
describes them in terms of how they might be incorporated into empirical studies of software engineering, in particular
how they might be combined with quantitative methods. To illustrate this use of qualitative methods, examples from real
software engineering studies are used throughout.},
    address = {Piscataway, NJ, USA},
    author = {Seaman, Carolyn B.},
    citeulike-article-id = {1421943},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=322687},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/32.799955},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=799955},
    doi = {10.1109/32.799955},
    issn = {0098-5589},
    journal = {IEEE Trans. Softw. Eng.},
    keywords = {methodology, proposal, research},
    month = jul,
    number = {4},
    pages = {557--572},
    posted-at = {2009-08-04 21:08:12},
    priority = {2},
    publisher = {IEEE Press},
    title = {Qualitative Methods in Empirical Studies of Software Engineering},
    url = {http://dx.doi.org/10.1109/32.799955},
    volume = {25},
    year = {1999}
}

@article{citeulike:4712961,
    abstract = {Over the past decade we have performed a sustained series of qualitative studies of software development
practice, focusing on social factors. Using an ethnographically-informed approach, we have addressed four areas of
software practice: software quality management systems, the emergence of object technology, professional end user
development and agile development. Several issues have arisen from this experience, including the nature of research
questions that such studies can address, the advantages and challenges associated with being a member of the community
under study, and how to maintain rigour in data collection. In this paper, we will draw on our studies to illustrate our
approach and to discuss these and other issues.},
    address = {Newton, MA, USA},
    author = {Robinson, H. and Segal, J. and Sharp, H.},
    citeulike-article-id = {4712961},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1240332.1240476},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.infsof.2007.02.007},
    doi = {10.1016/j.infsof.2007.02.007},
    issn = {09505849},
    journal = {Information and Software Technology},
    keywords = {methodology, proposal, research},
    month = jun,
    number = {6},
    pages = {540--551},
    posted-at = {2009-08-04 21:06:30},
    priority = {2},
    publisher = {Butterworth-Heinemann},
    title = {Ethnographically-informed empirical studies of software practice},
    url = {http://dx.doi.org/10.1016/j.infsof.2007.02.007},
    volume = {49},
    year = {2007}
}

@techreport{citeulike:5333719,
    author = {Barnes, N.},
    citeulike-article-id = {5333719},
    citeulike-linkout-0 = {http://www.ravenbrook.com/project/p4dti/master/design/ bugzilla-schema/},
    institution = {Ravenbrook Limited},
    keywords = {proposal},
    month = jul,
    posted-at = {2009-08-02 23:37:02},
    priority = {2},
    title = {Bugzilla database schema.},
    url = {http://www.ravenbrook.com/project/p4dti/master/design/ bugzilla-schema/},
    year = {2004}
}

@book{citeulike:1230319,
    abstract = {**Learn how to employ {JADE} to build multi-agent systems!**

{JADE} (Java Agent {DEvelopment} framework) is a middleware for the development of
applications, both in the mobile and fixed environment, based on the Peer-to-
Peer intelligent autonomous agent approach. {JADE} enables developers to
implement and deploy multi-agent systems, including agents running on wireless
networks and limited-resource devices.

{\_Developing} {Multi-Agent} Systems with {JADE\_} is a practical guide to using {JADE}.
The text will give an introduction to agent technologies and the {JADE}
Platform, before proceeding to give a comprehensive guide to programming with
{JADE}. Basic features such as creating agents, agent tasks, agent
communication, agent discovery and {GUIs} are covered, as well as more advanced
features including ontologies and content languages, complex behaviours,
interaction protocols, agent mobility, and the in-process interface. Issues
such as {JADE} internals, running {JADE} agents on mobile devices, deploying a
fault tolerant {JADE} platform, and main add-ons are also covered in depth.

{\_Developing} {Multi-Agent} Systems with {JADE\_}:

  * Comprehensive guide to using {JADE} to build multi-agent systems and agent
orientated programming.

  * Describes and explains ontologies and content language, interaction
protocols and complex behaviour.

  * Includes material on persistence, security and a semantics framework.

  * Contains numerous examples, problems, and illustrations to enhance
learning.

  * Presents a case study demonstrating the use of {JADE} in practice.

  * Offers an accompanying website with additional learning resources such as
sample code, exercises and {PPT}-slides.

This invaluable resource will provide multi-agent systems practitioners,
programmers working in the software industry with an interest on multi-agent
systems as well as final year undergraduate and postgraduate students in {CS}
and advanced networking and telecoms courses with a comprehensive guide to
using {JADE} to employ multi agent systems.

With contributions from experts in {JADE} and multi agent technology.},
    author = {Bellifemine, Fabio L. and Caire, Giovanni and Greenwood, Dominic},
    citeulike-article-id = {1230319},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0470057475},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0470057475},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0470057475},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0470057475},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0470057475/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0470057475},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0470057475},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0470057475},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0470057475\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0470057475},
    day = {02},
    edition = {1},
    howpublished = {Hardcover},
    isbn = {0470057475},
    keywords = {proposal},
    month = apr,
    posted-at = {2009-07-20 00:06:03},
    priority = {2},
    publisher = {Wiley},
    title = {Developing {Multi-Agent} Systems with {JADE} (Wiley Series in Agent Technology)},
    url = {http://www.worldcat.org/isbn/0470057475},
    year = {2007}
}

@phdthesis{citeulike:2703162,
    abstract = {A recent focus of interest in software engineering research is on low-level software processes, which
define how software developers or development teams should carry on development activities in short phases that last
from several minutes to a few hours. Anecdotal evidence exists for the positive impact on quality and productivity of
certain low-level software processes such as test-driven development and continuous integration. However, empirical
research on low-level software processes often yields conflicting results. A significant threat to the validity of the
empirical studies on low-level software processes is that they lack the ability to rigorously assess process
conformance. That is to say, the degree to which developers follow the low-level software processes can not be
evaluated. In order to improve the quality of empirical research on low-level software processes, I developed a
technique called Software Development Stream Analysis ({SDSA}) that can infer development behaviors 
using automatically collected in-process software metrics. The collection of development activities is supported by
Hackystat, a framework for automated software process and product metrics collection and analysis. {SDSA} abstracts the
collected software metrics into a software development stream, a time-series data structure containing time-stamped
development events. It then partitions the development stream into episodes, and then uses a rule-based system to infer
low-level development behaviors exhibited in episodes. With the capabilities provided by Hackystat and {SDSA}, I
developed the Zorro software system to study a specific low-level software process called {Test-Driven} Development
({TDD}). Experience reports have shown that {TDD} can greatly improve software quality with increased developer
productivity, but empirical research findings on {TDD} are often mixed. An inability to rigorously assess process
conformance is a possible explanation. Zorro can rigorously assess process conformance to a 
specific operational definition for {TDD}, and thus enable more controlled, comparable empirical studies. My research
has demonstrated that Zorro can recognize the low-level software development behaviors that characterize {TDD}. Both the
pilot and classroom case studies support this conclusion. The industrial case study shows that the automated data
collection and development behavior inference has the potential to be useful for researchers.},
    author = {Kou, Hongbing},
    citeulike-article-id = {2703162},
    citeulike-linkout-0 = {http://csdl.ics.hawaii.edu/techreports/07-04/07-04.pdf},
    keywords = {proposal},
    month = dec,
    posted-at = {2009-07-19 23:23:13},
    priority = {2},
    school = {University of Hawaii, Department of Information and Computer Sciences},
    title = {Automated Inference of Software Development Behaviors: Design, Implementation and Validation of Zorro for
{Test-Driven} Development},
    type = {{Ph.D.} Thesis},
    url = {http://csdl.ics.hawaii.edu/techreports/07-04/07-04.pdf},
    year = {2007}
}

@book{citeulike:709476,
    abstract = {{Our ability to generate and collect data has been increasing rapidly. Not only are all of our business,
scientific, and government transactions now computerized, but the widespread use of digital cameras, publication tools,
and bar codes also generate data. On the collection side, scanned text and image platforms, satellite remote sensing
systems, and the World Wide Web have flooded us with a tremendous amount of data. This explosive growth has generated an
even more urgent need for new techniques and automated tools that can help us transform this data into useful
information and knowledge.<br><br>Like the first edition, voted the most popular data mining book by KD Nuggets readers,
this book explores concepts and techniques for the discovery of patterns hidden in large data sets, focusing on issues
relating to their feasibility, usefulness, effectiveness, and scalability. However, since the publication of the first
edition, great progress has been made in the development of new data mining 
methods, systems, and applications. This new edition substantially enhances the first edition, and new chapters have
been added to address recent developments on mining complex types of data including stream data, sequence data, graph
structured data, social network data, and multi-relational data.<br><br>Whether you are a seasoned professional or a new
student of data mining, this book has much to offer you:<br>* A comprehensive, practical look at the concepts and
techniques you need to know to get the most out of real business data.<br>* Updates that incorporate input from readers,
changes in the field, and more material on statistics and machine learning.<br>* Dozens of algorithms and implementation
examples, all in easily understood pseudo-code and suitable for use in real-world, large-scale data mining
projects.<br>* Complete classroom support for instructors at www.mkp.com/datamining2e companion site.}},
    author = {Han, Jiawei and Kamber, Micheline and Pei, Jian},
    citeulike-article-id = {709476},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1558609016},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/1558609016},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/1558609016},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/1558609016},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/1558609016/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1558609016},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/1558609016},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN1558609016},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=1558609016\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/1558609016},
    day = {13},
    edition = {2},
    howpublished = {Hardcover},
    isbn = {1558609016},
    keywords = {proposal},
    month = jan,
    posted-at = {2009-07-18 17:25:55},
    priority = {2},
    publisher = {Morgan Kaufmann},
    title = {Data Mining: Concepts and Techniques, Second Edition (The Morgan Kaufmann Series in Data Management
Systems)},
    url = {http://www.worldcat.org/isbn/1558609016},
    year = {2006}
}

@manual{citer,
    address = {Vienna, Austria},
    author = {{R Development Core Team}},
    citeulike-article-id = {5173022},
    citeulike-linkout-0 = {http://www.R-project.org},
    comment = {{ISBN} 3-900051-07-0},
    organization = {R Foundation for Statistical Computing},
    posted-at = {2009-07-16 01:49:45},
    priority = {2},
    title = {R: A language and environment for statistical computing},
    url = {http://www.R-project.org},
    year = {2005}
}

@article{citeulike:5164952,
    abstract = {In the past, we proposed an incremental mining algorithm for maintenance of sequential patterns based on
the concept of pre-large sequences as new records were inserted. In this paper, we attempt to apply the concept of
pre-large sequences to maintain sequential  patterns as records are deleted. Pre-large sequences are defined by a lower
support threshold and an upper support threshold. They act as buffers to avoid the movements of sequential patterns
directly from large to small and vice-versa. Our proposed algorithm does not  require rescanning original databases
until the accumulative amount of deleted customer sequences exceeds a safety bound, which depends on database size. As
databases grow larger, the numbers of deleted customer sequences allowed before database rescanning  is required also
grow. The proposed approach is thus efficient for a large database.},
    address = {Los Alamitos, CA, USA},
    author = {Wang, Ching Y. and Hong, Tzung P. and Tseng, Shian S.},
    citeulike-article-id = {5164952},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/ICDM.2001.989562},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icdm.2001.989562},
    doi = {10.1109/icdm.2001.989562},
    isbn = {0-7695-1119-8},
    journal = {Data Mining, IEEE International Conference on},
    keywords = {proposal},
    pages = {536+},
    posted-at = {2009-07-15 21:44:03},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Maintenance of Sequential Patterns for Record Deletion},
    url = {http://dx.doi.org/10.1109/icdm.2001.989562},
    volume = {0},
    year = {2001}
}

@electronic{citeulike:5164923,
    abstract = {: The problem of mining sequential patterns was recently introduced in [{AS95}]. We are given a database
of sequences, where each sequence is a list of transactions ordered by transaction-time, and each transaction is a set
of items. The problem is to discover all sequential patterns with a user-specified minimum support, where the support of
a pattern is the number of data-sequences that contain the pattern. An example of a sequential pattern is \&\#034;5\% of
customers bought `Foundation\&\#039; and `Ringworld\&\#039; in one transaction, followed by `Second Foundation\&\#039;
in a later transaction\&\#034;. We generalize the problem as follows. First, we add time constraints that specify a
minimum and/or maximum time period between adjacent elements in a pattern. Second, we relax the restriction that the
items in an element of a sequential pattern must come from the same transaction, instead allowing the items to be
present in a set of transactions whose transaction-times are within a user-
specified time window. Third, g...},
    author = {Srikant, Ramakrishnan and Srikant, Ramakrishnan and Agrawal, Rakesh and Agrawal, Rakesh},
    citeulike-article-id = {5164923},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.7320},
    keywords = {proposal},
    pages = {3--17},
    posted-at = {2009-07-15 21:38:31},
    priority = {2},
    title = {Mining Sequential Patterns: Generalizations And Performance Improvements},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.7320},
    year = {1996}
}

@article{citeulike:769773,
    abstract = {The set of frequent closed itemsets uniquely determines the exact frequency of all itemsets, yet it can
be orders of magnitude smaller than the set of all frequent itemsets. In this paper, we present {CHARM}, an efficient
algorithm for mining all frequent closed itemsets. It enumerates closed sets using a dual itemset-tidset search tree,
using an efficient hybrid search that skips many levels. It also uses a technique called diffsets to reduce the memory
footprint of intermediate computations. Finally, it uses a fast hash-based approach to remove any "nonclosed\^{A}¿ sets
found during computation. We also present {CHARM}-L, an algorithm that outputs the closed itemset lattice, which is very
useful for rule generation and visualization. An extensive experimental evaluation on a number of real and synthetic
databases shows that {CHARM} is a state-of-the-art algorithm that outperforms previous methods. Further, {CHARM}-L
explicitly generates the frequent closed itemset lattice.},
    address = {Piscataway, NJ, USA},
    author = {Zaki, Mohammed J. and Hsiao, Ching J.},
    citeulike-article-id = {769773},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1048864},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/TKDE.2005.60},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/tkde.2005.60},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1401887},
    doi = {10.1109/tkde.2005.60},
    issn = {1041-4347},
    journal = {IEEE Trans. on Knowl. and Data Eng.},
    keywords = {proposal},
    month = apr,
    number = {4},
    pages = {462--478},
    posted-at = {2009-07-15 17:54:52},
    priority = {2},
    publisher = {IEEE Educational Activities Department},
    title = {Efficient Algorithms for Mining Closed Itemsets and Their Lattice Structure},
    url = {http://dx.doi.org/10.1109/tkde.2005.60},
    volume = {17},
    year = {2005}
}

@article{citeulike:5159924,
    abstract = {This paper presents a method for the discovery of temporal patterns in multivariate time series and
their conversion into a linguistic knowledge representation applied to sleep-related breathing disorders. The main idea
lies in introducing several abstraction levels that allow a step-wise identification of temporal patterns.
Self-organizing neural networks are used to discover elementary patterns in the time series. Machine learning ({ML})
algorithms use the results of the neural networks to automatically generate a rule-based description. At the next
levels, temporal grammatical rules are inferred. This method covers one of the main  ” bottlenecks” in the design of
knowledge-based systems, namely, the knowledge acquisition problem. An evaluation of the rules lead to an overall
sensitivity of 0.762, and a specificity of 0.758.},
    author = {Guimar\~{a}es, G.},
    citeulike-article-id = {5159924},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0933-3657(01)00089-6},
    doi = {10.1016/s0933-3657(01)00089-6},
    issn = {09333657},
    journal = {Artificial Intelligence in Medicine},
    keywords = {proposal},
    month = nov,
    number = {3},
    pages = {211--237},
    posted-at = {2009-07-15 16:50:49},
    priority = {2},
    title = {A method for automated temporal knowledge acquisition applied to sleep-related breathing disorders},
    url = {http://dx.doi.org/10.1016/s0933-3657(01)00089-6},
    volume = {23},
    year = {2001}
}

@phdthesis{citeulike:5159625,
    address = {Germany},
    author = {H\"{o}ppner, F.},
    citeulike-article-id = {5159625},
    institution = {Technical University Braunschweig},
    keywords = {proposal, thesis},
    posted-at = {2009-07-15 16:01:45},
    priority = {2},
    school = {Technical University Braunschweig},
    title = {Knowledge Discovery from {SequentialData}.},
    year = {2003}
}

@electronic{citeulike:5159615,
    abstract = {. Recently, association rule mining has been generalized to the  discovery of episodes in event
sequences. In this paper, we additionally  take durations into account and thus present a generalization to time 
intervals. We discover frequent temporal patterns in a single series of  such labeled intervals, which we call a state
sequence. A temporal pattern  is dened as a set of states together with their interval relationships  described in terms
of Allen\&\#039;s interval logic, for instance \A before B,  A overlaps C, C overlaps B\&\#034; or equivalently \state A
ends before state  B starts, the gap is covered by state C\&\#034;. As an example we consider  the problem of deriving
local weather forecasting rules that allow us to  conclude from the qualitative behaviour of the air-pressure curve to
the  wind-strength. Here, the states have been extracted automatically from  (multivariate) time series and characterize
the trend of the time series  locally within the assigned time interval.  1 },
    author = {H\"{o}ppner, Frank},
    citeulike-article-id = {5159615},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.701},
    keywords = {proposal},
    posted-at = {2009-07-15 15:58:33},
    priority = {2},
    title = {Discovery of Temporal Patterns - Learning Rules about the Qualitative Behaviour of Time Series},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.701},
    year = {2001}
}

@inproceedings{citeulike:5159362,
    abstract = {this paper, we consider interval-based events where the duration of events is expressed in terms of
endpoint values, and these are used to form temporal constraint in the discovery process. We introduce the notion of
temporal representation which is capable of expressing the relationships between interval-based events. We develop new
methods for finding such interesting patterns.},
    author = {Kam, Po-Shan and Fu, Ada W.},
    booktitle = {Proceedings of the 2nd International Conference on Data Warehousing and Knowledge Discovery (DaWaK'00},
    citeulike-article-id = {5159362},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.7200},
    keywords = {proposal},
    pages = {317--326},
    posted-at = {2009-07-15 15:24:48},
    priority = {2},
    title = {Discovering Temporal Patterns for Interval-based Events},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.7200},
    year = {2000}
}

@article{citeulike:3013168,
    abstract = {Large-scale clinical databases provide a detailed perspective on patient phenotype in disease and the
characteristics of health care processes. Important information is often contained in the relationships between the
values and timestamps of sequences of clinical data. The analysis of clinical time sequence data across entire patient
populations may reveal data patterns that enable a more precise understanding of disease presentation, progression, and
response to therapy, and thus could be of great value for clinical and translational research. Recent work suggests that
the combination of temporal data mining methods with techniques from artificial intelligence research on knowledge-based
temporal abstraction may enable the mining of clinically relevant temporal features from these previously problematic
general clinical data.},
    address = {Division of Clinical Informatics, Department of Public Health Sciences, University of Virginia, Suite
3181 West Complex, 1335 Hospital Drive, Charlottesville, VA 22908-0717, USA. arp4m@virginia.edu},
    author = {Post, A.},
    citeulike-article-id = {3013168},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cll.2007.10.005},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/18194720},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=18194720},
    doi = {10.1016/j.cll.2007.10.005},
    issn = {02722712},
    journal = {Clinics in Laboratory Medicine},
    keywords = {proposal},
    month = mar,
    number = {1},
    pages = {83--100},
    pmid = {18194720},
    posted-at = {2009-07-15 02:58:08},
    priority = {2},
    title = {Temporal Data Mining},
    url = {http://dx.doi.org/10.1016/j.cll.2007.10.005},
    volume = {28},
    year = {2008}
}

@incollection{citeulike:5153756,
    abstract = {Fluents are logical descriptions of situations that persist, and composite fluents are statistically
significant temporal relationships between {fluents.T} his paper presents an algorithm for learning composite fluents
incrementally from categorical time series {data.Th} e algorithm is tested with a large dataset of mobile robot
{episodes.I} t is given no knowledge of the episodic structure of the dataset (i.e., it learns without supervision) yet
it discovers fluents that correspond well with episodes.},
    author = {Cohen, Paul},
    citeulike-article-id = {5153756},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-44816-0\_27},
    citeulike-linkout-1 = {http://www.springerlink.com/content/p888cm6xygv80r9k},
    doi = {10.1007/3-540-44816-0\_27},
    journal = {Advances in Intelligent Data Analysis},
    keywords = {proposal},
    pages = {268--277},
    posted-at = {2009-07-15 02:49:06},
    priority = {2},
    title = {Fluent Learning: Elucidating the Structure of Episodes},
    url = {http://dx.doi.org/10.1007/3-540-44816-0\_27},
    year = {2001}
}

@incollection{citeulike:5153722,
    abstract = {In many daily transactions, the time when an event takes place is known and stored in databases.
Examples range from sales records, stock exchange, patient records, to scientific databases in geophysics and astronomy.
Such databases incorporate the concept of time which describes when an event starts and ends as historical records [9].
The temporal nature of data provides us with a better understanding of the trend or pattern over time. In market-basket
data, we can have a pattern like  ” 75\% of customers buy peanuts when butter starts to be in big sales and before bread
is sold out”. We observe that there may be some correlations among peanuts, butter and bread so that we can have better
planning for marketing strategy. Knowledge discovery in temporal databases thus catches the attention of researchers [8,
4].},
    address = {Berlin, Heidelberg},
    author = {Kam, Po-shan and Fu, Ada},
    booktitle = {Data Warehousing and Knowledge Discovery },
    chapter = {32},
    citeulike-article-id = {5153722},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-44466-1\_32},
    citeulike-linkout-1 = {http://www.springerlink.com/content/b5eg19hu445vx0q7},
    day = {6},
    doi = {10.1007/3-540-44466-1\_32},
    editor = {Kambayashi, Yahiko and Mohania, Mukesh and Tjoa, A. Min},
    isbn = {978-3-540-67980-6},
    journal = {Data Warehousing and Knowledge Discovery},
    keywords = {proposal},
    month = jul,
    pages = {317--326},
    posted-at = {2009-07-15 02:47:33},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Discovering Temporal Patterns for Interval-based Events},
    url = {http://dx.doi.org/10.1007/3-540-44466-1\_32},
    volume = {1874},
    year = {2000}
}

@inproceedings{citeulike:2804633,
    abstract = {. Data mining can be used to extensively automate the data analysis
process. Techniques for mining interval time series, however, have not been
considered. Such time series are common in many applications. In this paper,
we investigate mining techniques for such time series. Specifically, we propose
a technique to discover temporal containment relationships. An item A is said
to contain an item B if an event of type B occurs during the time span of an
event of type A, and this is a...},
    author = {Villafane, Roy and Hua, Kien A. and Tran, Duc and Maulik, Basab},
    booktitle = {Data Warehousing and Knowledge Discovery},
    citeulike-article-id = {2804633},
    citeulike-linkout-0 = {http://citeseer.ist.psu.edu/villafane99mining.html},
    citeulike-linkout-1 = {http://citeseer.lcs.mit.edu/villafane99mining.html},
    citeulike-linkout-2 = {http://citeseer.ifi.unizh.ch/villafane99mining.html},
    citeulike-linkout-3 = {http://citeseer.comp.nus.edu.sg/villafane99mining.html},
    keywords = {proposal},
    pages = {318--330},
    posted-at = {2009-07-15 02:11:00},
    priority = {2},
    title = {Mining Interval Time Series},
    url = {http://citeseer.ist.psu.edu/villafane99mining.html},
    year = {1999}
}

@electronic{citeulike:5128872,
    abstract = {In this paper, we introduce a knowledge-based meta-model which serves as a unified resource model for
integrating characteristics of major types of objects appearing in software development models ({SDMs}). The {URM}
consists of resource classes and a web of relations that link different types of resources found in different kinds of
models of software development. The {URM} includes specialized models for software systems, documents, agents, tools,
and development processes. The {URM} has served as the basis for integrating and interoperating a number of
process-centered {CASE} environments. The major benefit of the {URM} is twofold: First, it forms a higher level of
abstraction supporting {SDM} formulation that subsumes many typical models of software development objects. Hence, it
enables a higher level of reusability for existing support mechanisms of these models. Second, it provides a basis to
support complex reasoning mechanisms that address issues across different types of software 
objects. ...},
    author = {Mi, Peiwei and Scacchi, Walt},
    citeulike-article-id = {5128872},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.7533},
    keywords = {proposal},
    pages = {313--330},
    posted-at = {2009-07-12 22:05:44},
    priority = {2},
    title = {A {Meta-Model} for Formulating {Knowledge-Based} Models of Software Development},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.7533},
    volume = {17},
    year = {1994}
}

@article{citeulike:5128808,
    abstract = {Web-based open source software development ({OSSD}) project communities provide interesting and unique
opportunities for software process modeling and simulation. While most studies focus on analyzing processes in a single
organization, we focus on modeling software development processes both within and across three distinct but related
{OSSD} project communities: Mozilla, a Web artifact consumer; the Apache {HTTP} server that handles the transactions of
Web artifacts to consumers such as the Mozilla browser; and {NetBeans}, a Java-based integrated development environment
({IDE}) for creating Web artifacts and application systems. In this article, we look at the process relationships within
and between these communities as components of a Web information infrastructure. We employ expressive and comparative
techniques for modeling such processes that facilitate and enhance understanding of the software development techniques
utilized by their respective communities and the collective 
infrastructure in creating them. Copyright {\copyright} 2005 John Wiley \& Sons, Ltd.},
    address = {Institute for Software Research, University of California-Irvine, Irvine, CA, USA},
    author = {Jensen, Chris and Scacchi, Walt},
    citeulike-article-id = {5128808},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/spip.228},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/111083292/ABSTRACT},
    doi = {10.1002/spip.228},
    journal = {Software Process: Improvement and Practice},
    keywords = {proposal},
    number = {3},
    pages = {255--272},
    posted-at = {2009-07-12 21:55:48},
    priority = {2},
    title = {Process modeling across the web information infrastructure},
    url = {http://dx.doi.org/10.1002/spip.228},
    volume = {10},
    year = {2005}
}

@article{citeulike:5128170,
    abstract = {This paper presents a novel method to derive a Petri net from any specification model that can be mapped
into a state-based representation with arcs labeled with symbols from an alphabet of events (a Transition System, {TS}).
The method is based on the theory of regions for Elementary Transition Systems ({ETS}). Previous work has shown that,
for any {ETS}, there exists a Petri Net with minimum transition count (one transition for each label) with a
reachability graph isomorphic to the original Transition System. Our method extends and implements that theory by using
the following three mechanisms that provide a framework for synthesis of safe Petri nets from arbitrary {TSs}. First,
the requirement of isomorphism is relaxed to bisimulation of {TSs}, thus extending the class of synthesizable {TSs} to a
new class called {Excitation-Closed} Transition Systems ({ECTS}). Second, for the first time, we propose a method of
{PN} synthesis for an arbitrary {TS} based on mapping a {TS} event into a set 
of transition labels in a {PN}. Third, the notion of irredundant region set is exploited, to minimize the number of
places in the net without affecting its behavior. The synthesis method can derive different classes of place-irredundant
Petri Nets (e.g., pure, free choice, unique choice) from the same {TS}, depending on the constraints imposed on the
synthesis algorithm. This method has been implemented and applied in different frameworks. The results obtained from the
experiments have demonstrated the wide applicability of the method},
    author = {Cortadella, J. and Kishinevsky, M. and Lavagno, L. and Yakovlev, A.},
    booktitle = {Computers, IEEE Transactions on},
    citeulike-article-id = {5128170},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/12.707587},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=707587},
    doi = {10.1109/12.707587},
    journal = {Computers, IEEE Transactions on},
    keywords = {proposal},
    number = {8},
    pages = {859--882},
    posted-at = {2009-07-12 19:27:47},
    priority = {2},
    title = {Deriving Petri nets from finite transition systems},
    url = {http://dx.doi.org/10.1109/12.707587},
    volume = {47},
    year = {1998}
}

@electronic{citeulike:5128143,
    abstract = {Understanding the dynamic behavior of a workflow is crucial for being able to modify, maintain, and
improve it. A particularly difficult aspect of some behavior is concurrency. Automated techniques which seek to mine
workflow data logs to discover information about the workflows must be able to handle the concurrency that manifests
itself in the workflow executions. This paper presents techniques to discover patterns of concurrent behavior from
traces of workflow events. The techniques are based on a probabilistic analysis of the event traces. Using metrics for
the number, frequency, and regularity of event occurrences, a determination is made of the likely concurrent behavior
being manifested by the system. Discovering this behavior can help a workflow designer better understand and improve the
work processes they are managing.},
    author = {Cook, Jonathan E. and Du, Zhidian and Liu, Chongbing and Wolf, Alexander L. and Er},
    citeulike-article-id = {5128143},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.4990},
    keywords = {proposal},
    posted-at = {2009-07-12 18:35:49},
    priority = {2},
    title = {Discovering Models of Behavior for Concurrent Workflows},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.4990},
    year = {2004}
}

@incollection{citeulike:5128110,
    abstract = {The topic of process mining has attracted the attention of both researchers and tool vendors in the
Business Process Management ({BPM}) space. The goal of process mining is to discover process models from event logs,
i.e., events logged by some information system are used to extract information about activities and their causal
relations. Several algorithms have been proposed for process mining. Many of these algorithms cannot deal with
concurrency. Other typical problems are the presence of duplicate activities, hidden activities, non-free-choice
constructs, etc. In addition, real-life logs contain noise (e.g., exceptions or incorrectly logged events) and are
typically incomplete (i.e., the event logs contain only a fragment of all possible behaviors). To tackle these problems
we propose a completely new approach based on genetic algorithms. As can be expected, a genetic approach is able to deal
with noise and incompleteness. However, it is not easy to represent processes properly in a 
genetic setting. In this paper, we show a genetic process mining approach using the so-called causal matrix as a
representation for individuals. We elaborate on the relation between Petri nets and this representation and show that
genetic algorithms can be used to discover Petri net models from event logs. Keywords: Process Mining, Petri Nets,
Genetic Algorithms, Process Discovery, Business Process Intelligence, Business Activity Monitoring.},
    author = {van der Aalst, W. M. P. and de Medeiros, Alves K. A. and Weijters, A. J. M. M.},
    citeulike-article-id = {5128110},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11494744\_5},
    citeulike-linkout-1 = {http://www.springerlink.com/content/kue571vhwbm6x05n},
    doi = {10.1007/11494744\_5},
    journal = {Applications and Theory of Petri Nets 2005},
    keywords = {proposal},
    pages = {48--69},
    posted-at = {2009-07-12 17:40:46},
    priority = {2},
    title = {Genetic Process Mining},
    url = {http://dx.doi.org/10.1007/11494744\_5},
    year = {2005}
}

@article{citeulike:5128101,
    abstract = {Contemporary workflow management systems are driven by explicit process models, i.e., a completely
specified workflow design is required in order to enact a given workflow process. Creating a workflow design is a
complicated time-consuming process and typically, there are discrepancies between the actual workflow processes and the
processes as perceived by the management. Therefore, we propose a technique for rediscovering workflow models. This
technique uses workflow logs to discover the workflow process as it is actually being executed. The workflow log
contains information about events taking place. We assume that these events are totally ordered and each event refers to
one task being executed for a single case. This information can easily be extracted from transactional information
systems (e.g., Enterprise Resource Planning systems such as {SAP} and Baan). The rediscovering technique proposed in
this paper can deal with noise and can also be used to validate workflow processes by 
uncovering and measuring the discrepancies between prescriptive models and actual process executions.},
    address = {Amsterdam, The Netherlands, The Netherlands},
    author = {Weijters, A. J. M. M. and van der Aalst, W. M. P.},
    citeulike-article-id = {5128101},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1273325},
    issn = {1069-2509},
    journal = {Integr. Comput.-Aided Eng.},
    keywords = {proposal},
    number = {2},
    pages = {151--162},
    posted-at = {2009-07-12 17:36:56},
    priority = {2},
    publisher = {IOS Press},
    title = {Rediscovering workflow models from event-based data using little thumb},
    url = {http://portal.acm.org/citation.cfm?id=1273325},
    volume = {10},
    year = {2003}
}

@article{citeulike:3718014,
    abstract = {Abstract  Process mining includes the automated discovery of processes from event logs. Based on
observed events (e.g., activities being executed or messages being exchanged) a process model is constructed. One of the
essential problems in process mining is that one cannot assume to have seen all possible behavior. At best, one has seen
a representative subset. Therefore, classical synthesis techniques are not suitable as they aim at finding a model that
is able to exactly reproduce the log. Existing process mining techniques try to avoid such  ” overfitting” by
generalizing the model to allow for more behavior. This generalization is often driven by the representation language
and very crude assumptions about completeness. As a result, parts of the model are  ” overfitting” (allow only for what
has actually been observed) while other parts may be  ” underfitting” (allow for much more behavior without strong
support for it). None of the existing techniques enables the user to control the 
balance between  ” overfitting” and  ” underfitting”. To address this, we propose a two-step approach. First, using a
configurable approach, a transition system is constructed. Then, using the  ” theory of regions”, the model is
synthesized. The approach has been implemented in the context of {ProM} and overcomes many of the limitations of
traditional approaches.},
    author = {van der Aalst, W. and Rubin, V. and Verbeek, H. and van Dongen, B. and Kindler, E. and G\"{u}nther, C.},
    booktitle = {Software \& Systems Modeling},
    citeulike-article-id = {3718014},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10270-008-0106-z},
    citeulike-linkout-1 = {http://www.springerlink.com/content/u43v780550278h4l},
    citeulike-linkout-2 = {http://link.springer.com/article/10.1007/s10270-008-0106-z},
    doi = {10.1007/s10270-008-0106-z},
    journal = {Software and Systems Modeling},
    keywords = {proposal},
    number = {1},
    pages = {87--111},
    posted-at = {2009-07-11 23:17:06},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Process mining: a two-step approach to balance between underfitting and overfitting},
    url = {http://dx.doi.org/10.1007/s10270-008-0106-z},
    volume = {9},
    year = {2009}
}

@phdthesis{citeulike:5120757,
    address = {Boulder, CO, USA},
    author = {Cook, Jonathan E.},
    citeulike-article-id = {5120757},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=924798},
    isbn = {0-591-25740-8},
    keywords = {proposal},
    posted-at = {2009-07-11 22:03:30},
    priority = {2},
    publisher = {University of Colorado at Boulder},
    title = {Process discovery and validation through event-data analysis},
    url = {http://portal.acm.org/citation.cfm?id=924798},
    year = {1996}
}

@article{citeulike:5120603,
    author = {Biermann, A. W. and Feldman, J.},
    citeulike-article-id = {5120603},
    journal = {IEEE Trans. Computers},
    keywords = {proposal},
    pages = {592--597},
    posted-at = {2009-07-11 21:35:17},
    priority = {2},
    title = {On the Synthesis of {Finite-State} Machines from Samples of Their Behavior},
    year = {1972}
}

@article{citeulike:1222062,
    abstract = {Enterprise information systems support and control operational business processes ranging from simple
internal back-office processes to complex interorganizational processes. Technologies such as workflow management
({WFM}), enterprise application integration ({EAI}), enterprise resource planning ({ERP}), and web services ({WS})
typically focus on the realization of {IT} support rather than monitoring the operational business processes. Process
mining aims at extracting information from event logs to capture the business process as it is being executed. In this
paper, we put the topic of process mining into context, discuss the main issues around process mining, and finally we
introduce the papers in this special issue.},
    address = {Amsterdam, The Netherlands, The Netherlands},
    citeulike-article-id = {1222062},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=982251},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.compind.2003.10.001},
    citeulike-linkout-2 =
{http://www.sciencedirect.com/science/article/B6V2D-4B6CRVW-1/1/96d1afa0c132b42d9c072df93204b68c},
    doi = {10.1016/j.compind.2003.10.001},
    issn = {01663615},
    journal = {Computers in Industry},
    keywords = {proposal},
    month = apr,
    number = {3},
    pages = {231--244},
    posted-at = {2009-07-11 16:11:58},
    priority = {2},
    publisher = {Elsevier Science Publishers B. V.},
    title = {Process mining: a research agenda},
    url = {http://dx.doi.org/10.1016/j.compind.2003.10.001},
    volume = {53},
    year = {2004}
}

@inproceedings{citeulike:5112229,
    abstract = {Software is a ubiquitous component of our daily life. We often depend on the correct working of software
systems. Due to the difficulty and complexity of software systems, bugs and anomalies are prevalent. Bugs have caused
billions of dollars loss, in addition to privacy and security threats. In this work, we address software reliability
issues by proposing a novel method to classify software behaviors based on past history or runs. With the technique, it
is possible to generalize past known errors and mistakes to capture failures and anomalies. Our technique first mines a
set of discriminative features capturing repetitive series of events from program execution traces. It then performs
feature selection to select the best features for classification. These features are then used to train a classifier to
detect failures. Experiments and case studies on traces of several benchmark software systems and a real-life
concurrency bug from {MySQL} server show the utility of the technique in 
capturing failures and anomalies. On average, our pattern-based classification technique outperforms the baseline
approach by 24.68\% in accuracy.},
    address = {New York, NY, USA},
    author = {Lo, David and Cheng, Hong and Han, Jiawei and Khoo, Siau C. and Sun, Chengnian},
    booktitle = {KDD '09: Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data
mining},
    citeulike-article-id = {5112229},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1557019.1557083},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1557019.1557083},
    doi = {10.1145/1557019.1557083},
    isbn = {978-1-60558-495-9},
    keywords = {proposal},
    location = {Paris, France},
    pages = {557--566},
    posted-at = {2009-07-11 00:34:50},
    priority = {2},
    publisher = {ACM},
    title = {Classification of software behaviors for failure detection: a discriminative pattern mining approach},
    url = {http://dx.doi.org/10.1145/1557019.1557083},
    year = {2009}
}

@techreport{citeulike:5090131,
    address = {Pittsburgh, PA 15213},
    author = {Pomeroy-Huff, Marsha and Mullaney, Julia and Cannon, Robert and Seburn, Mark},
    citeulike-article-id = {5090131},
    editor = {Humphrey, Watts S.},
    institution = {Software Engineering Institute},
    keywords = {proposal},
    organization = {Carnegie Mellon University},
    posted-at = {2009-07-07 22:57:28},
    priority = {2},
    title = {The Personal Software Process ({PSP})
Body of Knowledge, Version 1.0},
    year = {2008}
}

@misc{Sayyad-Shirabad+Menzies:2005,
    author = {Shirabad, J. Sayyad and Menzies, T. J.},
    citeulike-article-id = {5070504},
    citeulike-linkout-0 = {http://promise.site.uottawa.ca/SERepository},
    howpublished = {School of Information Technology and Engineering, University of Ottawa, Canada},
    keywords = {proposal, white-paper},
    posted-at = {2009-07-06 03:15:39},
    priority = {2},
    title = {{The {PROMISE} Repository of Software Engineering Databases.}},
    url = {http://promise.site.uottawa.ca/SERepository},
    year = {2005}
}

@article{citeulike:328044,
    abstract = {Many software process methods and tools presuppose the existence of a formal model of a process.
Unfortunately, developing a formal model for an on-going, complex process can be difficult, costly, and error prone.
This presents a practical barrier to the adoption of process technologies, which would be lowered by automated
assistance in creating formal models. To this end, we have developed a data analysis technique that we term process
discovery. Under this technique, data describing process events are first captured from an on-going process and then
used to generate a formal model of the behavior of that process. In this article we describe a Markov method that we
developed specifically for process discovery, as well as describe two additional methods that we   adopted from other
domains and augmented for our purposes. The three methods range from the purely algorithmic to the purely statistical.
We compare the methods and discuss their application in an industrial case study.},
    address = {New York, NY, USA},
    author = {Cook, Jonathan E. and Wolf, Alexander L.},
    citeulike-article-id = {328044},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=287001},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/287000.287001},
    doi = {10.1145/287000.287001},
    issn = {1049-331X},
    journal = {ACM Trans. Softw. Eng. Methodol.},
    keywords = {white-paper},
    month = jul,
    number = {3},
    pages = {215--249},
    posted-at = {2009-07-03 13:04:14},
    priority = {2},
    publisher = {ACM},
    title = {Discovering models of software processes from event-based data},
    url = {http://dx.doi.org/10.1145/287000.287001},
    volume = {7},
    year = {1998}
}

@incollection{citeulike:5044991,
    abstract = {Modern enterprises increasingly use the workflow paradigm to prescribe how business processes should be
performed. Processes are typically modeled as annotated activity graphs. We present an approach for a system that
constructs process models from logs of past, unstructured executions of the given process. The graph so produced
conforms to the dependencies and past executions present in the log. By providing models that capture the previous
executions of the process, this technique allows easier introduction of a workflow system and evaluation and evolution
of existing process models. We also present results from applying the algorithm to synthetic data sets as well as
process logs obtained from an {IBM} Flowmark installation.},
    author = {Agrawal, Rakesh and Gunopulos, Dimitrios and Leymann, Frank},
    booktitle = {Advances in Database Technology — EDBT'98},
    chapter = {31},
    citeulike-article-id = {5044991},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/bfb0101003},
    citeulike-linkout-1 = {http://www.springerlink.com/content/0836165x01666l40},
    doi = {10.1007/bfb0101003},
    editor = {Schek, Hans-J\"{o}rg and Alonso, Gustavo and Saltor, Felix and Ramos, Isidro},
    isbn = {978-3-540-64264-0},
    journal = {Advances in Database Technology — EDBT'98},
    keywords = {white-paper},
    pages = {467--483},
    posted-at = {2009-07-03 12:55:20},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Mining process models from workflow logs Advances in Database Technology — {EDBT}'98},
    url = {http://dx.doi.org/10.1007/bfb0101003},
    volume = {1377},
    year = {1998}
}

@inproceedings{citeulike:5043676,
    abstract = {Software repositories such as source control systems, defect tracking systems, and archived
communications between project personnel are used to help manage the progress of software projects. Software
practitioners and researchers more and more recognize the potential benefit of mining this information to support the
maintenance of software systems, improve software design/reuse, and empirically validate novel ideas and techniques.
Research is now proceeding to uncover the ways in which mining these repositories can help to understand software
development, to support predictions about software development, and to plan various evolutionary aspects of software
projects.},
    address = {Washington, DC, USA},
    author = {Gall, Harald and Lanza, Michele and Zimmermann, Thomas},
    booktitle = {ICSE COMPANION '07: Companion to the proceedings of the 29th International Conference on Software
Engineering},
    citeulike-article-id = {5043676},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1248821.1248961},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icsecompanion.2007.8},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4222702},
    doi = {10.1109/icsecompanion.2007.8},
    isbn = {0-7695-2892-9},
    journal = {Software Engineering - Companion, 2007. ICSE 2007 Companion. 29th International Conference on},
    keywords = {white-paper},
    pages = {107--108},
    posted-at = {2009-07-03 02:09:42},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {4th International Workshop on Mining Software Repositories ({MSR} 2007)},
    url = {http://dx.doi.org/10.1109/icsecompanion.2007.8},
    year = {2007}
}

@incollection{citeulike:5043673,
    abstract = {Under the umbrella of buzzwords such as  Business Activity Monitoring  ({BAM}) and  Business Process
Intelligence  ({BPI}) both academic (e.g., {EMiT}, Little Thumb, {InWoLvE}, Process Miner, and {MinSoN}) and commercial
tools (e.g., {ARIS} {PPM}, {HP} {BPI}, and {ILOG} {JViews}) have been developed. The goal of these tools is to extract
knowledge from event logs (e.g., transaction logs in an {ERP} system or audit trails in a {WFM} system), i.e., to do
process mining. Unfortunately, tools use different formats for reading/storing log files and present their results in
different ways. This makes it difficult to use different tools on the same data set and to compare the mining results.
Furthermore, some of these tools implement concepts that can be very useful in the other tools but it is often difficult
to combine tools. As a result, researchers working on new process mining techniques are forced to build a mining
infrastructure from scratch or test their techniques in an isolated way, 
disconnected from any practical applications. To overcome these kind of problems, we have developed the {ProM}
framework, i.e., an  pluggable  environment for process mining. The framework is flexible with respect to the input and
output format, and is also open enough to allow for the easy reuse of code during the implementation of new process
mining ideas. This paper introduces the {ProM} framework and gives an overview of the plug-ins that have been
developed.},
    address = {Berlin, Heidelberg},
    author = {van Dongen, B. F. and de Medeiros, A. K. A. and Verbeek, H. M. W. and Weijters, A. J. M. M. and van der
Aalst, W. M. P.},
    booktitle = {Applications and Theory of Petri Nets 2005},
    chapter = {25},
    citeulike-article-id = {5043673},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11494744\_25},
    citeulike-linkout-1 = {http://www.springerlink.com/content/wvc1l0detqnj4tcm},
    doi = {10.1007/11494744\_25},
    editor = {Ciardo,, Gianfranco and Darondeau,, Philippe},
    isbn = {978-3-540-26301-2},
    journal = {Applications and Theory of Petri Nets 2005},
    keywords = {white-paper},
    pages = {444--454},
    posted-at = {2009-07-03 01:44:31},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {The {ProM} Framework: A New Era in Process Mining Tool Support},
    url = {http://dx.doi.org/10.1007/11494744\_25},
    volume = {3536},
    year = {2005}
}

@inbook{citeulike:1885717,
    abstract = {Software development processes are often not explicitly modelled and sometimes even chaotic. In order to
keep track of the involved documents and files, engineers use Software Configuration Management ({SCM}) systems. Along
the way, those systems collect and store information on the software process itself. Thus, {SCM} information can be used
for constructing explicit process models, which is called software process mining. In this paper we show that (1) a
Process Mining Framework can be used for obtaining software process models as well as for analysing and optimising them;
(2) an algorithmic approach, which arose from our research on software processes, is integrated in the framework.},
    address = {Berlin, Heidelberg},
    author = {Rubin, Vladimir and G\"{u}nther, Christian W. and Aalst, Wil M. P. and Kindler, Ekkart and Dongen,
Boudewijn F. and Sch\"{a}fer, Wilhelm},
    booktitle = {Software Process Dynamics and Agility},
    chapter = {15},
    citeulike-article-id = {1885717},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-72426-1\_15},
    citeulike-linkout-1 = {http://www.springerlink.com/content/e863ut5t2765110r},
    doi = {10.1007/978-3-540-72426-1\_15},
    editor = {Wang, Qing and Pfahl, Dietmar and Raffo, David M.},
    isbn = {978-3-540-72425-4},
    journal = {Software Process Dynamics and Agility},
    keywords = {white-paper},
    pages = {169--181},
    posted-at = {2009-07-03 01:42:24},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {Process Mining Framework for Software Processes},
    url = {http://dx.doi.org/10.1007/978-3-540-72426-1\_15},
    volume = {4470},
    year = {2007}
}

@article{citeulike:5043672,
    abstract = {The paper discusses the problems that a software development organization must address in order to
assess and improve its software processes. In particular, the authors are involved in a project aiming at assessing and
improving the current practice and the quality manual of the Business Unit Telecommunications for Defense ({BUTD}) of a
large telecommunications company. The paper reports on the usage of formal process modeling languages to detect
inconsistencies, ambiguities, incompleteness, and opportunities for improvement of both the software process and its
documentation},
    author = {Bandinelli, S. and Fuggetta, A. and Lavazza, L. and Loi, M. and Picco, G. P.},
    booktitle = {Software Engineering, IEEE Transactions on},
    citeulike-article-id = {5043672},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/32.387473},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=387473},
    day = {06},
    doi = {10.1109/32.387473},
    institution = {CEFRIEL, Milan},
    issn = {0098-5589},
    journal = {Software Engineering, IEEE Transactions on},
    keywords = {white-paper},
    month = may,
    number = {5},
    pages = {440--454},
    posted-at = {2009-07-03 01:38:26},
    priority = {2},
    publisher = {IEEE},
    title = {Modeling and improving an industrial software process},
    url = {http://dx.doi.org/10.1109/32.387473},
    volume = {21},
    year = {1995}
}

@incollection{citeulike:5043670,
    abstract = {Capturing a process as it is being executed in a descriptive process model is a key activity in process
improvement. Performing descriptive process modeling in industry environments is hindered by factors such as dispersed
process knowledge or inconsistent understanding of the process among different project members. A systematic approach
can alleviate some of the problems. This paper sketches fundamental difficulties in gaining process knowledge and
describes a systematic approach to process elicitation. The approach employs techniques from other domains like social
sciences that have been tailored to the process elicitation context and places them in a decision framework that gives
guidance on selecting appropriate techniques in specific modeling situations. Initial experience with the approach is
reported.},
    author = {Becker-Kornstaedt, Ulrike},
    citeulike-article-id = {5043670},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-44813-6\_27},
    citeulike-linkout-1 = {http://www.springerlink.com/content/fcwyxgtv9w6grfft},
    doi = {10.1007/3-540-44813-6\_27},
    journal = {Product Focused Software Process Improvement},
    keywords = {white-paper},
    pages = {312--325},
    posted-at = {2009-07-03 01:36:12},
    priority = {2},
    title = {Towards Systematic Knowledge Elicitation for Descriptive Software Process Modeling},
    url = {http://dx.doi.org/10.1007/3-540-44813-6\_27},
    year = {2001}
}

@incollection{citeulike:5043664,
    abstract = {This paper describes a reference model for open source software ({OSS}) processes and its application
towards discovering such processes from {OSS} project artifacts. This reference model is the means to map evidence of an
enacted process to a classification of agents, resources, tools, and activities that characterize the process.},
    author = {Jensen, Chris and Scacchi, Walt},
    citeulike-article-id = {5043664},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-0-387-72486-7\_26},
    citeulike-linkout-1 = {http://www.springerlink.com/content/6140868153323g56},
    doi = {10.1007/978-0-387-72486-7\_26},
    journal = {Open Source Development, Adoption and Innovation},
    keywords = {proposal, white-paper},
    pages = {265--270},
    posted-at = {2009-07-03 01:18:35},
    priority = {2},
    title = {Guiding the Discovery of Open Source Software Processes with a Reference Model},
    url = {http://dx.doi.org/10.1007/978-0-387-72486-7\_26},
    year = {2007}
}

@electronic{citeulike:5043104,
    author = {Conradi, Reidar},
    citeulike-article-id = {5043104},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.3010},
    keywords = {white-paper},
    posted-at = {2009-07-02 18:41:32},
    priority = {2},
    title = {{SPI} frameworks: {TQM}, {CMM}, {SPICE}, {ISO} 9001, {QIP} Experiences and trends - Norwegian {SPIQ}
project},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.3010}
}

@article{citeulike:5043101,
    abstract = {Mining knowledge about ordering from sequence data is an important problem with many applications, such
as bioinformatics, Web mining, network management, and intrusion detection. For example, if many customers follow a
partial order in their purchases of a series of products, the partial order can be used to predict other related
customers' future purchases and develop marketing campaigns. Moreover, some biological sequences (e.g., microarray data)
can be clustered based on the partial orders shared by the sequences. Given a set of items, a total order of a subset of
items can be represented as a string. A string database is a multiset of strings. In this paper, we identify a novel
problem of mining frequent closed partial orders from strings. Frequent closed partial orders capture the nonredundant
and interesting ordering information from string databases. Importantly, mining frequent closed partial orders can
discover meaningful knowledge that cannot be disclosed by previous data mining 
techniques. However, the problem of mining frequent closed partial orders is challenging. To tackle the problem, we
develop Frecpo (for Frequent closed partial order), a practically efficient algorithm for mining the complete set of
frequent closed partial orders from large string databases. Several interesting pruning techniques are devised to speed
up the search. We report an extensive performance study on both real data sets and synthetic data sets to illustrate the
effectiveness and the efficiency of our approach.},
    address = {Piscataway, NJ, USA},
    author = {Pei, Jian and Wang, Haixun and Liu, Jian and Wang, Ke and Wang, Jianyong and Yu, Philip S.},
    booktitle = {Knowledge and Data Engineering, IEEE Transactions on},
    citeulike-article-id = {5043101},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1176172},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/tkde.2006.172},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1704800},
    doi = {10.1109/tkde.2006.172},
    issn = {1041-4347},
    journal = {IEEE Trans. on Knowl. and Data Eng.},
    keywords = {white-paper},
    month = nov,
    number = {11},
    pages = {1467--1481},
    posted-at = {2009-07-02 18:36:57},
    priority = {2},
    publisher = {IEEE Educational Activities Department},
    title = {Discovering Frequent Closed Partial Orders from Strings},
    url = {http://dx.doi.org/10.1109/tkde.2006.172},
    volume = {18},
    year = {2006}
}

@electronic{citeulike:5043099,
    abstract = {Sequences of events describing the behavior and actions of users or systems can be collected in several
domains. An episode is a collection of events that occur relatively close to each other in a given partial order. We
consider the problem of discovering frequently occurring episodes in a sequence. Once such episodes are known, one can
produce rules for describing or predicting the behavior of the sequence. We give efficient algorithms for the discovery
of all frequent episodes from a given class of episodes, and present detailed experimental results. The methods are in
use in telecommunication alarm management.},
    author = {Mannila, Heikki and Toivonen, Hannu and Verkamo, A. Inkeri},
    citeulike-article-id = {5043099},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.7.3051},
    keywords = {white-paper},
    posted-at = {2009-07-02 18:34:20},
    priority = {2},
    title = {Discovery of Frequent Episodes in Event Sequences},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.7.3051},
    year = {1997}
}

@incollection{citeulike:5043097,
    abstract = {Sequential pattern mining is an important data mining problem with broad applications. However, it is
also a challenging problem since the mining may have to generate or examine a combinatorially explosive number of
intermediate subsequences. Recent studies have developed two major classes of sequential pattern mining methods: (1) a
candidate generation-and-test approach, represented by ({i)GSP} [30], a horizontal format-based sequential pattern
mining method, and (ii) {SPADE} [36], a vertical format-based method; and (2) a sequential pattern growth method,
represented by {PrefixSpan} [26] and its further extensions, such as {CloSpan} for mining closed sequential patterns
[35].},
    address = {Berlin/Heidelberg},
    author = {Han, J. and Pei, J. and Yan, X.},
    booktitle = {Foundations and Advances in Data Mining },
    chapter = {8},
    citeulike-article-id = {5043097},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11362197\_8},
    citeulike-linkout-1 = {http://www.springerlink.com/content/326516701585212q},
    doi = {10.1007/11362197\_8},
    editor = {Chu, Wesley and Lin, Tsau},
    isbn = {3-540-25057-3},
    journal = {Foundations and Advances in Data Mining},
    keywords = {white-paper},
    pages = {183--220},
    posted-at = {2009-07-02 18:32:10},
    priority = {2},
    publisher = {Springer-Verlag},
    series = {Studies in Fuzziness and Soft Computing},
    title = {Sequential Pattern Mining by {Pattern-Growth}: Principles and Extensions*},
    url = {http://dx.doi.org/10.1007/11362197\_8},
    volume = {180},
    year = {2005}
}

@inproceedings{citeulike:5043094,
    abstract = {Abstract. The Unification-based Temporal Grammar is a temporal extension of static unification-based
grammars. 
It defines a hierarchical temporal rule language to express complex patterns present in multivariate time series. The
Temporal Data Mining Method is the accompanying framework to discover temporal knowledge based on this rule language. A
semiotic hierarchy of temporal patterns, which are not a priori given, is build in a bottom up manner from static
logical descriptions of multivariate time instants. We demonstrate the methods using music data, extracting typical
parts of songs. 1},
    author = {M\"{o}rchen, Fabian and Ultsch, Alfred},
    booktitle = {Proceedings of the 27th Annual German Conference in Artificial Intelligence (KI'04},
    citeulike-article-id = {5043094},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.88.603},
    keywords = {white-paper},
    pages = {127--140},
    posted-at = {2009-07-02 18:24:06},
    priority = {2},
    title = {Mining hierarchical temporal patterns in multivariate time series},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.88.603},
    year = {2004}
}

@electronic{citeulike:5043086,
    abstract = {Rule mining is the practice of discovering interesting and unexpected rules from large data sets.
Depending on the exact problem formulation, this may be a very complicated problem. Existing methods typically make
strong simplifying assumptions about the form of the rules, and limit the measure of rule quality to simple properties,
such as confidence. Because confidence in itself is not a good indicator of how interesting a rule is to the user, the
mined rules are typically sorted according to some secondary interestingness measure. In this paper we present a rule
mining method that is based on genetic programming. Because we use specialized pattern matching hardware to evaluate
each rule, our method supports a very wide range of rule formats, and can use any reasonable fitness measure. We develop
a fitness measure that is well-suited for our method, and give empirical results of applying the method to synthetic and
real-world data sets.},
    author = {S{\ae}trom, P\r{a}l and Hetland, Magnus L.},
    citeulike-article-id = {5043086},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.3417},
    keywords = {white-paper},
    posted-at = {2009-07-02 18:16:42},
    priority = {2},
    title = {Unsupervised Temporal Rule Mining with Genetic Programming and Specialized Hardware},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.3417},
    year = {2003}
}

@article{citeulike:5042856,
    abstract = {Most of the software in regular use in businesses and organisations all over the world cannot be
completely specified. It cannot be implemented, once and for all. 
Both the original implementation and the inevitable subsequent evolution (maintenance) are a continual learning
experience driven, inter alia, by feedback from the results of the behaviour under execution of the software, as
perceived by various stakeholders, by advances and growth in the user organisations and by adaptation to changes in the
external world, both independent and as a result of installation and use of the software. Real world, termed {type-E},
software is essentially evolutionary in nature. The study of the processes of evolution of such software is of
considerable interest, as is that of the domains that co-evolve with the software. After briefly discussing the meaning
of the term evolution in the context of software, its technology, the software process and related domains, this paper
describes some of the facets 
of the evolution phenomenon and implications to the evolution process as identified during many years of active interest
in the topic.},
    author = {Lehman, Meir M. and Ramil, Juan F.},
    citeulike-article-id = {5042856},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a:1020557525901},
    citeulike-linkout-1 = {http://www.springerlink.com/content/rq6u388503844005},
    day = {1},
    doi = {10.1023/a:1020557525901},
    issn = {10227091},
    journal = {Annals of Software Engineering},
    keywords = {white-paper},
    month = dec,
    number = {1},
    pages = {275--309},
    posted-at = {2009-07-02 15:36:19},
    priority = {2},
    publisher = {Springer Netherlands},
    title = {Software Evolution and Software Evolution Processes},
    url = {http://dx.doi.org/10.1023/a:1020557525901},
    volume = {14},
    year = {2002}
}

@inproceedings{citeulike:5029482,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has
opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Humphrey, Watts S.},
    booktitle = {ESP '97: Papers presented at the seventh workshop on Empirical studies of programmers},
    citeulike-article-id = {5029482},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=266418},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/266399.266418},
    doi = {10.1145/266399.266418},
    isbn = {0-89791-992-0},
    keywords = {white-paper},
    location = {Alexandria, Virginia, United States},
    pages = {224--232},
    posted-at = {2009-07-01 05:18:32},
    priority = {2},
    publisher = {ACM},
    title = {What do we know about programming?},
    url = {http://dx.doi.org/10.1145/266399.266418},
    year = {1997}
}

@techreport{citeulike:5012661,
    address = {Finland},
    author = {Vilo, J.},
    citeulike-article-id = {5012661},
    institution = {University of Helsinki},
    keywords = {proposal},
    posted-at = {2009-06-29 14:40:15},
    priority = {2},
    school = {Department of Computer Science},
    title = {Discovering frequent patterns from strings.},
    year = {1998}
}

@inproceedings{citeulike:775528,
    abstract = {We are given a large database of customer transactions, where each
transaction consists of customer-id, transaction time, and the items
bought in the transaction. We introduce the problem of mining sequential
patterns over such databases. We present three algorithms to solve this
problem, and empirically evaluate their performance using synthetic
data. Two of the proposed algorithms, {AprioriSome} and {AprioriAll}, have
comparable performance, albeit {AprioriSome} performs a little better when
the minimum number of customers that must support a sequential pattern
is low. Scale-up experiments show that both {AprioriSome} and {AprioriAll}
scale linearly with the number of customer transactions. They also have
excellent scale-up properties with respect to the number of transactions
per customer and the number of items in a transaction},
    address = {Los Alamitos, CA, USA},
    author = {Agrawal, R. and Srikant, R.},
    booktitle = {Data Engineering, 1995. Proceedings of the Eleventh International Conference on},
    citeulike-article-id = {775528},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/ICDE.1995.380415},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icde.1995.380415},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=380415},
    doi = {10.1109/icde.1995.380415},
    institution = {IBM Almaden Res. Center, San Jose, CA},
    isbn = {0-8186-6910-1},
    issn = {1063-6382},
    journal = {Data Engineering, International Conference on},
    month = mar,
    pages = {3--14},
    posted-at = {2009-06-29 13:48:02},
    priority = {2},
    publisher = {IEEE},
    title = {Mining sequential patterns},
    url = {http://dx.doi.org/10.1109/icde.1995.380415},
    volume = {0},
    year = {1995}
}

@article{citeulike:707616,
    abstract = {An on-line algorithm is presented for constructing the suffix tree for a given string in time linear in
the length of the string. The new algorithm has the desirable property of processing the string symbol by symbol from
left to right. It has always the suffix tree for the scanned part of the string ready. The method is developed as a
linear-time version of a very simple algorithm for (quadratic size) suffix tries. Regardless of its quadratic worst-case
this latter algorithm can be a good...},
    author = {Ukkonen, Esko},
    citeulike-article-id = {707616},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.751},
    journal = {Algorithmica},
    keywords = {proposal},
    number = {3},
    pages = {249--260},
    posted-at = {2009-06-29 12:35:04},
    priority = {2},
    title = {{On-Line} Construction of Suffix Trees},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.751},
    volume = {14},
    year = {1995}
}

@inproceedings{citeulike:3978085,
    abstract = {Time series motifs are approximately repeated patterns foundwithin the data. Such motifs have utility
for many data mining algorithms, including rule-discovery,novelty-detection, summarization and clustering. Since the
formalization of the problem and the introduction of efficient linear time algorithms, motif discovery has been
successfully applied tomany domains, including medicine, motion capture, robotics and meteorology.},
    address = {New York, NY, USA},
    author = {Yankov, Dragomir and Keogh, Eamonn and Medina, Jose and Chiu, Bill and Zordan, Victor},
    booktitle = {KDD '07: Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data
mining},
    citeulike-article-id = {3978085},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1281282},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1281192.1281282},
    doi = {10.1145/1281192.1281282},
    isbn = {978-1-59593-609-7},
    keywords = {proposal},
    location = {San Jose, California, USA},
    pages = {844--853},
    posted-at = {2009-06-29 02:13:44},
    priority = {2},
    publisher = {ACM},
    title = {Detecting time series motifs under uniform scaling},
    url = {http://dx.doi.org/10.1145/1281192.1281282},
    year = {2007}
}

@inproceedings{citeulike:3025877,
    abstract = {The problem of finding a specified pattern in a time series database (i.e. query by content) has
received much attention and is now a relatively mature field. In contrast, the important problem of enumerating all
surprising or interesting patterns has received far less attention. This problem requires a meaningful definition of
"surprise", and an efficient search technique. All previous attempts at finding surprising patterns in time series use a
very limited notion of surprise, and/or do not scale to massive datasets. To overcome these limitations we introduce a
novel technique that defines a pattern surprising if the frequency of its occurrence differs substantially from that
expected by chance, given some previously seen data.},
    address = {New York, NY, USA},
    author = {Keogh, Eamonn and Lonardi, Stefano and Bill 'Yuan chi' Chiu},
    booktitle = {KDD '02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data
mining},
    citeulike-article-id = {3025877},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=775047.775128},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/775047.775128},
    doi = {10.1145/775047.775128},
    isbn = {1-58113-567-X},
    keywords = {proposal},
    location = {Edmonton, Alberta, Canada},
    pages = {550--556},
    posted-at = {2009-06-28 23:06:23},
    priority = {2},
    publisher = {ACM},
    title = {Finding surprising patterns in a time series database in linear time and space},
    url = {http://dx.doi.org/10.1145/775047.775128},
    year = {2002}
}

@incollection{citeulike:5003404,
    abstract = {We consider the problem of finding frequent subsequences in sequential data. We examine three algorithms
using a trie with K levels. The {O(K} 2 n) breadth-first ({BF}) algorithm inserts a pattern into the trie at level k
only if level k-1 has been completed. The {O(Kn}) depth-first ({DF}) algorithm inserts a pattern and all its prefixes
into the trie before examining another pattern. A threshold is used to store only frequent subsequences. Since {DF}
cannot apply the threshold until the trie is complete, it makes poor use of memory. The heuristic depth-first ({HDF})
algorithm, a variant of {DF}, uses the threshold in the same manner as {BF}. {HDF} gains efficiency but loses a
predictable amount of accuracy.},
    author = {Jiang, Linhui and Hamilton, Howard},
    citeulike-article-id = {5003404},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-44886-1\_38},
    citeulike-linkout-1 = {http://www.springerlink.com/content/2egrwglmw19ebur7},
    doi = {10.1007/3-540-44886-1\_38},
    journal = {Advances in Artificial Intelligence},
    keywords = {proposal},
    pages = {992},
    posted-at = {2009-06-28 23:01:07},
    priority = {2},
    title = {Methods for Mining Frequent Sequential Patterns},
    url = {http://dx.doi.org/10.1007/3-540-44886-1\_38},
    year = {2003}
}

@incollection{citeulike:5003338,
    abstract = {In the last years, the completion of the human genome sequencing showed up a wide range of new
challenging issues involving raw data analysis. In particular, the discovery of information implicitly encoded in
biological sequences is assuming a prominent role in identifying genetic diseases and in deciphering biological
mechanisms. This information is usually represented by patterns frequently occurring in the sequences. Because of
biological observations, a specific class of patterns is becoming particularly interesting: frequent structured
patterns. In this respect, it is biologically meaningful to look at both  ” exact” and  ” approximate” repetitions of
the patterns within the available sequences. This paper gives a contribution in this setting by providing some
algorithms which allow to discover frequent structured patterns, either in  ” exact” or  ” approximate” form, present in
a collection of input biological sequences.},
    author = {Palopoli, Luigi and Terracina, Giorgio},
    citeulike-article-id = {5003338},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-36182-0\_6},
    citeulike-linkout-1 = {http://www.springerlink.com/content/aj3mqw9nx2q2d4cv},
    doi = {10.1007/3-540-36182-0\_6},
    journal = {Discovery Science},
    keywords = {proposal},
    pages = {283--296},
    posted-at = {2009-06-28 22:52:07},
    priority = {2},
    title = {Discovering Frequent Structured Patterns from String Databases: An Application to Biological Sequences},
    url = {http://dx.doi.org/10.1007/3-540-36182-0\_6},
    year = {2008}
}

@book{citeulike:465665,
    abstract = {{This introductory text offers a clear exposition of the algorithmic principles driving advances in
bioinformatics. Accessible to students in both biology and computer science, it strikes a unique balance between
rigorous mathematics and practical techniques, emphasizing the ideas underlying algorithms rather than offering a
collection of apparently unrelated problems.<br /> <br /> The book introduces biological and algorithmic ideas together,
linking issues in computer science to biology and thus capturing the interest of students in both subjects. It
demonstrates that relatively few design techniques can be used to solve a large number of practical problems in biology,
and presents this material intuitively.<br /> <br /> <i>An Introduction to Bioinformatics Algorithms</i> is one of the
first books on bioinformatics that can be used by students at an undergraduate level. It includes a dual table of
contents, organized by algorithmic idea and biological idea; discussions of biologically 
relevant problems, including a detailed problem formulation and one or more solutions for each; and brief biographical
sketches of leading figures in the field. These interesting vignettes offer students a glimpse of the inspirations and
motivations for real work in bioinformatics, making the concepts presented in the text more concrete and the techniques
more approachable.<br /> <br /> PowerPoint presentations, practical bioinformatics problems, sample code, diagrams,
demonstrations, and other materials can be found at the Author's website.}},
    author = {Jones, Neil C. and Pevzner, Pavel A.},
    citeulike-article-id = {465665},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262101068},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262101068},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262101068},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262101068},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262101068/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262101068},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262101068},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262101068},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262101068\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262101068},
    day = {01},
    howpublished = {Hardcover},
    isbn = {0262101068},
    month = aug,
    posted-at = {2009-06-28 22:34:44},
    priority = {2},
    publisher = {{The MIT Press}},
    title = {An Introduction to Bioinformatics Algorithms (Computational Molecular Biology)},
    url = {http://www.worldcat.org/isbn/0262101068},
    year = {2004}
}

@incollection{citeulike:3978065,
    abstract = {The {Unification-Based} Temporal Grammar is a temporal extension of static unification-based grammars.
It defines a hierarchical temporal rule language to express complex patterns present in multivariate time series. The
Temporal Data Mining Method is the accompanying framework to discover temporal knowledge based on this rule language. A
semiotic hierarchy of temporal patterns, which are not a priori given, is built in a bottom up manner from static
logical descriptions of multivariate time instants. We demonstrate the methods using music data, extracting typical
parts of songs.},
    address = {Berlin / Heidelberg, Germany},
    author = {M\"{o}rchen, Fabian and Ultsch, Alfred},
    booktitle = {KI 2004: Advances in Artificial Intelligence},
    citeulike-article-id = {3978065},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/b100351},
    citeulike-linkout-1 = {http://www.springerlink.com/content/vpd1gm94l1p3c833},
    doi = {10.1007/b100351},
    editor = {Biundo, Susanne and Fr\"{u}hwirth, Thom and Palm, G\"{u}nther},
    isbn = {978-3-540-23166-0},
    issn = {0302-9743 (Print) 1611-3349 (Online)},
    journal = {KI 2004: Advances in Artificial Intelligence},
    keywords = {proposal},
    pages = {127--140},
    posted-at = {2009-06-28 17:36:05},
    priority = {2},
    publisher = {Springer},
    series = {Lecture Notes in Artificial Intelligence},
    title = {Mining Hierarchical Temporal Patterns in Multivariate Time Series},
    url = {http://dx.doi.org/10.1007/b100351},
    volume = {3238},
    year = {2004}
}

@article{citeulike:3978076,
    abstract = {{Abstract\&nbsp;\&nbsp;We} present a new method for the understandable description of local temporal
relationships in multivariate data, called Time Series Knowledge Mining ({TSKM}). We define the Time Series Knowledge
Representation ({TSKR}) as a new language for expressing temporal knowledge in time interval data. The patterns have a
hierarchical structure, with levels corresponding to the temporal concepts duration, coincidence, and partial order. The
patterns are very compact, but offer details for each element on demand. In comparison with related approaches, the
{TSKR} is shown to have advantages in robustness, expressivity, and comprehensibility. The search for coincidence and
partial order in interval data can be formulated as instances of the well known frequent itemset problem. Efficient
algorithms for the discovery of the patterns are adapted accordingly. A novel form of search space pruning effectively
reduces the size of the mining result to ease interpretation and speed up the 
algorithms. Human interaction is used during the mining to analyze and validate partial results as early as possible and
guide further processing steps. The efficacy of the methods is demonstrated using two real life data sets. In an
application to sports medicine the results were recognized as valid and useful by an expert of the field.},
    author = {M\"{o}rchen, Fabian and Ultsch, Alfred},
    citeulike-article-id = {3978076},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1285966},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s10618-007-0070-1},
    day = {1},
    doi = {10.1007/s10618-007-0070-1},
    journal = {Data Mining and Knowledge Discovery},
    keywords = {proposal},
    month = oct,
    number = {2},
    pages = {181--215},
    posted-at = {2009-06-28 17:34:38},
    priority = {2},
    title = {Efficient mining of understandable patterns from multivariate interval time series},
    url = {http://dx.doi.org/10.1007/s10618-007-0070-1},
    volume = {15},
    year = {2007}
}

@inproceedings{citeulike:5000906,
    author = {Vilain, M.},
    booktitle = {2nd National (US) Conference on Artificial Intelligence},
    citeulike-article-id = {5000906},
    keywords = {proposal},
    location = {Pittsburgh, Pa.},
    pages = {197--201},
    posted-at = {2009-06-28 17:13:46},
    priority = {2},
    publisher = {AAAI Press},
    title = {A system for reasoning about time.},
    year = {1982}
}

@article{citeulike:5000870,
    abstract = {The temporal interval relationships formalized by Allen, and later extended to accommodate semiintervals
by Freksa, have been widely utilized in both data modeling and artificial intelligence research to facilitate reasoning
between the relative temporal ordering of events. In practice, however, some modifications to the relationships are
necessary when linear temporal sequences are provided, when event times are aggregated, or when data is supplied to a
granularity which is larger than required. This paper discusses these modifications and outlines a solution to this
problem which accommodates any available knowledge of interval midpoints.},
    author = {Roddick, J. F. and Mooney, C. H.},
    booktitle = {Knowledge and Data Engineering, IEEE Transactions on},
    citeulike-article-id = {5000870},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tkde.2005.12},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1363770},
    doi = {10.1109/tkde.2005.12},
    journal = {Knowledge and Data Engineering, IEEE Transactions on},
    keywords = {proposal},
    number = {1},
    pages = {133--135},
    posted-at = {2009-06-28 17:08:08},
    priority = {2},
    title = {Linear temporal sequences and their interpretation using midpoint relationships},
    url = {http://dx.doi.org/10.1109/tkde.2005.12},
    volume = {17},
    year = {2005}
}

@inproceedings{citeulike:5000685,
    address = {London, UK},
    author = {Rainsford, Chris P. and Roddick, John F.},
    booktitle = {PKDD '99: Proceedings of the Third European Conference on Principles of Data Mining and Knowledge
Discovery},
    citeulike-article-id = {5000685},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=669526},
    isbn = {3-540-66490-4},
    pages = {504--509},
    posted-at = {2009-06-28 16:37:29},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Adding Temporal Semantics to Association Rules},
    url = {http://portal.acm.org/citation.cfm?id=669526},
    year = {1999}
}

@incollection{citeulike:4994404,
    abstract = {The class hierarchy is an important aspect of object-oriented software development. Design and
maintenance of such a hierarchy is a difficult task that is often accomplished without any clear guidance or tool
support. Formal concept analysis provides a natural theoretical framework for this problem because it can guarantee
maximal factorization while preserving specialization relationships. The framework can be useful for several software
development scenarios within the class hierarchy life-cycle such as design from scratch using a set of class
specifications, or a set of object examples, refactoring/reengineering from existing object code or from the observation
of the actual use of the classes in applications and hierarchy evolution by incrementally adding new classes. The
framework can take into account different levels of specification details and suggests a number of well-defined
alternative designs. These alternatives can be viewed as normal forms for class hierarchies where each 
normal form addresses particular design goals. An overview of work in the area is presented by highlighting the formal
concept analysis notions that are involved. One particularly difficult problem arises when taking associations between
classes into account. Basic scaling has to be extended because the scales used for building the concept lattice are
dependent on it. An approach is needed to treat this circularity in a well-defined manner. Possible solutions are
discussed.},
    author = {Godin, Robert and Valtchev, Petko},
    citeulike-article-id = {4994404},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11528784\_16},
    citeulike-linkout-1 = {http://www.springerlink.com/content/0plqbxahtp1q6ug6},
    doi = {10.1007/11528784\_16},
    journal = {Formal Concept Analysis},
    keywords = {proposal},
    pages = {304--323},
    posted-at = {2009-06-28 04:38:03},
    priority = {2},
    title = {Formal Concept {Analysis-Based} Class Hierarchy Design in {Object-Oriented} Software Development},
    url = {http://dx.doi.org/10.1007/11528784\_16},
    year = {2005}
}

@book{citeulike:257416,
    author = {Hesse, Wolfgang and Tilley, Thomas},
    citeulike-article-id = {257416},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11528784\_15},
    citeulike-linkout-1 = {http://www.metapress.com/content/1N26B36LQ2AJ2B7N},
    citeulike-linkout-2 = {http://www.springerlink.com/content/1n26b36lq2aj2b7n},
    doi = {10.1007/11528784\_15},
    journal = {Lecture Notes in Computer Science},
    keywords = {proposal},
    month = jul,
    pages = {288--303},
    posted-at = {2009-06-28 04:35:44},
    priority = {2},
    title = {Formal Concept Analysis Used for Software Analysis and Modelling},
    url = {http://dx.doi.org/10.1007/11528784\_15},
    volume = {3626},
    year = {2005}
}

@incollection{citeulike:1378634,
    abstract = {Formal Concept Analysis ({FCA}) has typically been applied in the field of software engineering to
support software maintenance and object-oriented class identification tasks. This paper presents a broader overview by
describing and classifying academic papers that report the application of {FCA} to software engineering. The papers are
classified using a framework based on the activities defined in the {ISO12207} Software Engineering standard. Two
alternate classification schemes based on the programming language under analysis and target application size are also
discussed. In addition, the authors work to support agile methods and formal specification via {FCA} is introduced.},
    author = {Tilley, Thomas and Cole, Richard and Becker, Peter and Eklund, Peter},
    citeulike-article-id = {1378634},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11528784\_13},
    citeulike-linkout-1 = {http://www.springerlink.com/content/0dnu56mmegnxk6ee},
    doi = {10.1007/11528784\_13},
    journal = {Formal Concept Analysis},
    keywords = {proposal},
    pages = {250--271},
    posted-at = {2009-06-28 04:34:12},
    priority = {2},
    title = {A Survey of Formal Concept Analysis Support for Software Engineering Activities},
    url = {http://dx.doi.org/10.1007/11528784\_13},
    year = {2005}
}

@article{citeulike:272197,
    abstract = {We propose the time interval multimedia event ({TIME}) framework as a robust approach for classification
of semantic events in multimodal video documents. The representation used in {TIME} extends the Allen temporal interval
relations and allows for proper inclusion of context and synchronization of the heterogeneous information sources
involved in multimodal video analysis. To demonstrate the viability of our approach, it was evaluated on the domains of
soccer and news broadcasts. For automatic classification of semantic events, we compare three different machine learning
techniques, i.c. C4.5 decision tree, maximum entropy, and support vector machine. The results show that semantic video
indexing results significantly benefit from using the {TIME} framework.},
    author = {Snoek, C. G. M. and Worring, M.},
    citeulike-article-id = {272197},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tmm.2005.850966},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1468150},
    doi = {10.1109/tmm.2005.850966},
    journal = {Multimedia, IEEE Transactions on},
    keywords = {proposal},
    number = {4},
    pages = {638--647},
    posted-at = {2009-06-28 04:04:05},
    priority = {2},
    title = {Multimedia {Event-Based} Video Indexing Using Time Intervals},
    url = {http://dx.doi.org/10.1109/tmm.2005.850966},
    volume = {7},
    year = {2005}
}

@electronic{citeulike:4072008,
    author = {Alspaugh, Thomas A.},
    citeulike-article-id = {4072008},
    citeulike-linkout-0 = {http://www.ics.uci.edu/\~{}alspaugh/foundations/allen.html},
    howpublished = {webpage},
    institution = {Department of Informatics, Bren School of Information and Computer Sciences},
    location = {Irvine},
    organization = {University of California},
    posted-at = {2009-06-28 03:09:03},
    priority = {2},
    title = {Allen's interval algebra},
    url = {http://www.ics.uci.edu/\~{}alspaugh/foundations/allen.html}
}

@article{citeulike:4991400,
    abstract = {Without Abstract},
    author = {Chittaro, Luca and Montanari, Angelo},
    citeulike-article-id = {4991400},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a:1018933906603},
    citeulike-linkout-1 = {http://www.springerlink.com/content/vn6gh847w564j627},
    day = {1},
    doi = {10.1023/a:1018933906603},
    journal = {Annals of Mathematics and Artificial Intelligence},
    keywords = {proposal},
    month = feb,
    number = {1},
    pages = {1--4},
    posted-at = {2009-06-27 20:12:54},
    priority = {2},
    title = {Editorial: Temporal representation and reasoning},
    url = {http://dx.doi.org/10.1023/a:1018933906603},
    volume = {22},
    year = {1998}
}

@article{citeulike:4991332,
    abstract = {An abstract is not available.},
    address = {Essex, UK},
    author = {Freksa, Christian},
    citeulike-article-id = {4991332},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=130596},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/0004-3702(92)90090-k},
    doi = {10.1016/0004-3702(92)90090-k},
    issn = {0004-3702},
    journal = {Artif. Intell.},
    keywords = {proposal},
    month = mar,
    number = {1-2},
    pages = {199--227},
    posted-at = {2009-06-27 19:59:03},
    priority = {2},
    publisher = {Elsevier Science Publishers Ltd.},
    title = {Temporal reasoning based on semi-intervals},
    url = {http://dx.doi.org/10.1016/0004-3702(92)90090-k},
    volume = {54},
    year = {1992}
}

@article{citeulike:191348,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Allen, James F.},
    citeulike-article-id = {191348},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=358434},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/182.358434},
    doi = {10.1145/182.358434},
    issn = {0001-0782},
    journal = {Commun. ACM},
    keywords = {proposal},
    month = nov,
    number = {11},
    pages = {832--843},
    posted-at = {2009-06-27 19:36:52},
    priority = {2},
    publisher = {ACM},
    title = {Maintaining knowledge about temporal intervals},
    url = {http://dx.doi.org/10.1145/182.358434},
    volume = {26},
    year = {1983}
}

@misc{citeulike:1277366,
    abstract = {this paper, we surveyed the list of existing association rule mining techniques.
This investigation is prepared to our new project titled mining historical changes
to web delta},
    author = {Zhao, Qiankun and Bhowmick, Sourav S.},
    citeulike-article-id = {1277366},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.8692},
    keywords = {proposal},
    posted-at = {2009-06-24 15:29:52},
    priority = {2},
    title = {Sequential Pattern Matching: A Survey},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.8692}
}

@article{citeulike:1748833,
    address = {New York, NY, USA},
    author = {M\"orchen, Fabian},
    citeulike-article-id = {1748833},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1294302},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1294301.1294302},
    doi = {10.1145/1294301.1294302},
    issn = {1931-0145},
    journal = {SIGKDD Explor. Newsl.},
    keywords = {proposal},
    month = jun,
    number = {1},
    pages = {41--55},
    posted-at = {2009-06-22 19:01:45},
    priority = {2},
    publisher = {ACM Press},
    title = {Unsupervised pattern mining from symbolic temporal data},
    url = {http://dx.doi.org/10.1145/1294301.1294302},
    volume = {9},
    year = {2007}
}

@article{citeulike:819708,
    abstract = {Periodicy detection in time series data is a challenging problem of great importance in many
applications. Most previous work focused on mining synchronous periodic patterns and did not recognize the misaligned
presence of a pattern due to the intervention of random noise. In this paper, we propose a more flexible model of
asynchronous periodic pattern that may be present only within a subsequence and whose occurrences may be shifted due to
disturbance. Two parameters min\&\#095;rep and max\&\#095;dis are employed to specify the minimum number of repetitions
that is required within each segment of nondisrupted pattern occurrences and the maximum allowed disturbance between any
two successive valid segments. Upon satisfying these two requirements, the longest valid subsequence of a pattern is
returned. A two-phase algorithm is devised to first generate potential periods by distance-based pruning followed by an
iterative procedure to derive and validate candidate patterns and locate the longest 
valid subsequence. We also show that this algorithm cannot only provide linear time complexity with respect to the
length of the sequence but also achieve space efficiency.},
    address = {Piscataway, NJ, USA},
    author = {Yang, Jiong and Wang, Wei and Yu, P. S.},
    citeulike-article-id = {819708},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=776785},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/TKDE.2003.1198394},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/tkde.2003.1198394},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1198394},
    day = {13},
    doi = {10.1109/tkde.2003.1198394},
    issn = {1041-4347},
    journal = {Knowledge and Data Engineering, IEEE Transactions on},
    keywords = {proposal},
    month = may,
    number = {3},
    pages = {613--628},
    posted-at = {2009-06-21 17:30:08},
    priority = {2},
    publisher = {IEEE Educational Activities Department},
    title = {Mining asynchronous periodic patterns in time series data},
    url = {http://dx.doi.org/10.1109/tkde.2003.1198394},
    volume = {15},
    year = {2003}
}

@book{citeulike:143101,
    abstract = {"People sometimes ask me what they should read to find out about artificial
intelligence. Herbert Simon's book The Sciences of the Artificial is always on
the list I give them. Every page issues a challenge to conventional thinking,
and the layman who digests it well will certainly understand what the field of
artificial intelligence hopes to accomplish. I recommend it in the same spirit
that I recommend Freud to people who ask about psychoanalysis, or Piaget to
those who ask about child psychology: If you want to learn about a subject,
start by reading its founding fathers." -- George A. Miller, {\_Complex}
Information Processing\_

Continuing his exploration of the organization of complexity and the science
of design, this new edition of Herbert Simon's classic work on artificial
intelligence adds a chapter that sorts out the current themes and tools --
chaos, adaptive systems, genetic algorithms -- for analyzing complexity and
complex systems. There are updates throughout the book as well. These take
into account important advances in cognitive psychology and the science of
design while confirming and extending the book's basic thesis: that a physical
symbol system has the necessary and sufficient means for intelligent action.
The chapter "Economic Reality" has also been revised to reflect a change in
emphasis in Simon's thinking about the respective roles of organizations and
markets in economic systems.},
    author = {Simon, Herbert A.},
    citeulike-article-id = {143101},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262691914},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262691914},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262691914},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262691914},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262691914/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262691914},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262691914},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262691914},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262691914\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262691914},
    day = {01},
    edition = {third edition},
    howpublished = {Paperback},
    isbn = {0262691914},
    keywords = {proposal},
    month = oct,
    posted-at = {2009-06-20 02:10:19},
    priority = {2},
    publisher = {The MIT Press},
    title = {The Sciences of the Artificial - 3rd Edition},
    url = {http://www.worldcat.org/isbn/0262691914},
    year = {1996}
}

@book{citeulike:606469,
    abstract = {"The watchmaker belongs to the eighteenth-century theologian William Paley, who made one of the most
famous creationist arguments: Just as a watch is too complicated and too functional to have sprung into existence by
accident, so too must all living things, with their far greater complexity, be purposefully designed. It was Charles
Darwin's brilliant discovery that put the lie to these arguments. But only Richard Dawkins could have written this
eloquent riposte to the creationists. Natural selection - the unconscious, automatic, blind, yet essentially nonrandom
process that Darwin discovered - has no purpose in mind. If it can be said to play the role of watchmaker in nature, it
is the blind watchmaker." "Acclaimed as perhaps the most influential work on evolution written in this century, The
Blind Watchmaker offers an engaging and accessible introduction to one of the most important scientific discoveries of
all {time."--BOOK} {JACKET}.},
    author = {Dawkins, Richard},
    citeulike-article-id = {606469},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0393315703},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0393315703},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/35648431},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0393315703},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0393315703},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0393315703/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0393315703},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0393315703},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0393315703},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0393315703\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0393315703},
    day = {17},
    howpublished = {Paperback},
    isbn = {0393315703},
    keywords = {proposal},
    month = sep,
    posted-at = {2009-06-20 02:07:35},
    priority = {2},
    publisher = {W. W. Norton \& Company},
    title = {The Blind Watchmaker: Why the Evidence of Evolution Reveals a Universe without Design},
    url = {http://www.worldcat.org/isbn/0393315703},
    year = {1996}
}

@article{citeulike:4913213,
    author = {Fischer, Gerhard},
    citeulike-article-id = {4913213},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a:1022972113929},
    citeulike-linkout-1 = {http://www.springerlink.com/content/r66202g8841551m3},
    day = {1},
    doi = {10.1023/a:1022972113929},
    journal = {Automated Software Engineering},
    keywords = {proposal},
    month = apr,
    number = {2},
    pages = {233--237},
    posted-at = {2009-06-20 01:34:55},
    priority = {2},
    title = {Desert Island: Software {Engineering—A} Human Activity},
    url = {http://dx.doi.org/10.1023/a:1022972113929},
    volume = {10},
    year = {2003}
}

@proceedings{citeulike:2826276,
    abstract = {Efficient and accurate similarity searching on a large time series data set is an important but non-
trivial problem. In this work, we propose a new approach to improve the quality of similarity search on time series data
by combining symbolic aggregate approximation ({SAX}) and piecewise linear approximation. The approach consists of three
steps: transforming real valued time series sequences to symbolic strings via {SAX}, pattern matching on the symbolic
strings and a post-processing via Piecewise Linear Approximation.},
    author = {Nguyen and Anh, Duong T.},
    booktitle = {Information Technology Convergence, 2007. ISITC 2007. International Symposium on},
    citeulike-article-id = {2826276},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/isitc.2007.24},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4410606},
    doi = {10.1109/isitc.2007.24},
    journal = {Information Technology Convergence, 2007. ISITC 2007. International Symposium on},
    keywords = {sax, search, similarity},
    pages = {58--62},
    posted-at = {2009-05-27 18:26:19},
    priority = {2},
    title = {Combining {SAX} and Piecewise Linear Approximation to Improve Similarity Search on Financial Time Series},
    url = {http://dx.doi.org/10.1109/isitc.2007.24},
    year = {2007}
}

@article{citeulike:4518026,
    abstract = {Process mining aims at extracting information from event logs to capture the business process as it is
being executed. Process mining is particularly useful in situations where events are recorded but there is no system
enforcing people to work in a particular way. Consider for example a hospital where the diagnosis and treatment
activities are recorded in the hospital information system, but where health-care professionals determine the
"careflow." Many process mining approaches have been proposed in recent years. However, in spite of many researchers'
persistent efforts, there are still several challenging problems to be solved. In this paper, we focus on mining
non-free-choice constructs, i.e., situations where there is a mixture of choice and synchronization. Although most
real-life processes exhibit non-free-choice behavior, existing algorithms are unable to adequately deal with such
constructs. Using a Petri-net-based representation, we will show that there are two kinds of causal 
dependencies between tasks, i.e., explicit and implicit ones. We propose an algorithm that is able to deal with both
kinds of dependencies. The algorithm has been implemented in the {ProM} framework and experimental results shows that
the algorithm indeed significantly improves existing process mining techniques.},
    address = {Hingham, MA, USA},
    author = {Wen, Lijie and Aalst, Wil M. and Wang, Jianmin and Sun, Jiaguang},
    citeulike-article-id = {4518026},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1285964},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s10618-007-0065-y},
    citeulike-linkout-2 = {http://www.springerlink.com/content/gv830pw5nx76258u},
    day = {1},
    doi = {10.1007/s10618-007-0065-y},
    issn = {1384-5810},
    journal = {Data Min. Knowl. Discov.},
    keywords = {mining, process},
    month = oct,
    number = {2},
    pages = {145--180},
    posted-at = {2009-05-14 13:33:00},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Mining process models with non-free-choice constructs},
    url = {http://dx.doi.org/10.1007/s10618-007-0065-y},
    volume = {15},
    year = {2007}
}

@article{citeulike:4501572,
    abstract = {The last decade has witnessed a tremendous growths of interests in applications that deal with querying
and mining of time series data. Numerous representation methods for dimensionality reduction and similarity measures
geared towards time series have been introduced. Each individual work introducing a particular method has made specific
claims and, aside from the occasional theoretical justifications, provided quantitative experimental observations.
However, for the most part, the comparative aspects of these experiments were too narrowly focused on demonstrating the
benefits of the proposed methods over some of the previously introduced ones. In order to provide a comprehensive
validation, we conducted an extensive set of time series experiments re-implementing 8 different representation methods
and 9 similarity measures and their variants, and testing their effectiveness on 38 time series data sets from a wide
variety of application domains. In this paper, we give an overview of these 
different techniques and present our comparative experimental findings regarding their effectiveness. Our experiments
have provided both a unified validation of some of the existing achievements, and in some cases, suggested that certain
claims in the literature may be unduly optimistic.},
    author = {Ding, Hui and Trajcevski, Goce and Scheuermann, Peter and Wang, Xiaoyue and Keogh, Eamonn},
    citeulike-article-id = {4501572},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1454159.1454226},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1454159.1454226},
    doi = {10.1145/1454159.1454226},
    issn = {2150-8097},
    journal = {Proc. VLDB Endow.},
    month = aug,
    number = {2},
    pages = {1542--1552},
    posted-at = {2009-05-10 22:19:43},
    priority = {2},
    publisher = {VLDB Endowment},
    title = {Querying and mining of time series data: experimental comparison of representations and distance measures},
    url = {http://dx.doi.org/10.1145/1454159.1454226},
    volume = {1},
    year = {2008}
}

@inproceedings{citeulike:4446167,
    abstract = {The last decade has seen a huge interest in classification of time series. Most of this work assumes
that the data resides in main memory and is processed offline. However, recent advances in sensor technologies require
resource-efficient algorithms that can be implemented directly on the sensors as real-time algorithms. We show how a
recently introduced framework for time series classification, time series bitmaps, can be implemented as efficient
classifiers which can be updated in constant time and space in the face of very high data arrival rates. We describe
results from a case study of an important entomological problem, and further demonstrate the generality of our ideas
with an example from robotics.},
    address = {Washington, DC, USA},
    author = {Kasetty, S. and Stafford, C. and Walker, G. P. and Wang, Xiaoyue and Keogh, E.},
    booktitle = {Tools with Artificial Intelligence, 2008. ICTAI \&\#039;08. 20th IEEE International Conference on},
    citeulike-article-id = {4446167},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1474547.1474583},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ictai.2008.143},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4669683},
    day = {5},
    doi = {10.1109/ictai.2008.143},
    institution = {Dept. of Comput. Sci. \& Eng., Univ. of California, Riverside, CA},
    isbn = {978-0-7695-3440-4},
    issn = {1082-3409},
    journal = {Tools with Artificial Intelligence, 2008. ICTAI '08. 20th IEEE International Conference on},
    keywords = {litreview, sax, similarity},
    month = nov,
    pages = {149--156},
    posted-at = {2009-04-30 19:36:30},
    priority = {2},
    publisher = {IEEE},
    title = {{Real-Time} Classification of Streaming Sensor Data},
    url = {http://dx.doi.org/10.1109/ictai.2008.143},
    volume = {1},
    year = {2008}
}

@inproceedings{citeulike:3175770,
    author = {Wei, Li and Keogh, Eamonn J. and Xi, Xiaopeng},
    booktitle = {ICDM},
    citeulike-article-id = {3175770},
    citeulike-linkout-0 = {http://dblp.uni-trier.de/rec/bibtex/conf/icdm/WeiKX06},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icdm.2006.138},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4053096},
    doi = {10.1109/icdm.2006.138},
    keywords = {litreview, sax, search, similarity},
    pages = {711--720},
    posted-at = {2009-04-30 19:33:04},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {{SAXually} Explicit Images: Finding Unusual Shapes},
    url = {http://dx.doi.org/10.1109/icdm.2006.138},
    year = {2006}
}

@book{citeulike:4434481,
    abstract = {Using high-quality, real-world case studies and examples, this introduction to
mathematical statistics shows how to use statistical methods and when to use
them. This book can be used as a brief introduction to design of experiments.
This successful, calculus-based book of probability and statistics, was one of
the first to make real-world applications an integral part of motivating
discussion. The number of problem sets has increased in all sections. Some
sections include almost 50\% new problems, while the most popular case studies
remain. For anyone needing to develop proficiency with Mathematical
Statistics.},
    author = {Larsen, Richard J. and Marx, Morris L.},
    citeulike-article-id = {4434481},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0139223037},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0139223037},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0139223037},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0139223037},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0139223037/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0139223037},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0139223037},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0139223037},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0139223037\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0139223037},
    day = {15},
    edition = {3rd},
    howpublished = {Hardcover},
    isbn = {0139223037},
    keywords = {litreview, similarity},
    month = jan,
    posted-at = {2009-04-29 14:54:10},
    priority = {2},
    publisher = {Prentice Hall},
    title = {An Introduction to Mathematical Statistics and Its Applications (3rd Edition)},
    url = {http://www.worldcat.org/isbn/0139223037},
    year = {2000}
}

@inproceedings{citeulike:227029,
    abstract = {Time series data is perhaps the most frequently encountered typeof data examined by the data mining
community. Clustering isperhaps the most frequently used data mining algorithm, beinguseful in it's own right as an
exploratory technique, and also as asubroutine in more complex data mining algorithms such as rulediscovery, indexing,
summarization, anomaly detection, andclassification. Given these two facts, it is hardly surprising thattime series
clustering has attracted much attention. The data to beclustered can be in one of two formats: many individual
timeseries, or a single time series, from which individual time seriesare extracted with a sliding window. Given the
recent explosion ofinterest in streaming data and online algorithms, the latter casehas received much {attention.In}
this work we make an amazing claim. Clustering of streamingtime series is completely meaningless. More concretely,
clustersextracted from streaming time series are forced to obey a certainconstraint that is 
pathologically unlikely to be satisfied by anydataset, and because of this, the clusters extracted by anyclustering
algorithm are essentially random. While this constraintcan be intuitively demonstrated with a simple illustration and
issimple to prove, it has never appeared in the {literature.We} can justify calling our claim surprising, since it
invalidatesthe contribution of dozens of previously published papers. We willjustify our claim with a theorem,
illustrative examples, and acomprehensive set of experiments on reimplementations ofprevious work.},
    address = {Washington, DC, USA},
    author = {Keogh, Eamonn and Lin, Jessica and Truppel, Wagner},
    booktitle = {Proceedings of the Third IEEE International Conference on Data Mining},
    citeulike-article-id = {227029},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=952156},
    isbn = {0-7695-1978-4},
    keywords = {litreview, sax},
    posted-at = {2009-04-28 14:29:55},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {ICDM '03},
    title = {Clustering of Time Series Subsequences is Meaningless: Implications for Previous and Future Research},
    url = {http://portal.acm.org/citation.cfm?id=952156},
    year = {2003}
}

@article{citeulike:4412621,
    abstract = {We develop an event detection framework that has two significant  advantages over past work. First, we
introduce an  extended set of time-wise and object-wise statistical features  including not only the trajectory
coordinates but also  the histograms and {HMM} based representations of object's  speed, orientation, location, size,
and aspect ratio. These  features enable detection of events that cannot be detected  with the existing trajectory
features reported so far. Second,  we introduce a spectral clustering algorithm that can automatically  estimate the
optimal number of clusters. First,  we construct feature-wise affinity matrices from the pair-wise  similarity scores of
objects using the extended set of  features. To determine the usual events, we apply eigen-vector  decomposition and
obtain object clusters. We show  that the number of eigenvectors used in the decomposition is  proportional to the
optimal number of clusters. Unlike the  conventional approaches that try to fit 
predefined models to  events, we analyze the conformity of objects using affinity  matrices to find the unusual events.
We improve the feature  selection process by incorporating feature variances.  We prove that the clustering stage is not
adversely affected  by high dimensionality of data space. Our simulations with  synthetic and real data reveal that the
proposed detection  methods accurately detect usual and unusual events.},
    address = {Los Alamitos, CA, USA},
    author = {Porikli, Fatih and Haga, Tetsuji},
    citeulike-article-id = {4412621},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2004.335},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/cvpr.2004.335},
    doi = {10.1109/cvpr.2004.335},
    issn = {1063-6919},
    journal = {Computer Vision and Pattern Recognition Workshop},
    keywords = {litreview, similarity},
    pages = {114+},
    posted-at = {2009-04-27 22:01:38},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Event Detection by Eigenvector Decomposition Using Object and Frame Features},
    url = {http://dx.doi.org/10.1109/cvpr.2004.335},
    volume = {7},
    year = {2004}
}

@inproceedings{citeulike:4412617,
    abstract = {Consider the problem of monitoring tens of thousands of time series data streams in an online fashion
and making decisions based on them. In addition to single stream statistics such as average and standard deviation, we
also want to find high correlations among all pairs of streams. A stock market trader might use such a tool to spot
arbitrage opportunities. This paper proposes efficient methods for solving this problem based on Discrete Fourier
Transforms and a three level time interval hierarchy. Extensive experiments on synthetic data and real world financial
trading data show that our algorithm beats the direct computation approach by several orders of magnitude. It also
improves on previous Fourier Transform approaches by allowing the efficient computation of time-delayed correlation over
any size sliding window and any time delay. Correlation also lends itself to an efficient grid-based data structure. The
result is the first algorithm that we know of to compute correlations over 
thousands of data streams in real time. The algorithm is incremental, has fixed response time, and can monitor the
pairwise correlations of 10,000 streams on a single {PC}. The algorithm is embarrassingly parallelizable.},
    author = {Zhu, Yunyue and Shasha, Dennis},
    booktitle = {VLDB '02: Proceedings of the 28th international conference on Very Large Data Bases},
    citeulike-article-id = {4412617},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1287401},
    keywords = {litreview, similarity},
    location = {Hong Kong, China},
    pages = {358--369},
    posted-at = {2009-04-27 21:58:48},
    priority = {2},
    publisher = {VLDB Endowment},
    title = {{StatStream}: statistical monitoring of thousands of data streams in real time},
    url = {http://portal.acm.org/citation.cfm?id=1287401},
    year = {2002}
}

@techreport{citeulike:4041809,
    abstract = {Hackystat is an open source framework for automated collection and analysis of software engineering
process and product data. Hackystat has been in development since 2001, and has gone through eight major architectural
revisions during that time. In 2007, we performed the latest architectural revision, whose primary goal was to
reimplement Hackystat as a service-oriented architecture ({SOA}). This version has now been in public release for a
year, and this paper reports on our experiences: the motivations that led us to reimplement the system as a {SOA}, the
costs and benefits of that conversion, and our lessons learned.},
    address = {Los Angeles, California},
    author = {Johnson, Philip M. and Zhang, Shaoxuan and Senin, Pavel},
    booktitle = {Submitted to the 2009 {IEEE} Service Cup Conference},
    citeulike-article-id = {4041809},
    citeulike-linkout-0 = {http://csdl.ics.hawaii.edu/techreports/09-07/09-07.pdf},
    institution = {Department of Information and Computer Sciences, University of Hawaii, Honolulu, Hawaii 96822},
    keywords = {publication},
    month = feb,
    number = {{CSDL}-09-07},
    posted-at = {2009-04-27 13:00:38},
    priority = {2},
    title = {Experiences with Hackystat as a service-oriented architecture},
    url = {http://csdl.ics.hawaii.edu/techreports/09-07/09-07.pdf},
    year = {2009}
}

@book{citeulike:167581,
    abstract = {This edition has been completely revised, enlarged and formatted in two colour. It is a systematic
account of the major topics in pattern recognition, based on the fundamental principles. It includes extensive examples,
exercises and a solutions manual.},
    author = {Peter},
    citeulike-article-id = {167581},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0471056693},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0471056693},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/41347061},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0471056693},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0471056693},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0471056693/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0471056693},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0471056693},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0471056693},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0471056693\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0471056693},
    day = {09},
    edition = {2},
    howpublished = {Hardcover},
    isbn = {0471056693},
    keywords = {litreview},
    month = nov,
    posted-at = {2009-04-26 20:58:15},
    priority = {2},
    publisher = {Wiley-Interscience},
    title = {Pattern Classification (Pt.1)},
    url = {http://www.worldcat.org/isbn/0471056693},
    year = {2000}
}

@inproceedings{citeulike:4408223,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has
opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Hellerstein, Joseph M. and Koutsoupias, Elias and Papadimitriou, Christos H.},
    booktitle = {PODS '97: Proceedings of the sixteenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database
systems},
    citeulike-article-id = {4408223},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=263661.263688},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/263661.263688},
    doi = {10.1145/263661.263688},
    isbn = {0-89791-910-6},
    keywords = {litreview, sax, search, similarity},
    location = {Tucson, Arizona, United States},
    pages = {249--256},
    posted-at = {2009-04-26 19:53:17},
    priority = {2},
    publisher = {ACM},
    title = {On the analysis of indexing schemes},
    url = {http://dx.doi.org/10.1145/263661.263688},
    year = {1997}
}

@electronic{citeulike:4406444,
    abstract = {We introduce an extended representation of time series that allows fast, accurate classification and
clustering in addition to the ability to explore time series data in a relevance feedback framework. The representation
consists of piecewise linear segments to represent shape and a weight vector that contains the relative importance of
each individual linear segment. In the classification context, the weights are learned automatically as part of the
training cycle. In the relevance feedback context, the weights are determined by an interactive and iterative process in
which users rate various choices presented to them. Our representation allows a user to define a variety of similarity
measures that can be tailored to specific domains. We demonstrate our approach on space telemetry, medical and synthetic
data. 1.0 Introduction Time series account for much of the data stored in business, medical, engineering and social
science databases. Much of the utility of collecting this data com...},
    author = {Keogh, Eamonn J. and Pazzani, Michael J.},
    citeulike-article-id = {4406444},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.9288},
    keywords = {litreview, paa, similarity},
    posted-at = {2009-04-26 16:51:34},
    priority = {2},
    title = {An Enhanced Representation of Time Series Which Allows Fast and Accurate Classification, Clustering and
Relevance Feedback},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.9288},
    year = {1998}
}

@book{citeulike:499150,
    abstract = {{Wavelets are a mathematical development that may revolutionize the world of information storage and
retrieval according to many experts. They are a fairly simple mathematical tool now being applied to the compression of
data--such as fingerprints, weather satellite photographs, and medical x-rays--that were previously thought to be
impossible to condense without losing crucial details.  <P>This monograph contains 10 lectures presented by Dr.
Daubechies as the principal speaker at the 1990 CBMS-NSF Conference on Wavelets and Applications. The author has worked
on several aspects of the wavelet transform and has developed a collection of wavelets that are remarkably efficient. 
<P>The opening chapter provides an overview of the main problems presented in the book. Following chapters discuss the
theoretical and practical aspects of wavelet theory, including wavelet transforms, orthonormal bases of wavelets, and
characterization of functional spaces by means of wavelets. The last chapter 
presents several topics under active research, as multidimensional wavelets, wavelet packet bases, and a construction of
wavelets tailored to decompose functions defined in a finite interval. Because of their interdisciplinary origins,
wavelets appeal to scientists and engineers of many different backgrounds.}},
    author = {Daubechies, Ingrid},
    citeulike-article-id = {499150},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0898712742},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0898712742},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/471046675},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0898712742},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0898712742},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0898712742/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0898712742},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0898712742},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0898712742},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0898712742\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0898712742},
    day = {01},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0898712742},
    keywords = {litreview, wavelet},
    month = jun,
    posted-at = {2009-04-26 13:49:40},
    priority = {2},
    publisher = {Society for Industrial and Applied Mathematics},
    title = {Ten lectures on wavelets},
    url = {http://www.worldcat.org/isbn/0898712742},
    year = {1992}
}

@article{citeulike:4384535,
    abstract = {Time series stored as feature vectors can be indexed by multi-dimensional index trees like {R-Tree} for
fast retrieval. Due to the dimensionality curse problem, transformations are applied to time series to reduce the number
of dimensions of the feature vectors. Different transformations like Discrete Fourier Transform ({DFT}), Discrete
Wavelet Transform ({DWT}), {Karhunen-Loeve} ({K-L}) transform or Singular Value Decomposition ({SVD}) can be applied.
While the use of {DFT} and {K-L} transform or {SVD} have been studied in the literature, to our knowledge, there is no
in-depth study on the application of {DWT}. In this paper, we propose to use Haar Wavelet Transform for time series
indexing. The major contributions are: (1) we show that Euclidean distance is preserved in the Haar transformed domain
and no false dismissal will occur in range query, (2) we show that Haar transform can outperform {DFT} through
experiments, (3) a new similarity model is suggested to accommodate vertical shift of 
time series, and (4) a two-phase method is proposed for efficient n-nearest neighbor query in time series databases.},
    address = {Los Alamitos, CA, USA},
    author = {Chan, Kin P. and Fu, Wai C.},
    citeulike-article-id = {4384535},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/ICDE.1999.754915},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icde.1999.754915},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=754915},
    doi = {10.1109/icde.1999.754915},
    issn = {1063-6382},
    journal = {Data Engineering, International Conference on},
    keywords = {litreview, similarity, wavelet},
    pages = {126+},
    posted-at = {2009-04-23 11:27:16},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Efficient Time Series Matching by Wavelets},
    url = {http://dx.doi.org/10.1109/icde.1999.754915},
    volume = {0},
    year = {1999}
}

@incollection{citeulike:4384496,
    abstract = {The existing multi-dimensional index structures are not adequate for indexing higher-dimensional data
sets. Although conceptually they can be extended to higher dimensionalities, they usually require time and space that
grow exponentially with the dimensionality. In this paper, we analyze the existing index structures and derive some
requirements of an index structure for content-based image retrieval. We also propose a new structure, called
{CIR}(Content-based Image Retrieval)-tree, for indexing large amounts of point data in high dimensional space that
satisfies the requirements. In order to justify the performance of the proposed structure, we compare the proposed
structure with the existing index structures in the various environments. We show through experiments that our proposed
structure outperforms the existing structures in terms of retrieval time and storage overhead.},
    author = {Yoo, Jae and Shin, Myung and Lee, Seok and Choi, Kil and Cho, Ki and Hur, Dae},
    citeulike-article-id = {4384496},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-48962-2\_10},
    citeulike-linkout-1 = {http://www.springerlink.com/content/7gju3tumwm46tt9b},
    doi = {10.1007/3-540-48962-2\_10},
    journal = {Advanced Multimedia Content Processing},
    keywords = {litreview, search, similarity, tree},
    pages = {131--144},
    posted-at = {2009-04-23 11:07:15},
    priority = {2},
    title = {An Efficient Index Structure for High Dimensional Image Data},
    url = {http://dx.doi.org/10.1007/3-540-48962-2\_10},
    year = {1999}
}

@inproceedings{citeulike:2843857,
    address = {San Francisco, CA, USA},
    author = {Berchtold, Stefan and Keim, Daniel A. and Kriegel, Hans-Peter},
    booktitle = {VLDB '96: Proceedings of the 22th International Conference on Very Large Data Bases},
    citeulike-article-id = {2843857},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=645922.673502},
    isbn = {1558603824},
    keywords = {litreview, similarity, tree},
    pages = {28--39},
    posted-at = {2009-04-23 11:06:15},
    priority = {2},
    publisher = {Morgan Kaufmann Publishers Inc.},
    title = {The X-tree: An Index Structure for {High-Dimensional} Data},
    url = {http://portal.acm.org/citation.cfm?id=645922.673502},
    year = {1996}
}

@proceedings{citeulike:4384489,
    abstract = {Feature-based similarity searching is emerging as an important search paradigm in database systems. The
technique used is to map the data items as points into a high-dimensional feature space which is indexed using a
multidimensional data structure. Similarity searching then corresponds to a range search over the data structure.
Although several data structures have been proposed for feature indexing, none of them is known to scale beyond 10-15
dimensional spaces. This paper introduces the hybrid tree-a multidimensional data structure for indexing
high-dimensional feature spaces. Unlike other multidimensional data structures, the hybrid tree cannot be classified as
either a pure data partitioning ({DP}) index structure (such as the R-tree, {SS}-tree or {SR}-tree) or a pure space
partitioning ({SP}) one (such as the {KDB}-tree or {hB}-tree); rather it combines the positive aspects of the two types
of index structures into a single data structure to achieve a search performance which is more 
scalable to high dimensionalities than either of the above techniques. Furthermore, unlike many data structures (e.g.
distance-based index structures like the {SS}-tree and {SR}-tree), the hybrid tree can support queries based on
arbitrary distance functions. Our experiments on \&ldquo;real\&rdquo; high-dimensional large-size feature databases
demonstrate that the hybrid tree scales well to high dimensionality and large database sizes. It significantly
outperforms both purely {DP}-based and {SP}-based index mechanisms as well as linear scans at all dimensionalities for
large-sized databases},
    author = {Chakrabarti, K. and Mehrotra, S.},
    booktitle = {Data Engineering, 1999. Proceedings., 15th International Conference on},
    citeulike-article-id = {4384489},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icde.1999.754960},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=754960},
    doi = {10.1109/icde.1999.754960},
    journal = {Data Engineering, 1999. Proceedings., 15th International Conference on},
    keywords = {litreview, search, similarity, tree},
    pages = {440--447},
    posted-at = {2009-04-23 11:03:52},
    priority = {2},
    title = {The hybrid tree: an index structure for high dimensional feature spaces},
    url = {http://dx.doi.org/10.1109/icde.1999.754960},
    year = {1999}
}

@inproceedings{citeulike:4373408,
    abstract = {Abstract: The problem of finding patterns of interest in time series databases (query by content) is an
important one, with applications in virtually every field of science. A variety of approaches have been suggested. These
approaches are robust to noise, offset translation, and amplitude scaling to varying degrees. However, they are all
extremely sensitive to scaling in the time axis (longitudinal scaling). We present a method for similarity search that
is robust to scaling in the time axis, in addition to noise, offset translation, and amplitude scaling. The method has
been tested on medical, financial, space telemetry and artificial data. Furthermore the method is exceptionally fast,
with the predicted 2 to 4 orders of magnitude speedup actually observed. The method uses a piecewise linear
representation of the original data. We also introduce a new algorithm which both decides the optimal number of linear
segments to use, and produces the actual linear representation.},
    address = {Washington, DC, USA},
    author = {Keogh, E.},
    booktitle = {ICTAI '97: Proceedings of the 9th International Conference on Tools with Artificial Intelligence},
    citeulike-article-id = {4373408},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=880107},
    keywords = {litreview, similarity},
    pages = {578+},
    posted-at = {2009-04-22 04:51:15},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Fast similarity search in the presence of longitudinal scaling in time series databases},
    url = {http://portal.acm.org/citation.cfm?id=880107},
    year = {1997}
}

@inproceedings{citeulike:4373332,
    abstract = {We examine the problem of finding similar tumor  shapes. Starting from a natural similarity  function
(the so-called `max morphological  distance\&\#039;), we show how to lower-bound it and  how to search for nearest
neighbors in large  collections of tumor-like shapes.  Specifically, we use state-of-the-art concepts  from morphology,
namely the `pattern spectrum  \&\#039; of a shape, to map each shape to a point  in n-dimensional space. Following [16,
30], we  organize the n-d points in an R-tree. We show  that the L1 (= max) norm in the n-d space  lower-bounds the
actual distance. This guarantees  no false dismissals for range queries. In  addition, we present a nearest neighbor
algorithm  that also guarantees no false dismissals.  Finally, we implemented the method and  tested it against a
testbed of realistic tumor  shapes, using an established tumor-growth  model of Murray Eden[13]. The experiments 
Permission to copy without fee all or part of this material is granted provided that the 
copies ...},
    author = {Korn, Flip and Sidiropoulos, Nikolaos and Faloutsos, Christos and Siegel, Eliot and Protopapas, Zenon},
    booktitle = {In Proceedings of the Int. Conf. on Very Large Data Bases},
    citeulike-article-id = {4373332},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.9993},
    keywords = {litreview, similarity},
    pages = {215--226},
    posted-at = {2009-04-22 02:57:59},
    priority = {2},
    title = {Fast Nearest Neighbor Search in Medical Image Databases},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.9993},
    year = {1996}
}

@article{citeulike:4373331,
    author = {Heck, A.},
    citeulike-article-id = {4373331},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/a:1005078508777},
    citeulike-linkout-1 = {http://www.springerlink.com/content/h080372124420064},
    day = {1},
    doi = {10.1023/a:1005078508777},
    journal = {Space Science Reviews},
    month = aug,
    number = {3},
    pages = {549},
    posted-at = {2009-04-22 02:54:00},
    priority = {2},
    title = {D. Maoz, A. Sternberg, and E. M. Leibowitz (eds.), Astronomical Time Series, Proceedings of The Florence
and George Wise Observatory 25th Anniversary Symposium},
    url = {http://dx.doi.org/10.1023/a:1005078508777},
    volume = {85},
    year = {1998}
}

@article{citeulike:4367455,
    author = {Kruskal, Joseph B.},
    citeulike-article-id = {4367455},
    citeulike-linkout-0 =
{http://scitation.aip.org/getabs/servlet/GetabsServlet?prog=normal\&id=SIREAD000025000002000201000001\&idtype=cvips\&gif
s=yes},
    citeulike-linkout-1 = {http://link.aip.org/link/?SIR/25/201},
    journal = {SIAM Review},
    keywords = {litreview, similarity},
    number = {2},
    pages = {201--237},
    posted-at = {2009-04-20 04:17:44},
    priority = {2},
    publisher = {SIAM},
    title = {An Overview of Sequence Comparison: Time Warps, String Edits, and Macromolecules},
    url =
{http://scitation.aip.org/getabs/servlet/GetabsServlet?prog=normal\&id=SIREAD000025000002000201000001\&idtype=cvips\&gif
s=yes},
    volume = {25},
    year = {1983}
}

@article{citeulike:3980022,
    abstract = {The Dynamic Time Warping ({DTW}) is a popular similarity measure between time
series. The {DTW} fails to satisfy the triangle inequality and its computation
requires quadratic time. Hence, to find closest neighbors quickly, we use
bounding techniques. We can avoid most {DTW} computations with an inexpensive
lower bound ({LB} Keogh). We compare {LB} Keogh with a tighter lower bound ({LB}
Improved). We find that {LB} Improved-based search is faster. As an example, our
approach is 2-3 times faster over random-walk and shape time series.},
    archivePrefix = {arXiv},
    author = {Lemire, Daniel},
    citeulike-article-id = {3980022},
    citeulike-linkout-0 = {http://arxiv.org/abs/0811.3301},
    citeulike-linkout-1 = {http://arxiv.org/pdf/0811.3301},
    day = {20},
    eprint = {0811.3301},
    keywords = {dtw, litreview, similarity},
    month = nov,
    posted-at = {2009-04-20 03:46:18},
    priority = {2},
    title = {Faster Retrieval with a {Two-Pass} {Dynamic-Time}-Warping Lower Bound},
    url = {http://arxiv.org/abs/0811.3301},
    year = {2008}
}

@book{citeulike:180287,
    abstract = {This title covers a broad range of algorithms in depth, yet makes their design and analysis accessible
to all levels of readers. Each chapter is relatively self-contained and can be used as a unit of study. The algorithms
are described in English and in a pseudocode designed to be readable by anyone who has done a little programming. The
explanations have been kept elementary without sacrificing depth of coverage or mathematical rigor. This second edition
features new chapters on the role of algorithms, probabilistic analysis and randomized algorithms, and linear
programming, as well as extensive revisions to virtually every section of the book. In a subtle but important change,
loop invariants are introduced early and used throughout the text to prove algorithm correctness. Without changing the
mathematical and analytic focus, the authors have moved much of the mathematical foundations material from Part I to an
appendix and have included additional motivational material at the beginning.},
    author = {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford},
    citeulike-article-id = {180287},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262032937},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262032937},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/473581164},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262032937},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262032937},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262032937/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262032937},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262032937},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262032937},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262032937\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262032937},
    day = {01},
    edition = {2nd},
    howpublished = {Hardcover},
    isbn = {0262032937},
    keywords = {litreview},
    month = sep,
    posted-at = {2009-04-20 00:51:56},
    priority = {2},
    publisher = {The MIT Press},
    title = {Introduction to Algorithms, Second Edition},
    url = {http://www.worldcat.org/isbn/0262032937},
    year = {2001}
}

@article{citeulike:343069,
    abstract = {The R-tree, one of the most popular access methods for rectangles, is based on the heuristic
optimization of the area of the enclosing rectangle in each inner node. By running numerous experiments in a
standardized testbed under highly varying data, queries and operations, we were able to design the R * -tree which
incorporates a combined optimization of area, margin and overlap of each enclosing rectangle in the directory. Using our
standardized testbed in an exhaustive performance comparison, it turned out that the R * -tree clearly outperforms the
existing R-tree variants. Guttman's linear and quadratic R-tree and Greene's variant of the R-tree. This superiority of
the R * -tree holds for different types of queries and operations, such as map overlay, for both rectangles and
multidimensional points in all experiments. From a practical point of view the R * -tree is very attractive because of
the following two reasons 1 it efficiently supports point and spatial data at the same time and 2 
its implementation cost is only slightly higher than that of other R-trees.},
    address = {New York, NY, USA},
    author = {Beckmann, Norbert and Kriegel, Hans P. and Schneider, Ralf and Seeger, Bernhard},
    booktitle = {SIGMOD '90: Proceedings of the 1990 ACM SIGMOD international conference on Management of data},
    citeulike-article-id = {343069},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=98741},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/93597.98741},
    doi = {10.1145/93597.98741},
    isbn = {0-89791-365-5},
    issn = {0163-5808},
    journal = {SIGMOD Rec.},
    keywords = {lcs, litreview},
    location = {Atlantic City, New Jersey, United States},
    month = jun,
    number = {2},
    pages = {322--331},
    posted-at = {2009-04-20 00:31:55},
    priority = {2},
    publisher = {ACM},
    title = {The R*-tree: an efficient and robust access method for points and rectangles},
    url = {http://dx.doi.org/10.1145/93597.98741},
    volume = {19},
    year = {1990}
}

@inproceedings{citeulike:4367061,
    abstract = {We propose an inter-sequence matching method for exact and similarity matching of image sequences. Our
method transforms the image sequence matching problem into matching sequences of real numbers. The method does not
require sequences to be of the same length. It uses a modified version of the Longest Common Subsequence ({LCS}) method
for actually matching two sequences. We also propose a feature-based indexing mechanism to filter out those sequences
which are matching candidates with a given query sequence from a large data set. Like all other feature-based indexing
methods, our method maps each sequence into a point in K dimensional space, where K is the number of extracted features
for the sequence. It operates in two phases, hypothesizing and verification. Lengths and moments (mean and variance) of
sequences are used as features. Experimental results indicate that the features and proposed method for query processing
do well as a filter.},
    address = {Washington, DC, USA},
    author = {Yazdani, Nasser and \"{o}zsoyoglu, Meral Z.},
    booktitle = {SSDBM '96: Proceedings of the Eighth International Conference on Scientific and Statistical Database
Management},
    citeulike-article-id = {4367061},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=695458},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ssdm.1996.505915},
    doi = {10.1109/ssdm.1996.505915},
    isbn = {0-8186-7264-1},
    keywords = {lcs, litreview},
    pages = {53--62},
    posted-at = {2009-04-20 00:24:26},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Sequence Matching of Images},
    url = {http://dx.doi.org/10.1109/ssdm.1996.505915},
    year = {1996}
}

@incollection{citeulike:4367057,
    abstract = {The purpose of subsequence matching is to find a query sequence from a long data sequence. Due to the
abundance of applications, many solutions have been proposed. Virtually all previous solutions use the Euclidean measure
as the basis for measuring distance between sequences. Recent studies, however, suggest that the Euclidean distance
often fails to produce proper results due to the irregularity in the data, which is not so uncommon in our problem
domain. Addressing this problem, some {non-Euclidean} measures, such as Dynamic Time Warping ({DTW}) and Longest Common
Subsequence ({LCS}), have been proposed. However, most of the previous work in this direction focused on the whole
sequence matching problem where query and data sequences are the same length. In this paper, we propose a novel
subsequence matching framework using a {non-Euclidean} measure, in particular, {LCS}, and a new index query scheme. The
proposed framework is based on the Dual Match framework where data sequences are 
divided into a series of disjoint equi-length subsequences and then indexed in an R-tree. We introduced similarity bound
for index matching with {LCS}. The proposed query matching scheme reduces significant numbers of false positives in the
match result. Furthermore, we developed an algorithm to skip expensive {LCS} computations through observing the warping
paths. We validated our framework through extensive experiments using 48 different time series datasets. The results of
the experiments suggest that our approach significantly improves the subsequence matching performance in various
metrics.},
    author = {Han, Tae and Ko, Seung-Kyu and Kang, Jaewoo},
    citeulike-article-id = {4367057},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-73499-4\_44},
    citeulike-linkout-1 = {http://www.springerlink.com/content/t7266776q1w60045},
    doi = {10.1007/978-3-540-73499-4\_44},
    journal = {Machine Learning and Data Mining in Pattern Recognition},
    keywords = {lcs, litreview},
    pages = {585--600},
    posted-at = {2009-04-20 00:20:00},
    priority = {2},
    title = {Efficient Subsequence Matching Using the Longest Common Subsequence with a Dual Match Index},
    url = {http://dx.doi.org/10.1007/978-3-540-73499-4\_44},
    year = {2007}
}

@proceedings{citeulike:4344279,
    abstract = {Jagadish et al. (see Proc. {ACM} {SIGACT}-{SIGMOD}-{SIGART} {PODS}, p.36-45, 1995) developed a general
framework for posing queries based on similarity. The framework enables a formal definition of the notion of similarity
for an application domain of choice, and then its use in queries to perform similarity-based search. We adapt this
framework to the specialized domain of real-valued sequences. (Although some of the ideas we present are applicable to
other types of data as well). In particular we focus on whole-match queries. By whole-match query we mean the case where
the user has to specify the whole sequence. Similarity-based search can be computationally very expensive. The
computation cost depends heavily on the length of sequences being compared. To make such similarity testing feasible on
large data sets, we propose the use of a signature based technique. In a nutshell, our approach is to
\&ldquo;shrink\&rdquo; the data sequences into signatures, and search the signatures instead of 
the real sequences, with further comparison being required only when a possible match is indicated. Being shorter,
signatures can usually be compared much faster than the original sequences. In addition, signatures are usually easier
to index. For such a signature-based technique to be effective one has to assure that (1) the signature comparison is
fast, and (2) the signature comparison gives few false alarms, and no false dismissals. We obtain measures of goodness
for our technique. The technique is illustrated with a couple of very different examples},
    author = {Faloutsos, C. and Jagadish, H. V. and Mendelzon, A. O. and Milo, T.},
    booktitle = {Compression and Complexity of Sequences 1997. Proceedings},
    citeulike-article-id = {4344279},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/sequen.1997.666899},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=666899},
    doi = {10.1109/sequen.1997.666899},
    journal = {Compression and Complexity of Sequences 1997. Proceedings},
    keywords = {litreview, similarity},
    pages = {2--20},
    posted-at = {2009-04-17 16:18:29},
    priority = {2},
    title = {A signature technique for similarity-based queries},
    url = {http://dx.doi.org/10.1109/sequen.1997.666899},
    year = {1997}
}

@inproceedings{citeulike:3168542,
    abstract = {We study a set of linear transformations on the Fourier series representation of a sequence that can be
used as the basis for similarity queries on time-series data. We show that our set of transformations is rich enough to
formulate operations such as moving average and time warping. We present a query processing algorithm that uses the
underlying R-tree index of a multidimensional data set to answer similarity queries efficiently. Our experiments show
that the performance of this algorithm is competitive to that of processing ordinary (exact match) queries using the
index, and much faster than sequential scanning. We relate our transformations to the general framework for similarity
queries of Jagadish et al.},
    address = {New York, NY, USA},
    author = {Rafiei, Davood and Mendelzon, Alberto},
    booktitle = {SIGMOD '97: Proceedings of the 1997 ACM SIGMOD international conference on Management of data},
    citeulike-article-id = {3168542},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=253264},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/253260.253264},
    doi = {10.1145/253260.253264},
    isbn = {0-89791-911-4},
    keywords = {litreview},
    location = {Tucson, Arizona, United States},
    pages = {13--25},
    posted-at = {2009-04-17 16:13:48},
    priority = {2},
    publisher = {ACM},
    title = {Similarity-based queries for time series data},
    url = {http://dx.doi.org/10.1145/253260.253264},
    year = {1997}
}

@article{citeulike:4343933,
    abstract = {Recently some fast methods ( {LAESA}  and  {TLAESA} ) have been proposed to find nearest neighbours in
metric spaces. The average number of distances computed by these algorithms does not depend on the number of prototypes
and they show linear space complexity. These results where obtained through vast experimentation using only artificial
data. In this paper, we corroborate this behaviour when applied to handwritten character recognition tasks. Moreover, we
compare  {LAESA}  and  {TLAESA}  with some classical algorithms also working in metric spaces.},
    author = {Mic\'{o}, L.},
    citeulike-article-id = {4343933},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0167-8655(98)00007-5},
    doi = {10.1016/s0167-8655(98)00007-5},
    issn = {01678655},
    journal = {Pattern Recognition Letters},
    keywords = {litreview},
    month = mar,
    number = {3-4},
    pages = {351--356},
    posted-at = {2009-04-17 14:31:47},
    priority = {2},
    title = {Comparison of fast nearest neighbour classifiers for handwritten character recognition},
    url = {http://dx.doi.org/10.1016/s0167-8655(98)00007-5},
    volume = {19},
    year = {1998}
}

@article{citeulike:4343286,
    address = {Amsterdam, The Netherlands, The Netherlands},
    author = {Vidal, Enrique and Casacuberta, Francisco},
    citeulike-article-id = {4343286},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=45611},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/0167-6393(88)90022-2},
    doi = {10.1016/0167-6393(88)90022-2},
    issn = {0167-6393},
    journal = {Speech Commun.},
    keywords = {litreview},
    number = {1},
    pages = {67--79},
    posted-at = {2009-04-17 14:31:35},
    priority = {2},
    publisher = {Elsevier Science Publishers B. V.},
    title = {On the verification of triangle inequality by dynamic time-warping dissimilarity measures},
    url = {http://dx.doi.org/10.1016/0167-6393(88)90022-2},
    volume = {7},
    year = {1988}
}

@incollection{citeulike:4342003,
    abstract = {Time series are comprehensively appeared and developed in many applications. Similarity search under
time warping has attracted much interest between the time series in the large databases. {DTW} (Dynamic Time Warping) is
a robust distance measure and is superior to Euclidean distance. Nevertheless, it is more unfortunate that {DTW} has a
quadratic time and the false dismissals are come forth since {DTW} distance does not satisfy the triangular inequality.
In this paper, we propose an efficient range query algorithm based on a new similarity search method under time warping.
When our range query applies for this method, it can remove the significant non-qualify time series as early as
possible. Hence, it speeds up the calculation time and reduces the number of scanning the time series. Guaranteeing no
false dismissals the lower bounding function is advised that consistently underestimate the {DTW} distance and satisfy
the triangular inequality. Through the experimental results, our range 
query algorithm outperforms the existing others.},
    author = {Li, Chuyu and Jin, Long and Seo, Sungbo and Ryu, Keun},
    citeulike-article-id = {4342003},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11596448\_106},
    citeulike-linkout-1 = {http://www.springerlink.com/content/jll3l458631049g7},
    doi = {10.1007/11596448\_106},
    journal = {Computational Intelligence and Security},
    keywords = {litreview},
    pages = {721--728},
    posted-at = {2009-04-17 10:28:40},
    priority = {2},
    title = {An Efficient Range Query Under the Time Warping Distance},
    url = {http://dx.doi.org/10.1007/11596448\_106},
    year = {2005}
}

@incollection{citeulike:4326324,
    abstract = {In retail industry, it is very important to understand seasonal sales pattern, because this knowledge
can assist decision makers in managing inventory and formulating marketing strategies. {Self-Organizing} Map ({SOM}) is
suitable for extracting and illustrating essential structures because {SOM} has unsupervised learning and topology
preserving properties, and prominent visualization techniques. In this experiment, we propose a method for seasonal
pattern analysis using {Self-Organizing} Map. Performance test with real-world data from stationery stores in Indonesia
shows that the method is effective for seasonal pattern analysis. The results are used to formulate several marketing
and inventory management strategies. Keywords: Visualization, Clustering, Temporal Data, {Self-Organizing} Maps.},
    author = {Denny and Lee, Vincent C.},
    citeulike-article-id = {4326324},
    citeulike-linkout-0 = {http://www.springerlink.com/content/k3q3tpd3acaf2c0b},
    journal = {Advances in Knowledge Discovery and Data Mining},
    keywords = {litreview},
    pages = {424--430},
    posted-at = {2009-04-16 13:56:51},
    priority = {2},
    title = {An Alternative Methodology for Mining Seasonal Pattern Using {Self-Organizing} Map},
    url = {http://www.springerlink.com/content/k3q3tpd3acaf2c0b},
    year = {2004}
}

@article{citeulike:3000416,
    abstract = {The problem of similarity search in large time series databases has attracted much attention recently.
It is a non-trivial problem because of the inherent high dimensionality of the data. The most promising solutions
involve first performing dimensionality reduction on the data, and then indexing the reduced data with a spatial access
method. Three major dimensionality reduction techniques have been proposed: Singular Value Decomposition ({SVD}), the
Discrete Fourier transform ({DFT}), and more recently the Discrete Wavelet Transform ({DWT}). In this work we introduce
a new dimensionality reduction technique which we call Piecewise Aggregate Approximation ({PAA}). We theoretically and
empirically compare it to the other techniques and demonstrate its superiority. In addition to being competitive with or
faster than the other methods, our approach has numerous other advantages. It is simple to understand and to implement,
it allows more flexible distance measures, including weighted Euclidean 
queries, and the index can be built in linear time.},
    author = {Keogh, Eamonn and Chakrabarti, Kaushik and Pazzani, Michael and Mehrotra, Sharad},
    citeulike-article-id = {3000416},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/pl00011669},
    citeulike-linkout-1 = {http://www.springerlink.com/content/dxd9j6wrk23x6n9r},
    day = {20},
    doi = {10.1007/pl00011669},
    issn = {0219-1377},
    journal = {Knowledge and Information Systems},
    keywords = {litreview, sax},
    month = aug,
    number = {3},
    pages = {263--286},
    posted-at = {2009-04-15 03:52:46},
    priority = {2},
    publisher = {Springer London},
    title = {Dimensionality Reduction for Fast Similarity Search in Large Time Series Databases},
    url = {http://dx.doi.org/10.1007/pl00011669},
    volume = {3},
    year = {2001}
}

@article{citeulike:2821475,
    abstract = {{Abstract\&nbsp;\&nbsp;Many} high level representations of time series have been proposed for data
mining, including Fourier transforms, wavelets, eigenwaves, piecewise polynomial models, etc. Many researchers have also
considered symbolic representations of time series, noting that such representations would potentiality allow
researchers to avail of the wealth of data structures and algorithms from the text processing and bioinformatics
communities. While many symbolic representations of time series have been introduced over the past decades, they all
suffer from two fatal flaws. First, the dimensionality of the symbolic representation is the same as the original data,
and virtually all data mining algorithms scale poorly with dimensionality. Second, although distance measures can be
defined on the symbolic approaches, these distance measures have little correlation with distance measures defined on
the original time series. In this work we formulate a new symbolic representation of time 
series. Our representation is unique in that it allows dimensionality/numerosity reduction, and it also allows distance
measures to be defined on the symbolic approach that lower bound corresponding distance measures defined on the original
series. As we shall demonstrate, this latter feature is particularly exciting because it allows one to run certain data
mining algorithms on the efficiently manipulated symbolic representation, while producing identical results to the
algorithms that operate on the original data. In particular, we will demonstrate the utility of our representation on
various data mining tasks of clustering, classification, query by content, anomaly detection, motif discovery, and
visualization.},
    author = {Lin, Jessica and Keogh, Eamonn and Wei, Li and Lonardi, Stefano},
    citeulike-article-id = {2821475},
    citeulike-linkout-0 = {http://dblp.uni-trier.de/rec/bibtex/journals/datamine/LinKWL07},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s10618-007-0064-z},
    citeulike-linkout-2 = {http://www.springerlink.com/content/g69808822l82t325},
    day = {1},
    doi = {10.1007/s10618-007-0064-z},
    issn = {1384-5810},
    journal = {Data Mining and Knowledge Discovery},
    keywords = {litreview, sax},
    month = oct,
    number = {2},
    pages = {107--144},
    posted-at = {2009-04-15 03:51:17},
    priority = {2},
    title = {Experiencing {SAX}: a novel symbolic representation of time series},
    url = {http://dx.doi.org/10.1007/s10618-007-0064-z},
    volume = {15},
    year = {2007}
}

@inproceedings{citeulike:4303331,
    abstract = {Ad hoc querying is difficult on very large datasets, since it is usually not possible to have the entire
dataset on disk. While compression can be used to decrease the size of the dataset, compressed data is notoriously
difficult to index or access.   In this paper we consider a very large dataset comprising multiple distinct time
sequences. Each point in the sequence is a numerical value. We show how to compress such a dataset into a format that
supports ad hoc querying, provided that a small error can be tolerated when the data is uncompressed. Experiments on
large, real world datasets ( {AT}\&{amp;T}  customer calling patterns) show that the proposed method achieves an average
of less than 5\% error in any data value after compressing to a mere 2.5\% of the original space ( i.e. , a 40:1
compression ratio), with these numbers not very sensitive to dataset size. Experiments on aggregate queries achieved a
0.5\% reconstruction error with a space requirement under 2\%.},
    address = {New York, NY, USA},
    author = {Korn, Flip and Jagadish, H. V. and Faloutsos, Christos},
    booktitle = {SIGMOD '97: Proceedings of the 1997 ACM SIGMOD international conference on Management of data},
    citeulike-article-id = {4303331},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=253332},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/253260.253332},
    doi = {10.1145/253260.253332},
    isbn = {0-89791-911-4},
    keywords = {litreview},
    location = {Tucson, Arizona, United States},
    pages = {289--300},
    posted-at = {2009-04-12 22:00:21},
    priority = {2},
    publisher = {ACM},
    title = {Efficiently supporting ad hoc queries in large datasets of time sequences},
    url = {http://dx.doi.org/10.1145/253260.253332},
    year = {1997}
}

@inproceedings{citeulike:4295248,
    abstract = {Key words numerical time sequence, subsequence matching, indexing structure, a sequence of linear
segments 1},
    author = {Morinaka, Y. and Yoshikawa, M. and Amagasa, T. and Uemura, S.},
    citeulike-article-id = {4295248},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.4751},
    journal = {PAKDD},
    keywords = {litreview, similarity},
    posted-at = {2009-04-09 19:11:07},
    priority = {2},
    title = {The L-index: An Indexing Structure for Efficient Subsequence Matching in {TimeSequence} Databases},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.4751},
    year = {2001}
}

@inproceedings{citeulike:4165220,
    abstract = {Similarity-based search over time-series databases has been a hot research topic for a long history,
which is widely used in many applications, including multimedia retrieval, data mining, web search and retrieval, and so
on. However, due to high dimensionality (i.e. length) of the time series, the similarity search over directly indexed
time series usually encounters a serious problem, known as the "dimensionality curse". Thus, many dimensionality
reduction techniques are proposed to break such curse by reducing the dimensionality of time series. Among all the
proposed methods, only  Piecewise Linear Approximation  ({PLA}) does not have indexing mechanisms to support similarity
queries, which prevents it from efficiently searching over very large time-series databases. Our initial studies on the
effectiveness of different reduction methods, however, show that {PLA} performs no worse than others. Motivated by this,
in this paper, we re-investigate {PLA} for approximating and indexing time 
series. Specifically, we propose a novel distance function in the reduced {PLA}-space, and prove that this function
indeed results in a lower bound of the Euclidean distance between the original time series, which can lead to no  false
dismissals  during the similarity search. As a second step, we develop an effective approach to index these lower bounds
to improve the search efficiency. Our extensive experiments over a wide spectrum of real and synthetic data sets have
demonstrated the efficiency and effectiveness of {PLA} together with the newly proposed lower bound distance, in terms
of both  pruning power  and  wall clock time , compared with two state-of-the-art reduction methods,  Adaptive Piecewise
Constant Approximation  ({APCA}) and  Chebyshev Polynomials  ({CP}).},
    author = {Chen, Qiuxia and Chen, Lei and Lian, Xiang and Liu, Yunhao and Yu, Jeffrey X.},
    booktitle = {VLDB '07: Proceedings of the 33rd international conference on Very large data bases},
    citeulike-article-id = {4165220},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1325851.1325903},
    isbn = {978-1-59593-649-3},
    keywords = {litreview, pla},
    location = {Vienna, Austria},
    pages = {435--446},
    posted-at = {2009-04-09 19:10:15},
    priority = {2},
    publisher = {VLDB Endowment},
    title = {Indexable {PLA} for efficient similarity search},
    url = {http://portal.acm.org/citation.cfm?id=1325851.1325903},
    year = {2007}
}

@inproceedings{citeulike:2753031,
    address = {New York, NY, USA},
    author = {Cai, Yuhan and Ng, Raymond},
    booktitle = {SIGMOD '04: Proceedings of the 2004 ACM SIGMOD international conference on Management of data},
    citeulike-article-id = {2753031},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1007568.1007636},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1007568.1007636},
    doi = {10.1145/1007568.1007636},
    isbn = {1581138598},
    keywords = {chebyshev, litreview},
    pages = {599--610},
    posted-at = {2009-04-09 19:08:19},
    priority = {2},
    publisher = {ACM},
    title = {Indexing spatio-temporal trajectories with Chebyshev polynomials},
    url = {http://dx.doi.org/10.1145/1007568.1007636},
    year = {2004}
}

@article{citeulike:3734066,
    abstract = {We consider the use of wavelet transformations as a dimensionality reduction technique to permit
efficient similarity search over high-dimensional time-series data. While numerous transformations have been proposed
and studied, the only wavelet that has been shown to be effective for this application is the Haar wavelet. In this
work, we observe that a large class of wavelet transformations (not only orthonormal wavelets but also bi-orthonormal
wavelets) can be used to support similarity search. This class includes the most popular and most effective wavelets
being used in image compression. We present a detailed performance study of the effects of using different wavelets on
the performance of similarity search for time-series data. We include several wavelets that outperform both the Haar
wavelet and the best known non-wavelet transformations for this application. To ensure our results are usable by an
application engineer, we also show how to configure an indexing strategy for the best 
performing transformations. Finally, we identify classes of data that can be indexed efficiently using these wavelet
transformations.},
    address = {Los Alamitos, CA, USA},
    author = {Popivanov, Ivan and Miller, Renee J.},
    booktitle = {Data Engineering, 2002. Proceedings. 18th International Conference on},
    citeulike-article-id = {3734066},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/ICDE.2002.994711},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icde.2002.994711},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=994711},
    doi = {10.1109/icde.2002.994711},
    isbn = {0-7695-1531-2},
    journal = {Data Engineering, International Conference on},
    keywords = {dwt, litreview},
    pages = {0212--221},
    posted-at = {2009-04-09 19:07:19},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Similarity Search Over {Time-Series} Data Using Wavelets},
    url = {http://dx.doi.org/10.1109/icde.2002.994711},
    volume = {0},
    year = {2002}
}

@electronic{citeulike:4295242,
    abstract = {Time series data are of growing importance in many newdatabase applications, such as data warehousing
and data mining [3, 8, 2, 12]. A time series (or time sequence) is a sequence ofreal numbers, each number representing a
value at a time point. Typical examples include stock prices or currency exchange rates,biomedical measurements, weather
data, etc... collected over time. Therefore, time series databases supporting fast retrieval oftime series data and
similarity queries are desired.},
    citeulike-article-id = {4295242},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.113.8628},
    keywords = {dwt, litreview},
    posted-at = {2009-04-09 19:05:40},
    priority = {2},
    title = {Efficient Time Series Matching by Wavelets},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.113.8628}
}

@incollection{citeulike:3973409,
    abstract = {We propose an indexing method for time sequences for processing similarity queries. We use the Discrete
Fourier Transform ({DFT}) to map time sequences to the frequency domain, the crucial observation being that, for most
sequences of practical interest, only the first few frequencies are strong. Another important observation is Parseval's
theorem, which specifies that the Fourier transform preserves the Euclidean distance in the time or frequency domain.
Having thus mapped sequences to a lower-dimensionality space by using only the first few Fourier coefficients, we use R
* -trees to index the sequences and efficiently answer similarity queries. We provide experimental results which show
that our method is superior to search based on sequential scanning. Our experiments show that a few coefficients (1–3)
are adequate to provide good performance. The performance gain of our method increases with the number and length of
sequences.},
    author = {Agrawal, Rakesh and Faloutsos, Christos and Swami, Arun},
    citeulike-article-id = {3973409},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-57301-1\_5},
    citeulike-linkout-1 = {http://www.springerlink.com/content/y35556n137721536},
    doi = {10.1007/3-540-57301-1\_5},
    journal = {Foundations of Data Organization and Algorithms},
    keywords = {litreview},
    pages = {69--84},
    posted-at = {2009-04-09 19:04:28},
    priority = {2},
    title = {Efficient similarity search in sequence databases},
    url = {http://dx.doi.org/10.1007/3-540-57301-1\_5},
    year = {1993}
}

@inproceedings{citeulike:3978002,
    abstract = {The problem of efficiently locating previously known patterns in a time series database (i.e., query by
content) has received much attention and may now largely be regarded as a solved problem. However, from a knowledge
discovery viewpoint, a more interesting problem is the enumeration of previously unknown, frequently occurring patterns.
We call such patterns  ” motifs,” because of their close analogy to their discrete counterparts in computation biology.
An efficient motif discovery algorithm for time series would be useful as a tool for summarizing and visualizing massive
time series databases. In addition, it could be used as a subroutine in various other data mining tasks, including the
discovery of association rules, clustering and classification. In this work we carefully motivate, then introduce, a
non-trivial definition of time series motifs. We propose an efficient algorithm to discover them, and we demonstrate the
utility and efficiency of our approach on several real world 
datasets.},
    author = {Lin, Jessica and Keogh, Eamonn J. and Lonardi, Stefano and Patel, Pranav},
    booktitle = {2nd Workshop on Temporal Data Mining, at the 8th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining},
    citeulike-article-id = {3978002},
    day = {23-26},
    keywords = {dtw, similarity, thesis},
    location = {Edmonton, Alberta, Canada},
    month = jul,
    posted-at = {2009-03-05 11:22:44},
    priority = {2},
    title = {Finding Motifs in Time Series},
    year = {2002}
}

@inproceedings{citeulike:2946589,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has
opted to expose the complete List rather than only correct and linked references.},
    address = {San Francisco, CA, USA},
    author = {Yi, Byoung K. and Faloutsos, Christos},
    booktitle = {VLDB '00: Proceedings of the 26th International Conference on Very Large Data Bases},
    citeulike-article-id = {2946589},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=645926.671689},
    isbn = {1-55860-715-3},
    keywords = {dtw, litreview, paa, similarity, thesis},
    pages = {385--394},
    posted-at = {2009-02-26 13:26:35},
    priority = {2},
    publisher = {Morgan Kaufmann Publishers Inc.},
    title = {Fast Time Sequence Indexing for Arbitrary Lp Norms},
    url = {http://portal.acm.org/citation.cfm?id=645926.671689},
    year = {2000}
}

@article{citeulike:1736140,
    abstract = {Similarity search in large time series databases has attracted much research interest recently. It is a
difficult problem because of the typically high dimensionality of the data. The most promising solutions involve
performing dimensionality reduction on the data, then indexing the reduced data with a multidimensional index structure.
Many dimensionality reduction techniques have been proposed, including Singular Value Decomposition ({SVD}), the
Discrete Fourier transform ({DFT}), and the Discrete Wavelet Transform ({DWT}). In this article, we introduce a new
dimensionality reduction technique, which we call Adaptive Piecewise Constant Approximation ({APCA}). While previous
techniques (e.g., {SVD}, {DFT} and {DWT}) choose a common representation for all the items in the database that
minimizes the global reconstruction error, {APCA} approximates each time series by a set of constant value segments of
varying lengths such that their individual reconstruction errors are minimal. We show how {
APCA} can be indexed using a multidimensional index structure. We propose two distance measures in the indexed space
that exploit the high fidelity of {APCA} for fast searching: a lower bounding Euclidean distance approximation, and a
non-lower-bounding, but very tight, Euclidean distance approximation, and show how they can support fast exact searching
and even faster approximate searching on the same index structure. We theoretically and empirically compare {APCA} to
all the other techniques and demonstrate its superiority.},
    address = {New York, NY, USA},
    author = {Chakrabarti, Kaushik and Keogh, Eamonn and Mehrotra, Sharad and Pazzani, Michael},
    citeulike-article-id = {1736140},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=568518.568520},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/568518.568520},
    doi = {10.1145/568518.568520},
    issn = {0362-5915},
    journal = {ACM Trans. Database Syst.},
    keywords = {dtw, gemini, litreview, paa, similarity, thesis},
    month = jun,
    number = {2},
    pages = {188--228},
    posted-at = {2009-02-26 13:25:29},
    priority = {2},
    publisher = {ACM},
    title = {Locally adaptive dimensionality reduction for indexing large time series databases},
    url = {http://dx.doi.org/10.1145/568518.568520},
    volume = {27},
    year = {2002}
}

@inproceedings{citeulike:532335,
    abstract = {The parallel explosions of interest in streaming data, and data mining of time series have had
surprisingly little intersection. This is in spite of the fact that time series data are typically streaming data. The
main reason for this apparent paradox is the fact that the vast majority of work on streaming data explicitly assumes
that the data is discrete, whereas the vast majority of time series data is real {valued.Many} researchers have also
considered transforming real valued time series into symbolic representations, nothing that such representations would
potentially allow researchers to avail of the wealth of data structures and algorithms from the text processing and
bioinformatics communities, in addition to allowing formerly "batch-only" problems to be tackled by the streaming
community. While many symbolic representations of time series have been introduced over the past decades, they all
suffer from three fatal flaws. Firstly, the dimensionality of the symbolic representation is 
the same as the original data, and virtually all data mining algorithms scale poorly with dimensionality. Secondly,
although distance measures can be defined on the symbolic approaches, these distance measures have little correlation
with distance measures defined on the original time series. Finally, most of these symbolic approaches require one to
have access to all the data, before creating the symbolic representation. This last feature explicitly thwarts efforts
to use the representations with streaming {algorithms.In} this work we introduce a new symbolic representation of time
series. Our representation is unique in that it allows dimensionality/numerosity reduction, and it also allows distance
measures to be defined on the symbolic approach that lower bound corresponding distance measures defined on the original
series. As we shall demonstrate, this latter feature is particularly exciting because it allows one to run certain data
mining algorithms on the efficiently manipulated symbolic representation,
 while producing identical results to the algorithms that operate on the original data. Finally, our representation
allows the real valued data to be converted in a streaming fashion, with only an infinitesimal time and space
{overhead.We} will demonstrate the utility of our representation on the classic data mining tasks of clustering,
classification, query by content and anomaly detection.},
    address = {New York, NY, USA},
    author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano and Chiu, Bill},
    booktitle = {Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery},
    citeulike-article-id = {532335},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=882086},
    citeulike-linkout-1 = {http://dblp.uni-trier.de/rec/bibtex/conf/dmkd/LinKLC03},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/882082.882086},
    doi = {10.1145/882082.882086},
    keywords = {dtw, litreview, similarity, thesis},
    location = {San Diego, California},
    pages = {2--11},
    posted-at = {2009-02-26 12:51:56},
    priority = {2},
    publisher = {ACM},
    series = {DMKD '03},
    title = {A symbolic representation of time series, with implications for streaming algorithms},
    url = {http://dx.doi.org/10.1145/882082.882086},
    year = {2003}
}

@incollection{citeulike:4107287,
    abstract = {In this digital age, great interest has been shifted toward multimedia data manipulations. This includes
videos, images, and audios, where typical manipulations require fairly large storage and are computationally intensive.
Recent research has demonstrated the utilities of time series representation in various data mining tasks, allowing
considerable reduction in time and space complexity. Specifically, the utilities of Uniform Scaling ({US}) and Dynamic
Time Warping ({DTW}) have been shown to be necessary in several human-related domains, where uniform stretching or
shrinking, as well as some local variation are typical. Classic examples include a query-by-humming system and motion
capture data. However, all the past work has neglected the importance of data normalization before distance
calculations, and therefore does not guarantee accurate retrievals. In this work, we discuss this concern and present a
technique that accurately and efficiently searches under the {US} with {DTW} for 
normalized time series data, where no-false-dismissals are guaranteed.},
    author = {Euachongprasit, Waiyawuth and Ratanamahatana, Chotirat},
    citeulike-article-id = {4107287},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-68125-0\_11},
    citeulike-linkout-1 = {http://www.springerlink.com/content/k364255778611382},
    doi = {10.1007/978-3-540-68125-0\_11},
    journal = {Advances in Knowledge Discovery and Data Mining},
    pages = {100--111},
    posted-at = {2009-02-26 12:45:40},
    priority = {2},
    title = {Accurate and Efficient Retrieval of Multimedia Time Series Data Under Uniform Scaling and Time Warping},
    url = {http://dx.doi.org/10.1007/978-3-540-68125-0\_11},
    year = {2008}
}

@proceedings{citeulike:4043115,
    abstract = {Dynamic Time Warping ({DTW}) is a pattern matching approach that can be used for limited vocabulary
speech recognition, which is based on a temporal alignment of the input signal with the template models. The main
drawback of this method is its high computational cost when the length of the signals increases. This paper presents a
modified ver- sion of the {DTW}, based on the Discrete Wavelet Transform ({DWT}), that reduces its original complexity.
Many wavelet families with different support-sizes are experimented and the corresponding results are reported.},
    author = {Junior, Sylvio B. and Guido, Rodrigo C. and Chen, Shi-Huang and Vieira, Lucimar S. and Sanchez, Fabricio
L.},
    booktitle = {Multimedia Workshops, 2007. ISMW '07. Ninth IEEE International Symposium on},
    citeulike-article-id = {4043115},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ism.workshops.2007.51},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4475980},
    doi = {10.1109/ism.workshops.2007.51},
    journal = {Multimedia Workshops, 2007. ISMW '07. Ninth IEEE International Symposium on},
    keywords = {dtw, litreview, thesis},
    pages = {256--263},
    posted-at = {2009-02-13 11:04:31},
    priority = {2},
    title = {Improved Dynamic Time Warping Based on the Discrete Wavelet Transform},
    url = {http://dx.doi.org/10.1109/ism.workshops.2007.51},
    year = {2007}
}

@inproceedings{citeulike:4036334,
    abstract = {A variety of techniques currently exist for measuring the similarity between time series datasets. Of
these techniques, the methods whose matching criteria is bounded by a specified \&\#949; threshold value, such as the
{LCSS} and the {EDR} techniques, have been shown to be robust in the presence of noise, time shifts, and data scaling.
Our work proposes a new algorithm, called the Fast Time Series Evaluation ({FTSE}) method, which can be used to evaluate
such threshold value techniques, including {LCSS} and {EDR}. Using {FTSE}, we show that these techniques can be
evaluated faster than using either traditional dynamic programming or even warp-restricting methods such as the
{Sakoe-Chiba} band and the Itakura Parallelogram.},
    address = {New York, NY, USA},
    author = {Morse, Michael D. and Patel, Jignesh M.},
    booktitle = {SIGMOD '07: Proceedings of the 2007 ACM SIGMOD international conference on Management of data},
    citeulike-article-id = {4036334},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1247480.1247544},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1247480.1247544},
    doi = {10.1145/1247480.1247544},
    isbn = {978-1-59593-686-8},
    keywords = {dtw, lcs, litreview, thesis},
    location = {Beijing, China},
    pages = {569--580},
    posted-at = {2009-02-11 18:02:03},
    priority = {2},
    publisher = {ACM},
    title = {An efficient and accurate method for evaluating time series similarity},
    url = {http://dx.doi.org/10.1145/1247480.1247544},
    year = {2007}
}

@article{citeulike:4031866,
    abstract = {We address the handling of time series search based on two important distance definitions: Euclidean
distance and time warping distance. The conventional method reduces the dimensionality by means of a discrete Fourier
transform. We apply the Haar wavelet transform technique and propose the use of a proper normalization so that the
method can guarantee no false dismissal for Euclidean distance. We found that this method has competitive performance
from our experiments. Euclidean distance measurement cannot handle the time shifts of patterns. It fails to match the
same rise and fall patterns of sequences with different scales. A distance measure that handles this problem is the time
warping distance. However, the complexity of computing the time warping distance function is high. Also, as time warping
distance is not a metric, most indexing techniques would not guarantee any false dismissal. We propose efficient
strategies to mitigate the problems of time warping. We suggest a Haar wavelet-
based approximation function for time warping distance, called Low Resolution Time Warping, which results in less
computation by trading off a small amount of accuracy. We apply our approximation function to similarity search in time
series databases, and show by experiment that it is highly effective in suppressing the number of false alarms in
similarity search.},
    author = {Chan, F. K. P. and Fu, A. W. C. and Yu, C.},
    booktitle = {Knowledge and Data Engineering, IEEE Transactions on},
    citeulike-article-id = {4031866},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tkde.2003.1198399},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1198399},
    doi = {10.1109/tkde.2003.1198399},
    journal = {Knowledge and Data Engineering, IEEE Transactions on},
    keywords = {dtw, litreview, similarity, thesis, wavelet},
    number = {3},
    pages = {686--705},
    posted-at = {2009-02-10 21:43:38},
    priority = {2},
    title = {Haar wavelets for efficient similarity search of time-series: with and without time warping},
    url = {http://dx.doi.org/10.1109/tkde.2003.1198399},
    volume = {15},
    year = {2003}
}

@proceedings{citeulike:4031865,
    abstract = {Mining time series data is an important approach for the analysis in many application areas as diverse
as biology, environmental research, medicine, or stock chart analysis. As nearly all data mining tasks on this kind of
data depend on a distance function between two time series, a huge number of such functions has been developed during
the last decades. The introduction of threshold-based distance functions presented a new concept of time series
similarity and these functions were applied to data mining techniques on a wide spectrum of time series data. In this
demonstration, we present the Java toolkit {T-Time} which is able to perform several data mining tasks for a complete
range of threshold values in an interactive way. The results are visually presented in a very concise way so that the
user can easily identify important threshold values. Combined with domain-specific knowledge, these pivotal values can
yield novel insights beyond the means of the underlying data mining techniques the 
analysis is based on.},
    author = {Assfalg, J. and Kriegel, H. P. and Kroger, P. and Kunath, P. and Pryakhin, A. and Renz, M.},
    booktitle = {Data Engineering, 2008. ICDE 2008. IEEE 24th International Conference on},
    citeulike-article-id = {4031865},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icde.2008.4497636},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4497636},
    doi = {10.1109/icde.2008.4497636},
    journal = {Data Engineering, 2008. ICDE 2008. IEEE 24th International Conference on},
    keywords = {dtw, litreview, similarity, thesis},
    pages = {1620--1623},
    posted-at = {2009-02-10 21:41:29},
    priority = {2},
    title = {{T-Time}: {Threshold-Based} Data Mining on Time Series},
    url = {http://dx.doi.org/10.1109/icde.2008.4497636},
    year = {2008}
}

@article{citeulike:3357064,
    abstract = {The paper investigates the possibilities of using clustering techniques in visual exploration and
analysis of large numbers of trajectories, that is, sequences of time-stamped locations of some moving entities.
Trajectories are complex spatio-temporal constructs characterized by diverse non-trivial properties. To assess the
degree of (dis)similarity between trajectories, specific methods (distance functions) are required. A single distance
function accounting for all properties of trajectories, (1) is difficult to build, (2) would require much time to
compute, and (3) might be difficult to understand and to use. We suggest the procedure of progressive clustering where a
simple distance function with a clear meaning is applied on each step, which leads to easily interpretable outcomes.
Successive application of several different functions enables sophisticated analyses through gradual refinement of
earlier obtained results. Besides the advantages from the sense-making perspective, progressive 
clustering enables a rational work organization where time-consuming computations are applied to relatively small
potentially interesting subsets obtained by means of 'cheap' distance functions producing quick results. We introduce
the concept of progressive clustering by an example of analyzing a large real data set. We also review the existing
clustering methods, describe the method {OPTICS} suitable for progressive clustering of trajectories, and briefly
present several distance functions for trajectories.},
    author = {Rinzivillo, Salvatore and Pedreschi, Dino and Nanni, Mirco and Giannotti, Fosca and Andrienko, Natalia and
Andrienko, Gennady},
    citeulike-article-id = {3357064},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1594715},
    citeulike-linkout-1 = {http://dx.doi.org/10.1057/palgrave.ivs.9500183},
    citeulike-linkout-2 = {http://ivi.sagepub.com/content/7/3-4/225.abstract},
    citeulike-linkout-3 = {http://ivi.sagepub.com/content/7/3-4/225.full.pdf},
    citeulike-linkout-4 = {http://www.ingentaconnect.com/content/pal/14738716/2008/00000007/F0020003/art00005},
    day = {21},
    doi = {10.1057/palgrave.ivs.9500183},
    issn = {1473-8724},
    journal = {Information Visualization},
    keywords = {litreview, publication, similarity, thesis},
    month = sep,
    number = {3-4},
    pages = {225--239},
    posted-at = {2009-02-10 21:31:06},
    priority = {2},
    publisher = {SAGE Publications},
    title = {Visually Driven Analysis of Movement Data by Progressive Clustering},
    url = {http://dx.doi.org/10.1057/palgrave.ivs.9500183},
    volume = {7},
    year = {2008}
}

@article{citeulike:2427286,
    address = {New York, NY, USA},
    author = {Schreck, Tobias and Teku\vsov\'a, Tatiana and Kohlhammer, J\"orn and Fellner, Dieter},
    citeulike-article-id = {2427286},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1345448.1345454},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1345448.1345454},
    doi = {10.1145/1345448.1345454},
    issn = {1931-0145},
    journal = {SIGKDD Explor. Newsl.},
    keywords = {dtw, litreview, similarity, thesis},
    month = dec,
    number = {2},
    pages = {30--37},
    posted-at = {2009-02-10 21:26:54},
    priority = {2},
    publisher = {ACM},
    title = {Trajectory-based visual analysis of large financial time series data},
    url = {http://dx.doi.org/10.1145/1345448.1345454},
    volume = {9},
    year = {2007}
}

@inproceedings{citeulike:4025073,
    abstract = {Time series data poses a significant variation to the traditional segmentation techniques of data mining
because the observation is derived from multiple instances of the same underlying record. Additionally, the standard
segmentation methods employed in traditional clustering require instances to be classified exactly by attaching an event
to a specific cluster at the exclusion of other clusters. This paper is an investigation into the predictive power of
the clustering technique on stock market data and its ability to provide stock predictions that can be utilised in
strategies that outperform the underlying market. This uses a brute force approach to the prediction of stock prices
based on the formation of a cluster around the query sequence. The prediction is then applied in a model designed to
capitalise on the derived prediction. The predictive accuracy of minimum distance clusters produced promising results
with a prediction error incorporated into the forecast strategy.},
    address = {Darlinghurst, Australia, Australia},
    author = {Nayak, Richi and Braak, Paul T.},
    booktitle = {AIDM '07: Proceedings of the 2nd international workshop on Integrating artificial intelligence and data
mining},
    citeulike-article-id = {4025073},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1386993.1387003},
    isbn = {978-1-920682-65-1},
    keywords = {litreview, similarity, thesis},
    location = {Gold Coast, Australia},
    pages = {95--103},
    posted-at = {2009-02-09 09:56:43},
    priority = {2},
    publisher = {Australian Computer Society, Inc.},
    title = {Temporal pattern matching for the prediction of stock prices},
    url = {http://portal.acm.org/citation.cfm?id=1386993.1387003},
    year = {2007}
}

@article{citeulike:973785,
    address = {New York, NY, USA},
    author = {Li, Tao and Li, Qi and Zhu, Shenghuo and Ogihara, Mitsunori},
    citeulike-article-id = {973785},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=772862.772870},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/772862.772870},
    doi = {10.1145/772862.772870},
    issn = {1931-0145},
    journal = {SIGKDD Explor. Newsl.},
    keywords = {litreview, thesis, wavelet},
    month = dec,
    number = {2},
    pages = {49--68},
    posted-at = {2009-02-09 09:54:19},
    priority = {2},
    publisher = {ACM Press},
    title = {A survey on wavelet applications in data mining},
    url = {http://dx.doi.org/10.1145/772862.772870},
    volume = {4},
    year = {2002}
}

@article{citeulike:2693625,
    address = {New York, NY, USA},
    author = {Maier, David},
    citeulike-article-id = {2693625},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=322075},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/322063.322075},
    doi = {10.1145/322063.322075},
    issn = {0004-5411},
    journal = {J. ACM},
    keywords = {lcs, litreview, thesis},
    month = apr,
    number = {2},
    pages = {322--336},
    posted-at = {2009-02-09 09:33:53},
    priority = {2},
    publisher = {ACM},
    title = {The Complexity of Some Problems on Subsequences and Supersequences},
    url = {http://dx.doi.org/10.1145/322063.322075},
    volume = {25},
    year = {1978}
}

@inproceedings{citeulike:4024793,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has
opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Hadlock, F.},
    booktitle = {IEA/AIE '88: Proceedings of the 1st international conference on Industrial and engineering applications
of artificial intelligence and expert systems},
    citeulike-article-id = {4024793},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=55674.55676},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/55674.55676},
    doi = {10.1145/55674.55676},
    isbn = {0-89791-271-3},
    keywords = {lcs, litreview, thesis},
    location = {Tullahoma, Tennessee, United States},
    pages = {645--653},
    posted-at = {2009-02-09 09:31:17},
    priority = {2},
    publisher = {ACM},
    title = {An efficient algorithm for pattern detection and classification},
    url = {http://dx.doi.org/10.1145/55674.55676},
    year = {1988}
}

@inproceedings{citeulike:2659746,
    abstract = {The aim of this paper is to give a comprehensive comparison of
well-known longest common subsequence algorithms (for two input strings)
and study their behaviour in various application environments. The
performance of the methods depends heavily on the properties of the
problem instance as well as the supporting data structures used in the
implementation. We want to make also a clear distinction between methods
that determine the actual lcs and those calculating only its length,
since the execution time and more importantly, the space demand depends
crucially on the type of the task. To our knowledge, this is the first
time this kind of survey has been done. Due to the page limits, the
paper gives only a coarse overview of the performance of the algorithms;
more detailed studies are reported elsewhere},
    author = {Bergroth, L. and Hakonen, H. and Raita, T.},
    booktitle = {String Processing and Information Retrieval, 2000. SPIRE 2000. Proceedings. Seventh International
Symposium on},
    citeulike-article-id = {2659746},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/SPIRE.2000.878178},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/spire.2000.878178},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=878178},
    doi = {10.1109/spire.2000.878178},
    institution = {Dept. of Comput. Sci., Turku Univ.},
    isbn = {0-7695-0746-8},
    journal = {String Processing and Information Retrieval, 2000. SPIRE 2000. Proceedings. Seventh International
Symposium on},
    keywords = {lcs, litreview, thesis},
    pages = {39--48},
    posted-at = {2009-02-09 09:26:20},
    priority = {2},
    publisher = {IEEE},
    title = {A survey of longest common subsequence algorithms},
    url = {http://dx.doi.org/10.1109/spire.2000.878178},
    year = {2000}
}

@proceedings{citeulike:4022060,
    abstract = {Monitoring predefined patterns in streaming time series is useful to applications such as trend-related
analysis, sensor networks and video surveillance. Most current studies on such monitoring employ Euclidean distance to
calculate the similarities between given query patterns and subsequences of streaming time series. Euclidean distance
has been shown to be ineffective in measuring distances of time series in which shifting and scaling usually exist.
Consequently, warping distances such as dynamic time warping ({DTW}), longest common subsequence ({LCSS}), have been
proposed to handle warps in temporal dimension. However, they are inadequate in handling shifting and scaling in
amplitude dimension. Moreover, they have been designed mainly for full sequence matching, whereas in online monitoring
applications, we typically have no knowledge on the positions and lengths of possible matching subsequences. In this
paper, we first discuss the weaknesses of existing warping distances on detecting 
patterns from streaming time series. We then propose a novel warping distance, which we name Spatial Assembling Distance
({SpADe}), that is able to handle shifting and scaling in both temporal and amplitude dimensions. We further propose an
efficient approach for continuous pattern detection using {SpADe}, that is fundamental for subsequence matching on
streaming data. Finally, our experimental results show that {SpADe} is effective and efficient for continuous pattern
detection in streaming time series.},
    author = {Chen, Yueguo and Nascimento, M. A. and Ooi, Beng C. and Tung, A. K. H.},
    booktitle = {Data Engineering, 2007. ICDE 2007. IEEE 23rd International Conference on},
    citeulike-article-id = {4022060},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icde.2007.367924},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4221727},
    doi = {10.1109/icde.2007.367924},
    journal = {Data Engineering, 2007. ICDE 2007. IEEE 23rd International Conference on},
    keywords = {dtw, litreview, thesis},
    pages = {786--795},
    posted-at = {2009-02-07 17:10:12},
    priority = {2},
    title = {{SpADe}: On Shape-based Pattern Detection in Streaming Time Series},
    url = {http://dx.doi.org/10.1109/icde.2007.367924},
    year = {2007}
}

@proceedings{citeulike:4022058,
    abstract = {Matching video segments in order to detect their similarity is a necessary task in retrieval and
summarization applications. In order to determine nearly identical content, such as repeated takes of the same scene,
very precise matching of sequences of features extracted from the video segments needs to be performed. In this paper we
compare the performance of three distance measures for the task of clustering multiple takes of the same scene: dynamic
time warping ({DTW}) and two variants of longest common subsequence ({LCSS}). We also evaluate the influence of the
quality of the input segmentation on the performance of the algorithms.},
    author = {Bailer, W.},
    booktitle = {Database and Expert Systems Application, 2008. DEXA '08. 19th International Conference on},
    citeulike-article-id = {4022058},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/dexa.2008.26},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4624782},
    doi = {10.1109/dexa.2008.26},
    journal = {Database and Expert Systems Application, 2008. DEXA '08. 19th International Conference on},
    pages = {595--599},
    posted-at = {2009-02-07 17:06:10},
    priority = {2},
    title = {A Comparison of Distance Measures for Clustering Video Sequences},
    url = {http://dx.doi.org/10.1109/dexa.2008.26},
    year = {2008}
}

@article{citeulike:4021682,
    abstract = {In a way similar to the string-to-string correction problem, we address discrete time series similarity
in light of a time-series-to-time-series-correction problem for which the similarity between two time series is measured
as the minimum cost sequence of edit operations needed to transform one time series into another. To define the edit
operations, we use the paradigm of a graphical editing process and end up with a dynamic programming algorithm that we
call time warp edit distance ({TWED}). {TWED} is slightly different in form from dynamic time warping ({DTW}), longest
common subsequence ({LCSS}), or edit distance with real penalty ({ERP}) algorithms. In particular, it highlights a
parameter that controls a kind of stiffness of the elastic measure along the time axis. We show that the similarity
provided by {TWED} is a potentially useful metric in time series retrieval applications since it could benefit from the
triangular inequality property to speed up the retrieval process while 
tuning the parameters of the elastic measure. In that context, a lower bound is derived to link the matching of time
series into down sampled representation spaces to the matching into the original space. The empiric quality of the
{TWED} distance is evaluated on a simple classification task. Compared to edit distance, {DTW}, {LCSS}, and {ERP},
{TWED} has proved to be quite effective on the considered experimental task.},
    author = {Marteau, P. F.},
    booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    citeulike-article-id = {4021682},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tpami.2008.76},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4479483},
    doi = {10.1109/tpami.2008.76},
    institution = {Univ. Europeenne de Bretagne-Sud-VALOR- IA, Vannes},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    month = feb,
    number = {2},
    pages = {306--318},
    posted-at = {2009-02-07 14:07:24},
    priority = {2},
    publisher = {IEEE},
    title = {Time Warp Edit Distance with Stiffness Adjustment for Time Series Matching},
    url = {http://dx.doi.org/10.1109/tpami.2008.76},
    volume = {31},
    year = {2009}
}

@book{citeulike:1454223,
    abstract = {A timeless classic in how complex information should be presented graphically.
The Strunk \& White of visual design. Should occupy a place of honor--within
arm's reach--of everyone attempting to understand or depict numerical data
graphically. The design of the book is an exemplar of the principles it
espouses: elegant typography and layout, and seamless integration of lucid
text and perfectly chosen graphical examples. Very Highly Recommended.},
    author = {Tufte, Edward R.},
    citeulike-article-id = {1454223},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/096139210X},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/096139210X},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/096139210X},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/096139210X},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/096139210X/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/096139210X},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/096139210X},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN096139210X},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=096139210X\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/096139210X},
    howpublished = {Hardcover},
    isbn = {096139210X},
    keywords = {dtw, litreview, thesis},
    posted-at = {2009-02-06 14:23:45},
    priority = {2},
    publisher = {Graphics Pr},
    title = {The Visual Display of Quantitative Information},
    url = {http://www.worldcat.org/isbn/096139210X}
}

@proceedings{citeulike:4015923,
    abstract = {Visualisations play an important part in the development of ideas. They make ingredients and relations
explicit, guide thinking processes of the designer or scientist, and support communications, often across the boundaries
of disciplines. In the fields of cognitive psychology and human-machine interaction, block diagrams have been a dominant
means for representing cognitive systems. However, we believe that this form of representation may constrain how we
think about cognition in undesirable ways. This form of representation biases viewers to see cognition as a sequential,
step-by-step process, under emphasizing the dynamical properties of closed-loop, adaptive processes. Block diagrams
emphasize activity and internal mental operations (awareness) and occlude the ecological or work domain (situational)
constraints},
    author = {Stappers, P. J. and Flach, J. M.},
    booktitle = {Systems, Man and Cybernetics, 2004 IEEE International Conference on},
    citeulike-article-id = {4015923},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icsmc.2004.1398404},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1398404},
    doi = {10.1109/icsmc.2004.1398404},
    journal = {Systems, Man and Cybernetics, 2004 IEEE International Conference on},
    keywords = {dtw, litreview, thesis},
    pages = {821--826 vol.1},
    posted-at = {2009-02-06 14:04:52},
    priority = {2},
    title = {Visualizing cognitive systems: getting past block diagrams},
    url = {http://dx.doi.org/10.1109/icsmc.2004.1398404},
    volume = {1},
    year = {2004}
}

@article{citeulike:3994742,
    author = {Tinbergen, J.},
    citeulike-article-id = {3994742},
    journal = {Zeitschrift f\"{u}r National- \"{o}konomie 1},
    pages = {669--679},
    posted-at = {2009-02-02 11:58:41},
    priority = {2},
    title = {Bestimmung und Deutung von Angebotskurven. Ein Beispiel.},
    year = {1930}
}

@misc{citeulike:3994561,
    author = {Hanau, A.},
    citeulike-article-id = {3994561},
    institution = {Vierteljahrshefte zur Konjunkturforschung 7},
    keywords = {dtw, litreview, thesis},
    posted-at = {2009-02-02 11:40:50},
    priority = {2},
    publisher = {Vierteljahrshefte zur Konjunkturforschung 7},
    title = {Die Prognose der Schweinepreise},
    year = {1928}
}

@misc{citeulike:3994263,
    author = {Koopmans, T. C.},
    citeulike-article-id = {3994263},
    institution = {Netherlands Economic Institute},
    keywords = {dtw, litreview, thesis},
    location = {Haarlem},
    posted-at = {2009-02-02 11:33:05},
    priority = {2},
    publisher = {Netherlands Economic Institute},
    title = {Linear Regression Analysis of Economic Time Series},
    year = {1937}
}

@inproceedings{citeulike:1237593,
    abstract = {The last few years have seen an increasing understanding that Dynamic Time Warping ({DTW}), a technique
that allows local flexibility in aligning time series, is superior to the ubiquitous Euclidean Distance for time series
classification, clustering, and indexing. More recently, it has been shown that for some problems, Uniform Scaling
({US}), a technique that allows global scaling of time series, may just be as important for some problems. In this work,
we note that for many real world problems, it is necessary to combine both {DTW} and {US} to achieve meaningful results.
This is particularly true in domains where we must account for the natural variability of human action, including
biometrics, query by humming, motion-capture/animation, and handwriting recognition. We introduce the first technique
which can handle both {DTW} and {US} simultaneously, and demonstrate its utility and effectiveness on a wide range of
problems in industry, medicine, and entertainment.},
    author = {Ada Wai chee Fu and Keogh, Eamonn and Leo Yung Hang Lau and Ratanamahatana, Chotirat A.},
    booktitle = {VLDB '05: Proceedings of the 31st international conference on Very large data bases},
    citeulike-article-id = {1237593},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1083592.1083668},
    isbn = {1-59593-154-6},
    location = {Trondheim, Norway},
    pages = {649--660},
    posted-at = {2009-02-01 20:27:56},
    priority = {2},
    publisher = {VLDB Endowment},
    title = {Scaling and time warping in time series querying},
    url = {http://portal.acm.org/citation.cfm?id=1083592.1083668},
    year = {2005}
}

@article{citeulike:1082000,
    abstract = {Periodicity mining is used for predicting trends in time series data. Discovering the rate at which the
time series is periodic has always been an obstacle for fully automated periodicity mining. Existing periodicity mining
algorithms assume that the periodicity rate (or simply the period) is user-specified. This assumption is a considerable
limitation, especially in time series data where the period is not known a priori. In this paper, we address the problem
of detecting the periodicity rate of a time series database. Two types of periodicities are defined, and a scalable,
computationally efficient algorithm is proposed for each type. The algorithms perform in O(n\log n) time for a time
series of length n. Moreover, the proposed algorithms are extended in order to discover the periodic patterns of unknown
periods at the same time without affecting the time complexity. Experimental results show that the proposed algorithms
are highly accurate with respect to the discovered periodicity rates 
and periodic patterns. Real-data experiments demonstrate the practicality of the discovered periodic patterns.},
    address = {Los Alamitos, CA, USA},
    author = {Elfeky, Mohamed G. and Aref, Walid G. and Elmagarmid, Ahmed K.},
    citeulike-article-id = {1082000},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1070763},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/TKDE.2005.114},
    citeulike-linkout-2 = {http://dblp.uni-trier.de/rec/bibtex/journals/tkde/ElfekyAE05},
    citeulike-linkout-3 = {http://dx.doi.org/10.1109/tkde.2005.114},
    citeulike-linkout-4 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1432698},
    day = {23},
    doi = {10.1109/tkde.2005.114},
    issn = {1041-4347},
    journal = {IEEE Transactions on Knowledge and Data Engineering},
    month = may,
    number = {7},
    pages = {875--887},
    posted-at = {2009-02-01 20:11:27},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Periodicity Detection in Time Series Databases},
    url = {http://dx.doi.org/10.1109/tkde.2005.114},
    volume = {17},
    year = {2005}
}

@inproceedings{citeulike:825581,
    address = {New York, NY, USA},
    author = {Faloutsos, Christos and Ranganathan, M. and Manolopoulos, Yannis},
    booktitle = {SIGMOD '94: Proceedings of the 1994 ACM SIGMOD international conference on Management of data},
    citeulike-article-id = {825581},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=191839.191925},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/191839.191925},
    doi = {10.1145/191839.191925},
    issn = {0163-5808},
    keywords = {dtw, litreview, thesis},
    pages = {419--429},
    posted-at = {2009-02-01 20:11:02},
    priority = {2},
    publisher = {ACM Press},
    title = {Fast subsequence matching in time-series databases},
    url = {http://dx.doi.org/10.1145/191839.191925},
    year = {1994}
}

@article{citeulike:3991527,
    author = {Young, P. and Shellswell, S.},
    booktitle = {Automatic Control, IEEE Transactions on},
    citeulike-article-id = {3991527},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1099963},
    journal = {Automatic Control, IEEE Transactions on},
    keywords = {dtw, litreview, thesis},
    number = {2},
    pages = {281--283},
    posted-at = {2009-02-01 16:52:35},
    priority = {2},
    title = {Time series analysis, forecasting and control},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1099963},
    volume = {17},
    year = {1972}
}

@book{citeulike:3449765,
    abstract = {Time Series Analysis With Applications in R, Second Edition, presents an
accessible approach to understanding time series models and their
applications. Although the emphasis is on time domain {ARIMA} models and their
analysis, the new edition devotes two chapters to the frequency domain and
three to time series regression models, models for heteroscedasticity, and
threshold models. All of the ideas and methods are illustrated with both real
and simulated data sets.

A unique feature of this edition is its integration with the R computing
environment. The tables and graphical displays are accompanied by the R
commands used to produce them. An extensive R package, {TSA}, which contains
many new or revised R functions and all of the data used in the book,
accompanies the written text. Script files of R commands for each chapter are
available for download. There is also an extensive appendix in the book that
leads the reader through the use of R commands and the new R package to carry
out the analyses.},
    author = {Cryer, Jonathan D. and Chan, Kung-Sik},
    citeulike-article-id = {3449765},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387759581},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0387759581},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0387759581},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0387759581},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0387759581/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0387759581},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0387759581},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0387759581},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0387759581\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0387759581},
    day = {11},
    edition = {2nd},
    howpublished = {Hardcover},
    isbn = {0387759581},
    keywords = {dtw, litreview, thesis},
    month = jun,
    posted-at = {2009-02-01 12:18:27},
    priority = {2},
    publisher = {Springer},
    title = {Time Series Analysis: With Applications in R (Springer Texts in Statistics)},
    url = {http://www.worldcat.org/isbn/0387759581},
    year = {2009}
}

@book{citeulike:2206845,
    abstract = {{<B>Time Series: Theory and Methods</B> is a systematic account of linear time series models and their
application to the modelling and prediction of data collected sequentially in time. The aim is to provide specific
techniques for handling data and at the same time to provide a thorough understanding of the mathematical basis for
techniques. Both time and frequency domain methods are discussed, but the book is written in such a way that either
approach could be emphasized. The book intended to be a text for graduate students in statistics, mathematics,
engineering, and the natural or social sciences. It contains substantial chapters on multivariate series and state-space
models (including applications of the Kalman recursions to missing-value problems) and shorter accounts of special
topics including long-range dependence, infinite variance processes and non-linear models. Most of the programs used in
the book are available on diskettes for the IBM-PC. These diskettes, with the accompanying 
manual, <I>ITSM: The Interactive Time Series</I> <I>Modelling </I> <I>Package</I> <I> for the</I> <I>PC</I>, also by
Brockwell and Davis, can be purchased from Springer-Verlag.}},
    author = {Brockwell, Peter J. and Davis, Richard A.},
    citeulike-article-id = {2206845},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387974296},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0387974296},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/803079532},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0387974296},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0387974296},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0387974296/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0387974296},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0387974296},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0387974296},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0387974296\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0387974296},
    day = {18},
    howpublished = {Hardcover},
    isbn = {0387974296},
    keywords = {dtw, litreview, thesis},
    month = sep,
    posted-at = {2009-02-01 11:02:02},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {Time series: theory and methods},
    url = {http://www.worldcat.org/isbn/0387974296},
    year = {1991}
}

@book{citeulike:3991239,
    abstract = {This book presents modern developments in time series econometrics that are
applied to macroeconomic and financial time series. It attempts to bridge the
gap between methods and realistic applications. This book contains the most
important approaches to analyse time series which may be stationary or
nonstationary. Modelling and forecasting univariate time series is the
starting point. For multiple stationary time series Granger causality tests
and vector autoregressive models are presented. For real applied work the
modelling of nonstationary uni- or multivariate time series is most important.
Therefore, unit root and cointegration analysis as well as vector error
correction models play a central part. Modelling volatilities of financial
time series with autoregressive conditional heteroskedastic models is also
treated.},
    author = {Kirchg\"{a}ssner, Gebhard and Wolters, J\"{u}rgen},
    citeulike-article-id = {3991239},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/354073290X},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/354073290X},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/354073290X},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/354073290X},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/354073290X/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/354073290X},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/354073290X},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN354073290X},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=354073290X\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/354073290X},
    day = {11},
    edition = {1},
    howpublished = {Hardcover},
    isbn = {354073290X},
    keywords = {dtw, litreview, thesis},
    month = oct,
    posted-at = {2009-02-01 10:47:08},
    priority = {2},
    publisher = {Springer},
    title = {Introduction to Modern Time Series Analysis},
    url = {http://www.worldcat.org/isbn/354073290X},
    year = {2007}
}

@book{citeulike:3991222,
    abstract = {This monograph of carefully collected articles reviews recent developments in
theoretical and applied statistical science, highlights current noteworthy
results and illustrates their applications; and points out possible new
directions to pursue. With its enlightening account of statistical discoveries
and its numerous figures and tables, Probability and Statistical Models with
Applications is a must read for probabilists and theoretical and applied
statisticians.},
    citeulike-article-id = {3991222},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1584881240},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/1584881240},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/1584881240},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/1584881240},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/1584881240/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1584881240},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/1584881240},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN1584881240},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=1584881240\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/1584881240},
    day = {21},
    edition = {1},
    howpublished = {Hardcover},
    isbn = {1584881240},
    keywords = {dtw, litreview, thesis},
    month = sep,
    posted-at = {2009-02-01 10:12:49},
    priority = {2},
    publisher = {Chapman \& Hall/CRC},
    title = {Probability and Statistical Models with Applications},
    url = {http://www.worldcat.org/isbn/1584881240},
    year = {2000}
}

@book{citeulike:3989988,
    abstract = {The Wiley Classics Library consists of selected books that have become
recognized classics in their respective fields. With these new unabridged and
inexpensive editions, Wiley hopes to extend the life of these important works
by making them available to future generations of mathematicians and
scientists. Currently available in the Series: T. W. Anderson Statistical
Analysis of Time Series T. S. Arthanari \& Yadolah Dodge Mathematical
Programming in Statistics Emil Artin Geometric Algebra Norman T. J. Bailey The
Elements of Stochastic Processes with Applications to the Natural Sciences
George E. P. Box \& George C. Tiao Bayesian Inference in Statistical Analysis
R. W. Carter Simple Groups of Lie Type William G. Cochran \& Gertrude M. Cox
Experimental Designs, Second Edition Richard Courant Differential and Integral
Calculus, Volume I Richard Courant Differential and Integral Calculus, Volume
{II} Richard Courant \& D. Hilbert Methods of Mathematical Physics, Volume I
Richard Courant \& D. Hilbert Methods of Mathematical Physics, Volume {II} D. R.
Cox Planning of Experiments Harold M. S. Coxeter Introduction to Modern
Geometry, Second Edition Charles W. Curtis \& Irving Reiner Representation
Theory of Finite Groups and Associative Algebras Charles W. Curtis \& Irving
Reiner Methods of Representation Theory with Applications to Finite Groups and
Orders, Volume I Charles W. Curtis \& Irving Reiner Methods of Representation
Theory with Applications to Finite Groups and Orders, Volume {II} Bruno de
Finetti Theory of Probability, Volume 1 Bruno de Finetti Theory of
Probability, Volume 2 W. Edwards Deming Sample Design in Business Research
Amos de Shalit \& Herman Feshbach Theoretical Nuclear Physics, Volume 1
—Nuclear Structure J. L. Doob Stochastic Processes Nelson Dunford \& Jacob T.
Schwartz Linear Operators, Part One, General Theory Nelson Dunford \& Jacob T.
Schwartz Linear Operators, Part Two, Spectral {Theory—Self} Adjoint Operators in
Hilbert Space Nelson Dunford \& Jacob T. Schwartz Linear Operators, Part Three,
Spectral Operators Herman Fsehbach Theoretical Nuclear Physics: Nuclear
Reactions Bernard Friedman Lectures on {Applications-Oriented} Mathematics
Gerald d. Hahn \& Samuel S. Shapiro Statistical Models in Engineering Morris H.
Hansen, William N. Hurwitz \& William G. Madow Sample Survey Methods and
Theory, Volume {I—Methods} and Applications Morris H. Hansen, William N. Hurwitz
\& William G. Madow Sample Survey Methods and Theory, Volume {II}—Theory Peter
Henrici Applied and Computational Complex Analysis, Volume {1—Power}
{Series—lntegration—Conformal} {Mapping—Location} of Zeros Peter Henrici Applied
and Computational Complex Analysis, Volume {2—Special} {Functions—Integral}
{Transforms—Asymptotics}—Continued Fractions Peter Henrici Applied and
Computational Complex Analysis, Volume {3—Discrete} Fourier {Analysis—Cauchy}
{Integrals—Construction} of Conformal {Maps—Univalent} Functions Peter Hilton \&
{Yel-Chiang} Wu A Course in Modern Algebra Harry Hochetadt Integral Equations
Erwin O. Kreyezig Introductory Functional Analysis with Applications William
H. Louisell Quantum Statistical Properties of Radiation All Hasan Nayfeh
Introduction to Perturbation Techniques Emanuel Parzen Modern Probability
Theory and Its Applications {P.M}. Prenter Splines and Variational Methods
Walter Rudin Fourier Analysis on Groups C. L. Siegel Topics in Complex
Function Theory, Volume {I—Elliptic} Functions and Uniformization Theory C. L.
Siegel Topics in Complex Function Theory, Volume {II}—Automorphic and Abelian
integrals C. L Siegel Topics in Complex Function Theory, Volume {III}—Abelian
Functions \& Modular Functions of Several Variables J. J. Stoker Differential
Geometry J. J. Stoker Water Waves: The Mathematical Theory with Applications
J. J. Stoker Nonlinear Vibrations in Mechanical and Electrical Systems},
    author = {Anderson, T. W.},
    citeulike-article-id = {3989988},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0471047457},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0471047457},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0471047457},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0471047457},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0471047457/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0471047457},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0471047457},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0471047457},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0471047457\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0471047457},
    day = {03},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0471047457},
    keywords = {dtw, litreview, thesis},
    month = jun,
    posted-at = {2009-02-01 10:02:38},
    priority = {2},
    publisher = {Wiley-Interscience},
    title = {The Statistical Analysis of Time Series},
    url = {http://www.worldcat.org/isbn/0471047457},
    year = {1994}
}

@article{citeulike:2090933,
    abstract = {Time series data, due to their numerical and continuous nature, are difficult to process, analyze, and
mine. However, these tasks become easier when the data can be transformed into meaningful symbols. Most recent works on
time series only address how to identify a given pattern from a time series and do not consider the problem of
identifying a suitable set of time points for segmenting the time series in accordance with a given set of pattern
templates (e.g., a set of technical patterns for stock analysis). However, the use of fixed-length segmentation is an
oversimplified approach to this problem; hence, a dynamic approach (with high controllability) is preferable so that the
time series can be segmented flexibly and effectively according to the needs of the users and the applications. In view
of the fact that this segmentation problem is an optimization problem and evolutionary computation is an appropriate
tool to solve it, we propose an evolutionary time series segmentation algorithm. 
This approach allows a sizeable set of pattern templates to be generated for mining or query. In addition, defining
similarity between time series (or time series segments) is of fundamental importance in fitness computation. By
identifying the perceptually important points directly from the time domain, time series segments and templates of
different lengths can be compared and intuitive pattern matching can be carried out in an effective and efficient
manner. Encouraging experimental results are reported from tests that segment both artificial time series generated from
the combinations of pattern templates and the time series of selected Hong Kong stocks.},
    author = {Chung, Fu-Lai and Fu, Tak-Chung and Ng, V. and Luk, R. W. P.},
    booktitle = {Evolutionary Computation, IEEE Transactions on},
    citeulike-article-id = {2090933},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tevc.2004.832863},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1347161},
    doi = {10.1109/tevc.2004.832863},
    journal = {Evolutionary Computation, IEEE Transactions on},
    keywords = {dtw, litreview, thesis},
    number = {5},
    pages = {471--489},
    posted-at = {2009-01-27 14:11:56},
    priority = {2},
    title = {An evolutionary approach to pattern-based time series segmentation},
    url = {http://dx.doi.org/10.1109/tevc.2004.832863},
    volume = {8},
    year = {2004}
}

@inproceedings{citeulike:3513035,
    abstract = {Recognition of hand-drawn shapes is an important and widely studied problem. By adopting a generative
probabilistic framework we are able to formulate a robust and flexible approach to shape recognition which allows for a
wide range of shapes and which can recognize new shapes from a single exemplar. It also provides meaningful
probabilistic measures of model score which can be used as part of a larger probabilistic framework for interpreting a
page of ink. We also show how Bayesian model comparison allows the trade-off between data fit and model complexity to be
optimized automatically.},
    address = {Washington, DC, USA},
    author = {Krishnapuram, Balaji and Bishop, Christopher M. and Szummer, Martin},
    booktitle = {IWFHR '04: Proceedings of the Ninth International Workshop on Frontiers in Handwriting Recognition},
    citeulike-article-id = {3513035},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1033907},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/iwfhr.2004.46},
    doi = {10.1109/iwfhr.2004.46},
    isbn = {0-7695-2187-8},
    keywords = {dtw, litreview, thesis},
    pages = {20--25},
    posted-at = {2009-01-26 13:43:27},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Generative Models and Bayesian Model Comparison for Shape Recognition},
    url = {http://dx.doi.org/10.1109/iwfhr.2004.46},
    year = {2004}
}

@book{citeulike:3822011,
    abstract = {This collection of twenty-three original papers represents the first effort to
bring together the work of constraint programming researchers scattered across
multiple disciplines and across the world. The collection contributes to the
understanding of the common principles of this emerging general paradigm, the
investigation of its theoretical foundations as well as applications to real-
world computing problems. It is organized around themes of concurrency and
reactive systems, languages and environments, algorithms, computer graphics,
and artificial intelligence. Constraint programming aims at supporting a wide
range of complex applications which are often modeled naturally in terms of
constraints. Early work, in the 1960s and 1970s, made use of constraints in
computer graphics, user interfaces, and artificial intelligence. Such work
introduced a declarative component in otherwise-procedural systems to reduce
the development effort. The mid-1980s have witnessed the emergence of general-
purpose programming languages based on constraints, such as constraint logic
programming and concurrent constraint programming, with significant
applications in academia and industry. Today, an increasing number of
researchers from all over the map of computing are looking at different
aspects of this new computational paradigm.},
    citeulike-article-id = {3822011},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262193612},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0262193612},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0262193612},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262193612},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262193612/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262193612},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262193612},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262193612},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262193612\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262193612},
    day = {26},
    howpublished = {Hardcover},
    isbn = {0262193612},
    keywords = {dtw, litreview, thesis},
    month = may,
    posted-at = {2008-12-23 13:02:48},
    priority = {2},
    publisher = {The MIT Press},
    title = {Principles and Practice of Constraint Programming},
    url = {http://www.worldcat.org/isbn/0262193612},
    year = {1995}
}

@inproceedings{citeulike:3821484,
    abstract = {A Query by Humming system allows the user to find a song by humming part of the tune. No musical
training is needed. Previous query by humming systems have not provided satisfactory results for various reasons. Some
systems have low retrieval precision because they rely on melodic contour information from the hum tune, which in turn
relies on the error-prone note segmentation process. Some systems yield better precision when matching the melody
directly from audio, but they are slow because of their extensive use of Dynamic Time Warping ({DTW}). Our approach
improves both the retrieval precision and speed compared to previous approaches. We treat music as a time series and
exploit and improve well-developed techniques from time series databases to index the music for fast similarity queries.
We improve on existing {DTW} indexes technique by introducing the concept of  envelope transforms , which gives a
general guideline for extending existing dimensionality reduction methods to {DTW} indexes.
 The net result is high scalability. We confirm our claims through extensive experiments.},
    address = {New York, NY, USA},
    author = {Zhu, Yunyue and Shasha, Dennis},
    booktitle = {SIGMOD '03: Proceedings of the 2003 ACM SIGMOD international conference on Management of data},
    citeulike-article-id = {3821484},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=872757.872780},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/872757.872780},
    doi = {10.1145/872757.872780},
    isbn = {1-58113-634-X},
    keywords = {dtw, litreview, thesis},
    location = {San Diego, California},
    pages = {181--192},
    posted-at = {2008-12-23 05:35:52},
    priority = {2},
    publisher = {ACM},
    title = {Warping indexes with envelope transforms for query by humming},
    url = {http://dx.doi.org/10.1145/872757.872780},
    year = {2003}
}

@article{citeulike:3056920,
    address = {New York, NY, USA},
    author = {Hjaltason, Gisli R. and Samet, Hanan},
    citeulike-article-id = {3056920},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=958948},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/958942.958948},
    doi = {10.1145/958942.958948},
    issn = {0362-5915},
    journal = {ACM Trans. Database Syst.},
    keywords = {dtw, litreview, thesis},
    month = dec,
    number = {4},
    pages = {517--580},
    posted-at = {2008-12-22 22:38:00},
    priority = {2},
    publisher = {ACM},
    title = {Index-driven similarity search in metric spaces (Survey Article)},
    url = {http://dx.doi.org/10.1145/958942.958948},
    volume = {28},
    year = {2003}
}

@proceedings{citeulike:3816328,
    abstract = {The problem of finding patterns of interest in time series databases (query by content) is an important
one, with applications in virtually every field of science. A variety of approaches have been suggested. These
approaches are robust to noise, offset translation, and amplitude scaling to varying degrees. However, they are all
extremely sensitive to scaling in the time axis (longitudinal scaling). We present a method for similarity search that
is robust to scaling in the time axis, in addition to noise, offset translation, and amplitude scaling. The method has
been tested on medical, financial, space telemetry and artificial data. Furthermore the method is exceptionally fast,
with the predicted 2 to 4 orders of magnitude speedup actually observed. The method uses a piecewise linear
representation of the original data. We also introduce a new algorithm which both decides the optimal number of linear
segments to use, and produces the actual linear representation},
    author = {Keogh, E.},
    booktitle = {Tools with Artificial Intelligence, 1997. Proceedings., Ninth IEEE International Conference on},
    citeulike-article-id = {3816328},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tai.1997.632306},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=632306},
    doi = {10.1109/tai.1997.632306},
    journal = {Tools with Artificial Intelligence, 1997. Proceedings., Ninth IEEE International Conference on},
    keywords = {dtw, litreview, thesis},
    pages = {578--584},
    posted-at = {2008-12-22 01:04:00},
    priority = {2},
    title = {Fast similarity search in the presence of longitudinal scaling in time series databases},
    url = {http://dx.doi.org/10.1109/tai.1997.632306},
    year = {1997}
}

@inproceedings{citeulike:3816327,
    abstract = {We introduce a new model of similarity of time sequences that captures the intuitive notion that two
sequences should be considered similar if they have enough non-overlapping time-ordered pairs of subsequences thar are
similar. The model allows the amplitude of one of the two sequences to be scaled by any suitable amount and its offset
adjusted appropriately. Two subsequences are considered similar if one can be enclosed within an envelope of a specified
width drawn around the other. The model also allows non-matching gaps in the matching subsequences. The matching
subsequences need not be aligned along the time axis. Given this model of similarity, we present fast search techniques
for discovering all similar sequences in a set of sequences. These techniques can also be used to find all
(sub)sequences similar to a given sequence. We applied this matching system to the {U.S}. mutual funds data and
discovered interesting matches.},
    author = {Agrawal, Rakesh and Lin, King-Ip and Sawhney, Harpreet S. and Shim, Kyuseok},
    booktitle = {In VLDB},
    citeulike-article-id = {3816327},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.4179},
    keywords = {dtw, litreview, thesis},
    pages = {490--501},
    posted-at = {2008-12-22 01:02:20},
    priority = {2},
    title = {Fast Similarity Search in the Presence of Noise, Scaling, and Translation in {Time-Series} Databases},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.4179},
    year = {1995}
}

@article{citeulike:3816322,
    abstract = {Motivation: Increasingly, biological processes are being studied   through time series of {RNA}
expression data collected for large   numbers of genes. Because common processes may unfold at varying   rates in
different experiments or individuals, methods are needed that will allow corresponding expression states in different
time series to be mapped to one another.  Results: We present implementations of time warping algorithms   applicable to
{RNA} and protein expression data and demonstrate their application to published yeast {RNA} expression time series.
Programs executing two warping algorithms are described, a simple warping algorithm and an interpolative algorithm,
along with programs that generate graphics that visually present alignment information. We show time warping to be
superior to simple clustering at mapping corresponding time states. We document the impact of statistical measurement
noise and sample size on the quality of time alignments,  and present issues related to 
statistical assessment of alignment   quality through alignment scores. We also discuss directions for algorithm
improvement including development of multiple time series alignments and possible applications to causality searches and
non-temporal processes ( concentration warping').  Availability: Academic implementations of alignment programs  
genewarp and genewarpi and the graphics generation programs grphwarp and grphwarpi are available as Win32 system {DOS}
box executables on our web site along with documentation on their use. The publicly available data on which they were
demonstrated may be found at http://genome-www.stanford.edu/cellcycle/.   Postscript files generated by grphwarp and
grphwarpi may be directly printed or viewed using {GhostView} software available at http://www.cs.wisc.edu/\~{}ghost/. 
Contact: church@arep.med.harvard.edu  Supplementary information: http://arep.med.harvard.edu/timewarp/supplement.htm.
10.1093/bioinformatics/17.6.495},
    author = {Aach, John and Church, George M.},
    citeulike-article-id = {3816322},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/bioinformatics/17.6.495},
    citeulike-linkout-1 = {http://bioinformatics.oxfordjournals.org/cgi/content/abstract/17/6/495},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/11395426},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=11395426},
    day = {1},
    doi = {10.1093/bioinformatics/17.6.495},
    journal = {Bioinformatics},
    keywords = {dtw, litreview, thesis},
    month = jun,
    number = {6},
    pages = {495--508},
    pmid = {11395426},
    posted-at = {2008-12-22 00:51:21},
    priority = {2},
    title = {Aligning gene expression time series with time warping algorithms},
    url = {http://dx.doi.org/10.1093/bioinformatics/17.6.495},
    volume = {17},
    year = {2001}
}

@incollection{citeulike:3816243,
    abstract = {Widespread interest in discovering features and trends in time- series has generated a need for tools
that support interactive {exploration.This} paper introduces timeboxes: a powerful direct-manipulation metaphor for the
specification of queries over time series datasets. Our {TimeSearcher} implementation of timeboxes supports interactive
formulation and modification of queries, thus speeding the process of exploring time series data sets and guiding data
mining.},
    author = {Hochheiser, Harry and Shneiderman, Ben},
    citeulike-article-id = {3816243},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-45650-3\_38},
    citeulike-linkout-1 = {http://www.springerlink.com/content/g0g4kcqd3mb2dctq},
    doi = {10.1007/3-540-45650-3\_38},
    journal = {Discovery Science},
    keywords = {dtw, litreview, thesis},
    pages = {441--446},
    posted-at = {2008-12-21 23:13:53},
    priority = {2},
    title = {Interactive Exploration of Time Series Data},
    url = {http://dx.doi.org/10.1007/3-540-45650-3\_38},
    year = {2001}
}

@book{citeulike:1109201,
    address = {Menlo Park, CA, USA},
    author = {Fayyad, Usama M. and Piatetsky-Shapiro, Gregory and Smyth, Padhraic and Uthurusamy, Ramasamy},
    citeulike-article-id = {1109201},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=257938},
    editor = {Fayyad, Usama M. and Piatetsky-Shapiro, Gregory and Smyth, Padhraic and Uthurusamy, Ramasamy},
    isbn = {0262560976},
    keywords = {dtw, litreview, thesis},
    posted-at = {2008-12-21 23:12:28},
    priority = {2},
    publisher = {American Association for Artificial Intelligence},
    title = {Advances in knowledge discovery and data mining},
    url = {http://portal.acm.org/citation.cfm?id=257938},
    year = {1996}
}

@inproceedings{citeulike:3816224,
    abstract = {Sequential data is easily understood through a simple line graph, yet systems to search such data
typically rely on complex interfaces or query languages. This paper presents {QuerySketch}, a financial database
application in which graphs are used for query input as well as output. {QuerySketch} allows users to sketch a graph
freehand, then view stocks whose price histories match the sketch. Using the same graphical format for both input and
output results in an interface that is powerful, flexible, yet easy to use.},
    address = {New York, NY, USA},
    author = {Wattenberg, Martin},
    booktitle = {CHI '01: CHI '01 extended abstracts on Human factors in computing systems},
    citeulike-article-id = {3816224},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=634292},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/634067.634292},
    doi = {10.1145/634067.634292},
    isbn = {1-58113-340-5},
    keywords = {dtw, litreview},
    location = {Seattle, Washington},
    pages = {381--382},
    posted-at = {2008-12-21 22:53:35},
    priority = {2},
    publisher = {ACM},
    title = {Sketching a graph to query a time-series database},
    url = {http://dx.doi.org/10.1145/634067.634292},
    year = {2001}
}

@inproceedings{citeulike:3816213,
    abstract = {{Query-by-Example} is a query language for use by non-programmers querying a relational data base. In an
earlier paper, the features of this language were introduced; however, it was assumed that the data base was already
defined and available to the user. In the first part of this paper we demonstrate that the operations of
{Query-by-Example} can be used not only to query the data base but also to define it, including data descriptions and
declarations of various integrity constraints. This is an attempt to provide the user with a simplified, unified
interface for a variety of functions. In the second part of this paper it is shown how one can make preliminary
interrogations to retrieve a subset of the data base needed for the formulation of a specific query. This becomes very
useful in cases where the data-base is very large and the user's initial task of scanning the tables for the ones
relevant to his specific query becomes by itself horrendous.},
    address = {New York, NY, USA},
    author = {Zloof, Mosh\'{e} M.},
    booktitle = {Proceedings of the 1st International Conference on Very Large Data Bases},
    citeulike-article-id = {3816213},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1282482},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1282480.1282482},
    doi = {10.1145/1282480.1282482},
    keywords = {dtw, litreview, thesis},
    location = {Framingham, Massachusetts},
    pages = {1--24},
    posted-at = {2008-12-21 22:48:45},
    priority = {2},
    publisher = {ACM},
    series = {VLDB '75},
    title = {Query-by-example: the invocation and definition of tables and forms},
    url = {http://dx.doi.org/10.1145/1282480.1282482},
    year = {1975}
}

@incollection{citeulike:3815893,
    abstract = {Conceptually, the techniques of linguistic pattern recognition are largely independent of the medium,
but overall performance is influenced by the preprocessing to such an extent that until a few years ago the pattern
recognition step was generally viewed as a small appendix to the main body of signal processing knowledge. To this day,
it remains impossible to build a serious system without paying close attention to preprocessing, and deep algorithmic
work on the recognizer will often yield smaller gains than seemingly more superficial changes to the front end. In
Section 9.1, we introduce a speech coding method, linear prediction, that has played an important role in practical
application since the {1970s.We} extend the discussion of quantization started in Section 8.1 from scalars to vectors
and discuss the Fourier transform-based (homomorphic) techniques that currently dominate the field.},
    citeulike-article-id = {3815893},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-1-84628-986-6\_9},
    citeulike-linkout-1 = {http://www.springerlink.com/content/rt72p43368108324},
    doi = {10.1007/978-1-84628-986-6\_9},
    journal = {Mathematical Linguistics},
    keywords = {dtw, litreview, thesis},
    pages = {219--246},
    posted-at = {2008-12-21 17:43:45},
    priority = {2},
    title = {Speech and handwriting},
    url = {http://dx.doi.org/10.1007/978-1-84628-986-6\_9},
    year = {2008}
}

@incollection{citeulike:3815889,
    abstract = {Efficient retrieval of time series data has gained recent attention from the research community. In
particular, finding meaningful distance measurements for various applications is one of the most important issues in the
field, since no single distance measurement works for all applications. In this paper, we propose a different distance
measurement for time series applications based on Constraint Continuous Editing Distance ({CCED}) that adjusts the
potential energy of each sequence for optimal similarity. Furthermore, we also propose a lower bounding distance for
{CCED} for efficient indexing and fast retrieval, even though {CCED} does not satisfy triangle inequality.},
    author = {Chhieng, Van and Wong, Raymond},
    citeulike-article-id = {3815889},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-71703-4\_51},
    citeulike-linkout-1 = {http://www.springerlink.com/content/r233161p50622670},
    doi = {10.1007/978-3-540-71703-4\_51},
    journal = {Advances in Databases: Concepts, Systems and Applications},
    keywords = {dtw, litreview, thesis},
    pages = {598--610},
    posted-at = {2008-12-21 17:38:37},
    priority = {2},
    title = {Adaptive Distance Measurement for Time Series Databases},
    url = {http://dx.doi.org/10.1007/978-3-540-71703-4\_51},
    year = {2008}
}

@article{citeulike:3815887,
    abstract = {{Abstract\&nbsp;\&nbsp;In} this paper, we define time series query filtering, the problem of monitoring
the streaming time series for a set of predefined patterns. This problem is of great practical importance given the
massive volume of streaming time series available through sensors, medical patient records, financial indices and space
telemetry. Since the data may arrive at a high rate and the number of predefined patterns can be relatively large, it
may be impossible for the comparison algorithm to keep up. We propose a novel technique that exploits the commonality
among the predefined patterns to allow monitoring at higher bandwidths, while maintaining a guarantee of no false
dismissals. Our approach is based on the widely used envelope-based lower-bounding technique. As we will demonstrate on
extensive experiments in diverse domains, our approach achieves tremendous improvements in performance in the offline
case, and significant improvements in the fastest possible arrival rate of the 
data stream that can be processed with guaranteed no false dismissals. As a further demonstration of the utility of our
approach, we demonstrate that it can make semisupervised learning of time series classifiers tractable.},
    author = {Wei, Li and Keogh, Eamonn and Van Herle, Helga and Mafra-Neto, Agenor and Abbott, Russell},
    citeulike-article-id = {3815887},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10115-006-0033-7},
    citeulike-linkout-1 = {http://www.springerlink.com/content/12577t2r80414611},
    day = {5},
    doi = {10.1007/s10115-006-0033-7},
    journal = {Knowledge and Information Systems},
    keywords = {dtw, litreview, thesis},
    month = apr,
    number = {3},
    pages = {313--344},
    posted-at = {2008-12-21 17:37:36},
    priority = {2},
    title = {Efficient query filtering for streaming time series with applications to semisupervised learning of time
series classifiers},
    url = {http://dx.doi.org/10.1007/s10115-006-0033-7},
    volume = {11},
    year = {2007}
}

@incollection{citeulike:3815884,
    abstract = {It is well known that Dynamic Time Warping ({DTW}) is superior to Euclidean distance as a similarity
measure in time series analyses. Use of {DTW} with the recently introduced warping window constraints and lower bounding
measures has significantly increased the accuracy of time series classification while reducing the computational expense
required. The warping window technique learns arbitrary constraints on the warping path while performing time series
alignment. This work utilizes genetic algorithms to find the optimal warping window constraints which provide a better
classification accuracy. Performance of the proposed methodology has been investigated on two problems from diverse
domains with favorable results.},
    author = {Kumar, Pankaj and Gupta, Ankur and Jayaraman, Valadi K. and Kulkarni, Bhaskard},
    citeulike-article-id = {3815884},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-72960-0\_12},
    citeulike-linkout-1 = {http://www.springerlink.com/content/h476185055620672},
    doi = {10.1007/978-3-540-72960-0\_12},
    journal = {Advances in Metaheuristics for Hard Optimization},
    keywords = {dtw, litreview, thesis},
    pages = {251--261},
    posted-at = {2008-12-21 17:35:01},
    priority = {2},
    title = {Aligning Time Series with Genetically Tuned Dynamic Time Warping Algorithm},
    url = {http://dx.doi.org/10.1007/978-3-540-72960-0\_12},
    year = {2008}
}

@article{citeulike:785210,
    author = {Keogh, Eamonn and Ratanamahatana, Chotirat A.},
    citeulike-article-id = {785210},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1047750.1047753},
    citeulike-linkout-1 = {http://dblp.uni-trier.de/rec/bibtex/journals/kais/KeoghR05},
    citeulike-linkout-2 = {http://dx.doi.org/10.1007/s10115-004-0154-9},
    citeulike-linkout-3 = {http://www.springerlink.com/content/m4xvnjnm1rxw041w},
    doi = {10.1007/s10115-004-0154-9},
    journal = {Knowledge and Information Systems},
    keywords = {dtw, litreview, thesis},
    month = mar,
    number = {3},
    pages = {358--386},
    posted-at = {2008-12-21 17:31:59},
    priority = {2},
    title = {Exact indexing of dynamic time warping},
    url = {http://dx.doi.org/10.1007/s10115-004-0154-9},
    volume = {7},
    year = {2005}
}

@incollection{citeulike:3815880,
    abstract = {Constraints are a natural mechanism for the specification of similarity queries on time-series data.
However, to realize the expressive power of constraint programming in this context, one must provide the matching
implementation technology for efficient indexing of very large data sets. In this paper, we formalize the intuitive
notions of exact and approximate similarity between time-series patterns and data. Our definition of similarity extends
the distance metric used in [2, 7] with invariance under a group of transformations. Our main observation is that the
resulting, more expressive, set of constraint queries can be supported by a new indexing technique, which preserves all
the desirable properties of the indexing scheme proposed in [2, 7].},
    author = {Goldin, Dina and Kanellakis, Paris},
    citeulike-article-id = {3815880},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-60299-2\_9},
    citeulike-linkout-1 = {http://www.springerlink.com/content/f08778365j018pp3},
    doi = {10.1007/3-540-60299-2\_9},
    journal = {Principles and Practice of Constraint Programming — CP '95},
    keywords = {dtw, litreview, thesis},
    pages = {137--153},
    posted-at = {2008-12-21 17:28:50},
    priority = {2},
    title = {On similarity queries for time-series data: Constraint specification and implementation},
    url = {http://dx.doi.org/10.1007/3-540-60299-2\_9},
    year = {1995}
}

@incollection{citeulike:3815871,
    citeulike-article-id = {3815871},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-37014-7\_2},
    citeulike-linkout-1 = {http://www.springerlink.com/content/a40676gw36708m04},
    doi = {10.1007/978-3-540-37014-7\_2},
    journal = {Dynamic Programming},
    keywords = {litreview},
    pages = {45--100},
    posted-at = {2008-12-21 17:15:50},
    priority = {2},
    title = {Applications of Dynamic Programming},
    url = {http://dx.doi.org/10.1007/978-3-540-37014-7\_2},
    year = {2007}
}

@proceedings{citeulike:3815864,
    abstract = {We investigate techniques for similarity analysis of spatio-temporal trajectories for mobile objects.
Such data may contain a large number of outliers, which degrade the performance of Euclidean and time warping distance.
Therefore, we propose the use of non-metric distance functions based on the longest common subsequence ({LCSS}), in
conjunction with a sigmoidal matching function. Finally, we compare these new methods to various L<sub>p</sub> norms and
also to time warping distance (for real and synthetic data) and present experimental results that validate the accuracy
and efficiency of our approach, especially in the presence of noise.},
    author = {Vlachos, M. and Gunopulos, D. and Kollios, G.},
    booktitle = {Database and Expert Systems Applications, 2002. Proceedings. 13th International Workshop on},
    citeulike-article-id = {3815864},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1045983},
    journal = {Database and Expert Systems Applications, 2002. Proceedings. 13th International Workshop on},
    keywords = {dtw, litreview, thesis},
    pages = {721--726},
    posted-at = {2008-12-21 17:09:37},
    priority = {2},
    title = {Robust similarity measures for mobile object trajectories},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1045983},
    year = {2002}
}

@incollection{citeulike:2902692,
    abstract = {Similarity of objects is one of the crucial concepts in several applications, including data mining. For
complex objects, similarity is nontrivial to define. In this paper we present an intuitive model for measuring the
similarity between two time series. The model takes into account outliers, different scaling functions, and variable
sampling rates. Using methods from computational geometry, we show that this notion of similarity can be computed in
polynomial time. Using statistical approximation techniques, the algorithms can be speeded up considerably. We give
preliminary experimental results that show the naturalness of the notion.},
    author = {Das, Gautam and Gunopulos, Dimitrios and Mannila, Heikki},
    citeulike-article-id = {2902692},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-63223-9\_109},
    citeulike-linkout-1 = {http://www.springerlink.com/content/r0726646326tt500},
    doi = {10.1007/3-540-63223-9\_109},
    journal = {Principles of Data Mining and Knowledge Discovery},
    keywords = {dtw, litreview, thesis},
    pages = {88--100},
    posted-at = {2008-12-21 17:07:58},
    priority = {2},
    title = {Finding similar time series},
    url = {http://dx.doi.org/10.1007/3-540-63223-9\_109},
    year = {1997}
}

@inproceedings{citeulike:2902876,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Gunopulos, Dimitrios and Das, Gautam},
    booktitle = {Tutorial notes of the sixth ACM SIGKDD international conference on Knowledge discovery and data
mining},
    citeulike-article-id = {2902876},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=349108},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/349093.349108},
    doi = {10.1145/349093.349108},
    isbn = {1-58113-305-7},
    keywords = {dtw, litreview, thesis},
    location = {Boston, Massachusetts, United States},
    pages = {243--307},
    posted-at = {2008-12-21 17:06:02},
    priority = {2},
    publisher = {ACM},
    series = {KDD '00},
    title = {Time series similarity measures (tutorial {PM}-2)},
    url = {http://dx.doi.org/10.1145/349093.349108},
    year = {2000}
}

@inproceedings{citeulike:3815082,
    author = {Chu, Selina and Keogh, Eamonn and Hart, David and Pazzani, Michael},
    citeulike-article-id = {3815082},
    citeulike-linkout-0 = {http://www.siam.org/meetings/sdm02/proceedings/sdm02-12.pdf},
    journal = {Proceedings of the Second SIAM Intl. Conf. on Data Mining},
    keywords = {litreview, thesis},
    posted-at = {2008-12-21 04:29:45},
    priority = {2},
    title = {Iterative Deepening Dynamic Time
Warping for Time Series},
    url = {http://www.siam.org/meetings/sdm02/proceedings/sdm02-12.pdf},
    year = {2002}
}

@proceedings{citeulike:3815076,
    abstract = {After the generation of multimedia data turned digital, an explosion of interest in their data storage,
retrieval, and processing has drastically increased. This includes videos, images, and audios, where we now have higher
expectations in exploiting these data at hands. Typical manipulations are in some forms of video/image/audio processing,
including automatic speech recognition, which require fairly large amount of storage and are computationally intensive.
In our recent work, we have demonstrated the utility of time series representation in the task of clustering multimedia
data using k-medoids method, which allows considerable amount of reduction in computational effort and storage space.
However, k- means is a much more generic clustering method when Euclidean distance is used. In this work, we will
demonstrate that unfortunately, k-means clustering will sometimes fail to give correct results, an unaware fact that may
be overlooked by many researchers. This is especially the case when 
Dynamic Time Warping ({DTW}) is used as the distance measure in averaging the shape of time series. We also will
demonstrate that the current averaging algorithm may not produce the real average of the time series, thus generates
incorrect k-means clustering results, and then show potential causes why {DTW} averaging methods may not achieve
meaningful clustering results. Lastly, we conclude with a suggestion of a method to potentially find the shape-based
time series average that satisfies the required properties.},
    author = {Niennattrakul, V. and Ratanamahatana, C. A.},
    booktitle = {Multimedia and Ubiquitous Engineering, 2007. MUE '07. International Conference on},
    citeulike-article-id = {3815076},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/mue.2007.165},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4197360},
    doi = {10.1109/mue.2007.165},
    journal = {Multimedia and Ubiquitous Engineering, 2007. MUE '07. International Conference on},
    keywords = {dtw, litreview, thesis},
    pages = {733--738},
    posted-at = {2008-12-21 04:17:26},
    priority = {2},
    title = {On Clustering Multimedia Time Series Data Using {K-Means} and Dynamic Time Warping},
    url = {http://dx.doi.org/10.1109/mue.2007.165},
    year = {2007}
}

@proceedings{citeulike:3815040,
    abstract = {Fast similarity searching in large time sequence databases has typically used Euclidean distance as a
dissimilarity metric. However, for several applications, including matching of voice, audio and medical signals (e.g.,
electrocardiograms), one is required to permit local accelerations and decelerations in the rate of sequences, leading
to a popular, field tested dissimilarity metric called the \&ldquo;time warping\&rdquo; distance. From the indexing
viewpoint, this metric presents two major challenges: (a) it does not lead to any natural indexable
\&ldquo;features\&rdquo;, and (b) comparing two sequences requires time quadratic in the sequence length. To address
each problem, we propose to use: (a) a modification of the so called \&{ldquo;FastMap}\&rdquo;, to map sequences into
points, with little compromise of \&ldquo;recall\&rdquo; (typically zero); and (b) a fast linear test, to help us
discard quickly many of the false alarms that {FastMap} will typically introduce. Using both ideas in 
cascade, our proposed method achieved up to an order of magnitude speed-up over sequential scanning on both real and
synthetic datasets},
    author = {Yi, Byoung-Kee and Jagadish, H. V. and Faloutsos, C.},
    booktitle = {Data Engineering, 1998. Proceedings., 14th International Conference on},
    citeulike-article-id = {3815040},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icde.1998.655778},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=655778},
    doi = {10.1109/icde.1998.655778},
    journal = {Data Engineering, 1998. Proceedings., 14th International Conference on},
    keywords = {dtw, litreview, thesis},
    pages = {201--208},
    posted-at = {2008-12-21 02:21:14},
    priority = {2},
    title = {Efficient retrieval of similar time sequences under time warping},
    url = {http://dx.doi.org/10.1109/icde.1998.655778},
    year = {1998}
}

@inproceedings{citeulike:3789964,
    abstract = {Abstract: Considerable effort has been put towards developing intelligent and natural interfaces between
users and computer systems. This is done by means of a variety of modes of information (visual, audio, pen, etc.) either
used individually or in combination. In this work, we focus on the visual sensory information to recognize human
activity in form of hand-arm movements from a small, predefined vocabulary. We accomplish this task by means of a
matching technique by determining the distance between the unknown input and a set of previously defined templates. A
dynamic time warping ({DTW}) algorithm is used to perform the time alignment and normalization by computing a temporal
transformation allowing the two signals to be matched. The system is trained with finite video sequences of single
gesture performances whose start and end point are accurately known. Preliminary experiments are accomplished off-line
and result in a recognition accuracy of up to 92\%.},
    address = {Washington, DC, USA},
    author = {Corradini, Andrea},
    booktitle = {RATFG-RTS '01: Proceedings of the IEEE ICCV Workshop on Recognition, Analysis, and Tracking of Faces
and Gestures in Real-Time Systems (RATFG-RTS'01)},
    citeulike-article-id = {3789964},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=882476.883586},
    keywords = {dtw, litreview, thesis},
    posted-at = {2008-12-15 17:14:19},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {Dynamic Time Warping for {Off-Line} Recognition of a Small Gesture Vocabulary},
    url = {http://portal.acm.org/citation.cfm?id=882476.883586},
    year = {2001}
}

@proceedings{citeulike:3789957,
    abstract = {In this paper an approach to classify hand shapes into different classes according to the similarity
measures between features is proposed. We show how to use an Exploratory Data Analysis to extract novel, single feature
of hand from images. Based on the obtained curve-like shape of the feature, hands are classified into one of 21 possible
classes of Croatian sign language using Dynamic Time Warping and Longest Common Subsequence as similarity measures.
Performance of the system was evaluated with 1260 images. Results show that high classification accuracy can be obtained
from a single feature recognition and a small number of training sample.},
    author = {Kuzmanic, A. and Zanchi, V.},
    booktitle = {EUROCON, 2007. The International Conference on "Computer as a Tool"},
    citeulike-article-id = {3789957},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/eurcon.2007.4400350},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4400350},
    doi = {10.1109/eurcon.2007.4400350},
    journal = {EUROCON, 2007. The International Conference on "Computer as a Tool"},
    keywords = {dtw, litreview, thesis},
    pages = {264--269},
    posted-at = {2008-12-15 17:10:27},
    priority = {2},
    title = {Hand shape classification using {DTW} and {LCSS} as similarity measures for vision-based gesture
recognition system},
    url = {http://dx.doi.org/10.1109/eurcon.2007.4400350},
    year = {2007}
}

@article{citeulike:2584345,
    abstract = {This survey describes the state of the art of online handwriting
recognition during a period of renewed activity in the field. It is
based on an extensive review of the literature, including journal
articles, conference proceedings, and patents. Online versus offline
recognition, digitizer technology, and handwriting properties and
recognition problems are discussed. Shape recognition algorithms,
preprocessing and postprocessing techniques, experimental systems, and
commercial products are examined},
    author = {Tappert, C. C. and Suen, C. Y. and Wakahara, T.},
    booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    citeulike-article-id = {2584345},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=83137},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/34.57669},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=57669},
    doi = {10.1109/34.57669},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {dtw, litreview, thesis},
    month = aug,
    number = {8},
    pages = {787--808},
    posted-at = {2008-12-15 17:04:49},
    priority = {2},
    publisher = {IEEE},
    title = {The state of the art in online handwriting recognition},
    url = {http://dx.doi.org/10.1109/34.57669},
    volume = {12},
    year = {1990}
}

@article{citeulike:3789944,
    abstract = {This paper compares the current state of the art in online Japanese character recognition with
techniques in western handwriting recognition. It discusses important developments in preprocessing, classification, and
postprocessing for Japanese character recognition in recent years and relates them to the developments in western
handwriting recognition. Comparing eastern and western handwriting recognition techniques allows learning from very
different approaches and understanding the underlying common foundations of handwriting recognition. This is very
important when it comes to developing compact modules for integrated systems supporting many writing systems capable of
recognizing multilanguage documents.},
    author = {Jaeger, S. and Liu, C. L. and Nakagawa, M.},
    citeulike-article-id = {3789944},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10032-003-0107-y},
    citeulike-linkout-1 = {http://www.springerlink.com/content/t6glat9xbwd3cn9k},
    day = {1},
    doi = {10.1007/s10032-003-0107-y},
    journal = {International Journal on Document Analysis and Recognition},
    keywords = {dtw, litreview, thesis},
    month = oct,
    number = {2},
    pages = {75--88},
    posted-at = {2008-12-15 16:59:51},
    priority = {2},
    title = {The state of the art in Japanese online handwriting recognition compared to techniques in western
handwriting recognition},
    url = {http://dx.doi.org/10.1007/s10032-003-0107-y},
    volume = {6},
    year = {2003}
}

@article{citeulike:125682,
    author = {Yutao, Shou and Nikos, Mamoulis and David, Cheung},
    citeulike-article-id = {125682},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10994-005-5828-3},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/klu/ml/2005/00000058/F0020002/00005828},
    citeulike-linkout-2 = {http://www.springerlink.com/content/m06l258t60m6172g},
    doi = {10.1007/s10994-005-5828-3},
    issn = {0885-6125},
    journal = {Machine Learning},
    keywords = {dtw, litreview, thesis},
    month = feb,
    number = {2-3},
    pages = {231--267},
    posted-at = {2008-12-15 16:45:58},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Fast and Exact Warping of Time Series Using Adaptive Segmental Approximations},
    url = {http://dx.doi.org/10.1007/s10994-005-5828-3},
    volume = {58},
    year = {2005}
}

@incollection{citeulike:3789897,
    abstract = {As the world has shifted towards manipulation of information and its technology, we have been
increasingly overwhelmed by the amount of available multimedia data while having higher expectations to fully exploit
these data at hands. One of the attempts is to develop content-based multimedia information retrieval systems, which
greatly facilitate us to intuitively search by its contents; a classic example is a {Query-by-Humming} system.
Nevertheless, typical content-based search for multimedia data usually requires a large amount of storages and is
computationally intensive. Recently, time series representation has been successfully applied to a wide variety of
research, including multimedia retrieval due to the great reduction in time and space complexity. Besides, an
enhancement, Uniform Scaling, has been proposed and applied prior to distance calculation, as well as it has been
demonstrated that Uniform Scaling can outperform Euclidean distance. These previous work on Uniform Scaling, 
nonetheless, overlook the importance and effects of normalisation, which make their frameworks impractical for real
world data. Therefore, in this paper, we justify this importance of normalisation in multimedia data and propose an
efficient solution for searching multimedia time series data under Uniform Scaling and normalisation.},
    author = {Euachongprasit, Waiyawuth and Ratanamahatana, Chotirat},
    citeulike-article-id = {3789897},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-78646-7\_49},
    citeulike-linkout-1 = {http://www.springerlink.com/content/435002l8552xj536},
    doi = {10.1007/978-3-540-78646-7\_49},
    journal = {Advances in Information Retrieval},
    keywords = {dtw, litreview, thesis},
    pages = {506--513},
    posted-at = {2008-12-15 16:16:06},
    priority = {2},
    title = {Efficient Multimedia Time Series Data Retrieval Under Uniform Scaling and Normalisation},
    url = {http://dx.doi.org/10.1007/978-3-540-78646-7\_49},
    year = {2008}
}

@incollection{citeulike:3789894,
    abstract = {Relatively few query tools exist for data exploration and pattern identification in time series data
sets. In previous work we introduced Timeboxes. Timeboxes are rectangular, direct-manipulation queries for studying
time-series datasets. We demonstrated how Timeboxes can be used to support interactive exploration via dynamic queries,
along with overviews of query results and drag-and-drop support for query-by-example. In this paper, we extend our work
by introducing Variable Time Timeboxes ({VTT}). {VTTs} are a natural generalization of Timeboxes, which permit the
specification of queries that allow a degree of uncertainty in the time axis. We carefully motivate the need for these
more expressive queries, and demonstrate the utility of our approach on several data sets.},
    author = {Keogh, Eamonn and Hochheiser, Harry and Shneiderman, Ben},
    citeulike-article-id = {3789894},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-36109-x\_19},
    citeulike-linkout-1 = {http://www.springerlink.com/content/wmpf85apmqg2b1xv},
    doi = {10.1007/3-540-36109-x\_19},
    journal = {Flexible Query Answering Systems},
    keywords = {dtw, litreview, thesis},
    pages = {240--250},
    posted-at = {2008-12-15 16:14:09},
    priority = {2},
    title = {An Augmented Visual Query Mechanism for Finding Patterns in Time Series Data},
    url = {http://dx.doi.org/10.1007/3-540-36109-x\_19},
    year = {2002}
}

@electronic{citeulike:3788829,
    author = {Dimitrios, Gunopulos},
    citeulike-article-id = {3788829},
    citeulike-linkout-0 = {http://mrw.interscience.wiley.com/emrw/9780470011812/eob/article/b2a12074/current/abstract},
    keywords = {litreview, thesis},
    posted-at = {2008-12-15 06:48:48},
    priority = {2},
    title = {Time Series Similarity Measures},
    url = {http://mrw.interscience.wiley.com/emrw/9780470011812/eob/article/b2a12074/current/abstract}
}

@article{citeulike:3788783,
    abstract = {{Abstract--In} this paper, we give a comprehensive description of our writer-independent online
handwriting recognition system frog on hand. The focus of this work concerns the presentation of the
classification/training approach, which we call cluster generative statistical dynamic time warping ({CSDTW}). {CSDTW}
is a general, scalable, {HMM}-based method for variable-sized, sequential data that holistically combines cluster
analysis and statistical sequence modeling. It can handle general classification problems that rely on this sequential
type of data, e.g., speech recognition, genome processing, robotics, etc. Contrary to previous attempts, clustering and
statistical sequence modeling are embedded in a single feature space and use a closely related distance measure. We show
character recognition experiments of frog on hand using {CSDTW} on the {UNIPEN} online handwriting database. The
recognition accuracy is significantly higher than reported results of other handwriting recognition 
systems. Finally, we describe the real-time implementation of frog on hand on a Linux Compaq {iPAQ} embedded device.},
    address = {Washington, DC, USA},
    author = {Bahlmann, Claus and Burkhardt, Hans},
    citeulike-article-id = {3788783},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=968862},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/tpami.2004.1262308},
    doi = {10.1109/tpami.2004.1262308},
    issn = {0162-8828},
    journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
    keywords = {dtw, litreview, thesis},
    number = {3},
    pages = {299--310},
    posted-at = {2008-12-15 06:30:08},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {The Writer Independent Online Handwriting Recognition System frog on hand and Cluster Generative
Statistical Dynamic Time Warping},
    url = {http://dx.doi.org/10.1109/tpami.2004.1262308},
    volume = {26},
    year = {2004}
}

@article{citeulike:3744226,
    abstract = {Poor handwriting is a diagnostic criterion for developmental coordination disorder. Typical of poor
handwriting is its low overall quality and the high variability of the spatial characteristics of the letters, usually
assessed with a subjective handwriting scale. Recently, Dynamic Time Warping ({DTW}), a technique originally developed
for speech recognition, was introduced for pattern recognition in handwriting. The present study evaluates its
application to analyze poor handwriting. Forty children attending Dutch mainstream primary schools were recruited and
based on their scores on the Concise Evaluation Scale for Children's Handwriting (Dutch abbreviation: {BHK}), 20 good
and 20 poor writers (of whom 13 were scheduled for handwriting intervention) were identified. The groups were matched
for age (7-9 years), school grade (grades 2 and 3) and handedness. The children subsequently wrote sequences of the
letter "a" on a graphics tablet in three conditions (normal, fast, and accurate). 
Classical kinematics were obtained and for each individual letter {DTW} was used to calculate the distance from the mean
shape. The {DTW} data revealed much higher variability in the letter forms of the poor writers that was independent of
the kinematic results of larger trajectories, faster movements, and higher pen pressure. The current results suggest
that {DTW} is a valid and objective technique for letter-form analysis in handwriting and may hence be useful to
evaluate the rehabilitation treatments of children suffering from poor handwriting. In education research it may be
exploited to explore how children (should) learn to write.},
    author = {Di Brina, C. and Niels, R. and Overvelde, A. and Levi, G. and Hulstijn, W.},
    citeulike-article-id = {3744226},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.humov.2008.02.012},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/18407363},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=18407363},
    doi = {10.1016/j.humov.2008.02.012},
    issn = {0167-9457},
    journal = {Human movement science},
    keywords = {dtw, litreview, thesis},
    month = apr,
    number = {2},
    pages = {242--255},
    pmid = {18407363},
    posted-at = {2008-12-04 02:15:21},
    priority = {2},
    title = {Dynamic time warping: a new method in the study of poor handwriting.},
    url = {http://dx.doi.org/10.1016/j.humov.2008.02.012},
    volume = {27},
    year = {2008}
}

@article{citeulike:3736775,
    abstract = {We present an efficient and robust multiscale {DTW} (Ms-
{DTW}) approach to music synchronization for time-aligning
{CD} recordings of different interpretations of the same piece.
The general strategy is to recursively project an alignment
path computed at a coarse resolution level to the next higher
level and then to refine the projected path. As main contributions,
we address several crucial issues including the design
and specification of robust and scalable audio features, suitable
local cost {measures,MsDTWlevels}, constraint regions,
as well as sampling rate adaptation and structural enhancement
strategies. Extensive experiments on Western classical
music show that our {MsDTW}-based algorithm yields the
same alignment result as the classical {DTW}-based strategy
while significantly reducing the running time and memory
requirements. Even for pieces of a duration of 10 to 15 minutes,
the alignment (based on previously extracted feature
sequences) can be computed in less than a second.},
    author = {Muller, M. and Mattes, H. and Kurth, F.},
    booktitle = {in Proc. ISMIR},
    citeulike-article-id = {3736775},
    citeulike-linkout-0 = {http://ismir2006.ismir.net/PAPERS/ISMIR0615\_Paper.pdf},
    citeulike-linkout-1 =
{http://www.google.com/url?sa=t\&\#38;source=web\&\#38;ct=res\&\#38;cd=2\&\#38;url=http\%3A\%2F\%2Farnetminer.org\%2Fvie
wpub.do\%3Fpid\%3D2106739\%26mode\%3Dpub\&\#38;ei=5I81SYviKZmWsAOrmoSHBg\&\#38;usg=AFQjCNGOl-fUcp4Q2PJKISmoUrdy16Fm3g\&\
#38;sig2=MB2z\_J\_cyQ766tYPoeXoKg},
    keywords = {dtw, litreview, thesis},
    location = {Victoria, Canada},
    pages = {192--197},
    posted-at = {2008-12-02 19:47:57},
    priority = {2},
    title = {An efficient multiscale approach to
audio synchronization},
    url = {http://ismir2006.ismir.net/PAPERS/ISMIR0615\_Paper.pdf},
    year = {2006}
}

@article{citeulike:3736765,
    abstract = {Dynamic Time Warping ({DTW}) has a quadratic time and space complexity that limits its use to small time
series. In this paper we introduce {FastDTW}, an approximation of {DTW} that has a linear time and space complexity.
{FastDTW} uses a multilevel approach that recursively projects a solution from a coarser resolution and refines the
projected solution. We prove the linear time and space complexity of {FastDTW} both theoretically and empirically. We
also analyze the accuracy of {FastDTW} by comparing it to two other types of existing approximate {DTW} algorithms:
constraints (such as {Sakoe-Chiba} Bands) and abstraction. Our results show a large improvement in accuracy over
existing methods.},
    address = {Amsterdam, The Netherlands, The Netherlands},
    author = {Salvador, Stan and Chan, Philip},
    citeulike-article-id = {3736765},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1367993},
    issn = {1088-467X},
    journal = {Intell. Data Anal.},
    keywords = {dtw, litreview, thesis},
    number = {5},
    pages = {561--580},
    posted-at = {2008-12-02 19:42:38},
    priority = {2},
    publisher = {IOS Press},
    title = {Toward accurate dynamic time warping in linear time and space},
    url = {http://portal.acm.org/citation.cfm?id=1367993},
    volume = {11},
    year = {2007}
}

@proceedings{citeulike:3733947,
    abstract = {In this paper, we discuss an on-line signature verification system based on dynamic time-warping
({DTW}). The {DTW}-algorithm originates from the field of speech recognition, and has been applied successfully in the
signature verification area more than once. However, until now, few adaptations have been made in order to take the
specific characteristics of signature verification into account. According to us, one of the most important differences
is the availability of a rather large number of reference patterns, making it possible to determine which parts of a
reference signature are important and which are not. By disconnecting the {DTW}-stage and the feature extraction process
we are able to deal efficiently with this extra amount of information. We demonstrate the benefits of our approach by
building and evaluating a complete system},
    author = {Martens, R. and Claesen, L.},
    booktitle = {Pattern Recognition, 1996., Proceedings of the 13th International Conference on},
    citeulike-article-id = {3733947},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icpr.1996.546791},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=546791},
    doi = {10.1109/icpr.1996.546791},
    journal = {Pattern Recognition, 1996., Proceedings of the 13th International Conference on},
    keywords = {dtw, litreview, thesis},
    pages = {38--42 vol.3},
    posted-at = {2008-12-02 03:27:24},
    priority = {2},
    title = {On-line signature verification by dynamic time-warping},
    url = {http://dx.doi.org/10.1109/icpr.1996.546791},
    volume = {3},
    year = {1996}
}

@proceedings{citeulike:3733945,
    abstract = {We focus on the use of the dynamic time warping ({DTW}) technique in the signature verification area.
The {DTW} algorithm originates from the field of speech recognition, where it is a highly appreciated component of
speaker specific isolated word recognisers. A few years ago the {DTW} algorithm was successfully introduced in the area
of online signature verification. The characteristics of speech recognition and signature verification are however
rather different. Starting from these dissimilarities, our objective is to extract an alternative {DTW} approach that is
better suited to the signature verification problem},
    author = {Martens, R. and Claesen, L.},
    booktitle = {Document Analysis and Recognition, 1997., Proceedings of the Fourth International Conference on},
    citeulike-article-id = {3733945},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icdar.1997.620587},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=620587},
    doi = {10.1109/icdar.1997.620587},
    journal = {Document Analysis and Recognition, 1997., Proceedings of the Fourth International Conference on},
    keywords = {dtw, litreview, thesis},
    pages = {653--656 vol.2},
    posted-at = {2008-12-02 03:26:10},
    priority = {2},
    title = {Dynamic programming optimisation for on-line signature verification},
    url = {http://dx.doi.org/10.1109/icdar.1997.620587},
    volume = {2},
    year = {1997}
}

@article{citeulike:1807913,
    abstract = {Despite their known weaknesses, hidden Markov models ({HMMs}) have been the dominant technique for
acoustic modeling in speech recognition for over two decades. Still, the advances in the {HMM} framework have not solved
its key problems: it discards information about time dependencies and is prone to overgeneralization. In this paper, we
attempt to overcome these problems by relying on straightforward template matching. The basis for the recognizer is the
well-known {DTW} algorithm. However, classical {DTW} continuous speech recognition results in an explosion of the search
space. The traditional top-down search is therefore complemented with a data-driven selection of candidates for {DTW}
alignment. We also extend the {DTW} framework with a flexible subword unit mechanism and a class sensitive distance
measure-two components suggested by state-of-the-art {HMM} systems. The added flexibility of the unit selection in the
template-based framework leads to new approaches to speaker and 
environment adaptation. The template matching system reaches a performance somewhat worse than the best published {HMM}
results for the Resource Management benchmark, but thanks to complementarity of errors between the {HMM} and {DTW}
systems, the combination of both leads to a decrease in word error rate with 17\% compared to the {HMM} results},
    author = {De Wachter, M. and Matton, M. and Demuynck, K. and Wambacq, P. and Cools, R. and Van Compernolle, D.},
    booktitle = {Audio, Speech and Language Processing, IEEE Transactions on [see also Speech and Audio Processing, IEEE
Transactions on]},
    citeulike-article-id = {1807913},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tasl.2007.894524},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4156191},
    doi = {10.1109/tasl.2007.894524},
    journal = {Audio, Speech and Language Processing, IEEE Transactions on [see also Speech and Audio Processing, IEEE
Transactions on]},
    keywords = {dtw, litreview, thesis},
    number = {4},
    pages = {1377--1390},
    posted-at = {2008-12-02 03:20:17},
    priority = {2},
    title = {{Template-Based} Continuous Speech Recognition},
    url = {http://dx.doi.org/10.1109/tasl.2007.894524},
    volume = {15},
    year = {2007}
}

@proceedings{citeulike:1033529,
    abstract = {For many performance analysis problems, the ability to reason across traces is invaluable. However, due
to non-determinism in the {OS} and virtual machines, even two identical runs of an application yield slightly different
traces. For example, it is unlikely that two identical runs of an application will suffer context switches at exactly
the same points. These sorts of variations across traces make it difficult to reason across traces. This paper describes
and evaluates an algorithm, dynamic time warping ({DTW}) that can be used to align traces, thus enabling us to reason
across traces. While {DTW} comes from prior work our use of {DTW} is novel. Also we describe and evaluate an enhancement
to {DTW} that significantly improves the quality of its alignments. Our results show that for applications whose
performance varies significantly over time, {DTW} does a great job at aligning the traces. For applications whose
performance stays largely constant for significant periods of time, the 
original {DTW} does not perform well; however, our enhanced {DTW} performs much better.},
    author = {Mytkowicz, T. and Diwan, A. and Hauswirth, M. and Sweeney, P. F.},
    citeulike-article-id = {1033529},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ipdps.2006.1639592},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1639592},
    doi = {10.1109/ipdps.2006.1639592},
    journal = {Parallel and Distributed Processing Symposium, 2006. IPDPS 2006. 20th International},
    keywords = {dtw, litreview, thesis},
    pages = {8 pp.+},
    posted-at = {2008-12-02 03:17:17},
    priority = {2},
    title = {Aligning traces for performance evaluation},
    url = {http://dx.doi.org/10.1109/ipdps.2006.1639592},
    year = {2006}
}

@incollection{citeulike:3733930,
    abstract = {In this paper, we report the results of recognition of online handwritten Tamil characters. We
experimented with two different approaches. One is subspace based method wherein the interactions between the features
in the feature spate are assumed to be linear. In the second approach, we investigated an elastic matching technique
using dynamic programming principles. We compare the methods to find their suitability for an on-line form-filling
application in writer dependent, independent and adaptive scenarios. The comparison is in terms of average recognition
accuracy and the number of training samples required to obtain an acceptable performance. While the first criterion
evaluates effective recognition capability of a scheme, the second one is important for studying the effectiveness of a
scheme in real time applications. We also perform error analysis to determine the advisability of combining the
classifiers.},
    author = {Joshi, Niranjan and Sita, G. and Ramakrishnan, A. G. and Madhvanath, Sriganesh},
    citeulike-article-id = {3733930},
    citeulike-linkout-0 = {http://www.springerlink.com/content/v8xlqt222kvw63kj},
    journal = {Neural Information Processing},
    keywords = {dtw, litreview, thesis},
    pages = {806--813},
    posted-at = {2008-12-02 03:12:44},
    priority = {2},
    title = {Tamil Handwriting Recognition Using Subspace and {DTW} Based Classifiers},
    url = {http://www.springerlink.com/content/v8xlqt222kvw63kj},
    year = {2004}
}

@article{citeulike:3733907,
    abstract = {One of the most challenging areas in the field of automatic control is the design of automatic control
devices that 'learn' to improve their performamce based upon experience, i.e., that can adapt themselves to
circumstances as they find them. The military and commercial implications of such devices are impressive, and interest
in the two main areas of research in the field of control, the {USA} and the {USSR}, runs high. Unfortunately, though,
both theory and construction of adaptive controllers are in their infancy, and some time may pass before they are
commonplace. Nonetheless, development at this time of adequate theories of processes of this nature is essential. The
purpose of our paper is to show how the functional equation technique of a new mathematical discipline, dynamic
programming, can be used in the formulation and solution of a variety of optimization problems concerning the design of
adaptive devices. Although, occasionally, a solution in closed form can be obtained, in 
general, numerical solution via the use of high-speed digital computers is contemplated. We discuss here the closely
allied problems of formulating adaptive control processes in precise mathematical terms and of presenting feasible
computational algoritbms for determining numerical solutioms. To illustrate the general concepts, consider a system
which is governed by the inhomogeneous Van der Pol equation},
    author = {Bellman, R. and Kalaba, R.},
    booktitle = {Automatic Control, IRE Transactions on},
    citeulike-article-id = {3733907},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tac.1959.1104847},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1104847},
    doi = {10.1109/tac.1959.1104847},
    institution = {Rand Corporation, Santa Monica, CA, USA},
    issn = {0096-199X},
    journal = {Automatic Control, IRE Transactions on},
    keywords = {dtw, litreview, thesis},
    month = nov,
    number = {2},
    pages = {1--9},
    posted-at = {2008-12-02 02:50:59},
    priority = {2},
    publisher = {IEEE},
    title = {On adaptive control processes},
    url = {http://dx.doi.org/10.1109/tac.1959.1104847},
    volume = {4},
    year = {1959}
}

@article{citeulike:3733894,
    abstract = {Comprehensive two-dimensional gas chromatography ({GC} × {GC}) is now recognized as the preferred
technique for the detailed analysis and characterization of complex mixtures of volatile compounds. However, for
comparison purposes, taking into account all the information contained in the chromatogram is far from trivial. In this
paper, it is shown that the combination of peak alignment by dynamic time warping and multivariate analysis facilitated
the comparison of complex chromatograms of tobacco extracts. The comparison is shown to be efficient enough to provide a
clear discrimination among three types of tobacco. A tentative interpretation of loadings is presented in order to give
access to the compounds which differ from one sample to another. Once located, mass spectrometry was used to identify
markers of tobacco type.},
    author = {Vial, J\'{e}r\^{o}me and No\c{c}airi, Hicham and Sassiat, Patrick and Mallipatu, Sreedhar and Cognon,
Guillaume and Thi\'{e}baut, Didier and Teillet, B\'{e}atrice and Rutledge, Douglas N.},
    citeulike-article-id = {3733894},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.chroma.2008.09.027},
    day = {13},
    doi = {10.1016/j.chroma.2008.09.027},
    issn = {00219673},
    journal = {Journal of Chromatography A},
    keywords = {dtw, litreview, thesis},
    month = apr,
    number = {14},
    pages = {2866--2872},
    posted-at = {2008-12-02 02:32:00},
    priority = {2},
    title = {Combination of dynamic time warping and multivariate analysis for the comparison of comprehensive
two-dimensional gas chromatograms},
    url = {http://dx.doi.org/10.1016/j.chroma.2008.09.027},
    volume = {1216},
    year = {2009}
}

@incollection{citeulike:3733893,
    abstract = {The problem of similarity search in time series database has attracted a lot of interest in the data
mining field. {DTW}(Dynamic Time Warping) is a robust distance measure function for time series, which can handle time
shifting and scaling. The main defect of {DTW} lies in its relatively high computational complexity of similarity
search. In this paper, we develop a simple but efficient approximation technique for {DTW} to speed up the search
process. Our method is based on a variation of the traditional histograms of the time series. This method can work with
a time linear with the size of the database. In our experiment, we proved that the proposed technique is efficient and
produces few false dismissals in most applications.},
    author = {Gu, Jie and Jin, Xiaomin},
    citeulike-article-id = {3733893},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11875581\_101},
    citeulike-linkout-1 = {http://www.springerlink.com/content/523455477328r6k1},
    doi = {10.1007/11875581\_101},
    journal = {Intelligent Data Engineering and Automated Learning – IDEAL 2006},
    keywords = {dtw, litreview, thesis},
    pages = {841--848},
    posted-at = {2008-12-02 02:31:17},
    priority = {2},
    title = {A Simple Approximation for Dynamic Time Warping Search in Large Time Series Database},
    url = {http://dx.doi.org/10.1007/11875581\_101},
    year = {2006}
}

@proceedings{citeulike:3731715,
    abstract = {Finding similar patterns in a time sequence is a well-studied problem. Most of the current techniques
work well for queries of a prespecified length, but not for variable length queries. We propose a new indexing technique
that works well for variable length queries. The central idea is to store index structures at different resolutions for
a given dataset. The resolutions are based on wavelets. For a given query, a number of subqueries at different
resolutions are generated. The ranges of the subqueries are progressively refined based on results from previous
subqueries. Our experiments show that the total cost for our method is 4 to 20 times less than the current techniques
including linear scan. Because of the need to store information at multiple resolution levels, the storage requirement
of our method could potentially be large. In the second part of the paper we show how the index information can be
compressed with minimal information loss. According to our experimental results, even 
after compressing the size of the index to one fifth, the total cost of our method is 3 to 15 times less than the
current techniques},
    author = {Kahveci, T. and Singh, A.},
    booktitle = {Data Engineering, 2001. Proceedings. 17th International Conference on},
    citeulike-article-id = {3731715},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icde.2001.914838},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=914838},
    doi = {10.1109/icde.2001.914838},
    journal = {Data Engineering, 2001. Proceedings. 17th International Conference on},
    keywords = {dtw, litreview, thesis},
    pages = {273--282},
    posted-at = {2008-12-01 06:05:35},
    priority = {2},
    title = {Variable length queries for time series data},
    url = {http://dx.doi.org/10.1109/icde.2001.914838},
    year = {2001}
}

@proceedings{citeulike:3731713,
    abstract = {We investigate the problem of searching similar multiattribute time sequences. Such sequences arise
naturally in a number of medical, financial, video, weather forecast, and stock market databases where more than one
attribute is of interest at a time instant. We first solve the simple case in which the distance is defined as the
Euclidean distance. Later we extend it to shift and scale invariance. We formulate a new symmetric scale and shift
invariant notion of distance for such sequences. We also propose a new index structure that transforms the data
sequences and clusters them according to their shiftings and scalings. This clustering improves the efficiency
considerably. According to our experiments with real and synthetic datasets, the index structure's performance is 5 to
45 times better than competing techniques, the exact speedup based on other optimizations such as caching and
replication.},
    author = {Kahveci, T. and Singh, A. and Gurel, A.},
    booktitle = {Scientific and Statistical Database Management, 2002. Proceedings. 14th International Conference on},
    citeulike-article-id = {3731713},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ssdm.2002.1029718},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1029718},
    doi = {10.1109/ssdm.2002.1029718},
    journal = {Scientific and Statistical Database Management, 2002. Proceedings. 14th International Conference on},
    keywords = {dtw, litreview, thesis},
    pages = {175--184},
    posted-at = {2008-12-01 06:04:10},
    priority = {2},
    title = {Similarity searching for multi-attribute sequences},
    url = {http://dx.doi.org/10.1109/ssdm.2002.1029718},
    year = {2002}
}

@inproceedings{citeulike:3731711,
    abstract = {Note: {OCR} errors may be found in this Reference List extracted from the full text article.  {ACM} has
opted to expose the complete List rather than only correct and linked references.},
    address = {New York, NY, USA},
    author = {Kelvin and Wong, Man H.},
    booktitle = {PODS '99: Proceedings of the eighteenth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database
systems},
    citeulike-article-id = {3731711},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=304000},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/303976.304000},
    doi = {10.1145/303976.304000},
    isbn = {1-58113-062-7},
    keywords = {dtw, litreview, thesis},
    location = {Philadelphia, Pennsylvania, United States},
    pages = {237--248},
    posted-at = {2008-12-01 06:02:47},
    priority = {2},
    publisher = {ACM},
    title = {Fast time-series searching with scaling and shifting},
    url = {http://dx.doi.org/10.1145/303976.304000},
    year = {1999}
}

@article{citeulike:3731706,
    abstract = {We consider the problem of finding similar patterns in a time sequence. Typical applications of this
problem involve large databases consisting of long time sequences of different lengths. Current time sequence search
techniques work well for queries of a prespecified length, but not for arbitrary length queries. We propose a novel
indexing technique that works well for arbitrary length queries. The proposed technique stores index structures at
different resolutions for a given data set. We prove that this index structure is superior to existing index structures
that use a single resolution. We propose a range query and nearest neighbor query technique on this index structure and
prove the optimality of our index structure for these search techniques. The experimental results show that our method
is 4 to 20 times faster than the current techniques, including sequential scan, for range queries and 3 times faster
than sequential scan and other techniques for nearest neighbor queries. Because of 
the need to store information at multiple resolution levels, the storage requirement of our method could potentially be
large. In the second part, we show how the index information can be compressed with minimal information loss. According
to our experimental results, even after compressing the size of the index to one fifth, the total cost of our method is
3 to 15 times less than the current techniques.},
    author = {Kahveci, T. and Singh, A. K.},
    booktitle = {Knowledge and Data Engineering, IEEE Transactions on},
    citeulike-article-id = {3731706},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tkde.2004.1269667},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1269667},
    doi = {10.1109/tkde.2004.1269667},
    journal = {Knowledge and Data Engineering, IEEE Transactions on},
    keywords = {dtw, litreview, thesis},
    number = {4},
    pages = {418--433},
    posted-at = {2008-12-01 05:59:02},
    priority = {2},
    title = {Optimizing similarity search for arbitrary length time series queries},
    url = {http://dx.doi.org/10.1109/tkde.2004.1269667},
    volume = {16},
    year = {2004}
}

@inproceedings{citeulike:2264785,
    abstract = {We investigate techniques for analysis and retrieval of object trajectories in two or three dimensional
space. Such data usually contain a large amount of noise, that has made previously used metrics fail. Therefore, we
formalize non-metric similarity functions based on the longest common subsequence ({LCSS}), which are very robust to
noise and furthermore provide an intuitive notion of similarity between trajectories by giving more weight to similar
portions of the sequences. Stretching of sequences in time is allowed, as well as global translation of the sequences in
space. Efficient approximate algorithms that compute these similarity measures are also provided. We compare these new
methods to the widely used Euclidean and time warping distance functions (for real and synthetic data) and show the
superiority of our approach, especially in the strong presence of noise. We prove a weaker version of the triangle
inequality and employ it in an indexing structure to answer nearest neighbor 
queries. Finally, we present experimental results that validate the accuracy and efficiency of our approach},
    author = {Vlachos, M. and Kollios, G. and Gunopulos, D.},
    booktitle = {Data Engineering, 2002. Proceedings. 18th International Conference on},
    citeulike-article-id = {2264785},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icde.2002.994784},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=994784},
    doi = {10.1109/icde.2002.994784},
    institution = {California Univ., Riverside, CA},
    isbn = {0-7695-1531-2},
    issn = {1063-6382},
    journal = {Data Engineering, 2002. Proceedings. 18th International Conference on},
    keywords = {dtw, litreview, thesis},
    pages = {673--684},
    posted-at = {2008-12-01 05:57:25},
    priority = {2},
    publisher = {IEEE},
    title = {Discovering similar multidimensional trajectories},
    url = {http://dx.doi.org/10.1109/icde.2002.994784},
    year = {2002}
}

@article{citeulike:603020,
    abstract = {The technique of dynamic programming for the time registration of a reference and a test pattern has
found widespread use in the area of isolated word recognition. Recently, a number of variations on the basic time
warping algorithm have been proposed by Sakoe and Chiba, and Rabiner, Rosenberg, and Levinson. These algorithms all
assume that the test input is the time pattern of a feature vector from an isolated word whose endpoints are known (at
least approximately). The major differences in the methods are the global path constraints (i.e., the region of possible
warping paths), the local continuity constraints on the path, and the distance weighting and normalization used to give
the overall minimum distance. The purpose of this investigation is to study the effects of such variations on the
performance of different dynamic time warping algorithms for a realistic speech database. The performance measures that
were used include: speed of operation, memory requirements, and recognition 
accuracy. The results show that both axis orientation and relative length of the reference and the test patterns are
important factors in recognition accuracy. Our results suggest a new approach to dynamic time warping for isolated words
in which both the reference and test patterns are linearly warped to a fixed length, and then a simplified dynamic time
warping algorithm is used to handle the nonlinear component of the time alignment. Results with this new algorithm show
performance comparable to or better than that of all other dynamic time warping algorithms that were studied.},
    author = {Myers, C. and Rabiner, L. and Rosenberg, A.},
    citeulike-article-id = {603020},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1163491},
    journal = {Acoustics, Speech, and Signal Processing [see also IEEE Transactions on Signal Processing], IEEE
Transactions on},
    keywords = {dtw, litreview, thesis},
    number = {6},
    pages = {623--635},
    posted-at = {2008-12-01 03:52:05},
    priority = {2},
    title = {Performance tradeoffs in dynamic time warping algorithms for isolated word recognition},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1163491},
    volume = {28},
    year = {1980}
}

@inproceedings{citeulike:964832,
    abstract = {This paper compares different similarity measures used for trajectory clustering in outdoor surveillance
scenes. Six similarity measures are presented and the performance is evaluated by correct clustering rate ({CCR}) and
time cost ({TC}). The experimental results demonstrate that in outdoor surveillance scenes, the simpler {PCA}+Euclidean
distance is competent for the clustering task even in case of noise, as more complex similarity measures such as {DTW},
{LCSS} are not efficient due to their high computational cost},
    address = {Washington, DC, USA},
    author = {Zhang, Zhang and Huang, Kaiqi and Tan, Tieniu},
    booktitle = {Pattern Recognition, 2006. ICPR 2006. 18th International Conference on},
    citeulike-article-id = {964832},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1170749.1172504},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icpr.2006.392},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1699726},
    doi = {10.1109/icpr.2006.392},
    institution = {Nat. Lab of Pattern Recognition, Chinese Acad. of Sci., Beijing},
    isbn = {0-7695-2521-0},
    issn = {1051-4651},
    keywords = {dtw, litreview, thesis},
    location = {Hong Kong, China},
    pages = {1135--1138},
    posted-at = {2008-12-01 03:51:45},
    priority = {2},
    publisher = {IEEE},
    title = {Comparison of Similarity Measures for Trajectory Clustering in Outdoor Surveillance Scenes},
    url = {http://dx.doi.org/10.1109/icpr.2006.392},
    volume = {3},
    year = {2006}
}

@article{citeulike:3568196,
    abstract = {To recognize speech, handwriting or sign language, many hybrid approaches have been proposed that
combine Dynamic Time Warping ({DTW}) or Hidden Markov Models ({HMM}) with discriminative classifiers. However, all
methods rely directly on the likelihood models of {DTW}/{HMM}. We hypothesize that time warping and classification
should be separated because of conflicting likelihood modelling demands. To overcome these restrictions, we propose to
use Statistical {DTW} ({SDTW}) only for time warping, while classifying the warped features with a different method. Two
novel statistical classifiers are proposed ({CDFD} and {Q-DFFM}), both using a selection of discriminative features
({DF}), and are shown to outperform {HMM} and {SDTW}. However, we have found that combining likelihoods of multiple
models in a second classification stage degrades performance of the proposed classifiers, while improving performance
with {HMM} and {SDTW}. A proof-of-concept experiment, combining {DFFM} mappings of 
multiple {SDTW} models with {SDTW} likelihoods, shows that also for model-combining, hybrid classification can provide
significant improvement over {SDTW}. Although recognition is mainly based on {3D} hand motion features, these results
can be expected to generalize to recognition with more detailed measurements such as hand/body pose and facial
expression.},
    author = {Lichtenauer, J. F. and Hendriks, E. A. and Reinders, M. J.},
    booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    citeulike-article-id = {3568196},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tpami.2008.123},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4527247},
    doi = {10.1109/tpami.2008.123},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {dtw, litreview, thesis},
    number = {11},
    pages = {2040--2046},
    posted-at = {2008-12-01 03:49:25},
    priority = {2},
    title = {Sign Language Recognition by Combining Statistical {DTW} and Independent Classification},
    url = {http://dx.doi.org/10.1109/tpami.2008.123},
    volume = {30},
    year = {2008}
}

@article{citeulike:2737624,
    abstract = {Continuously monitoring through time the correlation/distance of multiple data streams is of interest in
a variety of applications, including financial analysis, video surveillance, and mining of biological data. However,
distance measures commonly adopted for comparing time series, such as Euclidean and Dynamic Time Warping ({DTW}), either
are known to be inaccurate or are too time-consuming to be applied in a streaming environment. In this paper we propose
a novel {DTW}-like distance measure, called {Stream-DTW} ({SDTW}), which unlike {DTW} can be efficiently updated at each
time step. We formally and experimentally demonstrate that {SDTW} speeds up the monitoring process by a factor that
grows linearly with the size of the window sliding over the streams. For instance, with a sliding window of 512 samples,
{SDTW} is about 600 times faster than {DTW}. We also show that {SDTW} is a tight approximation of {DTW}, errors never
exceeding 10\%, and that it consistently outperforms approximations 
developed for the case of static time series.},
    author = {Capitani, Paolo and Ciaccia, Paolo},
    booktitle = {Including special issue: 20th Brazilian Symposium on Databases (SBBD 2005)},
    citeulike-article-id = {2737624},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1244699},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.datak.2006.08.012},
    citeulike-linkout-2 =
{http://www.sciencedirect.com/science/article/B6TYX-4M4KHYY-1/1/1e1bc47874af6ecffe38e5f4651326e1},
    doi = {10.1016/j.datak.2006.08.012},
    journal = {Data \& Knowledge Engineering},
    keywords = {dtw, litreview, thesis},
    month = sep,
    number = {3},
    pages = {438--458},
    posted-at = {2008-12-01 03:48:48},
    priority = {2},
    title = {Warping the time on data streams},
    url = {http://dx.doi.org/10.1016/j.datak.2006.08.012},
    volume = {62},
    year = {2007}
}

@article{citeulike:2713605,
    abstract = {{Abstract\&nbsp;\&nbsp;A} new data mining technique used to classify normal and pre-seizure
electroencephalograms is proposed. The technique is based on a dynamic time warping kernel combined with support vector
machines ({SVMs}). The experimental results show that the technique is superior to the standard {SVM} and improves the
brain activity classification.},
    author = {Chaovalitwongse, W. and Pardalos, P.},
    citeulike-article-id = {2713605},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10559-008-0012-y},
    day = {27},
    doi = {10.1007/s10559-008-0012-y},
    journal = {Cybernetics and Systems Analysis},
    month = jan,
    number = {1},
    pages = {125--138},
    posted-at = {2008-12-01 03:43:26},
    priority = {2},
    title = {On the time series support vector machine using dynamic time warping kernel for brain activity
classification},
    url = {http://dx.doi.org/10.1007/s10559-008-0012-y},
    volume = {44},
    year = {2008}
}

@article{citeulike:2838910,
    address = {Norwell, MA, USA},
    author = {Efrat, Alon and Fan, Quanfu and Venkatasubramanian, Suresh},
    citeulike-article-id = {2838910},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1265122.1265128},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/s10851-006-0647-0},
    citeulike-linkout-2 = {http://www.springerlink.com/content/vk4125751759l807},
    day = {30},
    doi = {10.1007/s10851-006-0647-0},
    issn = {0924-9907},
    journal = {Journal of Mathematical Imaging and Vision},
    keywords = {dtw, litreview, thesis},
    month = apr,
    number = {3},
    pages = {203--216},
    posted-at = {2008-12-01 03:42:32},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {Curve Matching, Time Warping, and Light Fields: New Algorithms for Computing Similarity between Curves},
    url = {http://dx.doi.org/10.1007/s10851-006-0647-0},
    volume = {27},
    year = {2007}
}

@incollection{citeulike:3728229,
    abstract = {As we have seen in Chap. 4, dynamic time warping is a flexible tool for comparing time series in the
presence of nonlinear time deformations. In this context, the choice of suitable local cost or distance measures is of
crucial importance, since they determine the kind of (spatial) similarity between the elements (frames) of the two
sequences to be aligned. For the mocap domain, we introduce two conceptually different local distance measures – one
based on joint angle parameters and the other based on {3D} coordinates – and discuss their respective strengths and
weaknesses (Sect. 10.1). The importance of {DTW} is then illustrated by some synthesis and analysis applications (Sect.
10.2). By comparing a motion data stream to itself, one obtains a cost or distance matrix that exhibits
self-similarities within the motion. In Sect. 10.3, we describe how this idea can be exploited for motion retrieval.
Finally, in Sect. 10.4, we discuss some work related to {DTW}-based motion retrieval.},
    citeulike-article-id = {3728229},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-74048-3\_10},
    citeulike-linkout-1 = {http://www.springerlink.com/content/h3w52t7t43358ut8},
    doi = {10.1007/978-3-540-74048-3\_10},
    journal = {Information Retrieval for Music and Motion},
    keywords = {dtw, litreview, thesis},
    pages = {211--226},
    posted-at = {2008-11-29 22:30:44},
    priority = {0},
    title = {{DTW}-Based Motion Comparison and Retrieval},
    url = {http://dx.doi.org/10.1007/978-3-540-74048-3\_10},
    year = {2007}
}

@incollection{citeulike:3728228,
    abstract = {Dynamic time warping ({DTW}) is a well-known technique to find an optimal alignment between two given
(time-dependent) sequences under certain restrictions (Fig. 4.1). Intuitively, the sequences are warped in a nonlinear
fashion to match each other. Originally, {DTW} has been used to compare different speech patterns in automatic speech
recognition, see [170]. In fields such as data mining and information retrieval, {DTW} has been successfully applied to
automatically cope with time deformations and different speeds associated with time-dependent data. In this chapter, we
introduce and discuss the main ideas of classical {DTW} (Sect. 4.1) and summarize several modifications concerning local
as well as global parameters (Sect. 4.2). To speed up classical {DTW}, we describe in Sect. 4.3 a general multiscale
{DTW} approach. In Sect. 4.4, we show how {DTW} can be employed to identify all subsequence within a long data stream
that are similar to a given query sequence (Sect. 4.4). A discussion of 
related alignment techniques and references to the literature can be found in Sect. 4.5.},
    citeulike-article-id = {3728228},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-74048-3\_4},
    citeulike-linkout-1 = {http://www.springerlink.com/content/p7u3126423112123},
    doi = {10.1007/978-3-540-74048-3\_4},
    journal = {Information Retrieval for Music and Motion},
    keywords = {dtw, litreview, thesis},
    pages = {69--84},
    posted-at = {2008-11-29 22:27:36},
    priority = {0},
    title = {Dynamic Time Warping},
    url = {http://dx.doi.org/10.1007/978-3-540-74048-3\_4},
    year = {2007}
}

@proceedings{citeulike:2019923,
    abstract = {Recently, we are attending to a huge evolution on the development of high performance computing
platforms. Among these platforms, the {GPU} (Graphics Processing Units) stimulated by game industries, constantly
demanding more graphical processing power, evolved from a simple graphical card to a general purpose computation
parallel data processing device. This article shows the {GPU}'s viability to general purpose computation, developing a
speech recognition application inside. Dynamic Time Warping ({DTW}) is applied on a voice password identification.
Normally, {DTW} requires large amount of data and processing time, so that it is an efficient technique to simple
vocabulary, when the voice commands set is small. Using {NVIDIA} {GeForce} 8800 {GTX}, with 128 processing unit cores,
and a {CUDA} (Compute Unified Device Architecture) software platform development architecture, the {DTW} application was
implemented, and tested its performance.},
    author = {Poli, Gustavo and Mari, Joao F. and Hiroki and Levada, Alexandre L.},
    booktitle = {Computer Architecture and High Performance Computing, 2007. SBAC-PAD 2007. 19th International Symposium
on},
    citeulike-article-id = {2019923},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/sbac-pad.2007.21},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4384038},
    doi = {10.1109/sbac-pad.2007.21},
    journal = {Computer Architecture and High Performance Computing, 2007. SBAC-PAD 2007. 19th International Symposium
on},
    keywords = {dtw, thesis},
    pages = {19--25},
    posted-at = {2008-11-20 17:42:35},
    priority = {2},
    title = {Voice Command Recognition with Dynamic Time Warping ({DTW}) using Graphics Processing Units ({GPU}) with
Compute Unified Device Architecture ({CUDA})},
    url = {http://dx.doi.org/10.1109/sbac-pad.2007.21},
    year = {2007}
}

@article{citeulike:3578001,
    abstract = {A computer system is described in which isolated words, spoken by a designated talker, are recognized
through calculation of a minimum prediction residual. A reference pattern for each word to be recognized is stored as a
time pattern of linear prediction coefficients ({LPC}). The total log prediction residual of an input signal is
minimized by optimally registering the reference {LPC} onto the input autocorrelation coefficients using the dynamic
programming algorithm ({DP}). The input signal is recognized as the reference word which produces the minimum prediction
residual. A sequential decision procedure is used to reduce the amount of computation in {DP}. A frequency normalization
with respect to the long-time spectral distribution is used to reduce effects of variations in the frequency response of
telephone connections.  The system has been implemented on a {DDP}-516 computer for the 200-word recognition experiment.
The recognition rate for a designated male talker is 97.3 percent for 
telephone input, and the recognition time is about 22 times real time.},
    author = {Itakura, F.},
    booktitle = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
    citeulike-article-id = {3578001},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1162641},
    journal = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
    keywords = {dtw, litreview, thesis},
    number = {1},
    pages = {67--72},
    posted-at = {2008-11-19 12:36:49},
    priority = {4},
    title = {Minimum prediction residual principle applied to speech recognition},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1162641},
    volume = {23},
    year = {1975}
}

@mastersthesis{citeulike:3577984,
    author = {Myers, C. S.},
    citeulike-article-id = {3577984},
    citeulike-linkout-0 = {http://dspace.mit.edu/bitstream/1721.1/27909/1/07888629.pdf },
    journal = {MS and BS thesis,  MIT Jun 20 1980,},
    keywords = {dtw, litreview, thesis},
    posted-at = {2008-11-19 12:30:07},
    priority = {2},
    title = {A Comparative Study Of Several Dynamic Time Warping Algorithms For Speech Recognition},
    url = {http://dspace.mit.edu/bitstream/1721.1/27909/1/07888629.pdf }
}

@article{citeulike:1920382,
    author = {Dunfield, Peter F. and Yuryev, Anton and Senin, Pavel and Smirnova, Angela V. and Stott, Matthew B. and
Hou, Shaobin and Ly, Binh and Saw, Jimmy H. and Zhou, Zhemin and Ren, Yan and Wang, Jianmei and Mountain, Bruce W. and
Crowe, Michelle A. and Weatherby, Tina M. and Bodelier, Paul L. E. and Liesack, Werner and Feng, Lu and Wang, Lei and
Alam, Maqsudul},
    citeulike-article-id = {1920382},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature06411},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature06411},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18004300},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18004300},
    day = {14},
    doi = {10.1038/nature06411},
    issn = {0028-0836},
    journal = {Nature},
    keywords = {publication},
    month = nov,
    pmid = {18004300},
    posted-at = {2008-11-08 22:50:08},
    priority = {0},
    publisher = {Nature Publishing Group},
    title = {Methane oxidation by an extremely acidophilic bacterium of the phylum Verrucomicrobia},
    url = {http://dx.doi.org/10.1038/nature06411},
    year = {2007}
}

@article{citeulike:2709869,
    abstract = {
                Papaya, a fruit crop cultivated in tropical and subtropical regions, is known for its nutritional
benefits and medicinal applications. Here we report a 3x draft genome sequence of '{SunUp}' papaya, the first commercial
virus-resistant transgenic fruit tree to be sequenced. The papaya genome is three times the size of the Arabidopsis
genome, but contains fewer genes, including significantly fewer disease-resistance gene analogues. Comparison of the
five sequenced genomes suggests a minimal angiosperm gene set of 13,311. A lack of recent genome duplication, atypical
of other angiosperm genomes sequenced so far, may account for the smaller papaya gene number in most functional groups.
Nonetheless, striking amplifications in gene number within particular functional groups suggest roles in the evolution
of tree-like habit, deposition and remobilization of starch reserves, attraction of seed dispersal agents, and
adaptation to tropical daylengths. Transgenesis at three locations is closely 
associated with chloroplast insertions into the nuclear genome, and with topoisomerase I recognition sites. Papaya
offers numerous advantages as a system for fruit-tree functional genomics, and this draft genome sequence provides the
foundation for revealing the basis of Carica's distinguishing morpho-physiological, medicinal and nutritional
properties.
            },
    author = {Ming, Ray and Hou, Shaobin and Feng, Yun and Yu, Qingyi and Dionne-Laporte, Alexandre and Saw, Jimmy H.
and Senin, Pavel and Wang, Wei and Ly, Benjamin V. and Lewis, Kanako L. and Salzberg, Steven L. and Feng, Lu and Jones,
Meghan R. and Skelton, Rachel L. and Murray, Jan E. and Chen, Cuixia and Qian, Wubin and Shen, Junguo and Du, Peng and
Eustice, Moriah and Tong, Eric and Tang, Haibao and Lyons, Eric and Paull, Robert E. and Michael, Todd P. and Wall, Kerr
and Rice, Danny W. and Albert, Henrik and Wang, Ming-Li L. and Zhu, Yun J. and Schatz, Michael and Nagarajan, Niranjan
and Acob, Ricelle A. and Guan, Peizhu and Blas, Andrea and Wai, Ching Man M. and Ackerman, Christine M. and Ren, Yan and
Liu, Chao and Wang, Jianmei and Wang, Jianping and Na, Jong-Kuk K. and Shakirov, Eugene V. and Haas, Brian and
Thimmapuram, Jyothi and Nelson, David and Wang, Xiyin and Bowers, John E. and Gschwend, Andrea R. and Delcher, Arthur L.
and Singh, Ratnesh and Suzuki, Jon Y. and Tripathi, Savarni and Neupane, 
Kabi and Wei, Hairong and Irikura, Beth and Paidi, Maya and Jiang, Ning and Zhang, Wenli and Presting, Gernot and
Windsor, Aaron and Navajas-P\'{e}rez, Rafael and Torres, Manuel J. and Feltus, F. Alex and Porter, Brad and Li, Yingjun
and Burroughs, A. Max and Luo, Ming-Cheng C. and Liu, Lei and Christopher, David A. and Mount, Stephen M. and Moore,
Paul H. and Sugimura, Tak and Jiang, Jiming and Schuler, Mary A. and Friedman, Vikki and Mitchell-Olds, Thomas and
Shippen, Dorothy E. and dePamphilis, Claude W. and Palmer, Jeffrey D. and Freeling, Michael and Paterson, Andrew H. and
Gonsalves, Dennis and Wang, Lei and Alam, Maqsudul},
    citeulike-article-id = {2709869},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature06856},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature06856},
    citeulike-linkout-2 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2836516/},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/18432245},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=18432245},
    day = {24},
    doi = {10.1038/nature06856},
    issn = {1476-4687},
    journal = {Nature},
    keywords = {publication},
    month = apr,
    number = {7190},
    pages = {991--996},
    pmcid = {PMC2836516},
    pmid = {18432245},
    posted-at = {2008-11-08 22:49:20},
    priority = {0},
    publisher = {Nature Publishing Group},
    title = {The draft genome of the transgenic tropical fruit tree papaya (Carica papaya Linnaeus).},
    url = {http://dx.doi.org/10.1038/nature06856},
    volume = {452},
    year = {2008}
}

@article{citeulike:2949501,
    author = {Hou, Shaobin and Makarova, Kira S. and Jimmy and Senin, Pavel and Ly, Benjamin V. and Zhou, Zhemin and
Ren, Yan and Wang, Jianmei and Galperin, Michael Y. and Omelchenko, Marina V. and Wolf, Yuri I. and Yutin, Natalya and
Koonin, Eugene V. and Stott, Matthew B. and Mountain, Bruce W. and Crowe, Michelle A. and Smirnova, Angela V. and
Dunfield, Peter F. and Feng, Lu and Wang, Lei and Alam, Maqsudul},
    citeulike-article-id = {2949501},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1745-6150-3-26},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/18593465},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=18593465},
    day = {01},
    doi = {10.1186/1745-6150-3-26},
    issn = {1745-6150},
    journal = {Biology Direct},
    keywords = {publication},
    month = jul,
    pages = {26+},
    pmid = {18593465},
    posted-at = {2008-11-08 22:48:37},
    priority = {0},
    title = {Complete genome sequence of the extremely acidophilic methanotroph isolate V4, "Methylacidiphilum
infernorum", 
a representative of the bacterial phylum Verrucomicrobia},
    url = {http://dx.doi.org/10.1186/1745-6150-3-26},
    volume = {3},
    year = {2008}
}

@article{citeulike:3496861,
    abstract = {This paper reports on an optimum dynamic progxamming ({DP}) based time-normalization algorithm for
spoken word recognition. First, a general principle of time-normalization is given using time-warping function. Then,
two time-normalized distance definitions, called symmetric and asymmetric forms, are derived from the principle. These
two forms are compared with each other through theoretical discussions and experimental studies. The symmetric form
algorithm superiority is established. A new technique, called slope constraint, is successfully introduced, in which the
warping function slope is restricted so as to improve discrimination between words in different categories. The
effective slope constraint characteristic is qualitatively analyzed, and the optimum slope constraint condition is
determined through experiments. The optimized algorithm is then extensively subjected to experimental comparison with
various {DP}-algorithms, previously applied to spoken word recognition by different 
research groups. The experiment shows that the present algorithm gives no more than about two-thirds errors, even
compared to the best conventional algorithm.},
    author = {Sakoe, H. and Chiba, S.},
    booktitle = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
    citeulike-article-id = {3496861},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1163055},
    journal = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
    keywords = {dtw, litreview, thesis},
    number = {1},
    pages = {43--49},
    posted-at = {2008-11-08 22:11:03},
    priority = {0},
    title = {Dynamic programming algorithm optimization for spoken word recognition},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1163055},
    volume = {26},
    year = {1978}
}

%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Bogdan Vasilescu at 2013-02-19 18:02:41 +0100
%% Updated manually (last update 2013-12-12)


%% Saved with string encoding Unicode (UTF-8) 

@inproceedings{Tausczik2014Collaborative,
        author = {Tausczik, Yla R. and Kittur, Aniket and Kraut, Robert E.},
        title = {Collaborative Problem Solving: A Study of MathOverflow},
        booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work and Social Computing},
        series = {CSCW '14},
        year = {2014},
        location = {Baltimore, Maryland, USA},
        pages = {355--367},
        numpages = {13},
        publisher = {ACM},
        address = {New York, NY, USA},
} 

@inproceedings{Halavais2014Badges,
        title = {Badges of Friendship: {S}ocial Influence and Badge Acquisition on {Stack Overflow}},
        author = {Halavais, Alexander and Kwon, K Hazel and Havener, Shannon and Striker, Jason},
        booktitle = {Proceedings of the 47th Hawaii International International Conference on Systems Science (HICSS-47 2014)},
        location = {Hawaii, USA},
        pages = {},
        publisher = {IEEE},
        year = {2014},
}

@inproceedings{Vasilescu2013Babel,
        author = {Vasilescu, Bogdan and Serebrenik, Alexander and van den Brand, Mark G.J.},
        title = {The {B}abel of software development: {L}inguistic diversity in {Open Source}},
        booktitle = {Proceedings of the 5th International Conference on Social Informatics},
        location = {Kyoto, Japan},
        pages = {391--404},
        series = {Lecture Notes in Computer Science},
        publisher = {Springer},
        year = {2013},
}

@inproceedings{Schenk2013Geo,
        title = {Geo-locating the knowledge transfer in {StackOverflow}},
        author = {Schenk, Dennis and Lungu, Mircea},
        booktitle = {Proceedings of the 2013 International Workshop on Social Software Engineering},
        pages = {21--24},
        year = {2013},
        publisher = {ACM},
}

@inproceedings{Wang2013Empirical,
        title = {An empirical study on developer interactions in {StackOverflow}},
        author = {Wang, Shaowei and Lo, David and Jiang, Lingxiao},
        booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
        pages = {1019--1024},
        year = {2013},
        publisher = {ACM},
}

@inproceedings{Vasilescu2013Associations,
        author = {Vasilescu, Bogdan and Filkov, Vladimir and Serebrenik, Alexander},
        title = {{StackOverflow} and {GitHub}: {A}ssociations between software development and crowdsourced knowledge},
        booktitle = {Proceedings of the 2013 ASE/IEEE International Conference on Social Computing},
        location = {Washington D.C., USA},
        pages = {188--195},
        publisher = {IEEE},
        year = {2013},
}

@inproceedings{VasilescuCSCW14,
        author = {Vasilescu, Bogdan and Serebrenik, Alexander and Devanbu, Premkumar T. and Filkov, Vladimir},
        title = {How social {Q\&A} sites are changing knowledge sharing in open source software communities},
        booktitle = {Proceedings of the 17th ACM Conference on Computer Supported Cooperative Work and Social Computing},
        location = {Baltimore, MD, USA},
        pages = {342--354},
        publisher = {ACM},
        year = {2014},
}

@article{VasilescuIWC13,
        author = {Vasilescu, Bogdan and Capiluppi, Andrea and Serebrenik, Alexander},
        title = {Gender, representation and online participation: {A} quantitative study},
        journal = {Interacting with Computers},
        volume = {},
        number = {},
        year = {2013},
        pages = {1--24},
        doi = {10.1093/iwc/iwt047}, 
        URL = {http://iwc.oxfordjournals.org/content/early/2013/09/27/iwc.iwt047.abstract}, 
        eprint = {http://iwc.oxfordjournals.org/content/early/2013/09/27/iwc.iwt047.full.pdf+html},
        publisher = {Oxford University Press},
}

@inproceedings{Vasilescu2012Gender,
        author = {Vasilescu, Bogdan and Capiluppi, Andrea and Serebrenik, Alexander},
        title = {Gender, representation and online participation: {A} quantitative study of {StackOverflow}},
        booktitle = {Proceedings of the 2012 ASE/IEEE International Conference on Social Informatics},
        location  = {Washington D.C., USA},
        pages = {332--338},
        publisher = {IEEE},
        year = {2012},
}

@inproceedings{Correa2013Fit,
        title = {Fit or unfit: {A}nalysis and prediction of 'closed questions' on {Stack Overflow}},
        author = {Correa, Denzil and Sureka, Ashish},
        booktitle = {Proceedings of the first ACM Conference on Online Social Networks},
        pages = {201--212},
        year = {2013},
        publisher = {ACM}
}

@article{Yao2013GoodAnswer,
        author = {{Yao}, Y. and {Tong}, H. and {Xie}, T. and {Akoglu}, L. and {Xu}, F. and {Lu}, J.},
        title = "{Want a Good Answer? Ask a Good Question First!}",
        journal = {ArXiv e-prints},
        eprint = {1311.6876},
        year = 2013,
}

@inproceedings{Ponzanelli2013Seahawk,
        title = {Seahawk: {Stack Overflow} in the {IDE}},
        author = {Ponzanelli, Luca and Bacchelli, Alberto and Lanza, Michele},
        booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
        pages = {1295--1298},
        year = {2013},
        publisher = {IEEE}
}

@inproceedings{Allamanis2013Why,
        title = {Why, when, and what: {A}nalyzing {Stack Overflow} questions by topic, type, and code},
        author = {Allamanis, Miltiadis and Sutton, Charles},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        pages = {53--56},
        year = {2013},
        publisher = {IEEE}
}

@inproceedings{Anderson2013Steering,
        title = {Steering user behavior with badges},
        author = {Anderson, Ashton and Huttenlocher, Daniel and Kleinberg, Jon and Leskovec, Jure},
        booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
        pages = {95--106},
        year = {2013},
        publisher = {International World Wide Web Conferences Steering Committee}
}

@inproceedings{Asaduzzaman2013Answering,
        title = {Answering questions about unanswered questions of {Stack Overflow}},
        author = {Asaduzzaman, Muhammad and Mashiyat, Ahmed Shah and Roy, Chanchal K and Schneider, Kevin A},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        pages = {97--100},
        year = {2013},
        publisher = {IEEE}
}

@inproceedings{Bosu2013Building,
        title = {Building reputation in {StackOverflow}: {A}n empirical investigation},
        author = {Bosu, Amiangshu and Corley, Christopher S and Heaton, Dustin and Chatterji, Debarshi and Carver, Jeffrey C and Kraft, Nicholas A},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        pages = {89--92},
        year = {2013},
        publisher = {IEEE}
}

@inproceedings{Campbell2013Deficient,
        title = {Deficient documentation detection: {A} methodology to locate deficient project documentation using topic analysis},
        author = {Campbell, Joshua Charles and Zhang, Chenlei and Xu, Zhen and Hindle, Abram and Miller, James},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        pages = {57--60},
        year = {2013},
        organization = {IEEE}
}

@inproceedings{Gomez2013Study,
        title = {A study of innovation diffusion through link sharing on {Stack Overflow}},
        author = {G{\'o}mez, Carlos and Cleary, Brendan and Singer, Leif},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        pages = {81--84},
        year = {2013},
        publisher = {IEEE}
}

@inproceedings{Grant2013Encouraging,
        title = {Encouraging user behaviour with achievements: {A}n empirical study},
        author = {Grant, Scott and Betts, Buddy},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        pages = {65--68},
        year = {2013},
        publisher = {IEEE}
}

@inproceedings{Linares2013Exploratory,
        title = {An exploratory analysis of mobile development issues using {Stack Overflow}},
        author = {Linares-V{\'a}squez, Mario and Dit, Bogdan and Poshyvanyk, Denys},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        pages = {93--96},
        year = {2013},
        publisher = {IEEE}
}

@inproceedings{Morrison2013Programming,
        title = {Is programming knowledge related to age? {A}n exploration of {Stack Overflow}},
        author = {Morrison, Patrick and Murphy-Hill, Emerson},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        pages = {69--72},
        year = {2013},
        publisher = {IEEE}
}

@inproceedings{Saha2013Discriminative,
        title = {A discriminative model approach for suggesting tags automatically for {Stack Overflow} questions},
        author = {Saha, Avigit K and Saha, Ripon K and Schneider, Kevin A},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        pages = {73--76},
        year = {2013},
        publisher = {IEEE}
}

@inproceedings{Sinha2013Exploring,
        author = {Sinha, Vibha Singhal and Mani, Senthil and Gupta, Monika},
        title = {Exploring Activeness of Users in {Q\&A} Forums},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        series = {MSR '13},
        year = {2013},
        pages = {77--80},
        publisher = {IEEE},
}

@inproceedings{Subramanian2013Making,
        title = {Making sense of online code snippets},
        author = {Subramanian, Siddharth and Holmes, Reid},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        pages = {85--88},
        year = {2013},
        publisher = {IEEE},
}

@inproceedings{Wang2013Detecting,
        title = {Detecting {API} usage obstacles: a study of {iOS} and {Android} developer questions},
        author = {Wang, Wei and Godfrey, Michael W},
        booktitle = {Proceedings of the 10th International Working Conference on Mining Software Repositories},
        pages = {61--64},
        year = {2013},
        publisher = {IEEE},
}

@inproceedings{Tausczik2012Participation,
        author = {Tausczik, Yla R. and Pennebaker, James W.},
        title = {Participation in an Online Mathematics Community: Differentiating Motivations to Add},
        booktitle = {Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work},
        series = {CSCW '12},
        year = {2012},
        location = {Seattle, Washington, USA},
        pages = {207--216},
        numpages = {10},
        publisher = {ACM},
        address = {New York, NY, USA},
}

@article{Barua2012Topics,
        Author = {Anton Barua and Stephen W. Thomas and Ahmed E. Hassan},
        Journal = {Empirical Software Engineering},
        Pages = {To appear},
        Title = {What are developers talking about? An analysis of topics and trends in Stack Overflow},
        Year = {2012}}

@article{Jiau2012Facing,
        Author = {Hewijin Christine Jiau and Feng-Pu Yang},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Ee = {http://doi.acm.org/10.1145/2088883.2088892},
        Journal = {ACM SIGSOFT Software Engineering Notes},
        Number = {1},
        Pages = {1--9},
        Title = {Facing up to the inequality of crowdsourced {API} documentation},
        Volume = {37},
        Year = {2012}}

@article{Osbourn2011Getting,
        Author = {Toby Osbourn},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Ee = {http://doi.ieeecomputersociety.org/10.1109/MS.2011.6},
        Journal = {IEEE Software},
        Number = {1},
        Pages = {96},
        Title = {Getting the Most out of the Web},
        Volume = {28},
        Year = {2011}}

@article{Pal2012Exploring,
        Author = {Aditya Pal and F. Maxwell Harper and Joseph A. Konstan},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Ee = {http://doi.acm.org/10.1145/2180868.2180872},
        Journal = {ACM Trans. Inf. Syst.},
        Number = {2},
        Pages = {10},
        Title = {Exploring Question Selection Bias to Identify Experts and Potential Experts in Community Question Answering},
        Volume = {30},
        Year = {2012}}

@inproceedings{Bacchelli2012Harnessing,
        Author = {Bacchelli, Alberto and Ponzanelli, Luca and Lanza, Michele},
        Booktitle = {2012 Third International Workshop on Recommendation Systems for Software Engineering (RSSE)},
        Organization = {IEEE},
        Pages = {26--30},
        Title = {Harnessing Stack Overflow for the IDE},
        Year = {2012}}

@inproceedings{Tausczik2011Predicting,
        author = {Tausczik, Yla R. and Pennebaker, James W.},
        title = {Predicting the Perceived Quality of Online Mathematics Contributions from Users' Reputations},
        booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
        series = {CHI '11},
        year = {2011},
        location = {Vancouver, BC, Canada},
        pages = {1885--1888},
        numpages = {4},
        publisher = {ACM},
        address = {New York, NY, USA},
} 

@inproceedings{Chang2013Routing,
        title={Routing questions for collaborative answering in community question answering},
        author={Chang, Shuo and Pal, Aditya},
        booktitle={Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
        pages={494--501},
        year={2013},
        organization={ACM}
}

@inproceedings{Schall2011Analysis,
        Author = {Daniel Schall and Florian Skopik},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {ADBIS},
        Crossref = {DBLP:conf/adbis/2011},
        Ee = {http://dx.doi.org/10.1007/978-3-642-23737-9_21},
        Pages = {285--301},
        Title = {An Analysis of the Structure and Dynamics of Large-Scale Q/A Communities},
        Year = {2011}}

@inproceedings{Mamykina2011Fastest,
        Author = {Lena Mamykina and Bella Manoim and Manas Mittal and George Hripcsak and Bj{\"o}rn Hartmann},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {CHI},
        Crossref = {DBLP:conf/chi/2011},
        Ee = {http://doi.acm.org/10.1145/1978942.1979366},
        Pages = {2857--2866},
        Title = {Design lessons from the fastest {Q\&A} site in the west},
        Year = {2011}}

@inproceedings{Hanrahan2012Modeling,
        Author = {Benjamin V. Hanrahan and Gregorio Convertino and Les Nelson},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {CSCW (Companion)},
        Crossref = {DBLP:conf/cscw/2012},
        Ee = {http://doi.acm.org/10.1145/2141512.2141550},
        Pages = {91--94},
        Title = {Modeling problem difficulty and expertise in {StackOverflow}},
        Year = {2012}}

@inproceedings{Treude2011How,
        Author = {Christoph Treude and Ohad Barzilay and Margaret-Anne D. Storey},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {ICSE},
        Crossref = {DBLP:conf/icse/2011},
        Ee = {http://doi.acm.org/10.1145/1985793.1985907},
        Pages = {804--807},
        Title = {How do programmers ask and answer questions on the web?},
        Year = {2011}}

@inproceedings{Nasehi2012GoodExample,
        Author = {Seyed Mehdi Nasehi and Jonathan Sillito and Frank Maurer and Chris Burns},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {ICSM},
        Crossref = {DBLP:conf/icsm/2012},
        Ee = {http://doi.ieeecomputersociety.org/10.1109/ICSM.2012.6405249},
        Pages = {25--34},
        Title = {What makes a good code example?: A study of programming {Q\&A} in {StackOverflow}},
        Year = {2012}}

@inproceedings{Pal2012Experts,
        Author = {Aditya Pal and Shuo Chang and Joseph A. Konstan},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {ICWSM},
        Crossref = {DBLP:conf/icwsm/2012},
        Ee = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM12/paper/view/4653},
        Title = {Evolution of Experts in Question Answering Communities},
        Year = {2012}}

@inproceedings{Anderson2012Discovering,
        Author = {Ashton Anderson and Daniel P. Huttenlocher and Jon M. Kleinberg and Jure Leskovec},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {KDD},
        Crossref = {DBLP:conf/kdd/2012},
        Ee = {http://doi.acm.org/10.1145/2339530.2339665},
        Pages = {850--858},
        Title = {Discovering value from community activity on focused question answering sites: a case study of {S}tack {O}verflow},
        Year = {2012}}

@inproceedings{Lotufo2012BugTracking,
        Author = {Rafael Lotufo and Leonardo Teixeira Passos and Krzysztof Czarnecki},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {MSR},
        Crossref = {DBLP:conf/msr/2012},
        Ee = {http://dx.doi.org/10.1109/MSR.2012.6224293},
        Pages = {2--11},
        Title = {Towards improving bug tracking systems with game mechanisms},
        Year = {2012}}

@inproceedings{Akoglu2012OPAvion,
        Author = {Leman Akoglu and Duen Horng Chau and U. Kang and Danai Koutra and Christos Faloutsos},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {SIGMOD Conference},
        Crossref = {DBLP:conf/sigmod/2012},
        Ee = {http://doi.acm.org/10.1145/2213836.2213941},
        Pages = {717--720},
        Title = {{OPAvion}: mining and visualization in large graphs},
        Year = {2012}}

@inproceedings{Pal2011Early,
        Author = {Aditya Pal and Rosta Farzan and Joseph A. Konstan and Robert E. Kraut},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {UMAP},
        Crossref = {DBLP:conf/um/2011},
        Ee = {http://dx.doi.org/10.1007/978-3-642-22362-4_20},
        Pages = {231--242},
        Title = {Early Detection of Potential Experts in Question Answering Communities},
        Year = {2011}}

@inproceedings{Raj2011Expertise,
        Author = {Nidhi Raj and Lipika Dey and Bhakti Gaonkar},
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {Web Intelligence},
        Crossref = {DBLP:conf/webi/2011},
        Ee = {http://doi.ieeecomputersociety.org/10.1109/WI-IAT.2011.93},
        Pages = {380--383},
        Title = {Expertise Prediction for Social Network Platforms to Encourage Knowledge Sharing},
        Year = {2011}}

@inproceedings{Parnin2011Measuring,
        Acmid = {1984706},
        Address = {New York, NY, USA},
        Author = {Parnin, Chris and Treude, Christoph},
        Booktitle = {2nd International Workshop on Web 2.0 for Software Engineering},
        Doi = {10.1145/1984701.1984706},
        Isbn = {978-1-4503-0595-2},
        Location = {Waikiki, Honolulu, HI, USA},
        Numpages = {6},
        Pages = {25--30},
        Publisher = {ACM},
        Series = {Web2SE '11},
        Title = {Measuring {API} documentation on the web},
        Url = {http://doi.acm.org/10.1145/1984701.1984706},
        Year = {2011},
        Bdsk-Url-1 = {http://doi.acm.org/10.1145/1984701.1984706},
        Bdsk-Url-2 = {http://dx.doi.org/10.1145/1984701.1984706}}

@proceedings{DBLP:conf/adbis/2011,
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {ADBIS},
        Editor = {Johann Eder and M{\'a}ria Bielikov{\'a} and A Min Tjoa},
        Ee = {http://dx.doi.org/10.1007/978-3-642-23737-9},
        Isbn = {978-3-642-23736-2},
        Publisher = {Springer},
        Series = {Lecture Notes in Computer Science},
        Title = {Advances in Databases and Information Systems - 15th International Conference, ADBIS 2011, Vienna, Austria, September 20-23, 2011. Proceedings},
        Volume = {6909},
        Year = {2011}}

@proceedings{DBLP:conf/chi/2011,
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {CHI},
        Editor = {Desney S. Tan and Saleema Amershi and Bo Begole and Wendy A. Kellogg and Manas Tungare},
        Isbn = {978-1-4503-0228-9},
        Publisher = {ACM},
        Title = {Proceedings of the International Conference on Human Factors in Computing Systems, CHI 2011, Vancouver, BC, Canada, May 7-12, 2011},
        Year = {2011}}

@proceedings{DBLP:conf/cscw/2012,
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {CSCW (Companion)},
        Editor = {Steven E. Poltrock and Carla Simone and Jonathan Grudin and Gloria Mark and John Riedl},
        Isbn = {978-1-4503-1051-2},
        Publisher = {ACM},
        Title = {CSCW '12 Computer Supported Cooperative Work, Seattle, WA, USA, February 11-15, 2012 - Companion Volume},
        Year = {2012}}

@proceedings{DBLP:conf/icse/2011,
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {ICSE},
        Editor = {Richard N. Taylor and Harald Gall and Nenad Medvidovic},
        Isbn = {978-1-4503-0445-0},
        Publisher = {ACM},
        Title = {Proceedings of the 33rd International Conference on Software Engineering, ICSE 2011, Waikiki, Honolulu , HI, USA, May 21-28, 2011},
        Year = {2011}}

@proceedings{DBLP:conf/icsm/2012,
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {ICSM},
        Ee = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6384336},
        Isbn = {978-1-4673-2313-0},
        Publisher = {IEEE Computer Society},
        Title = {28th IEEE International Conference on Software Maintenance, ICSM 2012, Trento, Italy, September 23-28, 2012},
        Year = {2012}}

@proceedings{DBLP:conf/icwsm/2012,
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {ICWSM},
        Editor = {John G. Breslin and Nicole B. Ellison and James G. Shanahan and Zeynep Tufekci},
        Ee = {http://www.aaai.org/Library/ICWSM/icwsm12contents.php},
        Publisher = {The AAAI Press},
        Title = {Proceedings of the Sixth International Conference on Weblogs and Social Media, Dublin, Ireland, June 4-7, 2012},
        Year = {2012}}

@proceedings{DBLP:conf/kdd/2012,
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {KDD},
        Editor = {Qiang Yang and Deepak Agarwal and Jian Pei},
        Ee = {http://dl.acm.org/citation.cfm?id=2339530},
        Isbn = {978-1-4503-1462-6},
        Publisher = {ACM},
        Title = {The 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '12, Beijing, China, August 12-16, 2012},
        Year = {2012}}

@proceedings{DBLP:conf/msr/2012,
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {MSR},
        Editor = {Michele Lanza and Massimiliano Di Penta and Tao Xi},
        Ee = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=6220358},
        Isbn = {978-1-4673-1761-0},
        Publisher = {IEEE},
        Title = {9th IEEE Working Conference o Mining Software Repositories, MSR 2012, June 2-3, 2012, Zurich, Switzerland},
        Year = {2012}}

@proceedings{DBLP:conf/sigmod/2012,
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {SIGMOD Conference},
        Editor = {K. Sel\c{c}uk Candan and Yi Chen and Richard T. Snodgrass and Luis Gravano and Ariel Fuxman},
        Ee = {http://dl.acm.org/citation.cfm?id=2213836},
        Isbn = {978-1-4503-1247-9},
        Publisher = {ACM},
        Title = {Proceedings of the ACM SIGMOD International Conference on Management of Data, SIGMOD 2012, Scottsdale, AZ, USA, May 20-24, 2012},
        Year = {2012}}

@proceedings{DBLP:conf/um/2011,
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {UMAP},
        Editor = {Joseph A. Konstan and Ricardo Conejo and Jos{\'e} L. Marzo and Nuria Oliver},
        Ee = {http://dx.doi.org/10.1007/978-3-642-22362-4},
        Isbn = {978-3-642-22361-7},
        Publisher = {Springer},
        Series = {Lecture Notes in Computer Science},
        Title = {User Modeling, Adaption and Personalization - 19th International Conference, UMAP 2011, Girona, Spain, July 11-15, 2011. Proceedings},
        Volume = {6787},
        Year = {2011}}

@proceedings{DBLP:conf/webi/2011,
        Bibsource = {DBLP, http://dblp.uni-trier.de},
        Booktitle = {Web Intelligence},
        Editor = {Olivier Boissier and Boualem Benatallah and Mike P. Papazoglou and Zbigniew W. Ras and Mohand-Said Hacid},
        Ee = {http://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6036749},
        Isbn = {978-0-7695-4513-4},
        Publisher = {IEEE Computer Society},
        Title = {Proceedings of the 2011 IEEE/WIC/ACM International Conference on Web Intelligence, WI 2011, Campus Scientifique de la Doua, Lyon, France, August 22-27, 2011},
        Year = {2011}}

@techreport{Parnin2012Crowd,
        Author = {Parnin, Chris and Treude, Christoph and Grammel, Lars and Storey, Margaret-Anne},
        Howpublished = {\url{http://www.cc.gatech.edu/~vector/papers/CrowdDoc-GIT-CS-12-05.pdf}},
        Institution = {Georgia Institute of Technology},
        Title = {Crowd documentation: Exploring the coverage and the dynamics of {API} discussions on {Stack Overflow}},
        Year = {2012}}

@techreport{Zolaktaf2011Modeling,
        Author = {Zolaktaf, Zainab and Riahi, Fatemeh and Shafiei, Mahdi and Milios, Evangelos},
        Institution = {Faculty of Computer Science, Dalhousie University, Canada},
        Title = {Modeling Community Question-Answering Archives},
        Year = {2011}}

@inproceedings{GinscaP13,
  author    = {Alexandru-Lucian Ginsca and
               Adrian Popescu},
  title     = {User profiling for answer quality assessment in Q{\&}A
               communities},
  booktitle = {DUBMOD@CIKM},
  year      = {2013},
  pages     = {25-28},
  ee        = {http://doi.acm.org/10.1145/2513577.2513579},
  crossref  = {DBLP:conf/cikm/2013dubmod},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@inproceedings{kartik:msr14,
  author = {Bajaj, Kartik and Pattabiraman, Karthik and Mesbah, Ali},
  title = {Mining Questions Asked by Web Developers},
  booktitle = {Proceedings of the Working Conference on Mining Software Repositories (MSR)},
  publisher = {ACM},
  pages = {10 pages},
  year = {2014},
  url = {http://salt.ece.ubc.ca/publications/docs/kartik-msr14.pdf},
  abstract = {Modern web applications consist of a significant amount of client-side code, written in JavaScript, HTML, and CSS. In this paper, we present a study of common challenges and misconceptions among web developers, by mining related questions asked on Stack Overflow. We use unsupervised learning to categorize the mined questions and define a ranking algorithm to rank all the Stack Overflow questions based on their importance. We analyze the top 50 questions qualitatively. The results indicate that (1) the overall share of web development related discussions is increasing among developers, (2) browser related discussions are prevalent; however, this share is decreasing with time, (3) form validation and other DOM related discussions have been discussed consistently over time, (4) web related discussions are becoming more prevalent in mobile development, and (5) developers face implementation issues with new HTML5 features such as Canvas. We examine the implications of the results on the development, research, and standardization communities.}
}

@inproceedings{VenkataramaniGAMB13,
  author    = {Rahul Venkataramani and
               Atul Gupta and
               Allahbaksh M. Asadullah and
               Basavaraju Muddu and
               Vasudev D. Bhat},
  title     = {Discovery of technical expertise from open source code repositories},
  booktitle = {WWW (Companion Volume)},
  year      = {2013},
  pages     = {97-98},
  ee        = {http://dl.acm.org/citation.cfm?id=2487832},
  crossref  = {DBLP:conf/www/2013c},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@inproceedings{SaxeMG13,
  author    = {Joshua Saxe and
               David Mentis and
               Christopher Greamo},
  title     = {Mining Web Technical Discussions to Identify Malware Capabilities},
  booktitle = {ICDCS Workshops},
  year      = {2013},
  pages     = {1-5},
  ee        = {http://doi.ieeecomputersociety.org/10.1109/ICDCSW.2013.56},
  crossref  = {DBLP:conf/icdcsw/2013},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@inproceedings{KavalerPGCDF13,
  author    = {David Kavaler and
               Daryl Posnett and
               Clint Gibler and
               Hao Chen and
               Premkumar T. Devanbu and
               Vladimir Filkov},
  title     = {Using and Asking: APIs Used in the Android Market and Asked
               about in StackOverflow},
  booktitle = {SocInfo},
  year      = {2013},
  pages     = {405-418},
  ee        = {http://dx.doi.org/10.1007/978-3-319-03260-3_35},
  crossref  = {DBLP:conf/socinfo/2013},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@article{Menzies13,
  author    = {Tim Menzies},
  title     = {Guest editorial for the Special Section on BEST PAPERS from
               the 2011 conference on Predictive Models in Software Engineering
               (PROMISE)},
  journal   = {Information {\&} Software Technology},
  volume    = {55},
  number    = {8},
  year      = {2013},
  pages     = {1477-1478},
  ee        = {http://dx.doi.org/10.1016/j.infsof.2013.03.006},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}