\documentclass[11pt]{article}

%%% Load some useful packages:
%% "New" LaTeX2e graphics support.
\usepackage{graphicx}
%%	using final option to force graphics to be included even in draft mode
%\usepackage[final]{graphicx}
\usepackage{paralist} % compact lists

%% Support sub-figures.
\usepackage{subfigure}

%% Make subsubsections numbered and included in ToC
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

%% Package to linebreak URLs in a sane manner.
\usepackage{url}

%% Define a new 'smallurl' style for the package that will use a smaller font.
\makeatletter
\def\url@smallurlstyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\ttfamily}}}
\makeatother
%% Now actually use the newly defined style.
\urlstyle{smallurl}

%% Make margins less ridiculous
\usepackage{fullpage}

%% Allows insertion of fixme notes for future work
\usepackage[footnote, nomargin]{fixme}

%%%% Turned off for tech report, should be turned on for research portfolio
%% Turn on double spacing
%\usepackage{setspace}
%\doublespacing

%% Make URLs clickable
\usepackage[colorlinks, bookmarks=true]{hyperref}
\usepackage[all]{hypcap}


%% Since I'm using the LaTeX Makefile that uses dvips, I need this
%% package to make URLs break nicely
\usepackage{breakurl}

\usepackage{array}

%% Make table cross pages.
\usepackage{longtable}

%% Make links to captions point to the figure, not just the caption at bottom
\usepackage[all]{hypcap}

% create a shortcut to typeset table headings
\newcommand\tabhead[1]{\small\textbf{#1}}

\begin{document}

\title{Serious Game Stakeholder Experience Assessment Method (SGSEAM) User Guide}

\author{
	 Yongwen Xu \\
\em  Collaborative Software Development Laboratory \\
\em  Department of Information and Computer Sciences \\
\em  University of Hawai'i at Manoa\\
     yxu@hawaii.edu \\
}

\date{\today}
\maketitle

\tableofcontents

\graphicspath{{figures/}} 
\DeclareGraphicsExtensions{.eps}

\section{Introduction}
One of the benefits of using a serious game framework is that, if correctly designed, it will 
provide useful and reusable ``building blocks'' with which to develop a variety of serious 
games. Yet how are we to know if a serious game framework has been ``correctly designed''?

We found no prior work concerning comprehensive assessment for the particular needs of a serious game framework. Serious Game Stakeholder Experience Assessment Method (SGSEAM) describes a method for assessing serious game frameworks from the stakeholder experience perspectives. We consider SGSEAM as an assessment method instead of an evaluation method. The main purpose of an
evaluation is to "determine the quality of a program by formulating a judgment"
\cite{hurteau2009legitimate}. An assessment, on the other hand, is nonjudgmental. SGSEAM does
not try to judge a framework according to a standard, or to compare one framework against another. Instead, it is used to identify the major strengths and shortcomings of a framework from the perspectives of major stakeholders. The benefits of SGSEAM assessment are for the developers of serious game frameworks to learn from the findings of the assessment.

\section{SGSEAM Overview}

\subsection{Stakeholders}
The goal of SGSEAM is to identify (a) major strengths of a serious game
framework, which aids the community by indicating features of the framework to emulate, and
(b) major shortcomings of the framework, which aids the community by indicating features to avoid.
The target audiences of SGSEAM are the developers of the serious game framework.

The approach that SGSEAM uses is to assess the experiences of various important stakeholders when
they interact with the serious game framework. In the full life cycle of a serious game framework
there are a great variety of potential stakeholders, including:

\begin{itemize}
\item \emph{Players}: those who participate in the game produced by the framework.
\item \emph{System admins}: those who install and maintain the technological game infrastructure.
\item \emph{Game designers}: those who design the content and game mechanics. They include  content experts, instructional designers, etc.
\item \emph{Game managers}: those who manage the game during the period of game play.
\item \emph{Game Developers}: those who use the game framework to customize, extend and enhance their games.
\item \emph{Researchers}: those who are conducting research using the game framework.
\item \emph{Spectators}: those who do not participate in the game play but are interested in the game and the results of game play. 
\item \emph{Community partners}: those who partner with the game organizers to help run the game (such as coordinating real-world events as part of the game, providing support for energy data
  collection if the serious game requires energy data, etc) 
\item \emph{Funding organizations}: the organizations who provide funding for the game or game framework.
\end{itemize}

The scope of SGSEAM is to assess serious game frameworks as software infrastructure. While
the overall success of a serious game depends on the individual success of all of these
stakeholders, SGSEAM only assess the experiences of the players, system admins, game designers, game managers, and game developers, which are closely related to software infrastructure. 

The following sections describe the methodology used in SGSEAM, followed by the detailed
description of assessment methods for each identified stakeholder.

\subsection{Assessment Methodology}
Creswell \cite{creswell2003} categorizes research methods into three approaches:
quantitative, qualitative, and mixed methods, according to what knowledge claims are being made
and how knowledge is acquired. Quantitative method reflects a post-positivist paradigm where
hypotheses are specified {\em a priori} and tested by experimental design. Qualitative method
reflects a constructivist or participatory paradigm where knowledge would be acquired by
observation and open-ended design. SGSEAM employs the mixed methods approach which based on
pragmatic knowledge claims and assumption that collecting diverse types of data provides better
understanding of the research problem: assessing the strengths and shortcomings of a serious game
framework.

In SGSEAM, the concurrent triangulation strategy described in Creswell's mixed method approach
is used.  Data collection and analysis involves both quantitative information (instrument and
analytical data recorded by the system such as website logs, interaction database, etc), as well
as qualitative information (interviews and questionnaire responses).

\subsection{Stakeholder Experience Assessment}

SGSEAM follows closely with the "Goal-Question-Metric" (GQM) approach \cite{caldiera1994goal} in
software engineering research. GQM defines a software  measurement model on three levels: a goal
of the measurement, a set of questions to assess the goal, and a set of metrics associated with
each question.

In SGSEAM, the assessment goals are the experiences of the identified stakeholders. For each
stakeholder, a set of questions is used to assess the strengths and shortcomings from the
stakeholder's perspective. For each question, a set of alternative assessment approaches is
proposed.

\autoref{table:overview} provides an overview of the assessment method:

\begin{table}[ht!]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    \multicolumn{1}{|p{0.2\columnwidth}|}{\centering\tabhead{Stakeholder}} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{\centering\tabhead{Assessment Goal}} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{\centering\tabhead{Assessment approaches}} \\
    \hline
    \multicolumn{1}{|p{0.2\columnwidth}|}{Players} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{To what extent does the framework affect players?
        To what extent does the framework engage players?} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{pre-post test, in-game survey, in-lab player assessment, beta testing} \\
    \hline
    \multicolumn{1}{|p{0.2\columnwidth}|}{System admins} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{How easy is it to install and maintain the system?} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{sysadmin interview, in-lab experiment of installation process} \\
    \hline
    \multicolumn{1}{|p{0.2\columnwidth}|}{Game designer} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{How easy is it to design a game?} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{game designer interview, in-lab experiment of designing process} \\
    \hline
    \multicolumn{1}{|p{0.2\columnwidth}|}{Game managers} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{How easy is it to manage a game?} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{game manager interview, in-lab experiment of managing the game} \\
    \hline
    \multicolumn{1}{|p{0.2\columnwidth}|}{Game Developers} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{How easy is it to enhancing the system?} &
    \multicolumn{1}{|p{0.35\columnwidth}|}{developer interview, in-lab experiment of developing a new feature} \\
    \hline
  \end{tabular}
  \caption{Overview of SGSEAM}
  \label{table:overview}
\end{table}

There are usually multiple assessment approaches for a specific question. The approaches listed above can be generally categorized into in-vivo and in-vitro assessments. The in-vivo approaches, such as pre-post test, in-game surveys and interviews, assess the real world instance of the game. The in-vitro approaches use in-lab experiments in a simulated environment. Different assessment
approaches will have different levels of rigor or validity. For example, the in-lab experiments (in-vitro) can enlist several subjects to perform the same pre-defined tasks and collect comparable data in a more controlled setting, while in-game surveys or interviews in the in-vivo approach typically collect data from different settings but the data reflect the real world interaction between the stakeholders and the framework.

The details of the individual assessment approach for each stakeholder are descried in the following sections. These approaches for each stakeholder can be additive. The more approaches applied, the higher confidence of the assessment for the stakeholder.

\section{SGSEAM User Guide}

This user guide section describes the three steps in using SGSEAM to assess a serious game framework:

\begin{itemize}
\item \textbf{\emph{Step 1: Identify all the potential stakeholders of the framework and categorize them into SGSEAM stakeholders.}}

For each stakeholder, identify the population, the name and contact if possible. For example, the 
player stakeholder could be identified as the users interact with the game interface, perform certain tasks given by the interface, or winning the prize if there is one. It is important to be able to contact the stakeholders in some way, either via email or phone, to get the feedback from their experiences with the framework.


\item \textbf{\emph{Step 2: Identify the important tasks that need to interact with the framework for each stakeholder.}}
    
For example, the players interaction with the game produced by the frameworks; the system admins install, backup, monitor the software system; the game designers create the content for the game, design or decide what game mechanics to used; the game managers manage the game during the game period; and the game developers develop enhancement, customization using the framework.

\item \textbf{\emph{Step 3: Determine the appropriate assessment approaches for each stakeholder.}}

The appropriate assessment approaches should be determined according to the resource available. Sometimes it is impossible or really hard to implement a certain approach. The more approaches applied, the higher confidence of the assessment can be achieved. The following sections describe in detailed the different approaches for each stakeholder.  Each assessment approach describes what data to collect, how to collect the data and how to analyze the data to obtain insights about the strengths and weaknesses of the framework from each stakeholder's perspective.

\end{itemize}

\subsection{Player Assessment}

The goal of player assessment is to determine the effectiveness of the game
framework from player's perspective. It is essential that a game produced by a serious game
framework could achieve its intended "serious" purpose. The intended purposes of serious games are
always subject specific. For example, the desired effect of a serious game for
energy education and conservation is to increases players' energy literacy and
reduces their energy consumption during (and, hopefully, after) the game. A serious game for
language learning would have a very different desired effect.

Users of SGSEAM could use domain-specific questions to assess the desired effects of their
serious game. For example, the following question could be used to assess a serious
game for sustainability education: To what extent does the game increase player's literacy in
sustainability? 

\subsubsection{Approach 1: Pre-Post Study}

One approach to assess the question of the effectiveness is a quasi-experimental pre-post
study. A set of survey questionnaires can be presented to a random selection of the players
before the game (pre-test). After the game ends, the same survey (post-test) is presented to the
players who responded the pre-test survey. These two set of survey response data are compared to
understand if the game has had an impact on the survey subjects. The extent of the changes reflected in the survey result could indicate the degree of effectiveness of the serious game for this subject.

Other measurements, for example, the energy consumption data in a energy challenge serious game, could be collected before and after the game to determine the extent of changes that may be caused by the participation in this serious game.

\subsubsection{Approach 2: Self-reported Metrics}
Another approach for assess the players' experience is to interview players about their self-reported
experience with the game. The interview could be administrated via a face-to-face conversation or through 
online survey. We found that the online survey is more cost effective than face-to-face conversation. 
In additions, the online survey could be potentially implemented as part of an activity inside the game, 
as in the Makahiki case. Some of the sample interview questions are included in the followings:

Open-ended questions:
\begin{itemize}
\item What did you like most about the website/game?
\item What did you found confusing?
\item What issues did you have while using the site/game?
\item What was the thing you liked the least about the site/game?
\item What can we do to improve the site/game?
\end{itemize}

Close-ended questions with Likert scale from "Strong disagree" to "Strongly agree":
\begin{itemize}
\item It was easy to find what I was looking for on the website
\item The website was responsive 
\item The website provided adequate help in teaching me how to play
\item I understood how to play
\item this is something my friends should participate in
\end{itemize}

\subsubsection{Approach 3: Engagement Metrics}

In addition to the domain-specific goals of serious games, SGSEAM assesses a common
aspect of serious games, player engagement, to address the question of "To what extent does the
framework engage players?"

Player engagement is an important measure for understanding the effectiveness of a serious game.
By investigating the degree of engagement, we can determine to what extent individuals are
participating in the game, as well as to what extent the community population is participating in
the game.

Engagement has a subtle relationship to the overall effectiveness of a serious game. It is
possible for the game to be played by only a subset of the target population, but
have an impact on those not playing by virtue of their contacts with players. Gaining
better insight into this effect is an area of active study for us. 

To obtain engagement data, SGSEAM analyzes the following measures
based upon system log data provided by the framework.

\begin{itemize}
\item participation rate
\item number of players per day
\item play time of a player per day
\item submissions of all player per day
\item social interaction of all player per day
\item website errors per day
\end{itemize}

The participation rate measures the percentage of users who used the game based on the total
eligible players. In the serious game context, it indicates the level of involvement or awareness
of the serious matters. The number of players and play time per day measure how frequently the
players interact with the game. The submissions per day measures the rate of serious game
specific activities (online or real world) that players completed, while the social interaction
per day measures the rate of social interactions happened in the game between the players. At
last, the website errors per day measures the rate of errors encountered by the players while
using the game website. In general, with the opposite of website error measurement, the higher
value these measurements are, the higher engagement level the game has.

\subsection{System Admin Assessment}

System administrators are responsible for installing and maintaining the software infrastructure
for the game. Their tasks include the framework and dependency installation, maintain the database, backups, and so forth.

\subsubsection{Approach 1: post-hoc interview}

One approach to assess the question of how easy it is to install and maintain the system is a post-hoc interview. The actual system admin(s) are asked about their experience after their installation in the production system. The interview includes the following questions:

\begin{itemize}
\item How much time did you require to install the system and the dependencies?
\item How much time did you require to maintain the system?
\item What problems did you encounter?
\item Did you find it difficult to admin the system? What was difficult?
\end{itemize}

After the interview data is acquired, the assessor will perform qualitative data
analysis, which involves transcribing (if the interview data is in audio format),
categorizing and coding the description of reported problems or difficulties.

\subsubsection{Approach 2: in-lab experimental study}

Another approach to assess the question is to use an in-lab experimental study. A group of system admins will 
be asked to install the system, record the time
spent and problem encountered as they complete each step. The qualitative data (i.e., the
descriptive problems reported by the participants of the study) will need to be categorized and
coded. The assessor will triangulate the reported time data and the problem categories to identify
the area of strength (less time spent) and weakness (problems and difficulties).

The level of confidence of the above two assessment approaches varies. The experimental study
approach is more rigor because of the generality achieved from the larger population of
participants under study. The data collected during the step by step experimental study is more
accurate than the one collected in the post-hoc interview.

\subsection{Game Designer Assessment}

A game designer uses the serious game framework to design and create a serious game.
A serious game framework always provides certain tools or interfaces to game designers
with the hope that these will simplify the design of a game. Such tools might involve
configuring global settings for the game, such as how long will the game run, who are the
players, and how to design individual game elements.

SGSEAM assesses the game designer stakeholder by addressing the following two questions: (a) How
much time is required to design an instance of a serious game using the framework? and (b) How
many, and how problematic are the errors that designers encounter during the design process?

There are three approaches for game designer assessment:

\subsubsection{Approach 1: Post-hoc interview}

One approach is to interview the actual game designer(s) after they had completed the design in a production system. The following questions will be asked:
\begin{itemize}
\item How much time did you spend to complete each design task?
\item What problems did you encounter?
\item Did you find it difficult to configure? What was difficult?
\item Did you find it difficult to design a specific game? Which one, and what was difficult?
\end{itemize}

The interview data will be transcribed (if audio recording), categorized and coded to identify the
strengths and weaknesses.

\subsubsection{Approach 2: In-lab experimental study}
Another approach is an in-lab experimental study, where a
goup of participants is asked to use the system to perform a same set of design tasks. The time
spent and problems encountered are recorded for each tasks. The assessor will triangulate the
reported time data and the problem categories to identify the strengths and weaknesses.

\subsubsection{Approach 3: Log data analysis}
A third approach is to collect the system log data related to the game designing tasks. When
available, the time spent and error encountered can be queried from the system logs. Although these
system generated data might be easier to gather in some systems, it might not provide the same
depths or insights than the other two approaches where the experiences are provided by the
participants directly. On the other hand, these system data can be supplemental to the other
approaches. They could be correlated with the data gathered from the other assessment approaches
 to increase the confident of the assessment.

\subsection{Game Manager Assessment}

A game manager uses the serious game framework to manage the serious game that the game
designers created. It is possible that a game manager is also the game designer.
Serious game frameworks normally provide certain interfaces for the managers to manage the
game. This may involve managing player submissions, monitoring the game state, entering
manual resource data, notifying winners of the game, etc.

SGSEAM assesses the game manager stakeholder with the following questions: (a) How much time is
required to manage an instance of a serious game using the framework? and (b) How many,
and how problematic are the errors that managers encounter during the design process?

Similar to the assessment of game designer experience, SGSEAM proposes three approaches. 

\subsubsection{Approach 1: Post-hoc interview}
The post-hoc interview approach
gather data from the game manger(s) by asking the following questions:

\begin{itemize}
\item How much time did you spend to complete each managing task?
\item What problems did you encounter?
\item Did you find it difficult to manage? What was difficult?
\end{itemize}

\subsubsection{Approach 2: In-lab experimental study}
The experimental study approach gather data from a group of participants about the time spent and
problems encountered for each task of managing the serious game. 

\subsubsection{Approach 3: Log data analysis}
The log data analysis collects system log data related to the game managing tasks. The time spent and error encountered can be deducted from the system log and reveals strengths and weaknesses of the game managing interface.

\subsection{Game Developer Assessment}

The game developer stakeholder is different from the game designer stakeholder, in that the
game designer stakeholder tailors the framework without requiring any software
development, while the game developer stakeholder enhances, corrects, and extends the system by
manipulating code. 

To investigate how easy it is to understand, extend, and debug a serious game
framework from a developer's perspective, SGSEAM assesses how much time it takes to develop an
enhancement to the game framework, and how many errors are encountered
during the process.

\subsubsection{Approach 1: Post-hoc interview}

This assessment approach is accomplished by interviewing the actual developer(s) to
answer the following questions:

\begin{itemize}
\item How much time did you spend developing and debugging an
  enhancement to the game framework?
\item What problem(s) did you encounter?
\item Did you find it difficult to understand, extend and debug the
  system? What was difficult?
\end{itemize}

\subsubsection{Approach 2: In-lab experimental study}

The experimental study assessment approach asks a group of developers to develop a same set of
enhancements to the system, and ask them to record the time spent to develop and problems
encountered.

Similarly, the descriptive data will be categorized and coded. The time data will be correlated to the problem data to identify the areas of strength and weakness.

%% Use this for an alphabetically organized bibliography
\bibliography{sustainability,csdl-trs,gamification,yxu}
\bibliographystyle{plain}

\end{document}
