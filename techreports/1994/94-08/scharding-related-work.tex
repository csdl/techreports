%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% scharding-related-work.tex -- 
%% RCS:            : $Id: icse94-related-work.tex,v 1.3 94/02/14 15:57:28 johnson Exp Locker: johnson $
%% Author          : Philip Johnson
%% Created On      : Thu Aug 12 16:29:25 1993
%% Last Modified By: Philip Johnson
%% Last Modified On: Sun Jun 19 07:49:00 1994
%% Status          : Unknown
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 1993 University of Hawaii
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%% History
%% 12-Aug-1993		Philip Johnson	
%%    

\section{Background on Formal Technical Review}

\subsection{Motivation}

We are drawn to research on computer-supported FTR for several reasons.
First, research on tools and techniques to improve software quality shows
that formal technical review (FTR) provides unique and important benefits.
Some studies provide evidence that FTR can be more effective at discovering
errors than testing, while others indicate that it can discover different
classes of errors than testing \cite{Myers78,Basili86}.  In concert with
other process improvements, Fujitsu found FTR to be so effective at
discovering errors that they dropped system testing from their software
development procedure \cite{Arthur93}.  FTR forms an essential part of
methods and models for very high quality software, such as Cleanroom
Software Engineering and the SEI Capability Maturity Model.  Finally, FTR
displays a unique ability to improve the quality of the producer as well as
the quality of the product.

Second, the use of FTR in software engineering parallels the notion of the
``shoemaker's children going barefoot.''  For a method of such apparent
significance and utility, the lack of computational support is glaring.
There are only a handful of systems known to us that supported formal
technical review (ICICLE \cite{Brothers90}, Scrutiny \cite{Gintell93},
INSPEQ \cite{Knight91}), and all of these are essentially prototype or
proof-of-concept systems.  The lack of computational support for FTR does
not appear to be due to lack of need: research studies of manual FTR show
it to be prone to breakdown and highly labor-intensive, consuming a great
deal of expensive human technical resources. For example, one study
documents that a single code inspection of a 20 KLOC software system
consumes one person-year of effort by skilled technical staff
\cite{Russell91}.  The lack of computational support also impedes the
collection and use of high quality, empirical, comparative data about the
process and products of FTR that can be used to improve the process. Only
one type of FTR, Fagan code inspection, enjoys a relatively broad range of
published data about its use and effectiveness.  The lack of such research
data makes it difficult to compare different methods, improve the process,
or match a method to a particular organizational culture and application
domain.  By implementing appropriate computational support, we could
simultaneously lower the cost of FTR and improve the quality of data
collected.

Third, our internal use of manual FTR to improve the quality of our
research software has proven to be extremely time-consuming and expensive.
We believe that computer-supported FTR is not only an interesting and
significant research area, but that any success will have second-order
benefits by improving our ability to create high quality software.


\subsection{The FTR literature}

During the first year of our research, we explored the domain both
by analyzing the literature and by building prototype systems.  
FTR always involves the bringing together of a group of technical
personnel to analyze an artifact of the software development process,
typically with the goal of discovering errors or anomolies, and always
results in a structured document specifying the outcome of review. 

Descriptions of formal technical review tend to fall
into two forms, which can be termed {\em descriptive}\/ and {\em
prescriptive}.  The descriptive literature describes the process and
products of review abstractly, advocates that organizations must create
their own individualized form of review, but provides little prescriptive
support for this process.  \cite{Schulmeyer87,Dunn90,Freedman90} exemplify
this literature.  Such work provides only vague and qualified answers to
many central questions concerning review, such as: How much should be
reviewed at one time? What issues should be raised during review, and are
standard issue lists effective? What is the relationship between time spent
in various review activities and their productivity? How many people should
be involved in a review? What artifacts should be produced and consumed
during a review?

The prescriptive literature, on the other hand, takes a relatively hard
line stance on both the process and products of review.
\cite{Fagan76,Fagan86,Russell91} exemplify this literature.  Such
literature comes to precise conclusions about the process and products
(meetings should last a maximum of two hours; each line of code must be
paraphrased; lines of code should be read at rate of 150 lines per hour;
etc).  This literature certainly presents evidence for its effectiveness
within the authors' organizations.  However, the strict prescriptions
appear to suggest that all organizations should simply adapt to the review
method, rather than that the review method should be substantially adapted
to the needs and characteristics of the organization and application
domain.

Regardless of its prescriptive or descriptive nature, literature on FTR
suffers from a lack of high quality, empirical studies comparing different
review methods to each other.  Past studies compare review to testing
\cite{Myers78,Hetzel76,Basili85} or compare different factors within a
single review method (usually Fagan's inspection), such as the effect of
the number of participants or group composition on review effectiveness
\cite{Bisant89,Martin90}.

Unfortunately, these latter comparative studies do not specify the actual
activities that occurred in precise detail, leaving unanswered such
questions as whether reviewers strictly followed the checklist, whether the
same checklist was used during the meeting, whether the reader applied the
test cases prepared by reviewers, and so forth. As a result, although each
study claimed to use the same approach (Fagan code inspection), there may
have been substantial and significant differences between the methods.

Another problem with the literature on FTR is the conflicting and/or
anecdotal explanations of the causal factors underlying review outcomes.
For example, \cite{Selby85} attributes review effectiveness to a technique
called stepwise abstraction.  \cite{Dunn90,Peele82} attribute the success
of software review to the presence of group synergy, yet \cite{Humphrey90}
finds that 75\% of errors are found during private preparation rather than
in the public meeting.  \cite{Myers78,Parnas85,Peele82} attribute the
success of review to the synergy effect between producer and reviewers, and
yet others discourage active participation of the producer during the
meeting \cite{Ackerman89,Russell91,Pfleeger91}.  Finally, \cite{Fagan76}
attributes review effectiveness to paraphrasing, \cite{Ackerman89} to the
use of selective test cases, and \cite{Knight91} to checklists.

From this analysis, we concluded that an important design requirement for
computer-supported FTR is {\em instrumentation}: the ability to precisely
and accurately measure aspects of the process and products of FTR.  In
addition, the ability of a computational environment to provide
experimental {\em control} over the FTR process could facilitate replicable
experimental study.

These design requirements, which seemed obvious and straightforward when
based upon literature analysis, would later give rise to substantial design
problems.  These design problems were not of an engineering nature, but of
a social nature, as will be discussed below.
 

\subsection{Problems in FTR}
\label{sec:issues-manual-review}

The FTR literature reveals a common set of problems facing organizations in
adopting an effective FTR process.  First, although the literature tends to
agree that manual review, when properly carried out, is effective, it also
agrees that it is expensive.  For example, \cite{Russell91} shows that in
his organization, one person-year of technical staff time was required per
20 KLOC for FTR, and that this cost added 15-20\% new overhead onto
development. Boeing Computer Services found reviews to be ``extremely
expensive'' \cite{Glass82}. Such admissions are usually followed by
analyses demonstrating that this upstream investment is more than recouped
through decreases in downstream rework costs.

Thus, although manual FTR is typically cost-effective in the long run when
properly carried out, this is a significant qualification, since manual FTR
is very difficult to properly carry out. Some of the major problems common
to most forms of manual FTR are as follows:

\begin{itemize}
\item {\em Insufficient preparation.} A major responsibility of the
  review leader is to ensure that participants adequately prepare for the
  review by reading and reflecting upon the review materials.
  Insufficiently prepared reviewers are a major cause of low quality review
  outcomes, where reviewers attend the meeting and attempt to ``bluff''
  their way through and/or read the code for the first time during the meeting.
  This problem is serious enough that fairly devious remedies are presented
  in the literature. One such approach is to deliberately leave out one
  page of the review materials when distributing them to participants:
  those who prepare will notice the absence and contact the review leader.
  
\item {\em Moderator domination.} In a group meeting, it is easy for the
  moderator to inadvertantly or premeditatedly abuse this role by
  inhibiting or intimidating the other participants.  This results in
  reduced participation and reduced review quality.

\item {\em Incorrect review rate.} Each minute of a review meeting is
  intrinsically expensive, since it requires the simultaneous attendance
  and involvement of at least three and frequently six to eight technical
  staff personnel.  Thus, the speed of review is critical to its
  cost-effectiveness: too slow and the time (and salaries) of several
  technical personnel is wasted; too fast and the quality of review
  decreases.

\item {\em Ego-involvement and personality conflict.} The fact that one of
  the review member's work artifacts is under review can lead to
  significant problems during review.  Review always requires substantial
  diplomacy and care on the part of each member.  Otherwise, the review
  process can degenerate or dissolve completely.

\item {\em Issue resolution and meeting digression.} The expense of
  review meetings and the complexity of software dictates that review
  sessions not evolve into problem-solving sessions.  All instructional
  materials we have seen cite this issue as crucial to review success,
  stating that reviewers should ``raise issues, don't resolve them.''  They
  also note that it requires significant reviewer effort and continual
  moderator vigilence to prevent such discussion.
  
\item {\em Recording difficulties and clerical overhead.} Manual review
  requires a scribe to record the outcome of the process.  Capturing the
  information generated during a review meeting completely and accurately is
  extremely difficult, as noted in the literature, and as anyone who has ever
  attempted the role of scribe will attest. Methods involving audio-visual
  aids and a ``telegram style'' of note-taking have been proposed to support
  this process.
  
  Finally, substantial additional clerical overhead is required to
  collect data adequate for research on FTR or FTR process improvement.
  Perhaps for this reason, published review data has only come from very
  large organizations able to allocate the additional resources to this
  activity.

\end{itemize}

Interestingly, these problems are not specific to FTR, but arise in many
forms of meeting-based group work.  \cite{Nunamaker91} discusses the
problems of manual meeting-based group work to motivate the design of an
electronic meeting room system, and each of the above issues appear in his
research.  

Armed with this set of problems, we set out to design the ``mother of all
computer-supported FTR environments''---one that would simultaneously
address all of these issues.  During the second year of our research, we
actually appeared to succeed: a collaborative FTR environment, called CSRS,
began to emerge which seemed to resolve both the identified issues in the
research on FTR, as well as the identified issues in the practice of FTR.
The next section provides some details on this environment and how it
addressed these problems.  The subsequent section discusses what happened
when we took this ``FTR panacea'' out to meet the real world.





