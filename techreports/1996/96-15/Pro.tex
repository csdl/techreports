
\documentstyle[nftimes,12pt]{report}

\begin{document}

\title{Investigating Data Quality in the Personal Software Process}
\author{Anne Disney\\
Collaborative Software Development Laboratory,\\
Department of Information and Computer Sciences\\
2565 The Mall\\
University of Hawaii, Manoa\\
Honolulu, Hawaii   96822\\
{\tt anne@uhics.ics.hawaii.edu}}
\maketitle

\setlength{\parindent}{0em}
\setlength{\parskip}{1ex}

\tableofcontents
\chapter{Introduction}
\section{What is PSP?}

The personal software process (PSP) of Watts Humphrey is
a method that enables individual software engineers to
collect data on how they develop a software project,
analyze this data, and use the results over multiple projects
to improve productivity, quality, and planning.

\section{Why do people want to use it?}

Humphrey and others provide data from the use of PSP in a
classroom setting that shows positive trends in various measures
of the software process, including defect density, yield
(percentage of defects actually removed), and time estimation.
We replicated these general results in clasroom use of PSP at the
University of Hawaii.

\section{What did a closer look at this data show?}

However, our experience teaching and using PSP uncovered an
important issue:  data quality.  In PSP, engineers must record
a great deal of data about the time they spend in each phase
of development and the numbers and types of defects they uncover
for a single project.  The engineer then analyzes the raw data in
a sophisticated, multi-step process.  Finally, the engineer also
performs analyses over all the project data.  Although tools such
as spreadsheets automate some of the analysis, the engineer must
manually collect, analyze, and interpret much of the data.  Our
initial experiences teaching PSP led us to believe that the PSP
method can suffer from a variety of data quality problems, including
missing raw data, incorrectly recorded raw data, incorrectly performed
analyses, and erroneous analyses.

\chapter{Other related work}

Most processes for producing high-quality software are designed to be 
used by groups of
software developers or even organizations.  Examples are

* CMM - get information from The Capability Maturity Model, Carnegie 
Mellon University, SEI

  - basic idea

  - how is high quality software produced?

* FTR  - source?

  - basic idea

  - how is high quality software produced?

* Others?


Watts Humphrey's Personal Software Process, however, focuses on the 
software development
process for an individual software engineer.

* main ideas described in introduction.  Restate?

* The main focus of the PSP is the individual programmer.  However, it 
can be used as
Engineeringa tool in group development as well.  (9th conf on Software 
Engineering Education, p119 (125)

* Like other software processes, PSP requires significant investment of 
time and effort by the
  software engineer.  However, it directly benefits the person who makes 
the effort with
  information about their own process and products. (9th conf on 
Software  Education,  
  p 52)

\chapter{Case Study}
\section{Description}

To investigate the issue of data quality in PSP, we taught a modified
version of the PSP curriculum in Fall, 1996.  Ten students participated
in this course, each of whom completed nine projects.
[do we need to say more about the students, such as level of education,
background, etc?] [do we need to say more about what kinds of projects
were done?  If so, should this info really go under PSP curriculum
modifications?]

\section{What is the standard PSP curriculum?}
\section{How did the class differ from standard PSP curriculum?}

Curriculum modifications included supplemental lecture material on
areas of the PSP subject to data quality problems, distribution of
spreadsheets to automate various analyses, and integrated technical
reviews and checklists focusing in part on data quality improvement.
Then, following the conclusion of the course, we designed and
implemented a database system to store all of the PSP data from this
course and to subject it to further data quality analysis. [should this
be developed into a separate section such as "How did we evaluate the
Student's PSP data?"?]

\chapter{Results}

The results of this postmortem analysis are dramatic.  Despite the
special care taken during the course to achieve high data quality,
we uncovered approximately 1500 data errors in the class project data.

\section{How did we count defects?}

When an incorrect value was found, a defect was recorded for the field,
but from that point on, the incorrect data value was considered to be
correct.  For example, consider this sample time recording log: \\ \\

\begin{center}
\begin{tabular}{|l|l|l|r|l|l|} \hline
\multicolumn{6}{|c|}{\bf Time Recording Log}\\ \hline
Date & Start & Stop & Minutes & Phase & Comment \\ \hline\hline
12/01/97 & 10:40 & 11:20 & 30 & plan       & total minutes should be 40 
\\ \hline
12/01/97 & 11:20 & 11:30 & 10 & design     & \\ \hline
12/01/97 & 12:30 & 12:50 & 20 & code       & \\ \hline
12/01/97 & 12:50 & 12:55 &  5 & compile    & \\ \hline
12/02/97 & 09:00 & 09:15 & 15 & test       & \\ \hline
12/02/97 & 09:15 & 09:25 & 10 & postmortem & \\ \hline
\end{tabular}
\end{center}

Since the user incorrectly subtracted {\it stop time} from {\it start 
time}
when calculating the number of minutes spent in planning, a defect
is recorded for the {\it minutes} field.  But when looking at {\it total 
actual
minutes} on the Project Plan Summary form, 90 is considered to be the
correct value, even though the time spent in planning was
actually 40 minutes, making the true value of {\it total actual minutes}
100 minutes.

\section{What did we find?}

\subsection{Defect Types}
I divided defects into eight types:\newline

{\bf Blank Field:}
Used when a data field that should contain a value, such as {\it start 
time},
was left blank.  This does not apply to fields where a value is
optional, such as comment fields.

{\bf Calculation Done Incorrectly:}
Applies to data fields whose value is derived using any
sort of calculation from addition to linear regression.  If the 
calculation
was not done correctly, a defect was counted.  This does not apply to
values that are incorrect because other fields used in the calculation
contain bad numbers.

{\bf Entry Error:}
Used when the student clearly did not understand the
purpose of a field or used an incorrect method in selecting data.  For
example, filling in the {\it defect fixed} field in the Defect Recording
Log with a phase name, or having the defect to-date values in the
Project Plan Summary originate from a different project than the LOC
to-date values.

{\bf Fields for a More Advanced Process Filled In:}
Included because on the first project, one student filled in values for 
the
{\it Defects Injected, Plan} and {\it Defects Removed, Plan} fields even
though there was no entry area provided for them on the form and
they are not part of the PSP0 Project Plan Summary.

{\bf Impossible Values:} Used when two values are mutually exclusive.  
For
example: overlapping time log entries, defect fix times for a phase 
adding
up to more time than the time log entries for the phase, or phases 
occurring
in the Defect Recording Log in a different order than those in the Time
Recording Log.

{\bf Process Sequence not Followed:} Used when the Time Recording Log 
showed a student
moving back and forth between phases instead of sequentially moving 
through
the phases appropriate for the process.

{\bf Transfer of Data Between Projects Incorrect:}
Used for incorrect values in fields that involve data from a prior
project.  Typically these fields are ``to-date'' fields that involve 
adding a
to-date value from a prior project with a similar value in the current 
project.
Unfortunately, it is often impossible to determine in these cases if the
error arose from bringing forward a bad number, incorrectly adding two 
good
numbers, or bringing forward the correct number and correctly adding it
to the wrong number from the current form.  However, in two important
areas, time and size estimation, the forms were modified so that 
students
were required to fill in the prior values to be used in the estimation
calculations. In these cases it was obvious when incorrect values
originated in the transfer.

{\bf Transfer of Data Within Project Incorrect:}
This is the same as the previous defect type, except that it refers to 
values
being transferred from one form to another within the current project.  
For
example, filling in 172 for {\it Estimated New and Changed LOC} on the 
Size
Estimating Template, but using 190 for {\it Total New and Changed, Plan} 
on
the Project Plan Summary.\\ \\

\begin{tabular}{|l|r|}\hline
\multicolumn{2}{|c|}{\bf Defects by Type}\\ \hline
Description & \\ \hline\hline
Calculation done incorrectly                 & 699 \\ \hline
Blank field                                  & 262 \\ \hline
Transfer of data between projects incorrect  & 175 \\ \hline
Entry error                                  & 146 \\ \hline
Transfer of data within project incorrect    & 100 \\ \hline
Impossible values                            &  88 \\ \hline
Process sequence not followed                &  16 \\ \hline
Fields for a more advanced process filled in &   2 \\ \hline

\end{tabular}


\subsection{Defect Severity Levels}
I divided defects into five severity levels:\newline

{\bf Defect has no impact on PSP data:} This includes errors such as
missing header data, incorrect dates in the time recording log, and 
filling
in fields for a more advanced process.

{\bf Results in a single bad value, single form:} Used if a significant
field which affects no other fields, such as {\it LOC/Hour, actual},
is blank or incorrect.

{\bf Results in multiple bad values, single form:} Used when an 
incorrect
or blank value is used in the calculation of values for one or more 
other
fields on the same form, but when none of these other values are used 
beyond
the current form.  For example, in PSP1 on the Size Estimating Template,
incorrectly calculating a regression parameter.  This results in a bad
prediction range and prediction intervals, but these values are not used
anywhere else in the process.

{\bf Results in multiple bad values, multiple forms, single project:} 
Used
when an incorrect or blank value is used to determine the values
for one or more other fields on one or more different forms in the same
project, but when none of these other values are used beyond the current
project.  For example, in PSP1, on the Size Estimating Template, an
incorrect value for {\it Estimated Total New Reused (T)}.  This results 
in an
incorrect value for {\it Total New Reused, Plan} on the Project Plan 
Summary
form, but this value is not referenced by future projects.

{\bf Results in multiple bad values, multiple forms, multiple projects:} 
Used
if an incorrect or blank value affects future projects.  For example, 
when
{\it Defects Injected, Planning, Actual} on the Project Plan Summary 
does
not match the number of defects entered for the planning phase in the
Defect Recording Log.\\ \\

\begin{tabular}{|l|r|}\hline
\multicolumn{2}{|c|}{\bf Defects by Severity}\\ \hline
Description & \\ \hline\hline
Results in a single bad value, single form   & 650 \\ \hline
Results in multiple bad values, multiple forms, multiple projects  & 512
\\ \hline
Results in multiple bad values, single form  & 184 \\ \hline
Defect has no impact on PSP data             & 102 \\ \hline
Results in multiple bad values, multiple forms, single project  & 40 \\ 
\hline

\end{tabular}

\subsection{A Closer Look at the Most Severe Defects}
34 percent of defects found were of the most serious type - persistent
errors.  These are the defects resulting in multiple bad values,
multiple forms, multiple projects.  A defect of this type not only 
causes
incorrect values in the current project, but is still causing flawed 
results
ten projects later, even if all subsequent calculations are done 
correctly.

Here are the four most common defects of this type:\\ \\
\begin{tabular}{|l|r|}\hline
\multicolumn{2}{|c|}{\bf Most Common Persistent Defects}\\ \hline
Description & \\ \hline\hline
Time Estimation: historical data not transferred correctly     & 59 \\ 
\hline
Size Estimation: historical data not transferred correctly     & 56 \\ 
\hline
Time Log: delta time incorrect                                 & 47 \\ 
\hline
Project Plan Summary: Total LOC, actual, not equal to B-D+A+R  & 44 \\ 
\hline

\end{tabular}

There are two main ways that the error in transferring time estimation 
data
seems to occur: an error in transferring the value from
correct field, or accidentally transferring the correct value from
an incorrect field.  Specifically, many times instead of transferring
{\it Total New and Changed (N)} (Plan or Actual), students transferred
{\it Total LOC (T)}.  This is easy to do
because the Project Plan Summary form has over 90 fields even
at the Level of PSP1, and on the form the two values are vertically
adjacent. It is particularly easy to make this mistake with the Actual
values because the fields are separated by one column from the labels.
Additionally, it appears that students made spreadsheets or 
"cheatsheets"
of these fields to avoid thumbing through the entire stack of completed
projects every time a time or size estimation was needed for a new
project.  This is inferred because the same value for the same project
would be incorrectly transferred for every project following it.\\

These transfer errors are not insignificant.  Over the 59 occurrences,
the errors add up to 7,294 LOC (lines of code), meaning that the average 
error
was 123.63 LOC.  The total LOC as they should have
been transferred adds up 17,234, which means an average of 292.10
LOC per field.  Thus, the average incorrect value varies about 42 
percent from
the value which should have been transferred.
[check this to be sure that time errors are not mixed up with size 
errors
 in data]
[be sure to check this later to be sure my math/inferences will hold 
up]\\

So, values involved in calculating some of the fields most important to
the PSP are severely corrupted by errors that do not even involve a
calculation [does this type of conclusion belong here?  How should it
be worded?]. \\

The error in transferring Size Estimation data is very similar.
Over 56 occurrences, the errors add up to 7,753 LOC, meaning that the
average error was 138.45 LOC. The total LOC as they should have been
transferred adds up to 10,255, which means an average of 183.13 LOC
per field.  Thus, the average incorrect value varies about 76 percent 
from
the value which should have been transferred. \\

The error in calculating {\it Delta Time} in the Time Recording Log is
notable in several respects.  First, the errors are not insignificant.
The average mistake was 38.43 minutes, which was an average of 41 
percent of
the correct value. [Should I use means here also?  What is the standard 
way
for wording all this?] Secondly, of 47 occurrences, 16 were in error by
one hour and 4 were in error by two hours, indicating very small errors
in simple arithmetic [should a conclusion be drawn here?  If not, 
where?]. 
Thirdly, the distribution of this error across projects is as follows: 
\\ \\

\begin{tabular}{|l|r|}\hline
\multicolumn{2}{|c|}{\bf Delta Time Errors by Project}\\ \hline
Description & \\ \hline\hline
Project 1  & 7 \\ \hline
Project 2  & 2 \\ \hline
Project 3  & 8 \\ \hline
Project 4  & 8 \\ \hline
Project 5  & 3 \\ \hline
Project 6  & 9 \\ \hline
Project 7  & 2 \\ \hline
Project 8  & 5 \\ \hline
Project 9  & 3 \\ \hline

\end{tabular}

Despite nine projects worth of experience, this error never "goes away".
However it does seem to occur less frequently after Project 6, 
especially
in proportion to the number of time log entries required.  
Interestingly,
the assignment for Project 6 was a Time Recording Log applet, which at 
least
some students appear to have used for subsequent projects.

\section{How important were these errors?}

These results clearly demonstrate that data error is a significant
concern in the PSP method.  However, it could be the case that
although users of PSP make many errors, these errors are only "noise"
and do not make a significant impact upon the trends and conclusions
reached from the method.  We attempted to look into this more closely
by computing the measures of yield, defect density, and so forth for
individual data and the aggregate results twice:  once using the
original data supplied by the students, and once using correct
versions of the data produced by our postmortem analysis.

\subsection{Types of errors uncovered}

When attempting to correct the students' data, it soon became clear that
the errors fall into two classes.  Some errors are correctable, such as 
a
mismatch between the number of defects entered in the Defect Recording 
Log
and the total calculated for the Project Plan Summary.  But in other 
cases,
such as a blank {\it Phase Injected} for a defect, it is impossible to
determine a correct value.

\subsection{Rules used in fixing raw data}

We decided to try to correct all the errors in the raw data, using this
set of rules: [add later]

\subsection{What did we find?}

[results of this analysis]

\chapter{Discussion}
\section{Can all defects be found?}

Two kinds of data values: raw/calculated.  Errors in calculation can be
fixed given correct raw data. 

Two kinds of errors in raw data: detectable/non-detectable
[word this to lead smoothly into discussion of measurement dysfunction]

Two classes of detectable/raw-data errors:  recoverable/non-recoverable

\section{So what is it about PSP that produces all these errors?}
\subsection{Many forms}
\subsection{Multiple processes, so as user learns PSP, familiar forms 
change}
\subsection{Complicated computations with higher PSP levels}
\subsection{Instructions in textbook not always clear}
\subsection{Data interdependencies between forms complicated in higher 
PSP levels}
\subsection{Many forms with many fields to fill out by hand, at the same 
time as coding}
\subsection{Tedious computations at the end of even minor projects}
\subsection{When computations rely on historical data, finding the data 
takes time}

\section{What are the implications?}

The results presented above show that the PSP method can lead to low 
data
quality, and that this low data quality can lead to incorrect 
conclusions
about individual and group performance.  However, these results do not 
imply
that the PSP method is wholly unuseful.  On the contrary, student 
evaluation
of the PSP method was uniformly positive, and even if certain numerical
values are incorrect, the process still provides students with profound 
new
insight into the software development process.  Instead, we believe 
these
results are most useful in motivating two kinds of improvements to the 
PSP
process.

\subsection{Automated tool support}

First this study shows that spreadsheets are insufficient as a data 
quality
assurance mechanism.  Instead, PSP needs more sophisticated tool support 
to
overcome the kinds of data quality problems observed in this research.
Such tools should satisfy the following requirements:

1. Automate as much of the collection of raw data as possible.

2. Do all calculations using the raw data.

3. Provide guidance to the user in choosing the correct form/fields
   to work with, based on the current position in the process script.

4. Only give the user forms/fields appropriate for the current
   process/phase.

5. Allow the user to see results of data analysis in many formats and
   allow the user access to raw data for further study.

[Add others]


\subsection{Measurement dysfunction}

Second, the PSP method must address the issue of measurement
dysfunction. Measurement dysfunction in software development
is a situation in which organizational forces lead to the
conscious or unconscious skewing of data to support the
trends desired by management, even when the true trend is
opposite that portrayed by the data.  As a simple example,
application of PSP should lead to lower defect density over
time.  Such an effect can be easily achieved by a student:
simply record less defects on the PSP defect data sheet in
later projects.  Given that defect data collection is quite
time consuming, and given that students are under
significant time pressures later in the semester, it is
possible that observed downward trends in PSP defect data
could be due more to increasing demands upon student time
than to improvements in their development skill.  Other
potential sources of measurement dysfunction in PSP include
[insert summary here].


\chapter{Conclusions/Future Directions}
In conclusion, this thesis describes a case study of PSP
to assess data quality issues. Through this case study,
we discovered that PSP users can make significant numbers
of errors, and that these errors can make
a significant impact upon measures of quality and
productivity.  Analysis of these errors leads to a
set of requirements for automated PSP support tools that
should alleviate many of these problems.  The errors also
lead to an analysis of PSP data from the standpoint of
measurement dysfunction, and the problems this issue
raises for data quality.  We propose future research
devoted to the empirical evaluation of these proposals
to determine whether they do lead to improvement of
data quality in the personal software process.




\end{document}

