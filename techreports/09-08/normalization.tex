\section{Time series normalization} \label{normalization}

Normalization is a type of mathematical transformation of time series from one value domain into another value domain with the purpose of obtaining a specific set of statistical features such as a limit of values, a certain variance, standard deviation, or average for the transformed (normalized) time series. The operation usually takes one or two steps and transforms each of the elements $x_{i} \in X$ of input sequence into the element $x_{i}^{'} \in X^{'}$, where $X^{'}$ is a normalized sequence. There are different types of normalization such as:
\begin{itemize}
	\item Normalization into an Interval \cite{citeulike:4295248} \cite{citeulike:2753031}
  \item Normalization to Sum 1
  \item Normalization to Euclidean Norm 1
  \item Normalization to Zero Mean
  \item Normalization to Zero Mean and Unit Standard Deviation \cite{citeulike:3815880}
\end{itemize}

\subsection{Normalization into an Interval}
This type of normalization procedure ensures that all elements of an input vector are scaled proportionally into an output vector with predefined upper and lower limits.
Let's $L_{min}$ to be a desired lower limit, $L_{max}$ to be a upper limit and let's $x_{max} = \max \left\{ x_{i}, x_{i} \in X \right\}$ and $x_{min} = \min \left\{ x_{i}, x_{i} \in X \right\}$. Than
\begin{equation}
x_{i}^{'} = \frac{ (x_{i}-x_{min}) (L_{max} - L_{min}) }{ x_{max} - x_{min} } + L_{min	}, \: i \in \mathbb{N}
\end{equation}
is a normalization procedure.

\subsection{Normalization to Sum 1 and Normalization to Euclidean Norm 1}
While normalization to Sum 1 ensures that elements of $X^{'}$ sum up to 1:
\begin{equation}
1 = \sum_{i=1}^{N} x_{i}^{'}
\end{equation}
by normalization procedure:
\begin{equation}
x_{i}^{'} = \frac{ x_{i} }{ \sum_{i=1}^{N} x_{i} }
\end{equation}
the Normalization to Euclidean Norm 1 transforms the input vector values proportionally into an output vector with a Euclidean norm of 1:
\begin{equation}
1 = \sum_{i=1}^{N} x_{i}^{' \: 2}
\end{equation}
by transformation procedure:
\begin{equation}
x_{i}^{'} = \frac{ x_{i} }{ \sum_{i=1}^{N} x_{i}^2 }
\end{equation}

\subsection{Normalization to the zero mean}
This method ensures that the mean of the normalized vector will be approximately $0$. The mean of the vector $X$ of length $N$ calculated as:
\begin{equation}
\mu_{X} = \frac{1}{N}\sum_{i=1}^{N}x_{i}
\end{equation}
and the normalization procedure is:
\begin{equation}
x_{i}^{'} = x_{i} - \mu, \: i \in \mathbb{N}
\end{equation}
The time-series shown at the Figure \ref{fig:happybirthday} are normalized to zero mean.

\subsection{Normalization to Zero Mean and Unit Standard Deviation} \label{sect:normalization}
This type of normalization is also called ``Normalization to Zero Mean and Unit of Energy'' in research literature and first found in \cite{citeulike:3815880}. It ensures that all elements of the input vector are transformed into the output vector whose mean is approximately $0$ while the standard deviation (and variance) are in a range close to $1$.
This procedure uses mean $\mu$ and standard deviation which calculated as 
\begin{equation}
\sigma = \sqrt{ \frac{ \sum_{i=1}^{N} (x_{i} - \mu)^{2} }{ N - 1 } }
\end{equation}
or equivalently
\begin{equation}
\sigma = \sqrt{ \frac{
                  N \left( \sum_{i=1}^{N} x_{i}^{2}  \right) - 
                  \left( \sum_{i=1}^{N} x_{i} \right) ^{2}
                }{
                  N(N-1)
                }  
          }
\end{equation}
The normalization itself is 
\begin{equation}
x_{i}^{'} = \frac{x_{i} - \mu}{\sigma}, \: i \in \mathbb{N}
\end{equation}
and yields the vector $X_{i}^{'}$ such as $\mu_{X^{'}} \approx 0$ and $\sigma_{X^{'}} \approx 1$.

According to most of the recent works \cite{citeulike:3815880} \cite{citeulike:2821475} \cite{citeulike:3978002} this type of time-series normalization is the best known transformation of the raw time-series which preserves original time-series features. Nevertheless, the article by Lin et al. \cite{citeulike:2821475} explains the reasons and solutions for some cases when the zero mean and unit standard deviation normalization fails. For example if a signal is constant over most of the time span with minor noise at short intervals, this normalization will overamplify the noise to the maximal amplitude. This will also occur if the time-series contains only single value and the standard deviation is not defined.