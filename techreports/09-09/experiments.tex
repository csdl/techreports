\section{Planned evaluation in the classroom}
Aiming a discovery of novel recurrent behavioral patterns in the software process, I am planning to conduct a classroom case study. The approach I am taking is based on the daily re-indexing and mining of the software process data collected by Hackystat from the classroom software project development during the Fall'09 and Spring'10 Software Engineering classes along with interaction with students. 

After collecting a certain amount of data, I expect to see some recurrent patterns gaining enough support to be considered as ``candidate patterns''. The function I am considering as support, will be a product of two metrics: one is based on the support function from AprioriAll algorithm and quantifies the fraction of the developers demonstrating the same pattern, and the second one is based on the total frequency of pattern appearance. The pool of these candidate patterns will be built and reviewed on the daily basis. By reviewing candidate patterns, I am planning to fulfill two goals: first is to identify truly useful and interesting patterns, and second is to enhance a knowledge base of the data-mining algorithm limiting the amount of reported unmeaningful or trivial patterns. The ability to capture patterns and communicate with students in real-time will be extremely helpful in this process providing mechanism for validation of my own guesses.


\section{Planned evaluation using public data}
In addition to the classroom experiments, I am planning to evaluate my research through the use of publicly available repositories. This validation is aiming to assess the ability of my approach to reproduce already published results indicating correctness and similar to other tools performance. If I can find some novel patterns within this data, it will provide a second form of evidence for the utility of my research.

As the main source of the data for the validation, I am planning to use public SCM repositories whose mining is traditionally used in the ``MSR Challenges'' \cite{citeulike:5043676} and published in proceedings of ``IEEE International Conference on Mining Software Repositories''. Following this popular approach, I will try to apply my framework to SCM repository artifacts with the goal of reproducing some of the published results and ultimately participating in the challenge. Second, there are various public data hosted by the ``PROMISE software engineering repository'' \cite{Sayyad:2005} which contains two kinds of data: the software product datasets used for the building of the predictive software models, and some ``universal'' data sets representing SACM repository transaction. Most of these datasets were used for a number of publications and I am planning to evaluate my framework by attempting to reproduce these results. 