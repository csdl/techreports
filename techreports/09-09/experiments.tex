\section{Planned evaluation in the classroom}
I am planning to conduct a classroom case study aiming a discovery of recurrent patterns. The approach I am taking is based on the daily re-indexing and mining of the software process data collected by Hackystat from the classroom software project development during the Fall'09 and Spring'10 Software Engineering classes. 

After collecting a certain (unknown right now) amount of data I expect to see some recurrent patterns to gain enough support to be considered as candidates. The function I am considering as support will be a product of two metrics: one is based on the support function from AprioriAll algorithm and quantifies the fraction of the developers demonstrating the same pattern, and the second one is based on the total frequency of appearance of the pattern. 

As proposed, the pool of these candidate patterns will be built and reviewed on the daily basis. While reviewing candidate patterns I am planning to fulfill two goals: first is to find truly useful and interesting patterns and second is to enhance a knowledge base of the data-mining algorithm constraints limiting the amount of reported unmeaningful or trivial patterns.

\section{Planned evaluation using public data}
In addition to the classroom experiments, I am planning to validate my research through the use of publicly available repositories. This validation is aiming to assess the ability of my approach to reproduce already published results indicating its correctness and similar to other toolsperformance, and the ability to find some novel patterns, which will in turn prove the expected contribution of my research.

As the main source of the data for the validation, I am planning to use public SCM repositories whose mining is traditionally used in the ``MSR Challenges'' \cite{citeulike:5043676} and published in proceedings of ``IEEE International Conference on Mining Software Repositories''. Following this popular approach I will try to apply my framework to SCM repository artifacts aiming reproducing some of the published results and ultimately participating in the challenge. Among others, the process analysis and change impact are two specific areas I am focusing on. Secondly, there are various public data hosted by the ``PROMISE software engineering repository'' \cite{Sayyad:2005} which contains two kinds of the data: the softare product datasets used for the building of the predictive software models. And some ``universal'' data stes representing SACM repository transaction. Most of this datsets were used for a number of publications and I am planning to evaluate my framework reproducing these results. 