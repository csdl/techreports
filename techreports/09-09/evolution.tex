\section{Mining software repositories}\label{evolution.discovery}
According to Kagdi et al. \cite{citeulike:4534888} the term \textit{mining software repositories (MSR)} ``... has been coined to describe a broad class of investigations into the examination of software repositories.'' The ``software repositories'' here refer to various sources containing artifacts produced by software process. Examples of such sources are version-control systems (CVS, SVN, etc.), requirements/change/bug control systems (Bugzilla, Trac etc.), mailing lists archives and social networks. These repositories have different purposes but they support a single goal - a software change which is the single unit of the software evolution. 

In the literature, \textit{software change} defined as an addition, deletion or modification of any software artifact such as requirement, design document, test case, function in the source code, etc. Typically, software change is realized as the source code modification; and while version control system keeps track of actual source code changes, other information repositories track various artifacts, called \textit{metadata}, about these changes: a description of a rationale behind the change, tracking number assigned to a change, assignment to a particular developer, communications among developers about the change, etc.

Researchers mine this wealth of data from repositories in order to extract relevant information and discover relationships about a particular evolutionary characteristic. For example, one may be interested in the growth of a system during each change, or reuse of components from version to version. In this section I will review some MSR research literature which is relevant to my research and based on the mining of temporal patterns from SCM audit trails.

\subsection{Mining evolutionary coupling and changes}
One of the approaches in MSR mining relevant to my research is built upon mining of the simultaneous changes occurring in software evolution. This type of mining takes in account changes in the code within short time-window interval which occur recurrently. Such changes are revealing logical coupling within the code which can not be captured by the static code analysis tools. This knowledge allows researcher and analysts predict the effort and impact of changes with a higher precision. 

Mining of evolutionary coupling typically performed on different levels of code abstraction: Zimmermann et al. in \cite{citeulike:4406375} discuss mining of version archives on the level of the lines of source-code using annotation graphs; Ying et al. in \cite{citeulike:983796} discuss mining of version archives for \textit{co-change} patterns among files by employing association rule mining algorithm and refining results introducing \textit{interestingness} measure which based on the call and usage patterns along with inheritance; Gall et al. in \cite{citeulike:5397994} use window-based heuristics on CVS logs for uncovering logical couplings and change patterns on the module/package level. Kim et al. in \cite{citeulike:5375867} taking a different approach by mining \textit{function signature change} and introducing kinds of signature changes and its metrics in order to understand and predict future evolution patterns and aid for software evolution analysis.

The fine-grain mining of changes on the level of lines of source code is implemented with the use of the family of \textit{diff} utilities which report differences between versions of the same file. For capturing temporal properties the sliding-window approach is used if mining CVS logs, while Subversion is able to report co-changed filesets (\textit{change-sets}). Use of the information extracted by parsing issue/bug tracking logs and developer comments from version control logs allows to capture co-occurring changes with higher precision.

What is common among all this work is that while researchers use different sources and abstraction levels of information, they are extracting only the relevant to a specific question data (using filters and taxonomy mappings) and compose data sets suitable for KDD algorithms. In order to refine and classify (prune) reported results, various support functions proposed.

The main contribution of this type of mining is in the discovery of patterns in software changes which are improving our  understanding of the software and allowing prediction of effort and impact of new changes.

\subsection{Ordered change patterns}
A step ahead in the analysis of co-occurring changes in source code entities was shown by Kagdi et al. in \cite{citeulike:3929070}. The authors investigated a problem of mining ordered sequences of changed files from change-sets. Six heuristics (\textit{Day, Author, File, Author-date, Author-file, and Day-file}) based on the version control transaction properties were developed and applied to each transaction. Abstracted sequences were mined with Apriori algorithm (see \ref{apriori}) discovering recurrent sequential patterns. The authors proposed a higher specificity and effectiveness of such approach in the software change prediction than using convenient change patterns mining.

\subsection{Usage patterns}
Another interesting approach for MSR, relevant to my work, is the mining of usage patterns proposed by Livshits \& Zimmermann in \cite{citeulike:5398684}. In this work, the authors approach a problem of finding violations of application-specific coding rules which are ultimately responsible for a number of errors. They designed approach to find ``surprise patterns'' (see Subsection \ref{tpatterns}) of the API and function usage in SCM audit trail by implementing a preprocessing of the functional calls and mining aggregated data with an Apriori algorithm (see \ref{apriori}) implementation. By considering past changes and bug fixes, authors were able to classify patterns into three categories: \textit{valid patterns}, \textit{likely error} patterns, and \textit{unlikely} patterns. Candidate patterns found with Apriori algorithms were considered to be a valid pattern if they were found a specified number of times and
an unlikely patterns otherwise. Similarly, if a previously labeled as valid pattern was violated a certain number of times, it was considered as an error pattern. The authors validated their approach on mining publicly available repositories effectively reporting error patterns.
