(Message inbox:736)
Return-Path: mvz@cs.UMD.EDU
Received: from ringding.cs.UMD.EDU 
	by festus.cs.UMD.EDU (8.6.11/UMIACS-0.9/04-05-88)
	id PAA05244; Thu, 19 Oct 1995 15:34:29 -0400
Received: from aaron.cs.UMD.EDU 
	by ringding.cs.UMD.EDU (8.6.11/UMIACS-0.9/04-05-88)
	id PAA29076; Thu, 19 Oct 1995 15:34:27 -0400
Received: by aaron.cs.UMD.EDU (8.6.11/UMIACS-0.9/04-05-88)
	id PAA03608; Thu, 19 Oct 1995 15:34:26 -0400
Date: Thu, 19 Oct 1995 15:34:26 -0400
From: mvz@cs.UMD.EDU (Marvin V. Zelkowitz)
Message-Id: <199510191934.PAA03608@aaron.cs.UMD.EDU>
To: aporter@cs.umd.edu
Subject: ICSE 18 paper

We are sorry to inform you that the paper you have submitted, 
"An experiment to access cost-benefits of inspection meetings ..."
has not been accepted for presentation at the 18th International Conference on 
Software Engineering, which is to be held at the Technical University of 
Berlin in Berlin, Germany during the week of March 25-30, 1996. Following this
message are referee comments which we hope will help you understand our
decision and enable you to prepare a more successful paper in the future.

Over 200 papers were submitted to this conference and less than 25% of the
submitted papers were accepted for presentation. ICSE has always had a
high level of professionalism in its presented papers, but not every qualified
paper could be accepted given the time constraints of a three-day conference.

We are sorry we couldn't have accepted any additional papers and still hope to
see you at the conference next March. 

Sincerely,
     Tom Maibaum
     Marv Zelkowitz
     Program Co-chairs, ICSE18
===================================cut here===================================

****The following will be returned anonymously to the authors****

Paper Summary:

The authors describe the conduct and results of a classroom experiment to
evaluate the benefits of inspection meetings. The results seem to indicate that
meetingless inspections are better than inspections with meetings.

Justification:

The points in favor of accepting this paper:

+ The paper proposes interesting hypotheses and describes an empirical
  study to test them. The experiment overall is well thought out.

The points in favor of rejecting this paper:

+ It is not clear that the authors have collected sufficient data to test
  their hypothesis about the cost/benefits of inspection meetings.

+ Also, some of the details of the experiment are not clear and are
  somewhat confusing.

Other Comments:

+ I was expecting a dependent variable that expresses the cost/benefit 
  ratio, in order to address the authors' hypothesis. However, the focus
  seems to be more in the evaluation of benefits (e.g., the authors
  mention "inspection performance" and "potential benefits of meetingless
  inspections")

+ The previous studies that are referred to in the paper involved code and
  design inspections. The current study uses requirements inspections. Is it
  sensible to expect the same effects for the inspection of _any_ document?
  This seems to be the authors' implicit assumption in generating the
  hypotheses, however, it is not substantiated.

+ It is not clear how students were assigned to the three-person teams. Also
  it is not clear what the random assignment of teams and inspection methods 
  means; did you use random number tables, did you put all the names in a hat
  and drew from it ... Similarly for the assignment of individuals to act
  as moderator, recorder, or reader during the collection meeting.

+ It is not obvious what Figure 5 is adding. Furthermore, it is not clear
  from the last paragraph of Section 3.2 where the numbers (23% and 19%) come
  from (are these supposed to be averages for each method?).

+ It is not clear what the point of the Monte Carlo simulation is (in the
  context of this paper). I think this section should be removed.

+ The decision criteria for drawing conclusions from some of the charts should
  be made more explicit (in particular for figs. 6, 7, & 8).

+ It is not clear how one should interpret the results in Section 3.3; 
  it seems that there is very weak evidence supporting the hypothesis,
  however, the authors do not make that clear.

+ In Table 2, it is not clear what are the values of the "Team Composition"
  entry; what was varied here?

+ The poorer performance of the PI and DC methods may be because of the
  time limit imposed on the meetings. If one argues that the fact that 
  there are more people, then defect detection or collection will be slower, then
  one can also argue that if these teams were given more time, their
  fault detection rate would increase.
 
+ As mentioned by the authors, the type of faults may differ (in type and in
  importance or criticality) between individual and team fault detection. Therefore, 
  it would be premature to draw strong conclusions from this study (where this issue 
  was not experimentally investigated).

+ The authors conclude that "this outcome suggests that meetings are not
  necessarily essential to successful inspections"; I think this conclusion,
  from the data presented, is too strong (especially that much of the data
  analysis is not easily understandable as pointed out above).

****The following will be returned anonymously to the authors****

Paper Summary:The paper sets out to perform a cost benefit analysis of 
inspection meetings. A comprehensive experimental set up is described.The 
authors hypothesis is that inspection meetings are nearly as cost effective as 
generally thought. A controlled and well measured experiment is carried out and the results are analysed.

Justification: 

Very well written paper with close to all aspects of a good paper covered.

One section that could be improved is the conclusion. What about future work?, 
what industrial impact may these results have ? What related work is going on?

Other Comments: Keywords are missing.

****The following will be returned anonymously to the authors****

Paper Summary:
Describes a controlled experiment to evaluate the effectiveness of
meetingless reviews, as compared to reviews with meetings.

Justification:

<What are the points in favor of accepting this paper?>
The study is still preliminary, as is stated in the paper. One would
like to see the review mechanism studied in more detail.

<What are the points in favor of rejecting this paper?>
The paper makes modest contribution showing through controlled experiment
that reviews without meetings are more effective, particularly if
done in two phases. The taxonomy of reviews is also nice.

Other Comments:
Not clear about the purpose of section 3.4. Am not sure if it is needed.
