For almost twenty years inspections have been used to validate software.
Although software development has changed substantially in that time,
inspections are still performed in much the same way. 
First each member of the review team 
analyzes the document. Later the team meets to inspect the document as 
a group. Finally, the author repairs the faults that have been discovered.

Some researchers, notably Parnas and Weiss \cite{parnas.1985}, have questioned the 
effectiveness of this approach. Specifically, they argued that group
meetings are unnecessary, even detrimental, because 
they add cost and congest developers' already full schedules, yet 
they find few very faults.

\subsection{Does every inspection need a meeting?}

Despite these objections many people are convinced that meetings
are an essential part of successful inspections. This conviction
stands on the argument that (1) many faults are found during meetings,
and therefore they justify their cost; and (2) because of these meetings
more faults are found than would be otherwise. Thus they believe that
a group of reviewers is likely to be more effective working together than
working separately.

Votta \cite{votta.1993} evaluated this argument in a case study involving 20 design 
inspections at AT\&T. To quantify the usefulness of inspection meetings, he
determined the proportion of faults found during the inspection
that were originally discovered at the meeting (the meeting gain rate).
He reported that the average meeting gain rate for these inspections was
$\approx 5\%$. This would mean that if 20 faults were discovered during the 
inspection, 19 were already known before the meeting ever started!

This result was striking, but a later data seemed to contradict it.
Porter, Siy, Toman and Votta \cite{PSTV:Live} conducted another study, also at AT\&T, 
involving $> 100 $ code inspections. Although their primary goal 
was not to study inspection meetings, they collected data 
on meeting gains in much the same way that Votta's earlier study had.\footnote{
We strongly believe that empirical research must be replicated. This
experience illustrates an economical way to do this. We instrumented the study 
so that it provided not only the data we were immediately interested in, but
also the data needed to replicate Votta's earlier study.}
This time the average meeting gain rate was 33\%, with considerable variance
in the observations (i.e., many meetings produced no gains at all,
while some had rates as high as 80\%.)

We have been unable to find any simple explanation for these 
differences\footnote{This actually points out a
fundamental limitation of case studies. They can be useful for
describing a specific process, but they're often incapable of explaining
differences among multiple processes because they lack the needed controls.},  
but our attempts to make sense
of these results generated hypotheses concerning the relationship
between inspection meetings and the entire inspection process.  And these 
hypotheses led us to some practical questions about the most cost-effective 
ways to conduct inspections.

Below we  discuss how we arrived at 
these questions and working hypotheses, describe the design, 
execution and analysis of an experiment to test them, and 
discuss the implications of our experimental results.

\subsection{Digging Deeper}

Obviously, meetings that produce little gain are a large, unnecessary expense, 
therefore, it is important to determine exactly how meetings contribute 
to inspections and whether superior alternatives exist.

To do this we conducted the following analyses: (1) we surveyed several AT\&T 
developers to find out how they practiced inspections, and (2) we reanalyzed 
the field notes we took from the code inspection study to better understand meeting
performance.

\subsubsection{Surveying Developers}

One observation we made from the code inspection study was that high meeting
gain rates were strongly correlated with specific developers. That is, if 
certain developers were on the inspection team, many faults were found 
at the meeting.
 
In talking with developers we learned that, even though inspections always involved
an initial phase in which they worked individually and a second phase in which they
worked as a group, different developers carried out the phases differently.
For one set of reviewers the purposes of the two phases were {\bf fault detection} 
and then {\bf fault collection}. During
the detection phase these reviewers individually 
analyzed the code to discover faults. The
collection meeting was then held primarily to inform
code unit's author of these discoveries 
-- not necessarily to find more faults.

For other reviewers the purposes were {\bf preparation} and then {\bf inspection}.
During the preparation phase these reviewers analyzed the code 
primarily to familiarize themselves with it, and not necessarily to find
faults. This prepared them for the inspection meeting (a group activity),
during which they would search for faults.

The obvious implication is that reviewers taking the second approach are
likely to generate more meeting gains than those taking the first approach.
This raises an important question, ``What effect does each approach have on 
overall inspection performance?'' Again, since meetings are expensive, if
the approach that deemphasizes meetings works just as well, 
then that might be the most cost-effective option.


\subsubsection{Analyzing the Field Notes}

We also realized that if certain developers tend to produce high meeting gains 
(no matter which team they're on), then some factor related to 
individual effort might explain differences in 
gain rates as well as or better than any
characteristics of the meetings themselves (e.g., group synergy or teamwork.)

To help us better understand this issue we reanalyzed the field notes that 
were recorded during the code inspection study. Our goal was to find
out how much individual effort or group interaction might account for
meeting gains.  To examine the effect of synergy, we determined
how often a fault was discovered
during or immediately after group discussions. This is clearly imprecise 
since synergy might manifest itself in other ways. (For example, early
in a meeting the reviewers might learn something that helps them
discover a fault much later in the meeting.) Still, this analysis helps us 
generate hypotheses even if it doesn't help us prove them.

We were able to gather this data on 40\% of the inspections. For these we 
saw that only 30\% of meeting gains grew out of a visible group discussion.
Despite the obvious limitations of this analysis, the results suggest that 
a non-negligible proportion of the faults discovered at an inspection meeting
are found simply because individuals are given a second opportunity to 
inspect the artifact, not because working in groups enables
more effective inspection.

This hypothesis led to another important question, ``How would inspection 
performance be affected if the time given to
meetings were devoted instead to additional individual analysis?" 


\subsection{Inspection Methods}

\input{treat}
The previous discussion suggests three methods for inspecting software.

\begin{itemize}
\item {\bf Preparation-Inspection (PI).}  Each reviewer individually analyzes the 
artifact in order to become familiar with it.  The goal is not to 
discover faults but only to prepare for the inspection meeting. 
After all reviewers have completed this 
Preparation the team holds an Inspection meeting to 
find as many faults as possible.

\item {\bf Detection-Collection (DC).} Each reviewer individually analyzes the
artifact with the goal of Detecting as many faults as possible. As with
the PI approach, the team then meets (the Collection phase) to inspect the
document. The results of the collection phase will, of course, contain many
faults already found during the detection phase.

\item {\bf Detection-Detection (DD).}  Each reviewer individually analyzes the
artifact with the goal of Detecting as many faults as possible. After all 
reviewers complete this first Detection phase, each is asked to conduct fault 
Detection a second time, again individually, and again with the goal of 
detecting as many faults as possible.
This approach does not involve a meeting, and instead 
the time is used by the reviewers to continue working individually.   

\end{itemize}

\subsection{Hypothesis} 

We hypothesize that inspection meetings are not nearly as cost-beneficial as 
many people believe; and that inspection methods that eliminate meetings
(the DD method) are at least as cost-effective than methods that rely heavily 
on them (the PI and DC methods) and probably more so, and that we expect to
see this result because we expect the benefit of 
additional individual analysis (as provided by the DD method)
to be equal to or greater than holding inspection meetings.
