<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>
  <head>
    <title></title>
  </head>

  <body>
<center>
<H1>LEAP Initial Toolset:<br> Software Requirements Specification</H1>
Philip Johnson<br>
Collaborative Software Development Laboratory <br>
Department of Information and Computer Sciences <br>
University of Hawaii <br>
ICS-TR-97-06<br>
http://www.ics.hawaii.edu/~csdl/techreports/97-06/97-06.html <br>
<p>

Last updated: Tue Oct 14 11:18:52 1997
</center>

<p>

<h2>Introduction</h2>

This SRS for the LEAP Toolset is based heavily upon the ideas specified in
the PSP/Baseline SRS (<A
HREF="http://www.ics.hawaii.edu/~csdl/techreports/96-19/96-19.html">http://www.ics.hawaii.edu/~csdl/techreports/96-19/96-19.html</A>).
Conceptually, the LEAP toolset is a variant of the PSP/Baseline toolset in
two major ways:
<p>
<ol>

<li> The LEAP toolset is substantially more simple to implement and use. It
will serve as a prototype for proof-of-concept evaluation of the ideas in
the PSP/Baseline toolkit.

<p><li> The LEAP toolset emphasizes group review and minimization of
measurement dysfunction to a greater extent than the PSP/Baseline toolset.

</ol>
<p>
The next section presents motivation for the approach taken to the LEAP
toolset.  The following sections present some operational scenarios.  The 
final section presents an initial work breakdown structure and timeline 
for completion of the initial release.

<h2>Background</h2>

Widespread commercial use and public availability of the Internet and World
Wide Web is having a dramatic effect on the software development industry.
First, electronic distribution of software dramatically reduces the cost of
getting new releases into the hands of customers. Partial or complete
electronic distribution reduces or eliminates the economic ``friction'' (in
the form of manual printing costs, disk or CD pressing, packaging, and
transport) that traditionally slows the frequency of releases. Second, the
Internet provides low-cost mechanisms for global marketing and
distribution.  This opens new markets and sources of investment capital for
the US software development industry, as well as new sources of competition
from abroad.
<p>
Low distribution costs, an extremely favorable investment climate for
software development, and increased competition makes a dramatic impact
upon the engineering of software.  Edward Yourdon describes the rise of
"death march" software projects, in which competition and desire for
marketshare leads to understaffed development teams with unrealistic
requirements, schedules, and budgets. Netscape, Microsoft, and others have
responded to reduced distribution costs by providing an avalanche of
``beta'' and ``preview'' releases to its customers at low or no cost.  As a
result, software users have begun to expect new releases and new features
on a monthly or more frequent basis, while acclimating to a substantially
lower level of quality and robustness.
<p>

Death march projects and widespread employment opportunities increase the
tendency toward "churning", or rapid turn-over, in development personnel.
Death march projects create an unhealthy workplace environment, and the
current demand for skilled programmers means that by moving to a different
organization, one might at least be better compensated for enduring poor
working conditions and implausibly tight schedules.
<p>

The frenetic pace of software development on ``Internet Time'' creates
significant obstacles for heavy-weight process-oriented software
development methods. Yourdon exhorts software project managers to rebel
against the ``Methodology'', ``Metrics'' and ``Process police'' in their
organizations.  Tom DeMarco likewise portrays methods like the Capability
Maturity Model in an unfavorable light.
<p>

These forces are affecting not only software engineering practice, but
software engineering education.  First, current industry expansion provides
unparalleled demand for programmers, resulting in lucrative wages for
people with bachelor's degrees in computer science and related disciplines.
With such plentiful and high-paying jobs, it is less attractive to pay
money to obtain graduate training in software engineering.  Second, the
increasing cost of full-time attendence at universities and the use of
internet-based instruction is making distance education an increasingly
attractive alternative.
<p>

These diverse issues and trends share at least one force in common: they tend
toward reduced software quality. Consider:
<p>

<ul>
  
<p><li> Death march projects are understaffed and have ``impossible''
  deadlines. Traditional software quality assurance activities, such as
  testing, software review, and upstream requirements and usability
  activities are trimmed or eliminated on such projects.
  
<p><li> ``Beta'' and ``preview'' releases are, by industry definition, of
  lower quality than ``final'' releases.
  
<p><li> Public distribution of beta and preview releases is acclimatizing the
  public to use and acceptance of software with lower quality.
  
<p><li> Churning tends to reduce the level of project staff experience (at
  least in the specific development domain) which tends to reduce software
  quality.
  
<p><li> Rejection by companies of heavy-weight software processes and methods
  is also a rejection of best practice with respect to production of high
  quality software systems. Lower quality results.
  
<p><li> The fierce demand for programmers reduces motivation for obtaining
  advanced degrees and skills in such areas as software engineering, which
  is still largely taught at the graduate level.  Less highly educated
  developers tends to reduce software quality.

</ul>

To be sure, there are exceptions to each of these claims, and the entire
software development industry does not yet run on Internet Time.  However,
the issues identified above apply quite well to a
highly visible and rapidly growing segment of the industry. 
<p>

Traditional software quality assurance (SQA) and software process
improvement (SPI) research and development will continue to play a vital
role in enhancing the state of software engineering in the US. However, the
trends identified above indicate the need for an additional, complementary
approach described in this proposal, which focuses on software <em>
  developer</em> improvement (SDI).  The motivation for SDI is that the primary
orientation of most SQA and SPI methods may be ill-suited to the business
context described above. The primary orientation of SQA methods is analysis
and improvement of the product. The primary orientation of SPI methods is
analysis and improvement of the organization's process.  In some cases, the
benefits of these methods to individual developers are implicit, such as
when the high quality of a product leads to sales which provides capital
for continued employment of the developer within the company. In other
cases, the benefits are long-term, such as when process measurement and
analysis, performed over a number of projects, leads eventually to process
changes which, when actually approved and adopted, improve working
conditions. In certain cases, the benefits to some individuals are actually
negative. For example, a design staff may be required to insert formal
technical reviews into their schedule because the reviews have been shown
to decrease test time, yet the design staff is not provided extra schedule
time or resources for review (because time-to-market is critical and
management wants to see coding begin as soon as possible).
<p>


In contrast to SQA and SPI, the primary orientation of SDI is on tools and
methods that improve the productivity and skills of the developer that
uses them.  In SDI, concrete improvements to individual developers ripple
upward into improvements to the product and organization, as opposed to SQA
and SPI, where improvements to the product and organization are supposed to
ripple downward to individual developers. In Project LEAP, the specific
tools and methods for software developer improvement must satisfy four
major criteria:

<ul>
  
<p><li> <b>  L</b>ight-weight.  SDI support must be ``light-weight''. In other
  words, they must be easy to learn, easy to integrate with existing
  methods and tools, and above all, not impose significant new overhead on
  the developer unless that investment of overhead will provide a direct
  return-on-investment to that same developer.
  
<p><li> <b>  E</b>mpirical. SDI support should have a quantitative, as well as
  qualitative dimension.  Software developer improvement should be able to
  be showed through measurements of effort, defects, size, and so forth.
  
<p><li> <b>  A</b>utomated. Light-weight support for empirically-based developer
  improvement virtually demands some form of automation.  On the other
  hand, automation does not guarantee light-weight processes or meaningful
  empirical evidence of improvement.
  
<p><li> <b>  P</b>ortable. As a developer-oriented approach, SDI recognizes that
  any long-term improvement mechanism must accomodate the fact that
  software developers change jobs and companies on a regular basis.  Useful
  SDI support cannot be locked to a particular organization such that the
  developer must ``give up'' the data and tools when they leave the
  organization. Rather, SDI support should be akin to a developer's
  address book; a kind of ``personal information assistant'' for their 
  software engineering skill set. 

</ul>

These criteria are difficult to satisfy simultaneously. Nevertheless, our
prior industry experiences with automated formal technical review systems
and non-automated personal software process methods appear to demonstrate
that many software quality improvement initiatives fail to be adopted in
industry due to the lack of an SDI orientation and/or LEAP constraints.  The
design of the Project LEAP builds directly upon these prior successes and
failures.
<p>
The remainder of this SRS details the use of the LEAP Defect Entry Tool (LeapDET)
and Defect Analysis Tool (LeapDAT) through a set of operational scenarios.

<h2>Operational Scenario: Initiating Review</h2>

Cam decides to initiate a review on the code of a prototype tool he
recently completed.  To accomplish this, he first edits 
a file named group.leapdef. Files with this extension contain 
declarations of projects, document types, defect types, document
IDs, and their relationships. Before beginning this review,
Cam needs  to add the documentID of the work product he wants
to review to a .leapdef file so that this document will have
a common definition within the system for all the reviewers.  
Cam accomplishes this by adding the following line to the 
group.leapdef file:
<pre>
DocID: "FooSys 1.0.0"  215   "Simple defect tool" "Java Source"   "Cam Thesis"
</pre>

Here, Cam specifies that there exists a work product called "FooSys
1.0.0", that is of size 215 (in the case of Java source, the group
has agreed to use non-comment source lines of code as the size metric),
with the short description "Simple Defect Tool", 
that FooSys 1.0.0 is of type "Java Source", and that FooSys 1.0.0
is part of the project "Cam Thesis".  
<p>

Note that other lines in this (or another) .leapdef file must declare the
document type "Java Source" and the project "Cam Thesis".  Thus, .leapdef
files gather together in one place common information required by all
members of a review team and make it easily accessable.  They are intended
to lower the overhead of reviewers (by eliminating the need to type the
name of work products and defect types and determine the size) and improve
analysis (by guaranteeing consistent use of defect types, project names,
sizes, and work product IDs by all members). 

<p>


Next, Cam sends an email to his fellow group members requesting that some
or all of them perform a review on his system:
<p>
<pre>
From: cmoore@hawaii.edu
To: csdl@ics.Hawaii.Edu
Subject: Review of FooSys?
Date: Wed, 1 Oct 1997 08:49:12 -1000

Folks,

If you are able, could you do a review of the FooSys source
code located in ~csdl/java/foosys/dev/*.java?  

Please use this command to invoke the review tool:

% java LeapDet "FooSys 1.0.0" ~csdl/group.leapdef 

Also, please indicate the location of your issue by using
either a package, file, class, or method name, as appropriate.

Mahalo,
Cam
</pre>

<h2>Operational Scenario: Responding to a review request</h2>

Jennifer receives Cam's email and decides to help him out and do a review. 
She brings up the tool as advised, reviews the source code, and makes
comments on potential defects.  The following screen dump illustrates 
the basic interface to the Leap Defect Entry Tool (LeapDET) tool and her comments:

<p>
<center>
<form>
<table width=100% border>
<tr><th colspan=5>LeapDET
<tr><td><b>Started:</b> 10/01/97
    <td><b>Project:</b> Cam Thesis
    <td><b>DocType:</b> Java Source
    <td><b>DocID:</b> FooSys 1.0.0 
    <td><b>Size:</b> 215
</table>
<table width=100% border>
<tr><th>Num<th>Loc<th>Issue Type<th>Description
<tr><td>1
    <td><input type=text size=3 name=foo value="Bar">
    <td><select name=bar size=1>
			    <option>10: Syntax
			    <option selected>20: Package/API
		            <option>30: Class
		            <option>40: Method
		            <option>50: Exceptions
		            <option>60: Data Structures
		            <option>70: Variables
		            <option>80: Data Types
		            <option>90: Inheritance
		            <option>Other
                    </select>
     <td><textarea name=foo cols=50 rows=2>I would split the Bar package
into two packages: a Baz package (containing qux-related classes) and 
a Zob package (containing fob-related classes).</textarea>
<tr><td>2
    <td><input type=text size=3 name=foo value="QuxPrint.java">
    <td><select name=bar size=1>
			    <option>10: Syntax
			    <option>20: Package/API
		            <option selected>30: Class
		            <option>40: Method
		            <option>50: Exceptions
		            <option>60: Data Structures
		            <option>70: Variables
		            <option>80: Data Types
		            <option>90: Inheritance
		            <option>Other
                    </select>
     <td><textarea name=foo cols=50 rows=2>Class QuxPrint needs a method to set the font. </textarea>
<tr><td>3
    <td><input type=text size=3 name=foo value="">
    <td><select name=bar size=1>
			    <option>10: Syntax
			    <option>20: Package/API
		            <option>30: Class
		            <option>40: Method
		            <option>50: Exceptions
		            <option>60: Data Structures
		            <option>70: Variables
		            <option>80: Data Types
		            <option>90: Inheritance
		            <option selected>Other
                    </select>
     <td><textarea name=foo cols=50 rows=2>Come talk to me about trying to
use this at DEC; I think there might be some takers!</textarea>
</table>
<table width=100% border>
<tr><td><b>Effort:</b> <input type=text size=3 name=foo value="45"> minutes
    <th>  <input type=button value="Done">
          <input type=button value="Save">
          <input type=button value="Load">
          <input type=button value="Clear">
          <input type=button value="Add Rows">
          <input type=button value="Delete Row(s)">
          <input type=button value="HTML">
          <input type=button value="Quit">
<tr><td colspan=2><b>System Status:</b> Idle
</table>
</form>
</center>
<p>

When Jennifer finishes, she hits the "Done" button.  (Had she been
interrupted in the middle of this review, she could have hit "Save" to save
out the review to a file, then "Quit" to quit the tool. Later, she could
have started the tool as before and hit "Load" to load the contents back
in.) The "Done" button initiates a sequence of two dialog boxes. The
first one enables her to save her review in an "internal", private directory 
which can contain other review comments she has made in the past. Here's
an illustration of the first dialog box:

<p>
<center>
<table border>
<tr><th>LeapDET
<tr><td>Please specify your internal directory and file:
<tr><td><IMG SRC=save.gif>
</table>
</center>
<p>

Note that the system provides a default file name which consists of the
document ID (with all spaces replaced by underscores) followed by a time
stamp generated at the time of invocation of this dialogue box. The time
stamp includes the year, month, day, hour, minute, and second. It serves as
a unique ID for this file so that reviewers and authors can easily store
multiple reviews of the same document with minimum change of a name 
conflict.
<p>
The second dialog box that pops up immediately after this one enables her
to send her review back to the author of the work product and/or other
reviewers. She decides to send the review back to everyone in CSDL along
with a brief comment:

<p>
<center>
<form>
<table border>
<tr><th colspan=2>LeapDET
<tr><th colspan=2>Send Review By Email
<tr><td><b>To:</b> <td><input type=text size=30 name=foo value="csdl">
<tr><td><b>Subject:</b><td> Review: FooSys 1.0.0 "
<tr><td><b>Comment:</b> <td> <textarea name=foo cols=50 rows=2>Nice Job, Cam!</textarea>
<tr><th colspan=2> <input type=button value="Send">
                   <input type=button value="Cancel">
</table>
</form>
</center>
<p>

Jennifer hits "Send", which results in the following email message (at
least as displayed when using the MIME extensions to VM in XEmacs):

<pre>
From: jgeis@hawaii.edu
To: csdl
Subject: Review: FooSys 1.0.0 
Date: Wed, 1 Oct 1997 14:36:15 -1000

[1  &lt;text/plain; US-ASCII (7bit)&gt;]
Nice Job, Cam!

[2 FooSys_1.0.0_1997_10_01_14_35_37.irl &lt;application/octet-stream&gt;]
</pre>
<p>

Pressing "Send" returned Jennifer to the original review entry window, whereupon
she hits "Quit" to exit the program and continue on with her life. 
<p>

Note that Jennifer's effort data gets saved in her personal file, but is
not sent out to the entire group.

<h2>Improving the work product</h2>

Each time Cam receives a review from a csdl member, he saves it into a file
in the directory ~cmoore/leap/external/.  (He does not do a review himself,
although he could if he wanted.)  After receiving a review from all the
csdl members, the first thing Cam wants to do with this data is use it to
remove defects from the work product. To do this, he brings up the Leap
Defect Analysis Tool, specifying the group Leap defaults file as the first
argument and a file directory specification with a wildcarded file
specifier that filters out files unrelated to this review.


<pre>
% java LeapDat  ~csdl/group.leapdef ~cmoore/leap/external/FooSys*
</pre>

The initial screen is similar to the following:

<p>
<center>
<form>
<table width=100% border>
<tr><th colspan=6>LeapDAT
<tr>    <td><b>Project:</b> <select name=bar size=1 multiple>
			    <option selected> Cam Thesis
                        </select>
	
    <td><b>DocType:</b> <select name=bar size=1 multiple>
			    <option selected> Java Source
                        </select>
    <td><b>DocID:</b>  <select name=bar size=1 multiple>
			    <option selected>FooSys 1.0.0 
                        </select>
    <th><input type=button value="Filter Defects">
    <td><b>Total Defects:</b> 34
    <td><b>Files:</b> 6
</table>
<table width=100% border>
<tr><th>Num<th><input type=button value="Valid"><th><input type=button
value="Fix Time"><th><input type=button value="Loc"><th><input type=button
value="Issue Type"><th>Description
<tr><td>1
    <th><input type=checkbox checked>
    <td><input type=text size=2 name=foo value="1">
    <td><input type=text size=3 name=foo value="Bar">
    <td><select name=bar size=1>
			    <option>10: Syntax
			    <option selected>20: Package/API
		            <option>30: Class
		            <option>40: Method
		            <option>50: Exceptions
		            <option>60: Data Structures
		            <option>70: Variables
		            <option>80: Data Types
		            <option>90: Inheritance
		            <option>Other
                    </select>
     <td><textarea name=foo cols=50 rows=2>I would split the Bar package
into two packages: a Baz package (containing qux-related classes) and 
a Zob package (containing fob-related classes).</textarea>
<tr><td>2
    <th><input type=checkbox checked>
    <td><input type=text size=2 name=foo value="1">
    <td><input type=text size=3 name=foo value="QuxPrint.java">
    <td><select name=bar size=1>
			    <option>10: Syntax
			    <option>20: Package/API
		            <option selected>30: Class
		            <option>40: Method
		            <option>50: Exceptions
		            <option>60: Data Structures
		            <option>70: Variables
		            <option>80: Data Types
		            <option>90: Inheritance
		            <option>Other
                    </select>
     <td><textarea name=foo cols=50 rows=2>Class QuxPrint needs a method to set the font. </textarea>
<tr><td>3
    <th><input type=checkbox checked>
    <td><input type=text size=2 name=foo value="1">
    <td><input type=text size=3 name=foo value="">
    <td><select name=bar size=1>
			    <option>10: Syntax
			    <option>20: Package/API
		            <option>30: Class
		            <option>40: Method
		            <option>50: Exceptions
		            <option>60: Data Structures
		            <option>70: Variables
		            <option>80: Data Types
		            <option>90: Inheritance
		            <option selected>Other
                    </select>
     <td><textarea name=foo cols=50 rows=2>Come talk to me about trying to
use this at DEC; I think there might be some takers!</textarea>
</table>
<table width=100% border>

<tr><th rowspan=5>Analyses on <br><b>DocType:<br></b> <select name=bar size=1>
			    <option selected> Java Source
			    <option selected> SRS
                        </select>
<tr><td colspan=2><b>Authoring:<b>  
    <td> <input type=button value="Density (project)">
         <input type=button value="Frequency">
         <input type=button value="Frequency (project)">
         <input type=button value="Fix Time">
         <input type=button value="Fix Time (project)">

<tr><td rowspan=3><b>Reviewing:<b> 
         <td> <b>Personal vs Group:<b> 
                   <td> <input type=button value="Density">
                        <input type=button value="Frequency">

<tr><td> <b>Personal Historical:<b>
    <td> <input type=button value="Density">                 

<tr><td><b>Personal Trend:<b>  
    <td><input type=button value="Density">                
        <input type=button value="Size Efficiency">                 
        <input type=button value="Detection Efficiency">                 
</table>

<table width=100% border>
<tr> <th> <input type=button value="Save">
    <th> <input type=button value="Load">
    <th> <input type=button value="Clear">
    <th> <input type=button value="HTML">
    <th> <input type=button value="Quit">
<tr><td colspan=4><b>System Status:</b> Idle
</table>
</form>
</center>
<p>

<h4>Defect Filtering</h4>

LeapDET reads in all the files specified on the command line, and builds a
list of all projects, document types, and document IDs contained within the
files. The first "header" line provides multiple selection lists 
for all the projects, document types, and document IDs found within the 
files. By default, all of the input projects, document types, and document
IDs are selected, which results in display of all defects contained in
the files.  A user can then "filter" the displayed defects by changing
the set of selected projects, document types, or document IDs, and then
pressing the "Filter Defects" button. (Note that this filter 
performs a <em>union</em> of the selected entries.  For example, selecting a
project name selects <em>all</em> defects from <em>every</em> document
type and document ID for that project, regardless of the selected 
doctypes and docIDs. In general, if you want to select only  a single 
document, then you must deselect all projects and document types
and select only that single document from the document ID list.)
<p>

In the case of Cam's invocation, all of the FooSys* files contain
a single project, document type, and document ID, so each of these
selectable lists contain only one element. In later scenarios, we will
illustrate how users read in data from more than one project, document
type, or document ID in order to do historical or trend analysis.

<p>

In this case of defect analysis, however, Cam is only interested in
removing the defects associated with this review. Since the file
specification loaded all and only the data associated with this work
product, Cam does not need to do any selection or filtering.

<p>

<h4>Defect Sorting</h4>

Next, since there are a reasonable number of defects displayed (34), 
Cam decides to sort the defects so that he can work through them in
an organized fashion.  Several of the column headers for the defect
list (i.e., "Valid", "Loc", "Fix Time", and "Issue Type") are actually buttons which,
when pressed, result in sorting the defect list in alphabetic order 
according to the value of the column.  
<p>
Cam decides to sort the defects by location, and presses the "Loc" button
to do this.  Cam had requested in his email that people use either a package
name, file name, class name, or method name as the value of the location
field, so sorting the defects in alphabetical order will group defects
related to the same general area of the code in the same location.


<h4>Defect Validation, Duplication, Fix Times, and Annotation</h4>

Not all the defects raised by reviewers might be valid upon closer
inspection, at least in the eyes of the author. To further help organize
the repair process, and also to support later defect and trend analysis,
Cam now makes a pass through the defect list to identify any that do
not appear to be valid.
<p>
By default, LeapDET marks all defects as valid, but the user
can toggle the value of this validity property for each issue. Cam goes
through and whittles down the original set of defects.  In some cases,
more than one reviewer identified the same defect.  In this case, Cam
simply marks the duplicates as "invalid" so that only one instance of
the defect is marked as valid (and counted in later analyses.)

<p>
In other cases, Cam decides to reword the reviewer's comments slightly,
and/or add a comment of his own about the cause/result of the defect.
He does this by simply typing or editing text in the description field.

<p>
Cam can also change the defect type or location field associated with 
any of the listed defects.

<p>
Finally, Cam has the option of annotating one or more defects with a fix
time.  By default, the system provides a fix time of one minute for
each defect. For defects that take substantially more than one minute, 
Cam can change this value to reflect the time spent.  This enables Cam
to track rework effort and relate it to the types of defects he makes
in his work products.


<h4>Saving and Restarting</h4>

Some of the required repairs are rather lengthy, so Cam needs to
periodically save and restart the tool over the next few days.  To do this,
Cam hits the "Save" button.  Saving in this context means that the tool
goes through each defect (both those displayed through selection and those
that aren't), identifies the file they came from, and writes a new, updated
version of that file that saves any changes to the validity, defect type,
location, or description associated with the defect.  (It is not possible
to change the project, document type, or document ID associated with a
defect in this version of the toolset.)

<p>
Note that the updated versions of these file may not necessarily preserve
the ordering of issues within the file. 

<p>

To restart, Cam simply invokes the same command line arguments as before.
The files, along with any changes he had made to them in previous sessions,
are read in and displayed. 

<h4>Additional defect recording</h4>

At times during rework, Cam discovers new defects in the document that he
decides he would like to record for later analysis.  The LeapDAT tool does
not support entry of new defects.  However, to record additional defects,
Cam brings up the LeapDET (Defect Entry Tool) and records the additional
defects found.  By saving those files with the appropriate name, he can 
load them into the LeapDAT tool for analysis.


<h4>Rework Reporting</h4>

Having finished the rework on the document, Cam decides to create a report
summarizing the changes made to the document.  Although the tool does not
provide direct support for all aspects of rework reports (such as the 
fix time, disposition, and so forth), Cam uses the HTML button to create
an initial version of a report which contains a nicely formatted version
of all the defects selected in the tool. He then edits this document
manually to include the additional information required by his management,
and sends it off to them via email.




<h2>Leap for Software Developer Improvement</h2>

The above discussion illustrates how the Leap toolset facilitates Software
Quality Improvement (SQI) of a single product through review. The Leap
toolset enables reviewers to efficiently generate and distribute commentary
and authors to efficiently receive this commentary and use it to improve
the work product in question.  We call this the "first order" benefit of
the Leap review toolset: low cost, efficient support for defect detection.

<p>

However, the fundamental mission of the Leap toolset is to enable software
developer improvement (SDI), both as an author of work products
(developer-as-author) and as a reviewer of other people's work products
(developer-as-reviewer). Thus, although low-cost support for SQI is nice,
the real goal is to support low-cost, effective SDI. The following two
sections outline the kinds of empirical analyses provided by these tools.


<p>
<h2>Improving the developer-as-author</h2>

For developers-as-authors, the Leap toolset provides automated analysis of
the defects recorded in work products of a similar type over time. The Leap
toolset generates this analysis from the defect data recorded by the author
and the defect data sent to the author by reviewers. (Defect data imported
from downstream phases such as testing would improve the accuracy of these
analyses but is not essential.)  The analysis enables the
developer-as-author to obtain three measures for a given work
product: defect density, defect frequency, and defect fix time. The toolset
also enables developers to view trends in these measures over a series
of work products of a given type. The following examples show how the Leap
toolset presents this data to the user and how the user can exploit this
information to discover opportunities for improvement in their capabilities.


<ol>

<p><li> <b>Detected defect density (per project).</b><p> Changes to
detected defect density over the course of several projects can help
developers understand whether their ability to develop work products of a
particular type without defects is improving or degrading, and support
inquiry into the causal factors underlying the values of this measure.
Consider the following example detected defect density graph generated by
the Leap toolset as part of Cam's SDI activities:

<p>

<form>
<table width=75% border>
<tr><th>Detected Defect Density (per project)
<tr><td>
<center>
<IMG SRC=defdens1.gif>
</center>
</table>
<table width=75% border>
<tr> <th> Secondary Measure: 
          <select name=bar size=1>
			    <option> Frequency
			    <option> Size
		            <option selected>None
                    </select>
    <th> <input type=button value="Re-Graph">
    <th> <input type=button value="Close">
</table>
</form>

<p>

First, note that the Y-axis graphs the detected defect density over
a series of work products that are, in this case, successive releases of
the Foo system.  The dark line indicates that detected defect density
is moving downward and then shows an upward spike at Foo-2.0.0, followed
by a return to 'normal' levels at Foo-2.0.1.  Why did this occur
and what are its implications for Cam's development capabilities?
<p>

First, after some exploration of graphing detected defect density with
other secondary data values, Cam discovered that the change from Foo-1.1.1
to Foo-2.0.0 was accompanied by a large increase of new code which
basically doubled the size of the system.  After this release, both the
amount of new code in the next release (Foo-2.0.) and the defect density
returned to their previous lower levels.

<p>
<form>
<table width=75% border>
<tr><th>Detected Defect Density (per project)
<tr><td>
<center>
<IMG SRC=defdens2.gif>
</center>
</table>
<table width=75% border>
<tr> <th> Secondary Measure: 
          <select name=bar size=1>
			    <option> Frequency
			    <option selected> Size
		            <option> None
                    </select>
    <th> <input type=button value="Re-Graph">
    <th> <input type=button value="Close">
</table> 
</form>
<p>


Thus, a sudden increase in code size as well as the occurrence of a new
major release is correlated with this upward "blip" in detected defect
density. How can Cam interpret these findings to improve his skills?  There
are several possible conclusions:

<ul>
<p><li> Major new releases (which are typically accompanied by a great deal
of new code) are prone to a greater than normal density of defects.  In
future development, Cam can explore whether the presence of a great deal of
new code serves as a predictor of defect density.  This indicates that
there is a consistent (i.e. at least partially causal) connection between new code and defect density.

<p><li> If Cam can detect a consistent relationship between new code and
actual defect density, then Cam could change his future release technique
to eliminate big jumps in new code. For example, a jump such as between
Foo-1.1.0 and Foo-2.0.0 would be replaced by several intermediate releases
with smaller amounts of new code.  Cam could explore if this eliminates
"spikes" in detected defect density.

<p><li> Cam can also explore whether this spike is an artifact of different
review standards for major releases.  Perhaps the effort (and/or numbers of
reviewers) involved in the major release review was much greater than the
effort applied to the minor releases.  If this is so, then perhaps the
value of detected defect density is not causally connected to new code
after all, but rather to level of review effort!  If this is the 
more important correlation, then Cam can improve his future development
effort by either encouraging greater review participation on all
releases, or by recognizing that new major releases get more review
participation and using that as a factor in deciding when to increment
the major release number. 
</ul>




<p><li> <b>Detected Defect Type Frequency Distribution.</b> <p>

Efforts made to reduce or prevent the most frequently occurring defects are
likely to have a high return on investment for the developer.
To investigate this, Cam begins by graphing the aggregate defect
distribution over the same series of Foo releases:

<p>
<form>
<table width= 75% border>
<tr><th>Detected Defect Type Frequency Distribution
<tr><td>
<center>
<IMG SRC=deftype1.gif>
</center>
</table>
<table width=75% border>
<tr> <th> Secondary Measure: 
          <select name=bar size=1>
			    <option> Frequency
			    <option> Size
		            <option selected> None
                    </select>
    <th> <input type=button value="Re-Graph">
    <th> <input type=button value="Close">
</table> 
</form>
<p>

Cam notices that three categories of defect types account for the vast
majority of defects: syntax errors, import statement errors, and data
structure errors.  To gain further insight, Cam graphs the trends
in just these three defect types over time:

<p>
<form>
<table width=75% border>
<tr><th>Selected Detected Defect Type Frequency Distribution (per project)
<tr><td>
<center>
<IMG SRC=deftype2.gif>
</center>
</table>
<table width=75% border>
<tr> <th> Selected Defect Types: 
          <select name=bar size=2 multiple>
			    <option selected>10: Syntax
			    <option selected>20: Import
		            <option>30: Class
		            <option>40: Method
		            <option>50: Exceptions
		            <option selected>60: Data Structures
		            <option>70: Variables
		            <option>80: Data Types
		            <option>90: Inheritance
		            <option>Other
                    </select>
    <th> <input type=button value="Re-Graph">
    <th> <input type=button value="Close">
</table> 
</form>

<p>

Interestingly, Cam now observes that syntax errors have remained
relatively constant over all the releases, while import errors
have sharply dropped, and data structure errors are actually on
the rise! Once again, how can Cam interpret this data and use
the interpretation to improve his development skills?

<ul>
<p><li>  The sharp decrease in import errors over time
might mean that Cam has gotten better at dealing with import
statements, and that its high aggregate value can be safely 
ignored.  An alternative explanation is that import errors are 
a problem for Cam only in the initial release or two of a system
(when most inter-package dependencies are being established)
and that after this, since import statements are no longer 
manipulated much, the level of defects drops. If this latter
interpretation is correct, then Cam can improve his development
process by remembering to focus on import statements as a likely
source of errors whenever he is in the early release stages
of development.  Cam tests this latter interpretation by 
graphing import defect data from all his early system releases:


<p>
<form>
<table width=75% border>
<tr><th>Selected Detected Defect Type Frequency Distribution (per project)
<tr><td>
<center>
<IMG SRC=deftype3.gif>
</center>
</table>
<table width=75% border>
<tr> <th> Selected Defect Types: 
          <select name=bar size=2 multiple>
			    <option>10: Syntax
			    <option selected>20: Import
		            <option>30: Class
		            <option>40: Method
		            <option>50: Exceptions
		            <option>60: Data Structures
		            <option>70: Variables
		            <option>80: Data Types
		            <option>90: Inheritance
		            <option>Other
                    </select>
    <th> <input type=button value="Re-Graph">
    <th> <input type=button value="Close">
</table> 
</form>
<p>

Surprise!  Import errors are always high for Cam in early
releases, which suggests he can improve his skills on early
releases by focussing on import statements, perhaps developing
a checklist item or quick reference sheet on imports.

<p><li> The constant high level of syntax errors suggests that this is a
standard problem for Cam.  To investigate this further, he sorts the defect
table by defect type, and peruses all the syntax defects listed. He
observes that there are two types of syntax errors that he makes
consistently: mismatched parentheses in nested method invocations, and
mistyping of the word "System".  

<p>

To lower the effort associated with these errors, Cam (having been an Emacs
wizard in a previous lifetime) takes a few minutes to develop two simple
Emacs-Lisp routines.  The first finds lines with more than three left
parentheses and highlights them.  The second checks for common mispellings
of "System" and automatically corrects them. He adds these routines to the
hook variable associated with the java compile command so that they are run
automatically each time he invokes the compiler. This change to his
environment allows him to quickly check those two frequent sources of
syntax errors, supporting early detection of one of them and automatic
removal of the second.

<p><li> Finally, Cam turns to the sudden increase in data structure errors,
which is a disturbing trend.  His first goal is to determine whether or not
this increase is actually due to an increase in data structure defects or
instead due to a recent change in the defect detection process. For
example, perhaps a new reviewer has started contributing defects recently
and tends to classify many defects as data structure errors, even though
the same defect was classified as an API error by other reviewers.  
<p>
By reviewing the actual defect log, Cam finds that the data structure
errors are concentrated in a new package of the Foo system, which involves
a highly interconnected set of classes with public variables, thus allowing
them to efficiently modify each other's internal state. 
<p>
Cam can use this insight in at least two ways. First, he could redesign
these classes to reduce the interdependencies, given that the current
structure is leading to an uncharacteristically high defect level.  Or, he
could decide that the current design is necessitated by the domain, and
test, review, and/or build in trace facilities to lower the defects
associated with such designs in his future development.

</ul>



<p><li> <b>Detected Defect Type Fix Time Distribution.</b><p> 

This distribution enables developers to assess which types of detected
defects are requiring the most rework effort.  In a manner similar to the
defect type frequency distribution, focussing on the defect types
requiring the most effort to fix is likely to lead to significant software
developer improvement. 
<p>

Cam graphs the detected defect type fix time distribution for the Foo system
releases as follows:

<p>
<form>
<table width=75% border>
<tr><th>Detected Defect Fix Time Distribution
<tr><td>
<center>
<IMG SRC=deftype4.gif>
</center>
</table>
<table width=75% border>
<tr> <th> Secondary Measure: 
          <select name=bar size=1>
			    <option> Frequency
			    <option> Size
		            <option selected> None
                    </select>
    <th> <input type=button value="Re-Graph">
    <th> <input type=button value="Close">
</table> 
</form>
<p>

Since he has already done some analysis on defect type distributions above,
he decides to check to see if this distribution is any different from the 
standard frequency distribution. To do this, he adds defect frequency as a
secondary plot:

<p>

<form>
<table width=75% border>
<tr><th>Detected Defect Fix Time Distribution
<tr><td>
<center>
<IMG SRC=deftype5.gif>
</center>
</table>
<table width=75% border>
<tr> <th> Secondary Measure: 
          <select name=bar size=1>
			    <option selected> Frequency
			    <option> Size
		            <option> None
                    </select>
    <th> <input type=button value="Re-Graph">
    <th> <input type=button value="Close">
</table> 
</form>
<p>

Interesting.  Although the trends in general match, there are two
significant exceptions: data structures and loop errors, which are low
frequency (as shown by the blue line) but costly (as shown by the burgundy
bar).  Cam goes back to the defect log and begins by looking at the 
loop errors.  He discovers that, in most cases, these loop errors result
from boundary conditions involving the index, where either the first or
last elements are not processed, or where the index goes "too far" and runs
off the end of some data structure.

<p>

Upon further reflection, Cam realizes that the reason these types of errors
tend to take so much time is because the system tends to fail in ways not
clearly related to the index value.  Thus, a great deal of debugging effort
is required to simply trace the problem back to the index value.  Cam
decides that the way to improve his capabilities in the case of these
defect types is to move from a "reactive" stance, in which he waits for the
system to fail and then traces back to the loop error, to a "proactive"
stance, in which he puts more effort into checking any loop code for
correctness prior to release of the system.  He also decides that in future
reviews, he will explicitly ask reviewers to look carefully at any loop 
code for potential "off-by-one" errors, since these can be the source of
high rework effort. 

<p>
Cam next goes back and does a similar analysis on the data structure
errors. His findings are left as an exercise to the reader. 


</ol>



<p>

In summary, this section has shown how the LEAP toolset enables developers
to inquire into their development history to learn about the kinds of
defects they make during development.  As the above case studies show,
developers must always be aware of the limitations of recorded data:
detected defects, for example, may not be the same as actual defects, and
changes in detected defects may be due to changes in the review process and
not necessarily due to changes in the actual defects present in the system.
Confronting the fact that there may be multiple explanations for a given
data analysis does not weaken the utility of the LEAP toolset; indeed, we
believe that such consideration of alternatives simply provides developers with 
more ways in which to improve their development capabilities. 


<h2>Improving the developer-as-reviewer</h2>

For developers-as-reviewers, the goal of the Leap toolset is to determine
how to improve both the efficiency and effectiveness of the developer's
skill as a reviewer.  Ideally, over time the developer-as-reviewer should
become able to detect a greater percentage of the total defects present in
the document and/or detect defects in a shorter period of time.  Note that
few if any FTR methods provide empirical support for improving the
reviewing skills of the developer.   

<p>

<ol>
<p><li> <b>Personal-vs-group review performance: detected defect densities.</b><p>

One type of analysis provided by the Leap toolset enables the
developer-as-reviewer to compare her performance to that of the entire
group. These analyses motivate the facilities in the toolset that make it
easy for reviewers to pass copies of their data on to other reviewers, and
the facilities for private archiving of a developer's past reviews of other
work products.  They also motivate the complete absence of information
about the identities of reviewers; the toolkit enables individuals to
privately compare their own performance to the groups, but does not 
provide support for analyses of other reviewer's individual data. 

<p>

The personal-vs-group analysis compares the detected defect density of the
developer-as-reviewer to the whole group.  This comparison isolates reviews
where the overall performance of the individual relative to the group is
especially good (or bad), and thus indicate the need for further inspection
of the particulars of those reviews. 

<p>

For example, if the developer did especially poorly relative to the group
on a given review, she might study that review's data more closely in an
attempt to determine why that occurred and what improvements she might make
in future reviews.

<p><li> <b>Personal-vs-group review performance: detected defect type frequencies.</b><p>

This analysis enables the developer-as-reviewer to compare her detected
defect type frequencies to the entire group's. This reveals whether there
are classes of defects present in work products that the developer is not
yet proficient at detecting.


<p><li> <b>Personal historical performance: detected defect type frequencies.</b><p>

The Leap toolset also allows the developer to compare her performance on a
single review to her own historical data.  For example, she can compare the
frequency of detection of defect types on a single review to her overall
defect type detection frequency.  This enables the developer to determine
if she is focussing on different areas in this review than is typical for
her, or if this work product has a substantially different "profile" of
defects compared to those she commonly encounters.

<p><li> <b>Personal trend analysis: defect density</b><p>

Finally, the Leap toolset provides the developer with trend information on
her own individual data for three measures: defects/size (defect density),
effort/size (size efficiency), and effort/defect (detection efficiency).
<p>
Abnormally low defect density (defects/size) values or trends indicate the need for
further investigation: either the reviewer is getting less effective, or
the work products are becoming of higher quality.  (A partial 
differential diagnosis can be made by checking the comparative data: if the
group's defect density on this work product is normal, then it's the
developer; if the group's is also abnormal, then either the document is
of better quality than normal or the group process is of lower quality than
normal.)


<p><li> <b>Personal trend analysis: size efficiency</b><p>


In general, size efficiency (effort/size) data helps the developer-as-reviewer determine
the appropriate "chunk" of material to review at one time.  As the size of
the document increases, the time spent inevitably levels off.  Size
efficiency data also helps the reviewer predict how much time might be
required to review a new work product, based upon its size.  Note that
since a developer has access only to their own effort data, it is not
possible to do comparative analysis of a developer's size efficiency to 
that of the group as a whole.

<p>

<p><li> <b>Personal trend analysis: detection efficiency</b><p>

Detection efficiency (effort/defect) helps the developer-as-reviewer
determine the average length of time it took her to detect a defect on a
single work product and trends in this value over time.  Work products for
which detection efficiency is low indicates either that the product is
hard to review, or that the defects in it were subtle and difficult to
detect, or that the developer invested a lot of time but her effectiveness
was compromised for some reason.  Over time, of course, it is desirable for
the reviewer to have a general upward trend in detection efficiency,
although it is possible for this value to be affected by many other factors
even when the reviewer is indeed becoming more efficient at review.
As with size efficiency, since this measure involves effort, the data set
is restricted to review data from the individual developer.


</ol>



<h2>Class List</h2>

The next two sections present a list of classes required in the
leap.det and leap.util packages to implement LeapDet.  Then a 
schedule for LeapDet is presented.  The following two sections
present the additional classes needed for LeapDat and its 
schedule.

<h4> Package csdl.java.leap.det</h4>
<ol>

<p><li><b>LeapDet</b> extends LeapGUI<p>
 Has a main that runs the whole thing, creates frame, etc.
Reads in .leaprc to get color/font settings and maybe size if we're excited.
Creates empty LeapDet frame with LeapDetHeader, table, action panels.
Reads in data to internal data structures.
Calls methods on LeapDetheader, table, action to provide correct initial
values. 
Sends message to status line of action panel periodically.
<p>

Note that people can provide more than one leapDefaults and
resources files by supplying more than one keyword. 

<p>RTest: None. Just invoke the main to test. Tries to do something
reasonable (like not core dumping) when invoked with no arguments.


<p>Releases: 
<br> 1.0 just brings up panels with buttons but no 
behavior and no file interface. 
<br> 1.1 supports command line argument processing.
<br> 1.2 supports  header initialized from command line.
<br> 1.3 supports  table saving.
<br> 1.4 supports table loading and clearing.
<br> 1.5 supports table emailing.
<br> 1.6 supports html writing.
<br> 1.7 supports adding and deleting rows.

<p><li> <b>HeaderPanel</b> extends Panel<p>
Constructor displays empty fields with appropriate font/color.
Methods allow setting of fields. 
Font and foreground/background color setting.

<p>RTest: Provides main and frame to display this panel independently
with dummy values of fields.

<p>Releases:
<br> 1.0 provides all features. Constructor takes arguments
providing values for panel info. These can be empty strings.
Methods are provided to add real values after they are read in.
Supports resizing.

<p><li><b>TablePanel </b> extends Panel<p>
Contains a JCTable.
Constructor builds a blank table with headers set etc and font/color.
Method accepts internal defect table object and uses it to set fields
in table. Sets the dirtyTable flag on LeapGUI each time a modification
is entered.

<p>RTest: Provides main and frame to display this panel independently
with empty or a bit of fake data. Useful to test resizing etc.
As IRLFileReader and DefaultsReader come on-line, additional tests
can be added to test their use with TablePanel.

<p>Releases:
<br> 1.0 Constructor builds the panel with an empty table. Supports resizing.
<br> 1.1 Support for initializing defect type column with choice lists.
<br> 1.2 Support for loading table with previously occurring data.
<br> 1.3 Support for selecting, deselecting, deleting, and adding rows
using the AddRows and DeleteRows buttons.

<p><li><b>ActionPanel </b> extends Panel<p>

Constructor sets up buttons and text field.  
Public method allowing people to set the contents of the status field when
busy, but must make sure they reset it to "Ready."


<p>RTest: Provides main and frame to display this panel independently.  To
write the RTest for the initial release, initial releases of LoadButton,
etc. must be provided that merely provide the button but no implementation.


<p>Releases:
<br> 1.0 supports resizable display of buttons but no behavior.
<br> Other releases as required to support new functionality
in buttons; perhaps not needed.

<p><li><b>LoadButton </b> extends Button<p>

Creates a FileDialog object to get the file name, then calls IRLFile
to get the contents of the IRL file, then overwrites 
the data previously in the table with the new data.
Leaves empty rows at end of table after a load.
<p>
If prior table contents have not been saved, pops up dialog
box to check if user really wants to blow away current entries..
<p>
Caches the directory specified so that future loads default to
that directory.
<p>
Sets status.

<p>RTest: Initial release's test just provides frame and panel to
allow display of a button with appropriate 
font/color. As other classes come on line, more of the functionality
can be added as additional RTests in subsequent releases.

<p>Releases:
<br> 1.0  supports button but no behavior.
<br> 1.1  provides all functionality.

<p><li><b>ClearButton </b> extends Button<p>

Emptys the TablePanel and the HeaderPanel contents.  If the
table has not been saved (i.e. dirty bit is set) then displays
dialog box asking user if they are sure they want to clear.
<p>

<p>RTest: Initial release's test just provides frame and panel to
allow display of a button with default
font/color. As other classes come on line, more of the functionality
can be added as additional RTests in subsequent releases.

<p>Releases:
<br> 1.0  supports button but no behavior.
<br> 1.1  provides all functionality.

<p><li><b>AddRows</b> extends Button<p>

Adds new empty rows to end of table.
<p>

<p>RTest: Initial release's test just provides frame and panel to
allow display of a button with default
font/color. As other classes come on line, more of the functionality
can be added as additional RTests in subsequent releases.

<p>Releases:
<br> 1.0  supports button but no behavior.
<br> 1.1  provides all functionality.

<p><li><b>DeleteRows </b> extends Button<p>

Deletes any selected rows in the table.  This button should
be deactivated except when the user has selected rows in the 
JCTable.  Selecting rows should result in this button being 
made active.  Then if the user presses it, the selected rows
should be deleted.  May want to prompt the user because this
is an unrecoverable operation. Unselecting rows should deactivate
this button, so this button requires interaction with JCTable.
<p>

<p>RTest: Initial release's test just provides frame and panel to
allow display of a button with default
font/color. As other classes come on line, more of the functionality
can be added as additional RTests in subsequent releases.

<p>Releases:
<br> 1.0  supports button but no behavior.
<br> 1.1  provides all functionality.

<p><li><b>SaveButton </b> extends Button<p>

It generates the file name when it finds by querying the value of the
LeapGUI file variable that this data is not bound already to a file.
Creates a fileDialog box with a file name.  Calls IrlFileWriter to do the
actual writing.  If the file is successfully saved, it sets the value of
the file variable of LeapDET before returning. Clears the dirtyTable flag
in LeapGUI.

<p>

Remember to set the project, document ID, and file name on each defect
before writing.

<p>

Caches the directory specified so that future saves default to
that directory.

<p>
Set status.

<p>RTest: 1.0 release's test just provides frame and panel to
allow display of a button with appropriate 
font/color. As other classes come on line, more of the functionality
can be added as additional RTests in subsequent releases.


<p>Releases:
<br> 1.0 provides just the button with no functionality.
<br> 1.1 provides the save dialog box in response to the press.

<p><li><b>QuitButton </b> extends Button<p>

Checks the dirtyTable value on LeapGUI and asks the user if they
really want to exit if there are changes, or else cancel.

<p>RTest: Initial release's test just provides frame and panel to
allow display of a button with appropriate 
font/color. As other classes come on line, more of the functionality
can be added as additional RTests in subsequent releases.

<p>Releases:
<br> 1.0 provides just the button with no functionality.
<br> 1.1 provides all functionality.


<p><li><b>HTMLButton </b> extends Button<p>

Saves out the HTML same way as always. Must query user for a filename.
Caches directory for use in subsequent file saves.

<p>
Sets status

<p>RTest: Initial release's test just provides frame and panel to
allow display of a button with appropriate 
font/color. As other classes come on line, more of the functionality
can be added as additional RTests in subsequent releases.


<p>Releases:
<br> 1.0 provides just the button with no functionality.
<br> 1.1 provides full functionality.

<p><li><b>MailSender </b> extends DialogBox<p>

Constructor gets passed a doc ID and a JCVector 
containing the data. Pops up the dialog box, figures out
how to make a mime type or whatever, and sends the bugger.
<p>
Sets status.

<p>RTest: Can be used to test mime-encoding and the interactive
use of the dialog box within a frame etc.

<p>Releases:
<br> 1.0 provides all functionality.


<p><li><b>DoneButton </b> extends Button<p>

Calls MailSender then various SaveButton classes to do the file save.
<p>

<p>RTest: Initial release's test just provides frame and panel to
allow display of a button with appropriate 
font/color. As other classes come on line, more of the functionality
can be added as additional RTests in subsequent releases.

<p>Releases:
<br> 1.0 provides just the button with no functionality.
<br> 1.1 provides full functionality.


</ol>

<h4>Package csdl.leap.util</h4>

<ol>

<p><li><b>LeapGUI </b><p>

Superclass of LeapDet and LeapDat.  Contains variables that store:
font, foreground, background, tableDirtyBit, and vectors
called projects, docTypes, and documents. And tableVector, which
stores a merging of all the IRL files read in thus far. 

<p>Rtest:  None.

<p>Releases:
<br> 1.0 provides all anticipated variables.
<br> Later releases include unanticipated variables :-).

<p><li><b>DefaultsFile </b><p>

Constructor takes the name of a Leap defaults file, reads in the file,
creates projects, docTypes, and documents, and provides methods for the
caller to get this info.

<p>
Here is a proposed example defaults file with all possible settings:
<pre>
# blank lines or lines starting with a # are comments
# The following lines document the syntax followed by an example.
# All fields are currently required.

# Project:	&lt;name&gt;		&lt;comment&gt;
Project:    	"FooSys"    	"The Foo System"

# DocType: 	&lt;name&gt; 		&lt;comment&gt;
DocType:   	"Java"       	"Java source code"

# DefType: 	&lt;doctype&gt;	&lt;name&gt;		&lt;comment&gt; 
DefType:   	"Java"     	"10: Syntax" 	"Any error involving syntax."

# DocID:   	&lt;name&gt;		&lt;size&gt;	&lt;comment&gt;	&lt;doctype&gt;	&lt;project&gt;
DocID:     	"FooSys 1.0" 	13	"Init. release"	"Java"      	 "FooSys"

</pre>


<p>Rtest: Main takes a sample defaults file and successfully
gets the right values.

<p>Releases:
<br> 1.0 provides all anticipated functionality.


<p><li><b>Project </b><p>

A project name (string) and a vector of document instances.

<p>Rtest: None.

<p><li><b> Document </b><p>

A document name  (string) and a doctype instance.

<p>Rtest: None.

<p><li><b>DocType </b><p>

A doctype name (string)  and a vector of associated defect types.

<p>Rtest: None.

<p><li><b>DefectType </b><p>

A defect type name (string) and a string description (this
field is unused for now.)

<p>Rtest: None.


<p><li><b>LeapRcFile </b><p>

Constructor takes a file name, reads in the resource
settings, and provides methods for the caller to get at them.
<p>
Here is a proposed example leaprc file with all possible defaults:
<pre>
# lines starting with a # are comments
FontName: Ariel
FontSize: 12
ForegroundColor: 100 100 100
BackgroundColor: 240 200 240
</pre>

<p>Rtest: Takes a sample RC file and correctly provides these values.

<p>Releases:
<br> 1.0 provides all anticipated functionality.

<p><li><b>IrlFile </b><p>

Constructor accepts the name of a IRL file and reads it in.
Provides a method (getVectors) that returns a JCVector or JCVectors containing
the values of the file, and another method (setVectors) that allows
the caller to set the JCVector that should correspond to this file. 
<p>
Provides two writing methods: writeIRLFile (to write the internal
representation of the file) and writeHTMLFile (to write an HTML
version of the file.)
<p>
Note that an IRL file should include, for each entry, the
project, docID, doctype, and filename.  This is needed for
the LeapDAT defect analysis tool. Maybe these are "hidden"
columns in LeapDet? 

<p>Rtest: Takes a sample IRL file name and a JCVector and
writes it out, then reads it in successfully. ALso tests HTML feature.

<p>Releases:
<br> 1.0 supports writing out an IRL file.
<br> 1.1 supports reading in an IRL file.
<br> 1.2 supports writing out an HTML file.
</ol>

<h2>Project Schedule: leap.det</h2>

<table width=100% border>
<tr><th>Class<th>Dependencies <th>Release Date <th> Author
<tr><td> LeapGUI 1.0
    <td> None
    <td> 
    <td> Cam
<tr><td> HeaderPanel 1.0
    <td> None
    <td> 
    <td> Cam
<tr><td> TablePanel 1.0
    <td> None
    <td> 
    <td> Cam
<tr><td> Done, <br> Save, <br> Load, <br> Clear, <br> AddRows, <br> DeleteRows, <br> HTML, <br> Quit buttons 1.0
    <td> None
    <td> 
    <td> Philip
<tr><td> ActionPanel 1.0
    <td> all 1.0 Buttons
    <td> 
    <td> Philip
<tr><th> LeapDet 1.0
    <td> 
    <td> Tuesday, 10/7
    <td> Philip
<tr><td> Project, <br> Document, <br> DocType, <br> DefectType 1.0
    <td> None
    <td>
    <td> Philip
<tr><td> DefaultsFile 1.0
    <td> Project et al. 1.0
    <td> 
    <td> Philip
<tr><td> LeapRcFile 1.0
    <td> None
    <td>
    <td> Cam
<tr><th> LeapDet 1.1 <br> (Command line processing)
    <td> none
    <td> Thursday, 10/9
    <td> Cam
<tr><th>  LeapDet 1.2 <br> (Initialized Header)
    <td> DefaultsFile 1.0
    <td> Friday, 10/10
    <td> Cam
<tr><td> TablePanel 1.1, <br> IRLFile 1.0 <br> (File writing)
    <td> 
    <td>
    <td> Cam
<tr><td> SaveButton 1.1
    <td> 
    <td>
    <td> Philip
<tr><th> LeapDet 1.3 <br> (Table saving)
    <td> IRLFile 1.0, SaveButton 1.1
    <td> Monday, 10/13
    <td> Philip
<tr><td> TablePanel 1.2, <br> LoadButton 1.1, <br> IRLFile 1.1
    <td> 
    <td>
    <td> Cam
<tr><th> LeapDet 1.4 <br> (File Reading)
    <td> LoadButton 1.1, IRLFile 1.1
    <td> Wednesday, 10/15
    <td> Cam
<tr><td> MailSender 1.0
    <td> None
    <td>
    <td> Jennifer
<tr><td> DoneButton 1.1
    <td> MailSender 1.0, SaveButton 1.1
    <td>
    <td> Philip
<tr><th> LeapDet 1.5 <br> (Email-enabled)
    <td> DoneButton 1.1
    <td> Friday, 10/17
    <td> Philip
<tr><td> IRLFile 1.2 <br> (HTML writing)
    <td> 
    <td>
    <td> Cam
<tr><th> LeapDet 1.6 <br> (HTML enabled)
    <td> IRLFile 1.2
    <td> Monday, 10/20
    <td> Cam
<tr><td> TablePanel 1.3, <br> AddRows 1.1 <br> DeleteRows 1.1
    <td> 
    <td>
    <td> Philip
<tr><th> LeapDet 1.7 <br> (Row manipulation)
    <td> 
    <td> Wednesday, 10/22
    <td> Philip


</table>



    <hr>
    <address><a href="mailto:johnson@natasha.ics.Hawaii.Edu">Philip Johnson</a></address>
<!-- Created: Wed Oct  1 08:09:22 HST 1997 -->
<!-- hhmts start -->
Last modified: Tue Oct 14 11:18:52 HST 1997
<!-- hhmts end -->
  </body>
</html>
