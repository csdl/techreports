%%% \documentstyle [12pt,/group/csdl/tex/definemargins,
%%% /group/csdl/tex/lmacros]{report}
%%% \input{/home/3/dxw/c/tex/psfig}
%%% \special{header=/group/csdl/tex/psfig/lprep71.pro}
%%% \begin{document}
%%% \ls{1.2}
%%% 
%%% \tableofcontents
%%% \newpage
%%% \pagenumbering{arabic}

\setcounter{chapter}{7}
\chapter{Conclusions}
\label{sec:conclusions}

This chapter concludes the dissertation --- the first step of the CLARE
journey. It attempts to provide a retrospective view of what has been done
thus far and a prospective view of what is still ahead. It begins by
summarizing the current work by providing a RESRA representation of the
major thematic features of this dissertation. Next, it highlights the main
contributions of CLARE to the emerging field of computer-supported
collaborative learning. And finally, it identifies a number of directions
--- both short and and long-term --- in which the representation,
implementation, and experimentation of CLARE might be extended.


\section{A RESRA representation of this dissertation}
\label{sec:c8-summary}

CLARE concerns collaborative learning from scientific text, to which this
dissertation unquestionably belongs. Hence, it is only fair to conclude
this work by applying the principles proposed herein to itself. Below is a
summarization of the major themes of the current research expressed in
terms of RESRA. The relationships between these nodes are depicted in
Figure \ref{fig:resra-of-clare}:

\small
\begin{itemize}
\item {\sf CLARE: the approach, the system, and the empirical results
  (\fbox{{\sf source}})\/}: D. Wan: {\it CLARE: a computer-based
  collaborative learning environment based on the thematic structure of
  scientific text.\/} Ph.D. Dissertation, University of Hawaii,
  Interdisciplinary Program in Communication and Information Sciences,
  1993.
  
\item {\sf Limitations of access-oriented CSCL systems (\fbox{{\sf
  problem}})\/}: Most existing CSCL systems are either access-oriented
  (e.g., virtual classroom systems such as CoSy at Open University \cite
  {Mason89}), or media-oriented (e.g., hypermedia systems such as
  Intermedia at Brown University \cite{Landow90Hypertext}).  Although these
  systems are found effective in overcoming the geographical, temporal, and
  media constraints of traditional face-to-face interactions, they do not
  provide support for explicit, fine-grained representation of the thematic
  structure of learning artifacts, electronic or printed. The lack of such
  representation is in part responsible for such problems as {\it
  information overload\/} in virtual classroom systems and {\it
  lost-in-the-hyperspace\/} in hypermedia systems.
  
\item {\sf CLARE's approach to collaborative learning (\fbox{{\sf
  method}})\/}: CLARE is a new approach to collaborative learning based
  on the assimilation theory of cognitive learning and the content of
  scientific text. It defines a particular type of learning called {\it
  collaborative learning from scientific text} that treats research
  literature as a basis for knowledge construction. Learning in this
  context requires learners to reconstruct the conceptual structure of
  research papers, to uncover inconsistencies, gaps, and other clues for
  new inquiry, to collaboratively deliberate reasoning behind each
  learner's positions, and to connect together similar points of view to
  form a coherent group knowledge base. CLARE comprises three components:

  \begin{itemize}
  \item A thematically-oriented representation language called RESRA;
    
  \item A collaborative learning model called SECAI; and
    
  \item A distributed computational environment that provides:
    \begin{itemize}
    \item Integrated support for RESRA and SECAI;
      
    \item Hypertext-based interface to scientific text; and
      
    \item Fine-grained, unobtrusive instrumentation of the learner's
      usage behavior.
    \end{itemize}
  \end{itemize}
  
\item {\sf RESRA (\fbox{{\sf concept}})\/}: RESRA stands for {\it
  REpresentational Schema of Research Artifacts\/}. It is a
  representational language for characterizing the thematic structure of
  scientific text and guiding collaborative knowledge construction among
  learners. It has two main components: node and link primitives for
  describing individual thematic features, and canonical forms (CRFs) for
  capturing artifact-level structures of scientific text.

%%%  RESRA is intended to serve as a meta-cognitive
%%%  framework for artifact-based collaborative learning.
  
\item {\sf SECAI learning model (\fbox{{\sf concept}})\/}: SECAI
  represents the abbreviations of five key activities in collaborative
  learning from scientific text: {\it Summarization\/}, {\it
  Evaluation\/}, {\it Comparison\/}, {\it Argumentation\/}, and {\it
  Integration\/}. These activities are organized into two phases: {\it
  exploration\/} and {\it consolidation\/}.  Exploration encompasses the
  first two activities and is performed privately by individual
  learners. Consolidation consists of the remaining three activities. It
  involves direct interactions among learners mediated through CLARE.
  
\item {\sf CLARE represents an viable approach to support collaborative
  learning (\fbox{{\sf claim}})\/}: CLARE is a viable environment for
  supporting collaborative learning from scientific text. The viability
  of CLARE is based on the viability of its individual components, such
  as RESRA and SECAI, and the environment as a whole.
  
\item {\sf RESRA is a useful representational basis for guiding
  collaborative learning (\fbox{{\sf claim}})\/}: RESRA is a useful
  language for mapping essential features of scientific text. It also
  provides structural model for guiding collaborative learning
  activities, such as evaluation, comparison, argumentation, and
  integration of different interpretations and points of view held by
  individual learners.
  
\item {\sf Evaluation experiments on CLARE (\fbox{{\sf method}})\/}: The
  evaluation of CLARE consists of five sets of experiments involving 24
  students from two different computer science classes (one undergraduate
  and one graduate). Five research papers in software engineering were
  used in these experiments. The subjects represent a convenient instead
  of a random sample.
  
\item {\sf Outcome, process, and assessment data from the CLARE
  experiments (\fbox{{\sf evidence}})\/}: The CLARE experiments resulted in
  a total of 16 group databases that contain about 1,800 nodes and 400
  kilobytes of learner-created text. The process data consists of about 80,
  000 timestamps gathered during the CLARE evaluation. The assessment data 
  consists of 64 post-session questionnaires.
\end{itemize}
\normalsize

\begin{figure}[hbtp]
 \fbox{\centerline{\psfig{figure=Figures/resra-of-clare.eps,width=5.0in}}}
 \caption{A RESRA representation of the major themes of this dissertation}
  \label{fig:resra-of-clare}
\end{figure}

This dissertation belongs to the CRF category of {\it concept paper\/}, for
it ``involves a new conception of a problem, or a new method, technique, or
approach to solving an existing problem, or often, both.'' The extensive
empirical component of this research is treated as the \fbox{{\sf
evidence\/}} in support of this approach.

It should be noted that the focus of the above representation is on the
artifact-level major themes. Its purpose is to serve as an overview of the
entire work. Individual chapters have their own major themes and
corresponding RESRA representation but they are omitted here.


\section{Main Contributions}
\label{sec:c8-contributions}

In sum, CLARE has made the following four major contributions to the field
of computer-supported collaborative learning:

\begin{enumerate}
\item It defines a new type of collaborative learning called {\it
  learning from scientific text} which links knowledge-building in the
  scientific community and knowledge-building in the classroom setting
  via collaborative interpretation and evaluation of the thematic feature
  of scientific text.
  
\item It introduces a new knowledge representation language called RESRA
  that is based on the thematic structure of scientific text, and that
  provides a structural model for evaluation, comparison, deliberation, and
  integration of different interpretations of scientific text.
  
\item It provides a theory-based, distributed collaborative learning
  environment called CLARE that integrates SECAI, RESRA, an
  instrumentation mechanism, and a hypertext-based interface.
  
\item It describes evaluation experiments that provide useful empirical
  insights on the learner's behavior in using the RESRA representation and
  the system. They also provide a rich data source for guiding further
  development of CLARE and future experimentation on collaborative learning
  in general.
\end{enumerate}

The subsequent sections elaborate upon each of these contributions.


\subsection{Collaborative learning from scientific text}

Learning and research have traditionally been regarded as two quite
distinct activities: one concerns the production of new knowledge and the
other, the acquisition or transmission of existing knowledge. This view, of
course, has been challenged by constructionism, which views that learning,
like scientific research, is also knowledge-building. The contribution of
CLARE at this level is twofold. First, CLARE makes an explicit attempt to
bridge the gap between these two types of knowledge-building via scientific
text. In CLARE, scientific text is not merely a primary source of
content-level knowledge but also a primary source of meta-knowledge. CLARE
encourages learners to discover the process of scientific
knowledge-building by systematically analyzing and evaluating the thematic
structures (both intra- and inter-artifact) of research literature. By
doing so, for example, learners can come to know how researchers evaluate
their peer's work, how they engage in constructive and scholarly
argumentation, and so on. They are also encouraged to apply these
principles to their own knowledge-building practice, both as students and
as researchers.

\begin{figure}[htbp]
 \fbox{\centerline{\psfig{figure=Figures/clst.eps,width=4.5in}}}
 \caption{CLARE as an environment for supporting collaborative knowledge-building}
  \label{fig:clst} 
\end{figure}

Second, CLARE defines what collaborative learning from scientific text is
by providing an {\it explicit\/} process model called SECAI, which
specifies the five key learning activities and the relationships between
them. Moreover, it also provides explicit representational and
computational support for this process.

As depicted in Figure \ref{fig:clst}, the experimental usage of CLARE
indicates that learners spent most of their time (66\%) on the outmost
layer --- {\it summarization/evaluation\/}, and a decreasing amount of time
in the inner layers, shown by the decreasing grey level toward the
center. This usage pattern indicates that representing the thematic content
of scientific text is an important but also time-consuming step in the
SECAI process. It is also an indication that the goal of collaboratively
building a group knowledge-base is a difficult one, and much further
research still needs to be done.


\subsection{RESRA representation language}

RESRA is the conceptual basis on which CLARE is built. It provides the
essential glue that ties together different components of the system.  More
importantly, it serves as the meta-cognitive framework that guides learners
in their interpretations of scientific text, and their interactions with
each other. Although the use of the semi-structured representation to help
organize ill-structured task is nothing new, (For a survey, see
\cite{Lee91What}), RESRA has the following unique features:

\begin{itemize}
\item It is designed specifically to facilitate collaborative learning by
  providing a shared frame of reference;
  
\item It provides a fine-grained means for characterizing the important
  contents of scientific text;
  
\item The layered design of RESRA parallels to that of the SECAI learning
  model, which gives RESRA additional flexibility and understandability;
  
\item The canonical RESRA forms (CRFs) provides a means to characterize
  common artifact-level thematic structures of scientific text; and
    
\item RESRA is an open language which can be extended by both the
  designer and the learner.
\end{itemize}

Despite a wide variety of mis-interpretations and incorrect usages, the
novelty and the usefulness of RESRA has been clearly demonstrated by the
usage experience of CLARE. For example, 80\% of the learners indicated that
RESRA node primitives are very or extremely useful. Certain features of
RESRA such as CRFs are still under-utilized.


\subsection{Design and implementation of the CLARE system}

CLARE is a medium-sized, distributed collaborative learning system that is
based on the SECAI learning model and the RESRA language. The novelty and
contribution of this system reside in the following features:

\begin{itemize}
\item {\it CLARE is grounded in a well-established learning theory.\/}
  The design of the system is based on the theory of cognitive learning
  that is successfully applied to traditional classroom settings
  over the past three decades \cite{Novak84}. One main benefit of such an
  approach is the consistency and comparability it permits with existing
  practice and other systems that share the same theoretic principles.
  For example, since concept mapping and CLARE are both based on
  cognitive learning theory, they can co-exist in a given learning
  context, and the learning outcomes from these two processes can be
  compared.
      
\item {\it CLARE is an evaluable system.\/} CLARE was designed to support
  rigorous empirical experimentation on collaborative learning.  To this
  end, it provides a built-in, fine-grained instrumentation mechanism that
  unobtrusively keeps track of such information as functions the user
  invokes, and the time and sequence in which these functions are invoked.
  During the CLARE experiments, for example, over 80,000 timestamps were
  collected.  Such process-level data is instrumental in understanding the
  detailed behavior of the users during their interactions with the system.
  
\item {\it CLARE is an extensible system.\/} Learning is an
  ill-structured problem domain, and collaborative learning is particularly
  so because of group dynamics involved. To accommodate these requirements,
  CLARE adopts a combination of a layered architecture and an
  object-oriented design which, along with the flexibility of the Emacs
  editing environment, makes CLARE an extensible system.
\end{itemize}


\subsection{Empirical evaluation of CLARE}

Five sets of experiments were conducted as part of the CLARE evaluation.
In general, these experiments resulted in primary data about the potential
of this new technology and new group process, and shed light on the
strengths and weaknesses of the approach. Specifically, these experiments
provide evidence in support of the following claims:

\begin{itemize}
\item CLARE is a viable tool for supporting collaborative learning
  from scientific text;
  
\item CLARE provides a useful means of allowing learners to {\it objectify\/}
  both the content and the process of learning from scientific text;
  
\item RESRA is useful in highlighting different points of view among
  learners;
  
\item RESRA primitives are found useful for {\it mapping\/} the thematic
  features of research literature; and
  
\item The SECAI learning model facilitates the formation of individual
  views on a research artifact.
\end{itemize}

The experiments also reveal a number of problems about the RESRA
representation, the CLARE system, and collaborative learning in general:

\begin{itemize}
\item RESRA is subject to many interpretations;
  
\item {\it Major themes\/} of a research paper were missed but its {\it minor
  themes\/} were represented;
  
\item The {\it major themes\/} of a research paper were often missed by
  entire groups of learners;
  
\item CRFs were used by only a fraction of learners;
  
\item The CLARE interface, especially the link mode, is still
  {\it less-than-intuitive\/} to the novice user; and
  
\item Collaborative learning with CLARE is time-consuming.
\end{itemize}

CLARE is still in an early stage of evolution. Hence, the lessons learned
from the current experiments are of particular importance, for they form a
basis on which future work will be performed. Uncovering the above problems
is an important part of the contribution of this research. The next section
presents several potential ways of addressing the above mentioned issues
and a number of new directions for further exploration.


\section{Where CLARE is heading}
\label{sec:future-directions}

This dissertation has raised more questions than it has answered. In many
ways, it represents only a small step toward a new paradigm of
computer-supported collaborative learning. Some basic questions it has
raised are: why does it seem so difficult to many learners to {\it map\/} the
content of an artifact to a representation such as RESRA, as evidenced from
the CLARE experiments? Where is the bottleneck: comprehension,
understanding of RESRA, analysis, synthesis, articulation, or any
combination of these factors? Does the use of RESRA truly enhance the
understanding of scientific text? If so, how? If not, why? To answer these
and many other similar questions require a more refined RESRA, a more
robust CLARE, and additional experimentation. The purpose of this section
is to suggest several ways in which RESRA and CLARE can be enhanced, and
more rigorous experiments can be performed. It begins by identifying some
short-term goals in these areas, followed by a number of long-term
directions.

\subsection{Short-term goals}

This section identifies a number of immediate enhancements to CLARE. Most
of these extensions are direct response to the findings from the evaluation
experiments. The section is organized into three parts: RESRA, CLARE, and
experimentation.

\subsubsection{RESRA}

At the RESRA level, the evaluation indicates that the major problem
learners encountered is related to the interpretation of the primitives.
The following measures are aimed primarily at alleviating this problem:

\begin{itemize}
\item {\it Categorization of common representation errors}: This will
  be a continuation of the work that has already started in Section
  \ref{common-errors}. The focus will be on consolidating various types
  of representation errors into a list of generalized error types with
  representative examples. These incorrect usage examples will be made
  available in CLARE as part of online examples.
  
\item {\it Guidelines on the usage of RESRA}: The four main areas of
  confusion on the use of RESRA are:

  \begin{enumerate}
  \item Distinction between the {\it major themes\/} and {\it minor themes\/};
    
  \item Granularity of representation;
    
  \item Distinction between {\it learners' views\/} and the {\it authors'
    views\/} during summarization; and
    
  \item Distinction between connotative and denotative interpretations
    of RESRA primitives. 
\end{enumerate}
  
Specific guidelines will be provided to detail how each of the above
situations be handled. Examples derived from the actual database will
also be supplied.
  
\item {\it Explicit support for representation-level deliberation\/}: A
  new slot, called {\it learning type\/}, will be added to all existing
  RESRA node primitives. This slot will initially take only two values:
  {\it content\/} (default) or {\it meta\/}. For example, with this
  extension, a learner can make a claim about a RESRA primitive by
  creating a \fbox{{\sf claim}} node, and then set the {\it learning
  type\/} slot to {\it meta.\/} CLARE will provide querying and
  comparison capabilities on this slot, for example, ``list all
  meta-level \fbox{{\sf question}} nodes created by user {\bf X}.''
  
\item {\it Refinement of online examples}: Real examples of RESRA
  instances offer a concrete way of illustrating what a good RESRA instance
  (for instance, \fbox{{\sf problem}}) is like. The current examples were
  not rated as adequate by the learners during the experiment. New and
  better examples will need to be introduced.
  
\item {\it Broadening and refining the current set of CRFs}: The CRF is
  still an under-utilized feature of CLARE. Its usefulness may become more
  evident when learners begin to focus their attentions on the {\it major
  themes\/} of an artifact. The existing CRFs, however, need to be extended
  to incorporate more artifact types, such as {\it case studies\/}.
\end{itemize}


\subsubsection{CLARE}

The following features are incremental extensions to the current version of
CLARE; they do not require redesign or major restructuring of the current
system. 

\begin{itemize}
\item {\it Enhancement in the reliability and robustness of CLARE}: One
  major step in this direction is to upgrade CLARE to use the most recent
  versions of EGRET and database server (HBS), both of which have
  improved reliability and performance.
  
\item {\it Improvement to the CLARE interface}: A short-term solution to
  the CLARE interface problem is to incorporate an auxiliary graphical
  browser that possesses the following functionalities:

  \begin{itemize}
  \item Link creation by direct selection of the source and destination
    nodes;
    
  \item Typed icons for predefined RESRA node primitives;
    
  \item Node selection, deletion, locking, unlocking by direct
    manipulation.
  \end{itemize}
  
  This browser will be used in conjunction with the existing
  CLARE's buffer-based interface.
  
\item {\it Enhancement to the comparison mode}: The assumption behind the
  current CLARE comparison mode is (1) the number of nodes created by each
  learner is small; and (2) learners focus on the representation of the
  major themes of an artifact. Since the experiment reveals that learners
  often represent many minor themes and create a relatively large number
  of nodes, the comparison mode will need to be extended to provide
  following capabilities:

  \begin{itemize}
  \item To differentiate major themes from minor ones;
    
  \item For major themes, comparison are made at the
    artifact level; and
    
  \item For minor themes, comparison are made at the semantic unit
    level if the number of nodes exceeds a user definable threshold
    value, and at the artifact level otherwise.
  \end{itemize}

\item {\it Node retyping and merging}: To allow learners to change
  the type of a node, or merge two nodes into a single node, for example,
  during link creation. A further enhancement will be to make these
  capabilities available through the browser. 
  
\item {\it Search capabilities}: The initial implementation might
  restrict search only to the {\sf Subject\/} field instead of the
  entire node content.
\end{itemize}


\subsubsection{Experimentation}

There were a few limitations in the design and execution of the CLARE
evaluation experiments:

\begin{itemize}
\item {\it Absence of pre- and post-session tests.\/} No tests on
  individual learning styles or locus of control were done prior to the
  experiment. Nor were comprehension tests done after the session.
  
\item {\it Group assignment.\/} The use of existing project groups in the
  first set of experiments seems to have created certain bias on the
  result.
  
\item {\it Improper selection of research papers.\/} For example, the
  first paper used in the experiment was considered as too long.
\end{itemize}


The following recommendations will help lead to better CLARE
experimentation:

\begin{itemize}
\item {\it Explicitly defined independent and dependent variables}: These
  variables are based on the hypotheses to be tested. Example independent
  variables are: summarization strategies and the number of passes over the
  source nodes. An example dependent variable is the instructor-assigned
  quality rating on the learning artifact generated.
  
\item {\it Careful selection of artifacts:\/} The content, style, length,
  and type of artifacts used need to be carefully weighted according to the
  learner's background.
  
\item {\it True experimental design:\/} Learners are divided into
  experimental groups (CLARE users) and control groups (non-CLARE users),
  Group members are randomly assigned. Pre-tests, such as on learning
  styles, cognitive styles, locus of control, are conducted when necessary.
  Learning outcomes are measured quantitatively (e.g., instructor assigned
  ratings on the quality of the artifact produced), and qualitatively,
  such as learners' perceived usefulness of CLARE features.
  
\item {\it Training and pilot testing:} Pilot testing is done on
  learner groups of the same characteristics as the intended subjects.
  Both off-line and online training is provided to the first time CLARE
  users.

\item {\it Demographic data:} Such data can help answer questions such
  as whether or not there is any difference between male and female
  learners in terms of usage strategies and learning outcomes.
\end{itemize}


\subsection{Long-term directions}

This section identifies a number of long-term research directions for
CLARE. Like the previous section, it is organized into three parts: 
RESRA, CLARE, and experimentation.


\subsubsection{RESRA}

\paragraph{Domain-specific RESRA (DSR).}

RESRA is a generic representation language that can be used in various
subject domains, ranging from software engineering to organizational
behavior. The utility of RESRA can be extended by creating domain-specific
instantiation of this representation:

\begin{itemize}
\item A set of RESRA node instances, such as ``Software quality crisis''
  (\fbox{{\sf problem}}), ``Formal technical review (FTR)'' (\fbox{{\sf
  method}}), ``FTR improves software quality'' (\fbox{{\sf claim}}), and link
  instances that express the relationships between these nodes, such as
  \fbox{{\sf FTR improves software quality}} \(\stackrel{
  responds-to}{\longrightarrow}\) \fbox{{\sf software quality crisis}}; and
  
\item A set of CRFs that characterize the exemplary structure of research
  artifacts in that domain, for example, ``experience reports in software
  engineering.''
\end{itemize}

These DSR instances pertain to a particular subject matter, such as
``software engineering.'' They might be generated by previous CLARE users
or experts on the subject, such as the course instructor. They may be
linked to the original source artifact.

DSR shares the same objectives as the general-purpose RESRA: facilitating
interpretations of scientific text and collaborative deliberation of these
interpretations. Moreover, it has one advantage: because of its
domain-specificity, it provides learners more concrete guidance on how to
use the representation to interpret the content of scientific text. DSR
serves the following specific roles in collaborative learning:

\begin{itemize}
\item {\it As an {\it index\/} to the {\it core knowledge\/} of the chosen
  domain\/}: This role is especially evident when DSR instances are created
  by experts in the field.
    
\item {\it As a {\it seed knowledge-base\/}\/}: To new comers of a field or
  new students in a course, such a collection of DSR instances represent a
  starting point for exploring other research artifacts in the domain.
\end{itemize}

Like the generic RESRA, DSR is dynamic: new instances can be added when
necessary, either by designated individuals or any CLARE users.  In fact,
it is much simpler to extend DSR than to extend the generic RESRA
primitives.


\paragraph{RESRA case libraries.}

RESRA case libraries (RCL) refer to collections of actual RESRA instances.
A {\it case\/} is defined as a {\it complete\/} representation of an
artifact by a given learner. It contains not only that outcome but also the
process steps that lead to the outcome. RCL is a generalization of RESRA
examples. It differs from examples in two ways:

\begin{itemize}
\item Examples are often given as individual nodes or tuples, while RCL is
  defined at the level of artifacts and learners; and
  
\item Examples represent only the outcome, but RCL encompasses both
  outcome and the process data.
\end{itemize}

RCL is also different from domain-specific RESRA (DSR). DSR is
RESRA-centered. It selects node and tuple instances based on their domain
significance. In contrast, RCL is learner-centered and much less selective
in what to be included.

RCL is significant for three reasons. First, it supports the situated
nature of RESRA --- the correctness and soundness of RESRA interpretation
and usage are assessed within the context of the learner and the artifact
being represented. Second, it provides a learner-centered high-level
construct for viewing and analyzing learner's interpretation of RESRA and
the content of artifacts.  When supported with necessary indexing and query
capabilities, a learner can ask CLARE to show ``all existing
representations of artifact {\bf X\/} that contain at least two but no more
than five tuples and, that are ranked as {\it good\/} in quality.'' Third,
when supported with animation features of CLARE (see below), a learner can
{\it re-play \/} the process by which a given representation is derived.


\subsubsection{CLARE}

\paragraph{Advanced interface support.}

As shown in Section \ref{sec:c6-hypothesis}, CLARE interface is the most
important barrier in the current implementation. The previous section
offers a short-term solution by incorporating a graphical browser that
supplements the current buffer-based interface. In a long run, CLARE needs
to move toward a complete graphical interface, similar to systems such as
NoteCards \cite{Halasz87Notecards}. Furthermore, to realize the
representational potentials of RESRA requires support for automatic graph
layout, visualization, and animation. For example, with visualization
capabilities, learners will be able see the overall structure of an
artifact, and the structure of each learner's representation. They may also
be able to superimpose two or more learners' representations to discern
differences and similarities between them, or to zoom in to a cluster of
tuples to have a closer view of what they are.  Moreover, such tools can
also be used to visualize where in the artifact are the {\it information-rich
spots,\/} as measured by the number of summarative nodes originated from
them, and where are the {\it center of controversy,\/} or clusters of
evaluative nodes.  Similarly, learners can use animation tools to
{\it replay\/} the sequence of CLARE commands that lead to the creation of a
given node, tuple, or case.


\paragraph{Inferencing capabilities.}

CLARE is a knowledge-based system; it embeds a knowledge representation
language (RESRA) and structural knowledge about selected scientific text
(CRFs). It currently provides a simple {\it advise\/} feature that, based
on the system's knowledge about the current artifact, the corresponding CRF
definition, and what the learner has done so far, suggests to the learner
what node and/or tuple to consider next. This feature may be extended to
support inferencing capabilities. For example, if a learner attempts to
create a link between a \fbox{{\sf method}} and \fbox{{\sf problem}}, and
the corresponding CRF contains the tuple \fbox{{\sf method}} \(\stackrel{
generates}{\longrightarrow}\) \fbox{{\sf evidence}}, CLARE may suggest to
the learner to consider changing the \fbox{{\sf problem}} to \fbox{{\sf
evidence}}. Similarly, CLARE may send a warning message to a learner if,
based on the analysis of its sentence structures, a \fbox{{\sf question}}
node he just created does not seem like a question.


\paragraph{Integration with other learning environments}

CLARE currently supports one particular type of learning --- learning from
scientific text. There are also many other types of learning, two of which
are listed below:

\begin{itemize}
\item {\it Project-based learning:\/} A form of {\it learning-by-doing\/}
  that is commonly found in science classes, for example, doing a physics
  or chemistry experiment. Systems such as CoVis \cite{Pea93} provide
  explicit support for such learning;
  
\item {\it Intentional learning:\/} A type of writing-oriented learning
  with particular emphasis on the deliberation of the reasoning behind each
  position the learner takes. CSILE is an environment for supporting
  intentional learning \cite{Scardamadia93}.
\end{itemize}

A learning setting such as a college-level biology class typically involves
a combination of several types of learning. Based upon the current state of
technology, however, it will require learners to use several systems at the
same time, which is often neither economically feasible, nor pedagogically
productive. Therefore, integrated learning environments, which can bring
together systems such as CLARE and CSILE, are called for.


\subsubsection{Experimentation}

\paragraph{Longitudinal field studies.}

At an empirical level, one major challenge facing CLARE is to find
institutional settings in which longitudinal studies (similar to those done
by the CSILE team \cite{Scardamadia93}) can be carried out. Such studies,
which may typically last for a semester or longer, will be conducted
as part of normal requirements of the selected courses. Research artifacts
to be used will be selected directly from the course reading list.
Experiment and control groups will be employed so that differences in their
learning outcomes, as measured by their understanding of the materials and
the quality of the artifacts produced, can be assessed. The results from
these studies will show the effect of CLARE on the learning process and
outcome under the intended usage setting.


\paragraph{Comparative studies.}

Under the above experimental settings, a number of control methods can be
used to assess the impact of different independent variables:

\begin{itemize}
\item {\it Type of research artifacts:\/} Good candidates include
  conceptual, opinion, and empirical papers.
  
\item {\it Subject domain:\/} The subject matter of learning may range
  from literature to computer science and zoology. 
  
\item {\it Learner backgrounds:\/} Selecting learners from different
  academic majors: science, engineering, social sciences, humanities, and
  so on.
  
\item {\it Expert-novice users:\/} Compare expert CLARE users with the
  ones who are the first-time users to determine whether different
  strategies are used.
\end{itemize}

In addition, experiments may also be conducted to compare CLARE with other
learning methods, such as concept mapping. The problem, however, is that
these methods are not always comparable. For example, concept maps are
rarely used to support collaborative learning. On the other hand,
RESRA/CLARE was designed primarily for such a purpose. Hence, to compare
them empirically requires one to {\it scale-down} RESRA by omitting its
evaluative primitives, or {\it scale-up\/} concept maps to equivalent
functionality of RESRA. Fortunately, the former is relatively easy to do.

%%% \newpage
%%% \singlespace
%%% \bibliography{../bib/clare,../bib/cscl-systems}
%%% \bibliographystyle{alpha}
%%% 
%%% \end{document}





