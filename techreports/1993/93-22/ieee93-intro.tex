%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ieee93-intro.tex -- 
%% RCS:            : $Id: ieee93-intro.tex,v 1.7 93/12/27 10:43:10 johnson Exp Locker: johnson $
%% Author          : Philip Johnson
%% Created On      : Mon Dec  6 13:15:19 1993
%% Last Modified By: Philip Johnson
%% Last Modified On: Fri Nov 25 09:19:20 1994
%% Status          : Unknown
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 1993 University of Hawaii
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%% History
%% 6-Dec-1993		Philip Johnson	
%%    

\section{Introduction}


Formal technical review (FTR) involves the bringing together of a group of
technical personnel to analyze an artifact of the software development
process, typically with the goal of discovering errors or anomalies, and
always results in a structured document specifying the outcome of review.
Beyond this general similarity, specific approaches to FTR exhibit wide
variations in process and products, from Fagan Code Inspection
\cite{Fagan86}, to Active Design Reviews \cite{Parnas85}, to Phased
Inspections \cite{Knight93}.  

Past research shows that FTR provides unique and important benefits.  Some
studies provide evidence that FTR can be more effective at catching errors
than testing, and that it can discover different types of errors than
testing \cite{Basili85}. 

In concert with other process improvements, Fujitsu finds FTR to be so
effective at removing defects that they have dropped system testing from
their software development procedure \cite{Arthur93}.  FTR is an integral
part of all current methods intended to produce very high quality software,
such as Cleanroom Software Engineering, and is present at all higher levels
of the SEI Capability Maturity Model \cite{Paulk93}.

Although the software engineering research literature contains many FTR
``success stories'', it is by no means ubiquitous within industrial
software engineering practice.  In fact, evidence suggests quite the opposite. For
example, in an informal survey of USENET readers on FTR, approximately 80\%
of 70 respondents replied that FTR is practiced irregularly or not at all
within their organization.

We believe that the poor rate of adoption of FTR within industry has its
roots in two fundamental properties of current FTR practice: it is manual,
and it is not measured. These two properties are actually related: because
FTR is manual, it is almost always too difficult and expensive to measure
effectively.  And because FTR is not measured effectively, it is difficult
to justify to management, difficult to justify to technical staff, and
difficult to customize to facilitate successful adoption and
cost-effectiveness within an organization's particular development style
and application domains.

As evidence, the first ``lesson learned'' from 6000 manual FTR
experiences at Bull HN Information Systems is that precise measurements are
usually too difficult and expensive to collect \cite{Weller93}. As Weller
puts it, ``you may have to sacrifice some data accuracy to make data
collection easier.''

In this paper, we describe our current research findings on highly
instrumented, computer-supported formal technical review.  The first
``lesson learned'' from our experiences is that you do {\em not} need to
sacrifice data accuracy to make data collection easier, because with a
computer-supported review system, highly accurate data can be collected
automatically.

We have demonstrated this through the design, implementation, and
evaluation of CSRS\foot{\underline{C}omputer-\underline{S}upported
\underline{R}eview \underline{S}ystem}, a collaborative environment for
formal technical review \cite{csdl-93-17,csdl-94-03}.  
CSRS contains novel instrumentation for precise,
high quality measurements of FTR process and products, along with analysis
tools to facilitate process improvement based upon these empirical
findings.  The studies reported in this article were based upon one
specific FTR method defined within CSRS, called
FTArm\foot{\underline{F}ormal, \underline{T}echnical,
\underline{A}synchronous \underline{r}eview \underline{m}ethod}.  However,
CSRS provides a method definition language that allows it to enact a wide
range of review methods.  Over the past two years, we have carried out
laboratory studies of FTR using CSRS that we have analyzed to improve the
environment itself and to gain new insight into FTR. Currently, we are
readying the environment, instrumentation, and analysis tools for guided
technology transfer into a select number of industry sites.

This paper discusses how to ``design for instrumentation'' in the domain of
formal technical review.  It describes how requiring high quality
measurement impacts upon the nature and scope of our system, as well as how
this requirement led to qualitatively different and better insight into our
computer-mediated group process.

Section \ref{sec:csrs} orients the reader to our system via selected
excerpts from a recent FTR experience using CSRS.  (Appendix
\ref{sidebar:csrs} provides more details about the CSRS data and process
model.)  Section \ref{sec:metrics} describes the CSRS instrumentation
with examples of the measurements of FTR process and products collected by
CSRS.  Section \ref{sec:applications} describes how these measurements are
utilized to generate new knowledge about FTR and devise improvements in its
process and products. Section \ref{sec:related} discusses related research,
and Section \ref{sec:design} summarizes the major
lessons we have learned from our efforts to design for instrumentation.


