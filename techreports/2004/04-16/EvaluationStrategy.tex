\chapter{Research Designs and Evaluation Strategies}
\label{Chapter:EvaluationStrategy}


There are a variety of possible approaches to empirical evaluation of the claims made in this dissertation. This chapter provides an overview based on the book \textit{Research Design: Qualitative, Quantitative, and Mixed Methods Approaches} \cite{Creswell:2003} by J. W. Creswell. My approach to the evaluation of software project telemetry is based on concepts and techniques presented in that work.  

This chapter starts with a brief review of approaches to evalution in Section \ref{EvaluationStrategy:Review} followed by a discussion of software project telemetry with respect to its evaluation strategies in Section \ref{EvaluationStrategy:Strategy}. The evaluation of software project telemetry is carried out in 3 case studies. Section \ref{EvaluationStrategy:CaseStudyOverview} gives a brief overview of each case study.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   Research Method Review
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Review of Research Designs} \label{EvaluationStrategy:Review}

Creswell \cite{Creswell:2003} categorizes research methods into 3 paradigms: quantitative, qualitative, and mixed methods. Each paradigm has different philosophical assumptions about what constitutes knowledge.

\textit {The quantitative paradigm} is related to \textit{postpositivism}\footnote{\textit{Postpositivism} differs from \textit{positivism} by recognizing there is no absolute truth. A hypothesis can never be proved. It is accepted by failing to reject it.}, which is often labeled as ``the traditional way of doing scientific research''. Postpositivism seeks to develop relevant true statements that can explain a situation or describe a causal relationship. The research is the process of making claims and using data and evidence to test hypotheses.

\textit{The qualitative paradigm} is related to \textit{constructivism}. It assumes that individuals seek understanding of the world in which they live to develop subjective meanings of their experiences. Qualitative research relies much on the participants' views of the situation being studied. It tends to use open-ended questions to allow the participants to express their views. 

\textit{The mixed methods paradigm} is related to \textit{pragmatism}, in which knowledge claims arise out of actions, situations, and consequences rather than antecedent conditions (such as in postpositivism). Instead of methods being important, the problem itself is the most important. As a result, mixed methods researchers do not subscribe to any single system of philosophy. They use both quantitative and qualitative data to best understand the problem and find solutions.


\subsection{Quantitative Research Paradigm}

A quantitative paradigm is one in which a researcher uses postpositivism approaches to acquire knowledge. The knowledge is conjectural in nature. The researcher tests a theory by specifying narrow hypotheses, collecting closed-ended data on predetermined instruments, and using statistical procedures to analyze the data to either support or refute the hypotheses. Typical inquiry strategies are surveys and experiments.

A survey can provide quantitative description\footnote{A survey can also gather qualitative information depending on the questions it asks.} of trends, attitudes, or opinions of a population by studying a sample of that population. The purpose is to generalize the results, so that inferences can be made about some characteristic, attitude, or behavior of the population \cite{Babbie:1990}. The main advantage of a survey is the economy of design and the possibility of rapid turnaround in data collection. 

In an experiment, a researcher may also select a sample and generalize the results to a population. However, the basic intent of an experiment is to test the impact of a treatment on an outcome, controlling for all other factors that might influence that outcome. There are many different experimental designs, ranging from true experiments (with random assignment of subjects), quasi-experiments (non-randomized designs), to correlation studies. 


\subsection{Qualitative Research Paradigm}

A qualitative paradigm is one in which a researcher makes knowledge claims based primarily on constructivism perspectives, such as multiple meanings of individual experiences, and socially or historically constructed meanings. The paradigm has its roots in cultural anthropology and American sociology. 

The intent of qualitative research is to understand a particular situation, event, role, group, or interaction from the views of the participants. As a result, a qualitative researcher collects data through open-ended questions or by observing the participants' behaviors. The research is largely an investigative process where the researcher gradually makes sense of a phenomenon by contrasting, comparing, replicating, cataloging and classifying the objects of study \cite{Miles:1994}.

A major factor that distinguishes qualitative methods from quantitative methods is that a researcher is not prescribing the questions that need to be answered from his/her standpoint. Instead, the researcher tries to learn from the participants. Other unique characteristics include:

\begin{itemize}
	\item Qualitative research takes place in natural settings where human behavior and events occur.
	\item Qualitative research is based on assumptions very different from quantitative research. Theories or hypotheses are established \textit{a posteriori} instead of \textit{a priori}.
	\item Qualitative research uses multiple interactive methods which includes open-ended questions, observations, and interviews.
	\item Qualitative research focuses on the participants' perceptions and experiences, as well as their understanding of the world in which they live and work.
	\item Qualitative research is emergent rather than tightly prefigured. 
	\item Qualitative data are usually descriptive, in the form of text rather than numbers. They are fundamentally interpretive.
\end{itemize}

A primary reason for conducting a qualitative study is that the research is exploratory in nature. The researcher seeks to listen to the participants in order to build an understanding based on their ideas and views. Ethnography and case study are the two commonly used methods.

In ethnography, the researcher studies an intact group of people in a natural setting over a prolonged period of time. The intent is to obtain a holistic picture of how people describe and structure their world by observing and interviewing them. The research process is flexible and typically evolves contextually in response to the lived realities encountered in the field setting \cite{LeCompte:1999}.

In a case study, the researcher explores in depth a program, an event, an activity, a process, or one or more individuals, by collecting detailed information using a variety of procedures over a sustained period of time. The case is always bounded by time and activity.

Other methods include grounded theory \cite{Strauss:1998}, phenomenological research \cite{Moustakas:1994}, and narrative research \cite{Clandinin:2000}.

%There are many established ways conducting qualitative inquiry. For example, 28 approaches are identified in \cite{Tesch:1990}, and 19 typed are identified in \cite{Wolcott:2001}.  



\subsection{Mixed Methods Research Paradigm}

A mixed methods paradigm is one in which a researcher bases knowledge claims on pragmatic grounds. Knowledge claims arise out of actions, situations, and consequences rather than antecedent conditions. To mixed methods researchers, understanding the problem and finding the solutions are more important than methodology. As a result, they are not committed to any single methodology. They use both quantitative and qualitative data to meet their needs and purposes. 

According to Creswell \cite{Creswell:2003}, the idea of mixing different methods probably originated in 1959 when Campbell and Fiske used multiple methods to study validity of psychological traits. They encouraged others to employ their ``multimethod matrix'' to examine multiple approaches to data collection in a study. This prompted others to mix methods, and soon approaches associated with field methods such as observations and interviews (qualitative data) were combined with traditional surveys (quantitative data). Important works in this field include \cite{Rorty:1990, Murphy:1990, Patton:1990, Cherryholmes:1992, Tashakkori:1998}.

In fact, the situation today is less quantitative versus qualitative and more how research practices lie somewhere on a continuum between the two \cite{Neuman:1998}. The best that can be said is that studies tend to be more quantitative or qualitative in nature.

A major factor that distinguishes mixed methods paradigm from others is that it is problem centered and real world practice oriented. Other unique characteristics include:

\begin{itemize}
	
	\item A mixed methods researcher does not mix different methods blindly. There is always a purpose for ``mixing'', i.e. a rationale for the reasons why quantitative and qualitative data need to be mixed in the first place. 
	
	\item A mixed methods researcher is ``free'' to choose the methods, techniques, and procedures of research that best meet their needs and purposes, rather than subscribing to only one way (e.g. quantitative or qualitative).
	
	\item A mixed methods researcher uses both quantitative and qualitative data because they work to provide the best understanding of a research problem. 
	
\end{itemize}

%For mixed methods researchers, pragmatism opens the door to multiple methods, different world views, and different assumptions, as well as to different forms of data collection and analysis in mixed methods studies \cite{Creswell:2003}.

In this dissertation, I \textcolor{red}{will follow} the mixed methods approach to empirical evaluation of software project telemetry. The rationale is given in Section \ref{EvaluationStrategy:Strategy:Methodology}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   SPT evaluation strategy
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Evaluation of Software Project Telemetry} \label{EvaluationStrategy:Strategy}

The evaluation of software project telemetry consists of 3 case studies in different settings. This section discusses general strategies and procedures. 
A brief overview of each case study is provided in the next section (Section \ref{EvaluationStrategy:CaseStudyOverview}). 
The specific details are reported in the next 3 chapters (Chapter \ref{Chapter:EvaluationInClassroom}, \ref{Chapter:EvaluationInCSDL}, and \ref{Chapter:EvaluationInIkayzo}) respectively.


\subsection{Bounding the Study}

Software project telemetry is a novel approach to metrics-based project management and process improvement. It attempts to lower metrics collection cost by using sensors to collect metrics automatically and unobtrusively, and facilitate metrics analysis by providing high level telemetry perspectives of development process. The main thesis of this research is that software project telemetry provides an effective automated approach to in-process, empirically-guided software development process problem detection and analysis.
%Project management and process improvement are enabled through cycles of process problem detection, process improvement hypothesis generation, corrective measure implementation, and hypothesis validation. 

Software project telemetry is a young technology, and as such this evaluation is an exploratory study with the purpose of understanding how software metrics participate in project management and process improvement decision-making and how software project telemetry provides or fails to provide metrics collection and analysis support. There are many competing metrics-based approaches to project management and process improvement, such as PSP, TSP and CMM. It is not the goal of this evaluation to compare software project telemetry to other approaches. It is my belief that each approach has its own unique strengths and weaknesses, and a comparative study is best performed after a good understanding of software project telemetry has been acquired. Therefore, an important part of this evaluation is to examine the application of software project telemetry in different software development environments and find out what works, what doesn't, and how the technology can be further improved.

Software development environments are diverse, and each may have different development processes and constraints on metrics collection and analysis. For example, at one end of the spectrum, there are tightly controlled environments such as those in classroom or experimental settings where it is possible to control the development process to the finest details. At the other end of the spectrum, there are free open-source projects collaborated on by geographically dispersed volunteer developers where project leaders have little control over individual developers. In the middle are the more traditional team-oriented software development environments.

The goal of this evaluation is to study the application of software project telemetry in different development environments. I categorize different environments according to how easily the technology and practice of software project telemetry can be introduced to the development team. I \textcolor{red}{have identified} three different but representative locations along this dimension in which to conduct case studies:

\begin{itemize}
	\item \textit{Classroom} --- The environment of the software engineering class taught by Dr. Philip Johnson at the University of Hawaii lies at one end of the spectrum. There is no technology adoption barrier. By curriculum design, students are required to install the sensors to collect their software product and process metrics and to use software project telemetry system to perform metrics analysis.
	
	\item \textit{CSDL} --- The environment of the Collaborative Software Development Lab at the University of Hawaii lies somewhere in the middle of the spectrum. It is typical of traditional software development environments. The project is collaborated on by a team of developers at the same location. A project manager controlls the overall direction. The use of software project telemetry as a metrics-based approach to project management and process improvement is endorsed by the manager and the developers. They are willing to try the technology but will commit to it only if it can be proved useful.
	
	\item \textit{Ikayzo} --- The Ikayzo environment lies at the opposite end of the spectrum. Ikayzo provides free hosting services to open source projects. It is similar to \textit{sourceforge.net} except much smaller in size. Ikayzo uses software project telemetry system to provide automated metrics collection and analysis support to the hosted projects, but does not participate in decision-making of the projects (including metrics application) in any way.
	
\end{itemize}

The experience gained from the application of software project telemetry in these three different software development environments will paint a holistic picture which helps me better understand the technology.

%% Central goveranance, tightly controlled  <==> Self goverance, loosely controlled 


\subsection{Evaluation Methodology} \label{EvaluationStrategy:Strategy:Methodology}

%-to converge or confirm findings form different data source - triangulating different quantitative and qualitative data sources.
%-problem centered and real world practice oriented

I \textcolor{red}{will} adopt the mixed methods research paradigm, collecting and analyzing both qualitative and quantitative data, while evaluating software project telemetry. A high priority \textcolor{red}{will be} given to qualitative information. The justifications are provided below:

To a large extent software engineering is about how people interact with each other and interact with tools to product software products. Software project telemetry is no exception. It is a metrics-based approach to project management and process improvement. It is designed to automate tedious metrics collection tasks and provide metrics analysis support through high level telemetry perspectives on the development process. It is not designed to replace human judgment in project decision-making. An important goal of the evaluation is to understand how software project telemetry provides metrics collection and analysis support and how project managers and developers interact with the technology to make decisions. As a result, a naturalistic approach and qualitative data analysis are consistent with the overall goal of this evaluation (i.e. exploration of a phenomenon). %survey and ethnography

Quantitative information such as the actual invocation of software project telemetry analysis will be used to assist or cross-validate the interpretation of qualitative findings when appropriate. The use of multiple forms of data collection and analysis have the potential to offset the weaknesses inherent within one method with the strengths of the other method. 


\subsubsection{Mixed Methods Strategies}

Creswell et al. \cite{Creswell:2003b} identifies 4 criteria for selecting an appropriate mixed methods inquiry approach: implementation, priority, integration, and theoretical perspective. I will structure the data collection, analysis, and validation procedures in my evaluation according to these criteria. The following discussion outlines the high-level strategies. They apply in full to the case studies in CSDL and at Ikayzo, but only partially to the case study in classroom which is designed to be a pilot study to gather students' opinions in a short period of time. Details with respect to each case study is presented in Chapter
Chapter \ref{Chapter:EvaluationInClassroom}, 
\ref{Chapter:EvaluationInCSDL}, 
and \ref{Chapter:EvaluationInIkayzo}.

\begin{itemize}
	\item \textit{Implementation --- What is the implementation sequence of the quantitative and qualitative data collection?}
		
Qualitative data will mostly cover how software project telemetry is used in project management and process improvement decision-making: what works, what does not work, and what can be improved. They will be collected through ethnographic observations, questionnaires, and/or interviews. 
Quantitative data will mainly cover the software project telemetry system setup and administration cost and the actual invocation of telemetry metrics analysis.
Both qualitative and quantitative data will be gathered concurrently, with the exception of the case study in the classroom where a questionnaire was distributed at the end of the semester.

	
	\item \textit{Priority --- What priority will be given to the quantitative and qualitative data collection and analysis?}
	
This evaluation is primarily designed as a naturalistic study since its purpose is to understand a phenomenon. Priority will be skewed toward qualitative information. Quantitative information will only be used to assist or cross-validate the interpretation of qualitative findings.
	
	
	\item \textit{Integration --- At what stage in the research project will the quantitative and qualitative data and findings be integrated?} %The two types of data can be integration at the data collection, the data analysis, interpretation, or some combination of places.
	
The results of the two methods will be integrated during the interpretation phase. I will either note the convergence of the findings as a way to strengthen the knowledge claims of the study or explain any lack of convergence that may result. 
	
	
	\item \textit{Theoretical Perspective ---  Will a theoretical lens or framework guide the study such as a theory from the social science or a lens from an advocacy perspective (e.g., feminism, racial perspective)?}
	
%pertinent in socialogy and psychology, but not particularly relevant to software engineering. This is not a study of how female or minority developers writing software.
I choose not to use a theoretical perspective as a lens in this study.

\end{itemize}


\subsubsection{Data Analysis Procedures}

This evaluation adopts mixed methods research paradigm with a higher priority on qualitative information. According to Schatzman and Strauss \cite{Schatzman:1973}, qualitative data analysis primarily entails classifying things, persons, events and the properties which characterize them. As a general procedure, I will organize the qualitative data from ethnographic observations, questionnaires, and interviews into categories, identify and describe patterns and themes from the perspective of the case study participants, and then attempt to understand and explain these patterns and themes. At the end of qualitative analysis, quantitative data such as software project telemetry analysis usage information will be integrated to assist or cross-validate the qualitative findings.



\subsubsection{Verification and Validation}

In order to ensure measurement validity and internal validity, the following steps will be employed:

\begin{itemize}
	\item \textit{Triangulation of data} --- Qualitative data will be collected through multiple sources such as my personal diary, questionnaires, interviews, and observations, and reconciled with each other. Quantitative data will be used to cross-validate the qualitative findings.
	
	\item \textit{Member checking} --- The case study participants will serve as a check throughout the analysis process. An ongoing dialog will be maintained with participants with respect to my interpretations of the data.
	
	\item \textit{Clarification of bias} --- My role in each case study and possible bias will be articulated in the report of each case study.
	
\end{itemize}




The primary strategy \textcolor{red}{I will use} to ensure external validity will be the provision of detailed descriptions of each case study so that anyone interested in transferability will have a solid framework for comparison \cite{Merriam:1998}. The following steps will be employed:

\begin{itemize}
	\item I will provide a detailed account of the focus of each case study, my role, the participant's position, and the context from which data will be gathered.%(LeCompte and Coetz 1984)
	
%	\item Triangulation or multiple methods of data collection and analysis will be used, which strengthens not only reliability but also internal validity \cite{Merriam:1998}.
	
	\item Data collection and analysis strategies will be reported in detail in order to provide a clear and accurate picture of the methods used in this study.
\end{itemize}















%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                       %
%                   S E C T I O N                       %
%                                                       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Overview of the Case Studies} \label{EvaluationStrategy:CaseStudyOverview}

This section provides a brief overview of each case study. The specific details are reported in Chapter \ref{Chapter:EvaluationInClassroom}, \ref{Chapter:EvaluationInCSDL}, and \ref{Chapter:EvaluationInIkayzo} respectively.

As a side note, I have completed the case study in classroom, but the case studies in CSDL and at Ikayzo are in preparation stage. The detailed schedule can be found in Section \ref{EvaluationStrategy:Schedule}.


\begin{itemize}

	\item \textbf{A pilot case study in a classroom}
	  
I have completed the first case study. It was conducted with senior undergraduate level and introductory graduate level software engineering students in 2005 Spring semester at the University of Hawaii. The study was designed to collect student feedback about software project telemetry in a short period of time. The design was the simple one shot case study. The students used software project telemetry to collect and analyze their metrics while performing software development tasks during the semester. Their invocation of telemetry analysis were recorded automatically by instrumenting the telemetry system. A survey was distributed at the end of the semester to collect their opinions with respect to how software project telemetry provided metrics collection and analysis support. The survey method was chosen because of its ease of administration, rapid turn around in data collection, and guarantee of 100\% response rate in the classroom setting. 

The limitation of this case study is mainly related to the classroom setting. The background of the students may not be representative of those of real world programmers, and class projects tend to be smaller in scope than real world projects. %I do not have the opportunity to observe how the students actually use software project telemetry to manage their projects and improve their processes. 
Despite the limitation, I was able to obtain significant insights from the student users. Details about the case study design and the results are reported in Chapter \ref{Chapter:EvaluationInClassroom}.

%The classroom environment lies at one end of the spectrum. In senior undergraduate and introductory graduate software engineering class taught by Dr. Phillip Johnson at University of Hawaii, students are required to collect and analyze their metrics while performing software development tasks. Installing the sensors to collect software product and process metrics and using software project telemetry system to analyze the metrics are mandatory since they are part of the curriculum design. 
	
% lots of study participant to listen for opinion	
%	no adoption barrier, less control, cannot observe behavior,
%	single questionnaire,
	 
	 
	 
	\item \textbf{A case study in CSDL}

I am starting the second case study. It will be conducted in Collaborative Software Development Lab at University of Hawaii, where a large scale software project (100 KSLOC) is being developed and maintained by a group of 5 to 10 active developers. The project is experiencing a significant rate of integration build failure (88 failures out of 300 builds in 2004). The goal of this case study is to apply software project telemetry process methodology to investigate and improve CSDL build process. 
	
I will customize the software project telemetry system to analyze the metrics related to quality assurance process of the developers and provide feedback. I will employ ethnography to collect detailed daily observation data, and I will interview developers on a weekly basis to detect and understand their response to telemetry feedback information. I will also collect and compare each developer's process metrics before and after the introduction of the software project telemetry feedback mechanism. Details about this case study are discussed in Chapter \ref{Chapter:EvaluationInCSDL}.

%The fact that I am a member of the project under study is both an advantage and disadvantage to the evaluation. 

%The advantage is that I have detailed knowledge about the project and meet with other developers almost on a daily basis, which enables me to collect detailed observational data and empowers me of greater insight into the development process. I have great control of the evaluation settings. I am able to fully instrument the development environment, and gather great amount of process and product metrics. I can apply software project telemetry process methodology to help the team understand and improve the current build process.

%On the other hand, the disadvantage is that I am the possible source of bias. This possible bias is addressed in several ways. First, triangulation will be used to ensure data validity. Data will be collected through multiple sources such as personal diary, interview and observation, and reconciled with each other. Second, the CSDL project member will serve as a check throughout the entire process of evaluation. An ongoing dialog will be maintained with other members with respect to my interpretations of the metrics. Lastly, sensors collect metrics automatically, which eliminates the bias in metrics collection.

%The CSDL environment lies somewhere in the middle of the spectrum. CSDL is acronym for Collaborative Software Development Lab at University of Hawaii. It has been developing and maintaining a large scale software project (100 KSLOC as of this writing) for several years. This CSDL environment is typical of traditional software development environment. The project is collaborated by a team of 5 to 10 active developers at the same location. A version control system (CVS) stores the source code; an issue management system (Jira) tracks features requirements, bugs, assigns tasks to developers; a custom-made integration system builds and tests the project automatically everyday; and code reviews are conducted on a regular basis. The project manager and the team seek to use software metrics to better understand the status and the development process of the project. The use of software project telemetry is endorsed by the management and the developers since they view it as a promising approach to metrics-based project management and process improvement. They are willing to try the technology for some period and will commit to the technology if it can prove its usefulness during the trial period.
	
% maximum control of the environment	
%	no adoption barrier, more control, can observe behavior,
%	ethonograpy, interview
	
	
	\item \textbf{A case study at Ikayzo} 

I am starting the last case study. It will be conducted in Ikayzo\footnote{http://www.ikayzo.org}. Ikayzo provides free open source project hosting services, which include source code version control, issue tracking and management, automated metrics collection and analysis, and wiki discussion. The metrics collection and analysis support is provided through software project telemetry system. Ikayzo does not participate in decision-making of the hosted projects. It cannot force the projects to adopt any metrics related technology. What it does is provide automated metrics collection and analysis support at zero overhead to the projects, and let them decide the value of the metrics. The primary focuses of this case study is to understand the adoption barrier of software project telemetry technology in an open source development environment where it is impossible to force people to use the technology. Details are discussed in Chapter \ref{Chapter:EvaluationInIkayzo}.

%I volunteer in Ikayzo, and my duties are strictly confined to providing metrics support for the hosted projects using software project telemetry. I do not participate in Ikayzo project hosting decision-making. Nor do I participate in any decision-making process of the hosted projects.

%However, the regular user interface of software project telemetry system is completely hidden from users. A background daemon process on Ikayzo sever collects metrics and updates telemetry charts automatically each night. Users access telemetry charts through a link on the project main page.
% The experience can be usefor for projects hosted elsewhere.		
	
	
	
\end{itemize}




%Tables \ref{table:CaseStudyComparison} is a comparison of the 3 case studies.
%
%\begin{table}[tbp]
%	\centering
%		\begin{tabular}{|c|c|c|c|} 
%			\hline
%			\textbf{} & \textbf{Classroom} & \textbf{CSDL} & \textbf{Ikayzo} \\
%			\hline
%			         \textbf{Qualitative Data} 
%			       & \textit{student opinion} 
%			       & \textit{} 
%			       & \textit{} \\
%			\hline
%		  \textbf{Quantitative Data} & \textit{telemetry analysis invocation record} & \textit{} & \textit{} \\
%			\hline
%			\textbf{Data Collection Method} & \textit{questionnaire, system instrumentation} & \textit{} & \textit{} \\
%			\hline
%			\textbf{Degree of Control} & \textit{technology adoption is class requirement} & \textit{} & \textit{} \\
%			\hline
%		\end{tabular}
%  \caption{Comparison of the 3 Case Studies}
%	\label{table:CaseStudyComparison}
%\end{table}
%





\section{Case Study Schedule} \label{EvaluationStrategy:Schedule}

The case study in the classroom was conducted in Spring 2005. 

The case study in CSDL is starting. It will last 6 months. I am customizing the telemetry analysis system to provide developer project quality assurance process feedback. The initial version was deployed on the week of Oct 9. The case study can start in a week or two once the initial version is field tested.

The case study in Ikayzo is starting. It will last 6 months.






































%Evaluation:
%
%	Two perspective: site hosting provider determing which project to provide more support.
%	                       project lead managing projects.
%	                       
%	      Metrics collection analysis overhead, me. What's the anticipated difficulty when someone else wants to use the system and maintain it themselves.
%	      
%	      Metrics/Sensors: what can be collected?
%	                       what is being collected?
%	                       what is desired?
%	                       how the metrics are used and what decisions are made?






%\subsection{The Goal}

%\subsection{The Questions}
%
%The questions that the evaluation tries to answer are identified as below:
%
%* How metrics is used in general? What metrics people want to see? How people use metrics in real life? How people make decisions based on metric.
%
%* How SPT provides support in metrics collection and analysis (the effectiveness of the support)?
%   - Metrics collection overhead
%   - SPT administration overhead
%   - Is analysis easy to use?
%   - Does analysis yield value?
%   
%   - What (or what problem) can be done with telemetry and what cannot. 
%   - The limitation of telemetry, what can be done in case of it.
   
%\subsection{The Approach}



%Telemetry analyses and their associated telemetry streams allow user to see the entire history of relevant software metrics and how they change from the beginning of the project. The project decisions are based not only on current values of metrics but also on their trend over time. Compared to the more traditional software management where decisions are mainly based on the current status of project, telemetry gives project managers and developers more information. The evaluation will investigate whether the extra information in telemetry-style management could result in early detection of problems and improvement of judgement or not.

%The survey conducted in the classroom is essentially a case study. It is not a controlled experiment where software project telemetry is compared to other measurement and process improvement programs, such as the Personal Software Process. I am not trying to establish statistically significant relationship regarding the superiority or inferiority of software project telemetry. Instead, I am simply asking whether software project telemetry has delivered utility to its users. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%          The following is commentted out
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{comment}

Two techniques to use:
\begin{itemize}
	\item \textit{Questionnaires and Interviews:} quick and simple if one knows what to ask. However, inappropriate questions will lead to incorrect answer.
	\item \textit{Ethnographic Studies:} An external observation of the process. (Ref: Ian Sommerville, Software Engineering, sixth edition, Pearson Education, Essex, 2001.)
\end{itemize}


Both quantitative and qualitative data will be collected. Quantitative data will include the actually usage of telemetry analyses on Hackystat server, and other software metrics related to evaluation subjects' software development processes. Qualitative data will be collected through surveys distributed in class, which will contain user feedback on telemetry-styled software project management and the usability of the current implementation of Hackystat telemetry sub-system.


Usage information can be collected automatically by instrumenting telemetry analysis on Hackystat public server. Before any user can access any service provided by the public server, Hackystat requires user to register an account. Each time an analysis is invoked, user information will be sent to the server along with other request parameters. Therefore, it's possible to collect information such as the content of the telemetry analysis being requested and the frequency the analysis are invoked by a particular user. Evaluation subjects' software development product and process metrics are the data collected by various Hackystat sensors.


Telemetry analyses are based on software projects registered with Hackystat server. When they are invoked, the project information will be available to instrumentation as well. This means that the project status (e.g. indicators of size, quality, effort, complexity, etc.) at the time telemetry analyses are invoked can be computed, which enables me to establish a statistical correlation between them. One possible conclusion from such exercise could be when software developers are spending lots of time on testing, they tend to invoke quality related telemetry analyses more frequently, and project coverage tends to go up. Note that this observation does not imply any causal relationship, it merely suggests that some events tend to happen together. But causal relationship might be established when user feedback is considered. 

\end{comment}

%In traditional software development, development takes places in a centralized way. Roles are clearly defined, which include people dedicated to designing, people responsible for managing the project, and people responsible for implementation.


%On, free open source softwares development are typically collaborated by geographically dispersed developers through internet. The typical tools used are source code repository, issue tracking system, wiki discussion board, and mailing list. There might be a project lead or project control group that oversee the general direction of the project.  Since all developers contribute to the project on a voluntary basis, there is little control over individual developer's development environment and development process.   
%
%One the other extreme, there are free open source projects collaborated by geographically dispersed developers. There are hundreds, if not thousands of open-source projects currently being actively developed. Some hugely successful projects are Linux, Apache Web Server, BIND internet domain name system, and mozilla web browser (including Firefox). Barring differences in license terms, the process employed by open source projects are significantly different than those employed in the more traditional development models.
%
%The participants may then be further divided into the following.
%
%   1. Project leaders who have the overall responsibility (Core). Most of them might have been involved in coding the first release of the software. They control the overall direction of individual projects.
%   2. Volunteer developers (Core / Periphery) who do actual coding for the project. These include:
%          * Senior members with broader overall authority
%          * Peripheral developers producing and submitting code fixes
%          * Occasional contributors
%          * Maintainers who maintain different aspects of the project
%   3. Everyday users who perform testing, identify bugs, deliver bug reports, etc. (Periphery)
%   4. Posters (Periphery) who participate frequently in newsgroups and discussions, but do not do any coding.