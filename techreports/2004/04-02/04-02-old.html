<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>The Hackystat-JPL Configuration: Round 2 Results</title>
</head>
<body>
<h2 align="center"><b>The Hackystat-JPL Configuration: Round 2 Results </b></h2>
<p align="center"><br>
  Aaron Kagawa<br>
  Philip Johnson <br>
  Collaborative Software Development Laboratory<br>
  Department of Information and Computer Sciences<br>
  University of Hawaii<br>
  <a href="mailto:kagawaa@hawaii.edu">kagawaa@hawaii.edu</a><br>
  <a href="mailto:johnson@hawaii.edu">johnson@hawaii.edu</a> </p>
<p align="center">CSDL-03-14</p>
<p align="center"><a href="http://csdl.ics.hawaii.edu/techreports/03-14/03-14.html">http://csdl.ics.hawaii.edu/techreports/03-14/03-14.html</a></p>
<p align="center"><b>Last update: 
  <!--webbot bot="Timestamp" S-Type="EDITED"

S-Format="%m/%d/%Y %I:%M:%S %p" startspan -->
  04/12/2004 08:19:06 AM 
  <!--webbot bot="Timestamp" i-CheckSum="30389" endspan -->
  &nbsp;</b></p>
<h2>Abstract</h2>
<p>This report presents selected round two results from Hackystat-based descriptive 
  analyses of Harvest workflow data gathered from the Mission Data System software 
  development project from January, 2003 to December, 2003. The information provided 
  in this report describes improvements and differences between the previous techreport 
  (The Hackystat-JPL Configuration: Overview and Initial Results, <a href="http://csdl.ics.hawaii.edu/techreports/03-07/03-07.html">http://csdl.ics.hawaii.edu/techreports/03-07/03-07.html</a>). 
</p>
<p>Until this point in our research we have been concerned with answering the 
  general question, &quot;Can Hackystat provide insights into the development 
  process of MDS?&quot;. We believe that the previous report shows that at least 
  some interesting analyses are capable with the scope of data that can be extracted 
  from Harvest. Thus, it make sense to continue our research. Now, we are concerned 
  with &quot;Are we collecting the right data and are we analyzing the right things?&quot; 
  and &quot;What specific insights can we look into?&quot;. In other words, it 
  seems that we are now ready to look at specific issues, opposed to the general 
  level that we have been operating on. </p>
<p>There are two reasons why we can redirect our research. First, the Sensor Data 
  is significantly higher in quality. Until this point the data we received were 
  either incomplete, wrong, or malformed. Second, we believe the current set of 
  analyses introduces interesting research questions. </p>
<p>In this report, we provide another set of questions about the Sensor Data and 
  Analyses.</p>
<p>&nbsp;</p>
<h2><a name="1.0">1.0</a> Sensor Data Validation</h2>
<p>Much of this report will talk about how the &quot;correctness&quot; of the 
  Build and StateChange data has improved thus changing the analyses. Section 
  1.1 discusses the progress that has been made. However there are still a couple 
  of issues present with the current set of data, Sections 1.2 and 1.3 discuss 
  some (potential) problems.</p>
<h3>1.1 Sensor Data Summary</h3>
<p>This section provides a summary of the progress that has been made in getting 
  the sensor data to an acceptable quality.</p>
<ul>
  <li>StateChange Sensor Data 
    <ul>
      <li>The State Change command files generated have perfect &quot;grammar&quot;.</li>
      <li>There are 12,367 State Change entries in the command file. All are successfully 
        sent and accounted for in the hackyJPLBuild system.</li>
      <li>There are 337 different days of State Change data in the hackyJPLBuild 
        system, ranging from January 2, 2003 to March 18, 2004.</li>
      <li>The hackyJPLBuild system now supports &quot;Dev Waiting&quot; and &quot;Dev 
        Null&quot; Harvest States.</li>
      <li>There are only two work packages that have &quot;illegal&quot; State 
        Changes. See Section 2.3 from more information.</li>
    </ul>
  </li>
</ul>
<ul>
  <li>Build Sensor Data 
    <ul>
      <li>The Build command files generated have perfect &quot;grammar&quot;.</li>
      <li>There are 1,002 entries in the command files. All are successfully sent 
        and accounted for in the hackyJPLBuild system.</li>
      <li>There are 233 different days of Build data in the hackyJPLBuild system, 
        ranging from January 2, 2003 to December 29, 2003.</li>
    </ul>
</ul>
<h3>1.2 Build Sensor Data Problem</h3>
<p>It was our understanding that CM Build State includes a compilation, linking 
  and testing. The Build SDT provides a specification of what failed during the 
  build, denoted by failureType. We have also have attributes for testPassed and 
  testFailed which should represent the number of test that passed and the number 
  of tests that failed, during the testing phase of the build. The following is 
  an example of Build Sensor Data from January 1, 2003.</p>
<pre> &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; 
   - &lt;sensor&gt;
   &lt;entry tstamp=&quot;1041949980009&quot; tool=&quot;Sensor Shell&quot; packageId=&quot;iar-01923,iar-01928,iar-01933&quot; testsPassed=&quot;0&quot; testsFailed=&quot;0&quot; failureType=&quot;compile&quot;/&gt; 
   &lt;entry tstamp=&quot;1041962700010&quot; tool=&quot;Sensor Shell&quot; packageId=&quot;iar-01923,iar-01928,iar-01933&quot; testsPassed=&quot;0&quot; testsFailed=&quot;0&quot; failureType=&quot;compile&quot;/&gt; 
   &lt;entry tstamp=&quot;1041967740011&quot; tool=&quot;Sensor Shell&quot; packageId=&quot;iar-01923,iar-01928,iar-01933&quot; testsPassed=&quot;0&quot; testsFailed=&quot;0&quot; failureType=&quot;runtime&quot;/&gt; 
   &lt;entry tstamp=&quot;1041984840012&quot; tool=&quot;Sensor Shell&quot; packageId=&quot;iar-01923,iar-01928,iar-01933,iar-01936&quot; testsPassed=&quot;0&quot; testsFailed=&quot;0&quot; failureType=&quot;runtime&quot;/&gt; 
   &lt;/sensor&gt;</pre>
<p>As you can see the last two Builds contains a &quot;runtime&quot; failure. 
  We believe that this represents a test failure. However, there is no indication 
  of how many test failed or how many tests passed. Is this data obtainable?</p>
<ul>
  <li>[Q.1.2.a] <b>Are the number of test that pass and fail obtainable? </b></li>
  <li>[Q.1.2.b] <b>Is there any other Build data that could be extracted that 
    could provide use information? </b></li>
</ul>
<p>&nbsp;</p>
<h3>1.3 StateChange Sensor Data Problem</h3>
<p>All the attributes of the StateChange Sensor Data are not being used. The following 
  is an example Sensor Data Entry.</p>
<pre> &lt;entry tstamp=&quot;1043462911371&quot; tool=&quot;Sensor Shell&quot; packageId=&quot;IAR-01959&quot; startState=&quot;dev&quot; endState=&quot;dev complete&quot; 
    newFiles=&quot;MDS_Rep/source/Msl/Ma/Rovers/Position/PositionAndHeadingFullConstraint.cpp,
                    MDS_Rep/source/Msl/Ma/Rovers/Position/PositionAndHeadingFullConstraint.h,
                    MDS_Rep/source/Msl/Ma/Rovers/Position/WaypointConstraint.cpp,
                    MDS_Rep/source/Msl/Ma/Rovers/Position/WaypointConstraint.h&quot;
    modifiedFiles=&quot;&quot; deletedFiles=&quot;&quot; unchangedFiles=&quot;&quot; iar=&quot;&quot; developer=&quot;cxing&quot; /&gt; </pre>
<p>The StateChange Sensor Data provides attributes that consider the files associated 
  with the StateChange: newFiles, modifiedFiles, deletedFiles, and unchangedFiles. 
  Other than newFiles the data shows that the other file attributes are not being 
  utilized. There are 5 of the 1421 work packages that have modified files. And 
  there are 5 of the 1242 work packages that have deleted files.</p>
<p>If these file attributes provide the exact set of files associated with each 
  work package, then the hackyJPLBuild system can recognize possible dependency 
  problems before they actually occur, ie File Entanglement. Currently, the hackyJPLBuild 
  analyses use the larger-grained work package information (i.e. not their associated 
  files). Once the package-level analyses settle down we would like to look into 
  issues of dependency and entanglement.</p>
<ul>
  <li>[Q.1.3.a] <b>What causes the low amount of modified and deleted files?</b></li>
  <li>[Q.1.3.b] <b>Is it possible to obatin information about unchanged files?</b> 
    Again, if we have the files associated with Work Package we can then recognize 
    File Entanglement.</li>
</ul>
<p>&nbsp;</p>
<h2><a name="2.0">2.0</a> Sample Analyses</h2>
<p>The following subsections present examples of significant changes in the analysis
  due to data quality. </p>
<h3><a name="2.1">2.1 </a> Analysis Example: System Summary </h3>
<p></p>
<p>This system summary page is intended to provide a high level overview of the 
  numbers and kinds of entities under analysis. </p>
<p>This analysis presents some overall statistics regarding the data currently
  present in the system. </p>
<p><img border="0" src="03-14.2.JPG"></p>
<p>This system summary page is intended to provide a high level overview of the 
  numbers and kinds of entities under analysis. In this case, the system summary 
  generates the following question:</p>
<ul>
  <li>[Improvement.2.1.a] <b>There has been a significant improvement in the number 
    of Builds that are accounted for.</b> The previous amount of builds were 78. 
    Given the number of transitions to CM Build (1559) the number of Build Entries 
    (1002) seems reasonable.</li>
  <li>[Improvement.2.1.b] <b>The amount of files accounted for almost doubled.</b> 
    However, hackyJPLBuild does not do any interesting analyses dealing with files.</li>
  <li>[Q.2.1.a] <b>Where are the VPRs and VPs MDS package types? </b></li>
  <li>[Q.2.1.b] <b>Just curious, how many files are in the MDS system?</b></li>
</ul>
<p>&nbsp;</p>
<h3><a name="2.2">2.2</a> Analysis Example: Transition Sequence </h3>
<p>This analysis shows how the various MDS packages moved between workflow states 
  over a given period of time.&nbsp; The first screen below provides two tables, 
  one that displays the types and occurrences of &quot;forward&quot; transitions, 
  and one that counts the types and occurrences of &quot;backward&quot; transitions:</p>
<p><img border="0" src="03-14.3.JPG" ></p>
<h4><b>2.2.1 Forward and Backward Transitions Table Discussion</b></h4>
<p>There are a couple of things that we notice here:</p>
<ul>
  <li>The new Harvest workflow data provides two new Harvest states that are now 
    integrated with the system. These are the &quot;dev waiting&quot; and &quot;dev 
    null&quot; states.</li>
  <li>Forward Transitions (aka Promotions) significantly out number Backward Transitions 
    (AKA Demotions).</li>
</ul>

<ul>
  <li>[Q.2.2.a] <b>What Backward Transitions &quot;cost&quot; the most? </b>This 
    is an open question, basically we would like to know what backward transition 
    causes the most delay. Or, what Backward Transition is considered to be the 
    worst?</li>
  <li>[Q.2.2.b] <b>Should an Integration Test be considered as a Build event? 
    </b>And should we be collecting data about that event? Just by the very definition 
    of the name &quot;Integration Test&quot; one would assume that we are actually 
    testing how the code integrates into the Baseline code. If there is a failure 
    packages that are testing should be demoted. Apparently, there have been 19 
    packages that have been demoted (backward transition) from Integration Test 
    to CM Build.</li>
</ul>
<p>&nbsp;</p>
<h3><a name="2.3">2.3</a> Analysis Example: Illegal Transition Sequence</h3>

<p>As noted in the previous report, we discovered that the sequences of state 
  transition data entries provided to us did not always appear to be &quot;legal&quot;, 
  in that the end state of one transition is equal to the start state of the next 
  transition in chronological order. The improvements to the data has drastically 
  reduced the amount of illegal transitions.</p>

<p><img src="03-14.illegal.JPG" width="823" height="354"></p>
<p>Just as a reminder a &quot;Illegal Transition&quot; is a transition where the 
  start state of a transition does not equal the end state of the previous transition. 
  In the case of CP-00966 the illegal transition occurs between the transitions 
  CM-&gt;Integration Test and Test Complete-&gt;Release.</p>
<p><img src="03-14.list-package-sensor-data.illegal.JPG" width="824" height="582"></p>
<p>&nbsp;</p>
<h3><a name="2.3">2.4</a> Analysis Example: Promotion vs Demotion</h3>
<p>The Promotions vs. Demotions analysis provides a perspective on both development 
  &quot;velocity&quot; (as represented by the number of promotions) and its &quot;friction&quot; 
  (as represented by the number of demotions) over time. This analysis is a aggregation 
  of Forward and Backward Transitions that are shown in Transition Sequence Analysis. 
  For the following example, we display promotions and demotions in a monthly 
  chart. </p>
<p><img src="03-14.promotion.JPG" width="820" height="338"></p>
<p><img src="03-14.promotion.graph.png" width="600" height="480"></p>
<p>The following questions appeared in the previous report but weren't answered.</p>
<ul>
  <li>[Q.2.4.a] <b>Does the cyclical rise and fall of promotions represent a predictable 
    pattern of development activity? </b>This chart shows that the number of promotions 
    in a given month interval seems to cycle regularly between a low of around 
    400 and a high of over 1300. What causes this cycle, and can this aid in project 
    planning? </li>
  <li>[Q.2.4.b]<b> Does the relatively constant level of demotions represent a 
    predictable pattern of development activity?</b> This chart also shows that 
    the number of demotions in a two week interval does not appear to vary much 
    at all.</li>
</ul>
<p>Even though monthly intervals do not have much variation in Promotions Vs Demotions. 
  I have found a greater variation at the day interval during April 2003.</p>
<p><img src="03-14.promotion.daily.graph.april.png" width="775" height="480"></p>
<p>For example, one could say that April 21, 2003 was a bad day, where 9 of the 
  26 transitions where Demotions. Interesting questions like what caused this 
  unproportunate amount of Demotions arise. In addition, it appears in this month 
  and in other months, that once a Demotion occurs one of two things happen: (1) 
  there are Demotions the next day as well and/or (2) the number of promotions 
  are affected. This makes sense in that the developers should be in the Rework 
  phase. Also, Demotions is caused by dependency the problem could cause a ripple 
  affect causing other Demotions throughout the system.</p>
  
<ul>
  <li>[Q.2.4.c] <b>Does a Demotion significantly change the work flow? </b>We 
    have noticed that Demotions are &quot;grouped together&quot;. </li>
</ul>

<p>&nbsp;</p>
<h3><a name="2.3">2.5</a> Analysis Example: Work vs. Rework</h3>
<p>This analysis attempts to represent the proportional effort allocated to &quot;new&quot; 
  work activities vs. &quot;rework&quot; activities. The approach used is to count 
  the number of transitions from Dev to Dev Complete, and categorize them as a 
  &quot;Work&quot; transition or a &quot;Rework&quot; transition. A &quot;Work&quot; 
  transition is defined as a transition involving a Change Package without an 
  associated IAR. A &quot;Rework&quot; transition is defined as a transition involving 
  an IAR, an IM, or a Change Package with an associated IAR. In some sense, &quot;rework&quot; 
  combines both defect repair and unscheduled work.</p>
<p><img src="03-14.work.JPG" width="820" height="329"></p>
<p><img src="03-14.work.graph.png" width="600" height="480"></p>
<p>Obviously, this analysis shows that &quot;Rework&quot; is a significant source 
  of effort. In fact, there are approximately 3 times more IARs and IMs than CPs. 
  Furthermore, we claim that CPs that have been demoted back to Dev and then promoted 
  to Dev Complete also qualifies as Rework. However, we do not count that towards 
  Rework so in fact the number of Work could be reduced significantly.</p>
<ul>
  <li>[Q.2.5.a] <b>Are we accurately representing Rework? </b>An open question 
    is the extent to which this representation of work and rework based upon state 
    transitions accurately models the effort spent by the development group on 
    work vs. rework. The amount of Rework that we have calculated seems outrageous. 
    Are the number that we get comparable to your understanding of then amount 
    of Rework that is occuring.</li>
  <li>[Q.2.5.b] <b>Does the decrease in Rework represent a process improvement? 
    </b>Another open question is whether the decrease in percentage transitions 
    allocated to rework during the October to December represents a process improvement. 
    <br>
  </li>
</ul>
<p>Looking at the day interval, we see that most days are spent on Rework. Rarely, 
  is there a day that Work dominates.</p>
<p><img src="03-14.work.daily.graph.png" width="775" height="480"></p>
<ul>
  <li>[Q.2.5.c] <b>How are Demotions associated with Rework? </b>It appears that 
    there are a relatively low number of Demotions, as evidence by Section 2.4, 
    however there is apparently a lot of rework being done. Why is that? Does 
    a single Demotion cause a significant amount of Rework?</li>
  <li>[Q.2.5.d] <b>Does the low level of Work indicate that the system is growing 
    slowly? </b>Where as the amount of Rework to make the system function as it 
    is supposed to dominates the development process. An open question is, if 
    the amount of Rework is reduced, then would &quot;Throughput&quot;, the rate 
    at which packages reach relase, increase significantly?</li>
  <li>[Q.2.5.e] <b>Does the amount of Rework indicate that there is low software 
    quality in the planed Work? </b>In other words, if we can improve planning 
    and the quality spent on &quot;Work&quot; would this decrease the amount of 
    Rework needed?</li>
</ul>
<p>&nbsp;</p>
<h3><a name="2.6">2.6</a> Analysis Example: MDS Build Worksheet</h3>
<p>We have obtained a bunch of &quot;MDS Build Worksheets&quot; which provide 
  detailed information about the Build events during that day. In the first section 
  of the worksheet (the token expiry Section) the work packages that have been 
  &quot;squared&quot; are packages that have entered and moved from the specified 
  Harvest State. For example, CP-1224 started the day in the Build Queue. It was 
  then built in CM Build and stopped its movement there. That means that CP-1224 
  has either a compilation, linking, or testing failure. The second section, provides 
  the results of a CM Build.</p>
  
<p><img src="03-14.build-worksheet-actual.jpg" width="700" height="730"></p>
<p>We don't know exactly what this information is used for. More importantly, 
  it would be really hard to extract statistics from this paper version. Therefore, 
  we have built the coresponding equivalent Hackystat Analysis to this MDS Build 
  Worksheet. It is a really useful analysis to show a summary of what happend 
  on a specific day. The following is the Build Worksheet analysis.</p>
<p><img src="03-14.build-worksheet.JPG" width="827" height="894"></p>
<p>As you can see, it is quite obvious that that a compile error kept IAR-02059 
  from being promoted to the Intergration Test State. One glaring problem appears. 
  Notice that the Results of the CM Build indicates that only one build occured 
  with a single package IAR-02059. What happened to the other packages that were 
  in the Build Queue and made it to CM Build. Furthermore, how did the long list 
  of packages get promoted to Integration Test without being built.</p>
<ul>
  <li>[Q.2.6.a] <b>Is the Build data complete? </b>There seems to be a mystery 
    Promotion where supposedly a Build event should be the cause. Can CM Administrators 
    by pass the a Build event and promote work packages to Integration Test with 
    out them actually being built?</li>
</ul>
<p>&nbsp;</p>
<h3><a name="2.7">2.7</a> Interlude: The Box-And-Whisker Chart representation</h3>
<p>The next several analyses provide a Box-and-Whisker chart
representation.&nbsp; This section documents the visual structure and
interpretation of the box and whisker chart:</p>
<table border="1" width="100%">
  <tr>
    <td width="23%"><b>Visual Representation</b></td>
    <td width="77%"><b>Statistical Meaning</b></td>
  </tr>
  <tr>
    <td width="23%">Horizontal line (inside box)</td>
    <td width="77%">The median of the observations</td>
  </tr>
  <tr>
    <td width="23%">Solid black dot</td>
    <td width="77%">The mean of the observations</td>
  </tr>
  <tr>
    <td width="23%">Solid colored box</td>
    <td width="77%">The interquartile range (IQR).&nbsp; Divide the observations
      into four equal groups. The box represents Q2 and Q3.</td>
  </tr>
  <tr>
    <td width="23%">Upper whisker</td>
    <td width="77%">Observations (if any) with values up to 1.5 times the
      highest IQR value.</td>
  </tr>
  <tr>
    <td width="23%">Lower whisker</td>
    <td width="77%">Observations (if any) with values down to 1.5 times less
      than the lowest IQR value.</td>
  </tr>
  <tr>
    <td width="23%">Unfilled circle</td>
    <td width="77%">Outliers: observations between 1.5 and 3 times greater than
      (or less than) the highest (or lowest) IQR value.</td>
  </tr>
  <tr>
    <td width="23%">Triangle</td>
    <td width="77%">Extremes: observations beyond 3 times the IQR. Indicates
      data points outside the chart.</td>
  </tr>
</table>

<h3><a name="2.8">2.8</a> Analysis Example: MDS Released Package Age</h3>
<p>This analysis generates box-and-whisker charts to illustrate the distribution 
  of age values for the set of package types specified as a parameter to the analysis.&nbsp; 
  Only those packages that made it to the Release state are included in this analysis, 
  since that is required to compute their &quot;final&quot; age.</p>
<p><img src="03-14.mds-released-package-age.JPG" width="829" height="317"></p>
<p><img src="03-14.mds-released-package-age.graph.png" width="600" height="480"></p>
<p>Running this analysis on the new set of data shows two differences from the 
  old data we received; (1) there is less variability in Age for RP, CP, IAR, 
  and IMs package types and (2) there is a greater variability in the ITR, IT, 
  and CPR package types. You can see the previous Box and Whisker chart here, 
  <a href="http://csdl.ics.hawaii.edu/techreports/03-07/03-07.html#3.8">http://csdl.ics.hawaii.edu/techreports/03-07/03-07.html#3.8</a>. 
  Hopefully, as the data set grows there will be less variability in the Age of 
  released packages.</p>
<p>We claim that this analysis is too coarse-grained to provide anything that 
  is useful. The Released Age of a package is an &quot;after-the-fact&quot; measurement 
  and probably cannot provide any help with identifying potential problems during 
  the &quot;life&quot; of the workpackage. However, we believe that this analysis 
  can be useful if we can identify reasons, factors, or attributes that contribute 
  to a Work Package's Released Age that lay out side of the Interquartile Range.</p>
<p>For example, a future Hackystat analysis can be built to find the specific 
  Work Packages' that have a unordinary Released Age and identify the factors 
  such as amount of files, the degree of entanglement, the amount of rework, the 
  number of demotions, etc that can contribute to a unordinary Released Age. Once 
  these factors have been identified then Hackystat can send &quot;Red Flags&quot; 
  that notify the appropriate JPL personel that a particular Work Package has 
  attributes that could mean that the package will take a longer than usual amount 
  of time to reach Release. NOTE: we should probably use Test Complete Harvest 
  State due to due to the following statement by Rich Hug, </p>
<blockquote> 
  <p>&quot;The methodology is set up such that as each package passes the test 
    suite, the package is moved to Test Complete. When a release is to be made, 
    all packages in Test Complete are moved to Release. For purposes of metrics, 
    I believe that we can interpret that a package is &quot;closed&quot; when 
    it moves to Test Complete&quot;.</p>
</blockquote>
<p>Therefore, I believe that this analysis should actually be calculating the 
  Test Complete Age to accurately reflect the time it takes for a Work Package 
  to reach the Release State.</p>
<ul>
  <li>[Q.2.8.a] <b>What factors influence the &quot;Age&quot; of a Work Package? 
    </b>This is an open question, but it illustrates the level of analyses that 
    we want to get to.</li>
</ul>
<p>&nbsp;</p>
<h3><a name="2.9">2.9</a> Analysis Example: State Days Distribution</h3>

<p>This analysis takes the specified package type, and collects all of the
instances of that package type that have a transition recorded for them between
the specified start and end date and that have not reached the Release state. By
excluding packages that have reached the Release state, the analysis provides a
perspective on the packages currently in the &quot;pipeline&quot; during the
specified period.&nbsp;</p>

<p>For each of these active package instances, we find the number of days it
spent in each of the Harvest states, and graph that distribution as a
box-and-whisker chart.</p>

<p><img src="03-14.state-days.cp.JPG" width="829" height="317"></p>
<p><img src="03-14.state-days.cp.graph.png" width="600" height="480"></p>
<p>The above analysis shows the amount and variability in time spent in the various 
  states for Change Packages. This chart shows that Change Packages spend most 
  of their time in Dev, Integration Test, or Test Complete. This analysis shows 
  that there is less variablity in the Dev Harvest State and more variablity in 
  the Integration Test Harvest State compared to the previous amount of data that 
  we received. What is interesting is why is there a &quot;delay&quot; in the 
  Intergration Test Harvest State? The following screen shot shows an example 
  Work Package that took about 3 months to move from Integration Test to Test 
  Complete.</p>
<p><img src="03-14.list-package-sensor-data.long-integr-test.JPG" width="821" height="557"></p>
<ul>
  <li>[Q.2.9.a] <b>What causes the delay in the Integration Test Harvest State? 
    </b>The previous screen shot shows that IAR-02258 spent almost 3 months in 
    Integration Test. It is obvious that other Work Packages share a similar situation.</li>
</ul>
<p>A re-running of this analysis specifying IAR as the package type reveals a 
  different distribution, as illustrated next: </p>
<p><img src="03-14.state-days.iar.graph.png" width="600" height="480"></p>
<p>The IARs have considerably less amount of time spent in the Dev Harvest State 
  compared to Chackage Packages (CP). Why is that? What would be interesting to 
  determine is does the low amount of time spent in Dev influence the number of 
  Demotions that a particular Work Package has?</p>
<ul>
  <li>[Q.2.9.b] <b>Why is the number of days spent on IARs in the Dev state significantly 
    less than days spent on CPs in the Dev state?</b> One could guess that IARs 
    are &quot;easier&quot; to develop because after all they are just fixes. Is 
    that a correct assumtion? However, one would hope that there would be less 
    problems associated with IARs. </li>
  <li>[Q.2.9.c] <b>If CPs spend more time in the Dev State would that decrease 
    the amount of IARs needed?</b> What causes an IAR to be formed? Are they born 
    due to the lack of software quality in the CPs? If so, is it possible to focus 
    more attention to the development of CPs thus reducing the amount of IARs 
    needed? Or, are the amount of IARs something that cannot be improved?</li>
</ul>
<p>&nbsp;</p>
<h2><a name="2.9">2.10</a> Analysis Example: MDS Package Summary</h2>
<p>The MDS Package Summary analyses provides a tabular representation of the data 
  available in the system between the chosen start and end days. The following 
  screen shot shows the different selections that are possible with the analysis.<br>
</p>
<p><img src="03-14.mds-package-summary.iar-cpr.JPG" width="820" height="457"></p>
<p>The first screen shot shows IARs that are associated with a CPR, sorted so 
  that the IARs with CPR association are at the top of the page.</p>
<p><img src="03-14.mds-package-summary.iar-cpr.data.JPG" width="821" height="550"></p>
<p>As you can see there is a very low number of IARs that are associated with 
  a CPR. Rich Hug said, &quot;IARs are associated only with CPRs.&quot; Should 
  all IARs be associated with a CPR? Currently there are only 19 (out of 650) 
  IARs assocaited with a CPR. In addition, there are only 10 (out of 126) unique 
  CPRs that have an associated IAR. However, we are not sure what and how we would 
  use this information.</p>
<ul>
  <li>[Q.2.10.a] <b>Why are the number of IARs that are associated with a CPR 
    so low?</b> Are we missing data? Or is it the case that not all IARs are associated 
    with a CPR? If that is the case what does it mean for a IAR to be associated 
    with a CPR?</li>
  <li>[Q.2.10.b] <b>Are there any other Work Package associations that can be 
    extracted from Harvest? </b>The previous problem suggests that maybe other 
    Work Package association can be extracted from Harvest, for example can we 
    obtain what CPs are associated with a CPR? However, we aren't sure what we 
    would use this information for.</li>
</ul>
<p>&nbsp;</p>
<h2>3.0 Summary and Conclusions</h2>
<p>&nbsp;</p>
<h2>4.0 Next steps</h2>
<p>&nbsp;</p>
<p>&nbsp;</p>


</body>
</html>