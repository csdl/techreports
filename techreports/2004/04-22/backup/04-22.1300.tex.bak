%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 04-22.tex -- IEEE Software Paper on Telemetry
%% Author          : Philip Johnson
%% Created On      : Mon Sep 23 11:52:28 2002
%% Last Modified By: Philip M. Johnson
%% Last Modified On: Wed Dec 08 12:23:35 2004
%% RCS: $Id$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 2002 Philip Johnson
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 

%% Review: David Zubrow/SEI

\documentclass[11pt]{article} 
\input{/export/home/csdl/tex/psfig/psfig}
\usepackage{/export/home/csdl/tex/icse2003/latex8}
\usepackage{times}
%% A verbatim-like environment which allows font changes
%%\usepackage{alltt}
%% New LaTeX2e graphics support
\usepackage[final]{graphicx}
% uncomment the % away on next line to produce the final camera-ready version
% and uncomment the \thispagestyle{empty} following \maketitle
\pagestyle{empty}

\begin{document}

\title{Understanding HPCS development through automated process and product measurement}


\author{Philip M. Johnson \\ Michael Paulding \\
\em  Collaborative Software Development Laboratory \\
\em  Department of Information and Computer Sciences \\
\em  University of Hawai'i \\
\em  Honolulu, HI 96822 \\
\em  johnson@hawaii.edu}
\maketitle
\thispagestyle{empty}

\Section{Introduction}
\label{sec:intro}

High performance computing systems are becoming increasingly mainstream due
to decreasing costs and increasing numbers of application areas with
computation and/or data intensive processing.  As interest increases in
high performance computing in new technical communities, new problems are
arising.  For example, recent initiatives in the HPCS community, such as
the DARPA High Productivity Computing Systems Program and the Workshop on
the Roadmap for the Revitalization of High-End computing have concluded
that low-level HPCS HPCS benchmarks of processor speed and memory access
times no longer necessarily translate into high-level increases in actual
development productivity.  Put another way, the bottleneck in high
performance computing systems is increasingly due to software engineering,
not hardware engineering.

However, high performance computing application development often differs
in significant ways from the systems and development processes more
typically studied by the software engineering community:

\begin{itemize}

\item The requirements often include conformance to sophisticated
mathematical models. Indeed, requirements may often take the form of an
executable model in a system such as Mathematica, and the implementation
involves porting to the HPCS.
       
\item The software development process, or ``workflow" for HPCS application
development may differ profoundly from traditional software engineering
processes. For example, one scientific computing workflow, dubbed the ``lone
researcher", involves a single scientist developing a system to test a
hypothesis. Once the system runs correctly once and returns its results,
the scientist has no further need of the system. This contrasts with
standard software engineering lifecycle models, in which the useful life of
the software is expected to begin, not end, after the first correct
execution.
       
\item ``Usability" in the context of HPCS application development may
revolve around optimization to the machine architecture so that
computations complete in a reasonable amount of time. The effort and
resources involved in such optimization may exceed initial development of
the algorithm.

\end{itemize}

To deal with this issue, there is an emerging interdisciplinary community
involving both HPCS and software engineering who are attempting to define
new ways of measuring high performance computing systems, ways which take
into account not only the low-level hardware components, but also the
higher-level productivity costs associated with producing usable HPCS
applications.

This paper presents a new approach to addressing the software engineering
problems associated with high performance computing system application
development.  It involves the introduction of technology into the HPCS
development environment which unobtrusively gather process and product
data.  This process and product data can be used for two purposes. First,
it can be used to provide a more wholistic perspective on productivity, one
that includes measures of performance, functionality, and development.
Second, it can be used to provide new insight into the process of high
performance system application development, which can be used to identify
bottlenecks in the development process and assess the consequences of
process or product changes on these bottlenecks.  We have been applying
this approach to an ongoing case study of high performance computing system
application development in our laboratory, and this paper reports
on our initial results.

The remainder of the paper is organized as follows.  Section
\ref{sec:hackystat} introduces the technology we have developed, called
Hackystat, which supports unobtrusive collection and analysis of product
and process measures. Section \ref{sec:telemetry} introduces ``Software
Project Telemetry``, which is an approach to measurement collection and
interpretation we have adopted for this research. Section \ref{sec:truss}
introduces the HPCS application, called the Optimal Truss Problem, that we
have chosen for our case study.  Section \ref{sec:metrics} introduces the
metrics we have defined to support HPCS with examples from our case study.
Section \ref{sec:conclusions} presents our initial conclusions from the use
of these metrics and our future directions.

\Section{Automated process and product measurement with Hackystat}
\label{sec:hackystat}

An important characteristic of our approach to understanding HPCS software development 
and productivity is that measures of product and process must be automatically collected. 
This requirement limits the kinds of data we can collect, but dramatically lowers the 
cost of collecting these measures and provides a level of scalability for measurement not
possible with expensive, manual data collection. 

For the past several years, we have been developing a framework for automated software 
development process and product metric collection and analysis called Hackystat. 
This framework differs from other approaches to automated support for product
and process measurement in one or more of the following ways:

\begin{itemize}

\item Hackystat uses sensors to unobtrusively collect data from development
environment tools; there is no chronic overhead on developers to collect
product and process data.

\item Hackystat is tool, environment, process, and application agnostic.
The architecture does not suppose a specific operating system platform, a
specific integrated development environment, a specific software process,
or specific application area.  A Hackystat system is configured from a set
of modules that determine what tools are supported, what data is collected,
and what analyses are run on this data.

\item Hackystat is intended to provide in-process project management
support. Many traditional software metrics approaches are based upon the
``project repository" method, in which data from prior completed projects
are used to make predictions about or support control of a current
project. In contrast, Hackystat is designed to collect data from a current,
ongoing project, and use that data as feedback into the current project.

\item Hackystat provides infrastructure for empirical experimentation.  For
those wishing to compare alternative approaches to development, or for
those wishing to do longitudinal studies over time, Hackystat can provide a
low-cost approach to gathering certain forms of project data.

\item Hackystat is open source and is available to the academic and
commercial software development community for no charge.

\end{itemize}

The design of Hackystat \cite{csdl2-02-07,csdl2-03-12} has resulted from of prior
research in our lab on software measurement, beginning with research into
data quality problems with the PSP \cite{csdl-98-04,csdl-98-11} and which
continued with the LEAP system for lightweight, empirical, anti-measurement
dysfunction, and portable software measurement
\cite{csdl-99-08,csdl2-00-03}.

\begin{figure*}[htpb]
  \centering
  \includegraphics[width=0.75\textwidth]{architecture.eps}
  \caption{The basic architecture of Hackystat. Sensors are attached to
  tools directly invoked by developers (such as Eclipse or Emacs) as
  well as to tools implicitly manipulated by developers (such as CVS or 
  an automated build process using Ant).}
  \label{fig:architecture}
\end{figure*}

Figure \ref{fig:architecture} illustrates the overall architecture of the
system. First, the project development environment must be instrumented by
installing Hackystat sensors, which developers attach to the various tools
such as their editor, build system, configuration management system, and so
forth. Once installed, the Hackystat sensors unobtrusively monitor
development activities and send process and product data to a centralized
web service.  Project members can log in to the web server to see the
collected raw data and run analyses that integrate and abstract the raw
sensor data streams into telemetry.  Hackystat also allows project members
to configure ``alerts`` that watch for specific conditions in the telemetry
stream and send email when these conditions occur.

Hackystat is an open source project with sources, binaries, and
documentation available at http://www.hackystat.org.  There is also a
public server available at http://hackystat.ics.hawaii.edu.  Hackystat has
been under development for approximately three years, and currently
consists of around 900 classes and 60,000 lines of code.  Sensors are
available for a variety of tools including Eclipse, Emacs, JBuilder,
Jupiter, Jira, Visual Studio, Ant, JUnit, JBlanket, CCCC, DependencyFinder,
Harvest, LOCC, Office, and CVS.  Hackystat development has been supported
by funding from NASA, NSF, IBM, and Sun Microsystems.


\Section {Software Project Telemetry}
\label{sec:telemetry}

A major application of Hackystat has been the development of a new approach to
software measurement analysis called ``Software Project Telemetry``. We define
Software Project Telemetry as a style of software engineering process and product
collection and analysis  which satisfies
the following properties:

{\em Software project telemetry data is collected automatically by tools
that unobtrusively monitor some form of state in the project development
environment.}  In other words, the software developers are working in a
``remote or inaccessable location`` from the perspective of metrics
collection activities. This contrasts with software metrics data that
requires human intervention or developer effort to collect, such as PSP/TSP
metrics \cite{Humphrey95}.
        
{\em Software project telemetry data consists of a stream of time-stamped
events, where the time-stamp is significant for analysis.}  Software
project telemetry data is thus focused on evolutionary processes in
development.  This contrasts, for example, with Cocomo \cite{Boehm81},
where the time at which the calibration data was collected about the
project is not significant.

{\em Software project telemetry data is continuously and immediately
available to both developers and managers.}  Telemetry data is not hidden
away in some obscure database guarded by the software quality improvement
group.  It is easily visible to all members of the project for
interpretation.

{\em Software project telemetry exhibits graceful degradation.}  While
complete telemetry data provides the best support for project management,
the analyses should not be brittle: they should still provide value even if
sensor data occasionally ``drops out`` during the project. Telemetry
collection and analysis should provide decision-making value even if these
activities start midway through a project.
         
{\em Software project telemetry is used for in-process monitoring, control,
and short-term prediction.} Telemetry analyses provide representations of
current project state and how it is changing at the time scales of days,
weeks, or months.  The simultaneous display of multiple project state
values and how they change over the same time periods allow opportunistic
analyses---the emergent knowledge that one state variable appears to
co-vary with another in the context of the current project.

Software Project Telemetry enables a more incremental, distributed,
visible, and experiential approach to project decision-making. For example,
if one finds that complexity telemetry values are increasing, {\em and}
that defect density telemetry values are also increasing, then one could
try corrective action (such as simplification of overly complex modules)
and see if that results in a decrease in defect density telemetry
values. One can also monitor other telemetry data to see if such
simplification has unintended side-effects (such as performance
degradation).   

\Section{The Optimal Truss Design problem}
\label{sec:truss}

Description of the optimal truss system goes here. 

\Section{Process and Product measures for HPCS}
\label{sec:metrics}

In this case study, we have developed techniques for automated collection and 
analysis of the following measures of process and product: Active Time, Most Active File,
Command Line Invocations, Parallel and Serial Lines of Code, Milestone Test Success,
and Performance. 

\SubSection{Active Time}
\label{sec:activetime}

This is a measure of the time spent by developers editing source code (or
other files) related to the system.  Active Time can be collected
automatically through the use of sensors attached to the editor used by
developers.  The sensors collect active time via a timer-based process
inside the editor that wakes up every 30 seconds and checks to see if the
active buffer has changed in identity or size since the last 30 seconds. If
so, a timestamped ``statechange" event is sent to the Hackystat server.
Active Time does not reflect effort spent by developers on the project that
does not involve editing files, including time spent in meetings, time
spent on the telephone, time spent in the shower, and so forth.  Active
Time may be useful in the HPC context as a proxy for overall effort.

Figure \ref{fig:activetime} shows the Active Time associated with development of the
Optimal Truss Design application for a sample period in May, 2004.

\begin{figure*}[htpb]
  \centering
  \includegraphics[width=0.75\textwidth]{truss.activetime.eps}
  \caption{Active time}
  \label{fig:activetime}
\end{figure*}

\SubSection{Most Active File}
\label{sec:mostactivefile}

A measure related to Active Time is the ``Most Active File".  One way to
abstract the raw event stream sent from an editor-based Hackystat server
begins by representing each day as a sequence of 288 five minute intervals.
If a developer actively edits one or more files within a five minute
period, then determine which file was edited most during that five minutes,
and assign the ``credit" for that five minute interval to that file and that
file alone, which we call the ``Most Active File''.  (We performed a
calibration study which found this to be a reasonable abstraction.)  The
Most Active File abstraction may be useful in the HPC context as a way of
determining what specific files were the focus of developer attention, and
how that focus of attention changed over the course of development.

For example, Figure \ref{fig:mostactivefile} shows the Most Active Files associated with
Optimal Truss Design during the first few days of this time interval.  Note
that the sum of Active Time on the files for 14-Oct-2004 equals the total
Active Time for that day, as shown in Figure \ref{fig:activetime}.

\begin{figure*}[htpb]
  \centering
  \includegraphics[width=0.75\textwidth]{truss.activetime.eps}
  \caption{Most Active File}
  \label{fig:mostactivefile}
\end{figure*}

\SubSection{Command Line Invocations}

In addition to time spent editing files in an editor, HPC development
frequently involves extensive use of shell processes to invoke programs
such as make, gcc, etc.  We have implemented a sensor for the Unix command
shell (based upon the 'history' shell mechanism) to record these command
line invocations. Command Line Invocation data may be useful in the HPC
context as a way of providing further insight into the types of activities
performed by developers during the development of the HPC code.  For
example, if the HPC developer spends significant time working at the
command line without concurrent editing of code, then it might be useful to
develop an enhanced representation of Active Time that accounts for this
type of effort as well. While the current sensor only captures command
invocations and not their results, it might be useful to extend the sensor
to capture the results of command line invocations in certain
circumstances. For example, recording whether or not a compilation
succeeded or failed as well as what types of run-time errors occur could
help identify potential development bottlenecks.

Figure \ref{fig:commandlineinvocations} illustrates Command Line Invocation data for the 
Optimal Truss Design system.

\begin{figure*}[htpb]
  \centering
  \includegraphics[width=0.75\textwidth]{truss.parallelfiles.eps}
  \caption{Command Line Invocations}
  \label{fig:commandlineinvocations}
\end{figure*}

\SubSection{Parallel and Serial Size}

We have enhanced our size measurement tool, LOCC, with a token-based
counter for C++ that allows us to count non-comment source lines of code,
and determine for each line of code whether or not an MPI directive occurs
on it.  Thus, for HPC programs built using C++ and MPI, we can determine
(a) the total number of files in the system, (b) the total non-commented
size of each file in the system; (c) whether or not a file consists purely
of serial (non-MPI) code or not; (d) for files containing MPI directives,
the frequency of occurrence of each MPI directive; and (e) for files
containing MPI code, what percentage of the non-comment source lines of
code contained an MPI directive.  We hope it will be straightforward to
extend this approach to support other languages (such as Fortran) and other
HPC packages (such as OpenMP).  Parallel and Serial LOC measurement is
useful in the HPC context by providing insight into how the code evolves
during the course of development, both with respect to its overall size, as
well as with respect to the kinds of parallel constructs that occur in it
and their evolution.

Figures \ref{fig:truss.parallelconstructs}, \ref{fig:truss.parallelfiles},
and \ref{fig:truss.parallelvsequential} provide various perspectives on
size data for the Optimal Truss Design system.

\begin{figure*}[htpb]
  \centering
  \includegraphics[width=0.75\textwidth]{truss.parallelconstructs.eps}
  \caption{Parallel vs. sequential constructs}
  \label{fig:truss.parallelconstructs}
\end{figure*}

\begin{figure*}[htpb]
  \centering
  \includegraphics[width=0.75\textwidth]{truss.parallelfiles.eps}
  \caption{Parallel vs. Sequential SLOC}
  \label{fig:truss.parallelfiles}
\end{figure*}

\begin{figure*}[htpb]
  \centering
  \includegraphics[width=0.75\textwidth]{truss.parallelvsequential.eps}
  \caption{Parallel vs. Sequential Files}
  \label{fig:truss.parallelvsequential}
\end{figure*}


\SubSection{Functionality}

(write about functionality)


\SubSection{Performance}

(write about performance)


\Section{Conclusions}
\label{sec:conclusions}



\bibliographystyle{/export/home/csdl/tex/icse2003/latex8}
\bibliography{/export/home/csdl/techreports/04-11/04-11,/export/home/csdl/bib/csdl-trs,/export/home/csdl/bib/hackystat,/export/home/csdl/bib/psp}
\end{document}
 










