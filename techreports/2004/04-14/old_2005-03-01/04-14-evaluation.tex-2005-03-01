%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 04-14-evaluation.tex -- Thesis proposal - PRI 
%% Author          : Aaron A. Kagawa
%% Created On      : Mon Sep 23 11:52:28 2004
%% Last Modified By: Aaron Kagawa
%% Last Modified On: Tue Mar  1 15:13:23 2005
%% RCS: $Id$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 2004 Aaron A. Kagawa
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Evaluation Methodology}
\label{chapter:evaluation}
This chapter discusses the proposed evaluation methodology of this
research. The main thesis of this proposed research is that Priority Ranked
Inspection (PRI) can distinguish documents that are more in need of
inspection (MINI) from those less in need of inspection (LINI).

One approach of implementing PRI is through Hackystat, thus I will create a
Hackystat Extension called hackyPRI. This extension will provide a
Hackystat analysis, which will distinguish what documents are MINI from
documents that are LINI.  This determination is based on a ranking function
of different process and product measures. Some measures include: reported
defects, unit tests, test coverage, active time, and number of changes.
Each measure will implement a different ranking function and will be
individually calibrated. See Chapter 4: The Hackystat PRI Extension for
more details.

It is important to note two limitations of this research. First, I am not
defining a set of measures that represent the PRI ranking function for
all software projects. Instead, by using hackyPRI I will be able to go
through a methodology to best calibrate the measures to accurately reflect
the determination for the project I am studying. Second, PRI is more
beneficial for organizations that have limited inspection resources. PRI is
of less use for organizations that have the necessary resources to
thoroughly inspect every document, although this is yet to be studied.


\section{Subjects Used in the Evaluation}
In this evaluation, I will study the implementation and inspection process
of the Hackystat System developed in the Collaborative Software Development
Laboratory (CSDL), of the University of Hawaii at Manoa. Like most
organizations, CSDL's inspection resources are limited and therefore
inspections are conducted, if at all, on a weekly basis regardless of the
number of ``ready'' documents. 

%%In addition, unlike most organizations who
%%conduct Software Inspection and have limited resources, CSDL does not
%%conduct sampling or inspections on up-stream documents to enhance the
%%inspection process as recommended by Tom Gilb \cite{Gilb93}. CSDL does not
%%follow these recommendations for two reasons. First, CSDL does not have
%%enough resources to conduct sampling. Second, Hackystat does not contain
%%many up-stream requirement and design documents.

CSDL primarily inspects source code grouped by Java packages; therefore, I
will use the term 'packages' when referring to CSDL's use of PRI. I will
use the term 'documents' when referring to the general idea of inspections.

Although I am a member of CSDL and have been contributing to Hackystat, I
will minimize any possible data contamination by doing two things. First, I
will ensure that the inspection participants are ``Blind'' to the document
selection method. There are two methods of selection that will be used in
this evaluation; selection without aid of PRI and selection with the aid of
PRI. To accomplish I will work with inidividual authors to select documents
based on their subjective selection or with the aid of PRI and keep that
decission a secret from the rest of the participants. Second, I obviously
will not participate in the inspections themselves.

%%Second, I will ensure that the request for inspection will not indicate
%%whether the package for inspection was chosen by a developer or with the
%%aid of PRI.  This practice is called ``Double Blind''. The importance of
%%``Double Blind'' is to ensure that the Inspection participants are not
%%influenced conciously or subconciously. The only CSDL member, besides
%%myself, who will know of the method in which a document was chosen is the
%%author.

The use of CSDL in my study indicates another limitation on this research.
The most accurate and thorough evaluation of PRI should inspect
\textit{all} documents to evaluate if PRI correctly classifies MINI and
LINI documents. However, because I am using CSDL's inspection resources,
which are limited, this is not possible.



\section{Evaluation of Thesis Claims}
To evaluate this thesis, I have decomposed it into three claims based upon
the three intended benefits of PRI.

\begin{enumerate}
\item PRI can enhance the volunteer-based document selection process. 
\item PRI can identify documents that need to be inspected that are not
  typically identified by volunteering.
\item MINI documents will generate more critical defects than LINI
  documents.
\end{enumerate}

The following sections will detail the methodologies used to evaluate each
of the three claims.



\subsection{Claim 1: PRI Enhances the Volunteering Process}
\label{sec:claim1}
In the traditional inspection process, developers volunteer their documents
for inspection. In most cases, developers select documents to volunteer to
remove any critical defects before it is released. However, the current
literature does not provide much guidance on which documents should be
volunteered. One of the intended benefits of PRI is the enhancement of the
volunteering process by providing suggestions on what should be inspected.
PRI can do this in two ways. First, it can minimize the number of documents
that should be considered for inspection. Second, it provides a priority
ranking of what documents would be most beneficial to inspect.

PRI can minimize the number of documents that should be considered for
inspection. In Software Inspection \cite{Gilb93}, the number of possible
inspection includes \textit{all} the documents currently moving through the
development cycle.  (This technique tends to emphasize only current
documents and not the highest priority documents for inspection. Claim 2
addresses this issue.)  In PRI, the number of possible documents is
minimized to MINI documents. This reduces the number of possibile
inspections and can be advantageous for organizations that cannot inspect
every document, because it will eliminate the need and more importantly it
limits the possibility of inspecting LINI documents.

As an example of how PRI benefits an organization with limited resources
consider the following fictitious scenario:

\begin{quotation}
  \textit{ The FooBar organization has enough resources available to
    conduct inspections at least once a week. Because this organization
    produces more code than is possible to inspect, they use a round-robin
    approach by allowing a different developer to volunteer a piece of code
    to inspect. This developer must pick a small portion of the code he/she
    is currently working on and this decision is primarily based solely on
    his/her subjective opinions of the code.  }
\end{quotation}

This method works well if the developer can be trusted to pick the right
code to inspect. However, developers often do not know where every critical
defect will appear. In other words, leaving this decision up to the
subjective understanding of a developer maybe error prone. PRI provides an
alternative solution to this limited resource problem.  Instead of leaving
the decision of what code to inspect entirely up to the developer, PRI can
minimize the number of possibilities by providing a smaller area of
selection. For this fictional organization, the developer can find the MINI
documents and choose code from this smaller list.

PRI provides a priority ranking of what documents would be most beneficial
to inspect. This advantage supports the volunteering process by allowing
the developer to prioritize his/her selection of documents. The previous
discussion showed how PRI can minimize the number of documents; and now
that the number is reduced the developer still must select from this
smaller number. To support this selection, PRI ranks the documents
according to the calibration and numerical ranking. For example consider
this scenario:

\begin{quotation}
  \textit{ Developer John Doe is currently working on 10 different
    documents and he wants to volunteer one of them for inspection. He has
    a rough idea of what documents he thinks would be most beneficial for
    inspection but he isn't sure. He consults the PRI ranking and finds
    that 6 of his documents appear to be LINI. In addition, he is able to
    use the rankings to select a MINI document that he believes would
    generate more critical defects.}
\end{quotation}

This scenario illustrates how PRI can enhance the volunteering process by
first minimizing the number of documents that should be considered for
inspection and then prioritizing them.

\subsubsection{Evaluation Methodology} 
To evaluate this claim, I will ask the developers of Hackystat to provide a
numerical ranking, based on their subjective feelings, of what packages
they would volunteer for inspection. With these results I will be able to
compare the developers' subjective rankings against the PRI ranking In
addition, I will present each developer with the results of the hackyPRI
analysis, which provides the PRI weighting fuction and ranking. Then I will
ask the developers to re-rank the packages based on the new information.
This evaluation will indicate whether PRI is really needed. The findings
could indicate that developers can correctly distinguish, using their own
subjective reasoning, what packages need to be inspected.

To conduct this evaluation, I will provide each developer with a list of
Hackystat packages that they are currently working on. This will be
determined by assessing the developers' active time and commits to a
particular package. Given this listing I will ask each developer to provide
a numerical ranking of each package.

The following steps will occur in this evaluation:
\begin{enumerate}
\item Obtain the rankings of packages from each individual developer. I
  will use the questionnaire presented in Appendix
  \ref{appendix:questionnaire} to obtain these rankings.
\item Analyze the difference between the developers' ranking against the
  PRI MINI and LINI determination.
\item Conduct the following inspections: 
\begin{enumerate}
\item Inspect 2 packages, where the developer and the PRI determinations
  agree, that are MINI.
\item Inspect 2 packages, where the developer and the PRI determinations
  agree, that are LINI.
\item Inspect 2 packages where the developer and the PRI determinations
  disagree. The developer provides a low ranking but the PRI claims that
  the package is MINI.
\item Inspect 2 packages where the developer and the PRI determinations
  disagree. The developer provides a high ranking but the PRI claims that
  the package is LINI.
\end{enumerate}
\item Analyze the results of each inspection, which includes correlating
  the number of critical issues generated with both the developer ranking
  and the PRI determination. In addition, I may ask the developers for
  explanations of their rankings where applicable.
\item After each inspection I will adjust PRI calibration or add new
  product and process measures as necessary.
\end{enumerate}

There are three possible results from this evaluation. First, I may find
that developers automatically have a sense of what code is MINI and what
code is LINI. This would indicate that PRI provides little added value.
Second, developers have no idea what code needs to be inspected. The third
possible result represents a middle ground between the two previous
results, sometimes the developers are correct and sometimes they are wrong.
The last two results will indicate that PRI provides some benefit.


In addition, this evaluation will provide more data to refine the
calibration of the PRI weighting function.  For example, if a developer
rates a package very high, but PRI finds the package to be LINI and many
critical issues are found, then this indicates that the PRI weighting
function is flawed. Therefore, the PRI weighting function needs to be
recalibrated to include this document. In addition to calibration, more
process and product measures could be introduced. This event, although
detrimental to the previous PRI weighting function, will provide more data
for calibration and the addition of new measures will hopefully lead to a
better and more accurate PRI weighting function.



\subsection{Claim 2: PRI Identifies Documents that are Not Typically
  Identified by the Volunteering Process}
\label{sec:claim2}
Another intended benefit of PRI is it can find MIN documents that are not
typically identified using a volunteer-based document selection process.
If organizations with limited inspection resources blindly volunteer
documents for inspection they could be missing some areas of the system
that need inspection. A real example of this benefit is illustrated in the
following scenario:

\begin{quotation}
  \textit{ Not all Hackystat packages have experts. Instead there are some
    packages that I considered to be orphans. Orphaned-packages are usually
    packages that are considerably old code or code that has been written
    by developers who have left CSDL. In addition, these packages are
    usually never inspected and are considered to be in working order.  }
\end{quotation}

This situation is quite dangerous, because as we all know a software system
evolves and outdated packages may become error prone. Therefore, it is
important to realize that old packages can and should be MINI. Software
Inspection \cite{Gilb93} does not address this issue of outdated documents.
The common adage of Software Inspection is to inspect documents as they
move through the development cycle. This process tends to ignore documents
that have already finished the development cycle. In addition, because
organizations with limited resources can not inspect every document moving
through the development cycle, it is very likely that some documents will
finish the development cycle with major defects.  Therefore, ensuring that
``finished'' documents are included as potential inspection candidates is
very important.

\hspace*{1pt}

To evaluate this claim, I will make several inspection recommendations of
MINI packages and have not been investigated in the previous study. Again,
developers cannot always identify areas of the system that they think is
low quality and only using the volunteering method will likely miss some
documents that need inspection. The following steps will occur in this
evaluation:

\begin{enumerate}
\item Select a few packages that were not investigated in the previous
  study and has been classified as MINI and LINI. 
\item Conduct inspections on the selected packages. 
\item Analyze the results of each inspection, which includes correlating
  the number of critical defects generated with the PRI determination
  (either MINI or LINI). 
\item After each inspection I will adjust PRI calibration or add new
  product and process measures as necessary.
\end{enumerate}

There are two possible results of this evaluation. First, the packages that
were selected were correctly categorized by PRI. This finding will support
my claim. Second, the packages that were selected did not reflect the PRI
weighting function.




\subsection{Claim 3: More in need of inspection versus less in need of inspection}
\label{sec:claim3}
The last benefit of PRI is MINI documents will generate more critical
defects than LINI documents. This claim is critically important for PRI's
success. However, if a package is identified as LINI and yields many
critical defects, then PRI weighting function is flawed. I will use this
information to refine the PRI weighitng function. It is my hope that in the
end of the study I will have been able to successfully calibrate the PRI
weighting function for the Hackystat project.

During the evaluations of the previous two claims, CSDL will have conducted
at least 12 inspections.  In addition, I have and will collect information
on past and future inspections on Hackystat packages. In total, I believe I
will have data on 20 inspections and information on the PRI weighting
functions and rankings..

Currently, Hackystat and its extensions are comprised of 167 packages. As I
previously stated, an accurate and thorough evaluation of PRI requires the
inspection of all packages within the PRI rankings. However, because of
CSDL's limited resources this is not possible. At best this will take 3
hours per inspection, totaling 501 hours of inspection. This is
unrealistic.  Therefore, my proposed evaluation will investigate a small
percentage of the system, 20 of the 167 packages, in hopes that this
cross-section will provide adequate and acceptable results.

\hspace*{1pt}

To evaluate this claim, I will monitor the validity of the PRI weighting
function, adjusting the calibration as necessary, throughout each
inspection. To accomplish this, I will collect specific pieces of
information when conducting inspections. The following is a specific list
of the information collected:

\begin{itemize}
\item Inspection date
\item Hackystat module, package, and inspection ID
\item PRI determination (MINI or LINI)
\item PRI measures and values
\item Subjective discussion of the validity of the PRI weighting function
  before the inspection
\item Number of issues generated and the categorization of these issues
  according to severity
\item Retrospective discussion after the inspection was conducted to
  indicate possible areas of improvement. 
\end{itemize}

This information will help me keep track of the progress of the inspections
and the validity of the PRI weighting function. See Appendix
\ref{appendix:log} for a copy of the full log. As I previously stated, the
calibration of the PRI weighting function is an ongoing and evolving
process.  This information will help keep track of that evolution.  The end
goal of this evaluation is to create a best practices recommendation of the
types of process and product measures and their calibration that will
provide the best PRI results for different projects.

\section{Evaluation Timeline}
The following timeline  provides a timeline for the evaluation of this thesis:
\begin{table}[htbp]
  \begin{center}
    \label{tab:eval-timeline}
    \caption{Evaluation Timeline}
    \begin{tabular}{|l|l|l|} \hline
      {\bf Timeline} & {\bf Evaluation Activity} \\ \hline
February 9, 2005 & Pilot trial of the developer workspace rankings \\ \hline
February 16, 2005 & Request developer workspace rankings \\ \hline
February 16, 2005 & Process developer responses and create a plan of what
will be inspected \\ \hline
February 23, 2005 & Start 4 weeks of inspection, inspecting 2 packages a
week \\ \hline
March 30, 2005 & Hand pick 2 packages to inspect that was not
volunteered \\ \hline
March April 6, 2005 & Finished analyzing the results.  \\ \hline
    \end{tabular}
  \end{center}
\end{table}


\section{Initial Results of Evaluation}
\label{sec:intialresults}
The use of PRI to provide the determination of MINI and LINI has been
promising. The initial implementation of the system has proven that it is
technically possible to do what I have envisioned. In addition, I have
already recommended the inspection of a few package that were ``more in
need of inspection'' and the defects and issues identified have confirmed
that the PRI ranking was correct. See the inspection log
(\ref{appendix:log} for a detailed description of the inspection results.

I will continue to discover new measures to add to the PRI weighting
function, fine tune the numerical weights associated with the measures, and
continue to recommend inspections.















