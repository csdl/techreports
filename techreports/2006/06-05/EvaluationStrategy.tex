\chapter{Evaluation Strategy}
\label{Chapter:EvaluationStrategy}


There are a variety of possible approaches to empirical evaluation of software project telemetry. This chapter provides an overview of these approaches based on \textit{Creswell's} book \textit{Research Design: Qualitative, Quantitative, and Mixed Methods Approaches} \cite{Creswell:2003}. The approach I chose is based on the concepts and techniques presented in that work.  
This chapter starts with a review of research methods in Section \ref{EvaluationStrategy:ResearchMethods}, followed by a discussion of the evaluation strategy with respect to software project telemetry in Section \ref{EvaluationStrategy:EvaluationStategy}.
Section \ref{EvaluationStrategy:Summary} concludes the chapter.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                       %
%                   S E C T I O N                       %
%                                                       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Review of Research Methods} \label{EvaluationStrategy:ResearchMethods}

Creswell \cite{Creswell:2003} categorizes research methods into three paradigms: \textit{quantitative}, \textit{qualitative}, and \textit{mixed-methods}, according to their underlying philosophical assumptions about what constitutes knowledge and how knowledge is best acquired. The \textit{quantitative} paradigm is related to \textit{post-positivism}; the \textit{qualitative} paradigm is related to \textit{constructivism}; and the \textit{mix-methods} paradigm is related to \textit{pragmatism}.






\subsection{Quantitative Paradigm and Post-Positivism}

The philosophical underpinning of the quantitative paradigm is post-positivism. Post-positivism differs from positivism by recognizing that there is no absolute truth. Instead, it seeks to develop ``relevant true statements'' that can explain a situation and describe a causal relationship. Knowledge is conjectural in nature. The researcher tests a theory by specifying narrow hypotheses, collecting closed-ended data on predetermined instruments, and using statistical procedures to analyze the data to either support or refute the hypotheses. 

The most often used inquiry strategy in the post-positivist paradigm is the experiment. There are three basic experimental designs. From the least rigid to the most rigid, they are: correlation study, quasi-experiment, and true experiment. In a correlation study, a single group is studied without comparison to an equivalent non-treatment group. The quasi-experiment design introduces a control group, but it falls short on random assignment of study subjects.  The true experiment design employs both a control group and randomization. The purpose of increased rigidity is to control as many confounding variables as possible in order to determine true cause and effect. It is often thought that a true experiment is the only research method that can adequately measure the causal relationship. However, in the real world, a true experiment might be too expensive or might not be feasible at all.

The primary criteria with which to judge post-positivist research are \textit{internal validity} and \textit{external validity}. 
Internal validity is related to causality. It is demonstrated by showing that the cause not only correlates with but also precedes the effect, and that there is no plausible alternative explanation for the observed effect. 
External validity is related to generality. It is the degree to which the results obtained in a study can be applied to a larger population. 
Thus, for example, the use of control groups and randomization techniques are crucial to mitigate the threats to internal and external validity.








\subsection{Qualitative Paradigm and Constructivism}

The philosophical underpinning of the qualitative paradigm is constructivism. Constructivism assumes that all knowledge is ``constructed'' by observers who are the product of traditions, beliefs, and the social and political environment within which they operate. A researcher makes knowledge claims primarily based on constructivist perspectives, such as multiple meanings of individual experiences and socially or historically constructed meanings. The researcher tends to collect data through open-ended questions or by observing the participants' behaviors, trying to understand a particular situation, event, role, group, or interaction from their views. The research is largely an investigative process where the researcher gradually makes sense of a phenomenon by contrasting, comparing, replicating, cataloging, and classifying the objects of study \cite{Miles:1994}.

A major factor that distinguishes constructivism from post-positivism is that a researcher is not prescribing the questions that need to be answered from his / her own standpoint. Instead, the researcher tries to learn from the participants. In other words, the difference lies in the views about the nature of knowledge and how knowledge is best acquired. While hypotheses are specified \textit{a priori} in the post-positivist paradigm, they are established \textit{a posteriori} in the constructivist paradigm. Other unique characteristics of the constructivist paradigm are:

\begin{itemize}
	\item A constructivist study usually takes place in natural settings where human behavior and events occur.
	\item A constructivist study often uses multiple interactive methods such as open-ended questions, observations, and interviews.
	\item A constructivist study focuses on the participants' perceptions, experiences, and their understanding of the world in which they live and work.
	\item A constructivist study is emergent rather than tightly pre-configured. 
	\item A constructivist study places little importance on developing statistically valid samples, or on searching for statistical support for hypotheses.
\end{itemize}

A primary reason for conducting a constructivist study is that the research is exploratory in nature. The researcher seeks to listen to the participants in order to build an understanding based on their ideas and views. There are many established methods to conduct constructivist inquiries. For example, 28 methods were identified in \cite{Tesch:1990}, and 19 in \cite{Wolcott:2001}. Among them, the most commonly-used methods are observation, interview, case study, and grounded theory\footnote{Some of them, such as case study and grounded theory, might be better called methodologies instead of methods. However, the difference in terminology is not important to this research.}:

\begin{itemize}
	\item In the observation method, a researcher gathers firsthand data on programs, processes, or behaviors being studied. The intent is to obtain a holistic picture of how people describe and structure their world in the context of the social settings they live in. There are various observation techniques. The most fundamental distinction is the extent to which a researcher is a participant in the setting being studied. It can range from complete involvement in the setting as a full participant, to complete separation from the setting as an outside spectator.
	
	\item In the interview method, the assumption is that the participants' perspectives are meaningful, knowable, and able to be made explicit. There are two types of interview: structured vs. in-depth. A structured interview is essentially a carefully-worded questionnaire that follows a rigid form. The purpose is to ensure uniformity of interview administration. On the other hand, an in-depth interview encourages free responses for more detailed exploration of open-ended questions.
	
	\item In the case study method, a researcher explores one or more cases (a program, an event, an activity, a process, etc.) in depth in order to gain a sharpened understanding of why the instance happened as it did, and what might become important to look at more extensively in future research. It lends itself especially to generating rather than testing hypotheses. The emphasis of a case study is on investigating a few cases in detail, rather than using large samples and following a rigid protocol to examine a limited number of variables.
 
	\item In the grounded theory method, a researcher generates theories from data. The goal is to formulate hypotheses based on conceptual ideas from empirical data. The basic approach is to read and re-read a textual database such as a collection of field notes in order to label variables and note their interrelationships. Formally, the approach includes steps of coding (open coding, selective coding) and memoing (theoretical memoing). When the method is followed correctly, the researcher should be able to generate a theory that fits the data perfectly.
	
\end{itemize}

%In the ethnographic approach, a researcher studies an intact group of people in a natural setting over a prolonged period of time. The intent is to obtain a holistic picture of how people describe and structure their world by observing and interviewing them. Ethnographic accounts are both descriptive and interpretive. The research process is flexible and typically evolves contextually in response to the lived realities encountered in the field setting \cite{LeCompte:1999}. Ethnography emphasizes passive observation (no intervention) and holistic approach (subjects cannot be understood independent of the social settings they live in).


The distinctions between these methods are blurred at best. They are not mutually exclusive. They just have different emphases. For example, the observation and interview methods focus more on data collection, while the grounded theory method focuses more on hypothesis generation. Therefore, it is possible to say that \textit{``I am conducting a case study, collecting data through observation and interview, and generating hypotheses following the grounded theory method.''}

The goal of constructivist research is quite different than that of post-positivist research. Instead of controlling the context by using random assignment and control groups in order to develop ``truth'' that is ``broadly'' applicable outside the context in which the research occurred, constructivist research focuses on ``deep'' understanding of the context in which the observed events and outcomes occurred. The results in a constructivist study are thus closely tied to the context in which the research was carried out. 

As a result, the criteria with which to judge constructivist research are quite different than that for post-positivist research. 
Internal validity carries a different meaning than that in a post-positivist research. Since the results in a constructivist study are actually an integrated set of conceptual hypotheses emerging from empirical data in the particular context the study was conducted, internal validity in its traditional sense is consequently not an issue \cite{Glaser:1998, Glaser:1967}. In other word, it no longer focuses on causality. Instead, a constructivist study should be judged by the degree to which its results fit the existing data.
External validity also carries a different meaning. Since the results in a constructivist study are somewhat tied to the context in which the research is conducted, they may not be applicable in another context. While in the post-positivism paradigm, external validity focuses on the extent to which the results obtained in one study can be generalized to a larger population; in the constructivism paradigm, it focuses more on whether the process used in acquiring the 
knowledge could work in a different setting. Therefore, most constructivist studies seek to provide \textit{thick descriptions},\footnote{According to \textit{wikipedia}, thick description is a phrase used most famously by the anthropologist Clifford Geertz to describe his own work: explaining the context of the practices and discourse that take place within a society such that these practices become meaningful to an ``outsider.''} so that anyone who is interested in transferability of the results can have a solid framework for comparison \cite{Merriam:1998}.



\subsection{Mixed-Methods Paradigm and Pragmatism}

Once the relationship between the quantitative paradigm and the qualitative paradigm is clear, the mixed-methods paradigm is easy to comprehend. Strictly speaking, it is not really a paradigm of its own. It is just a mix of different methods in the same research. The methods in the mix can come from either the post-positivist tradition, or the constructivist tradition, or both. 

The philosophical underpinning of the mixed-methods paradigm is pragmatism, in which knowledge claims arise out of actions, situations, and consequences rather than antecedent conditions such as those in post-positivism. To mixed methods researchers, understanding the problem and finding the solutions are more important than commitment to a single methodology. As a result, they use whatever methods that are available in order to best understand the problem and find solutions.

According to Creswell \cite{Creswell:2003}, the idea of mixing different methods probably originated in 1959 when Campbell and Fiske used multiple methods to study validity of psychological traits. They encouraged others to employ their ``multi-method matrix'' to examine multiple approaches to data collection in a study, which prompted other researchers to start mixing methods. Soon approaches associated with field methods such as observations and interviews were combined with traditional surveys. 

%Lot of work has been done in this field. It includes \cite{Cherryholmes:1992, Murphy:1990, Patton:1990, Rorty:1990, Tashakkori:1998}. The situation today is less \textit{quantitative versus qualitative}, and more how research practices lie somewhere on \textit{a continuum between the two} \cite{Neuman:1998}. The best that can be said is that studies tend to be more quantitative or qualitative in nature.

A major factor that distinguishes the mixed-methods paradigm from others is that it is problem centered and real world practice oriented. Other unique characteristics of mixed methods research include:

\begin{itemize}
	
	\item A mixed-methods researcher does not mix different methods blindly. There is always a purpose for ``mixing.''
	
	\item A mixed-methods researcher is ``free'' to choose the methods, techniques, and procedures of research that best meet his/her needs and purposes, rather than subscribing to only one way.
	
	\item A mixed-methods researcher uses different methods because they work to provide the best understanding of the research problem. 
	
\end{itemize}








\subsection{Clarification of Terminologies}

Before discussing my approach to the evaluation of software project telemetry, I will first try to clear some terminology confusions around ``quantitative vs. qualitative.''

To reiterate briefly, \textit{post-positivism} is the philosophical underpinning of the \textit{quantitative} paradigm. It seeks to develop ``relevant truth'' that can explain a situation and describe a causal relationship. 
\textit{Constructivism} is the philosophical underpinning of the \textit{qualitative} paradigm. It assumes that all knowledge is ``constructed'' by observers who are the product of traditions, beliefs, and the social and political environment within which they operate. 

Creswell did a good job of distinguishing the various kinds of research methods according to their underlying philosophy about knowledge. However, many researchers, including Creswell himself, overloaded the phrases like ``quantitative research'' and ``qualitative research'' with multiple meanings. Sometimes they were used to refer to the post-positivist and constructivist paradigms to acquire knowledge, while other times they were used to refer to the collection and analysis of quantitative (numeric) and qualitative (non-numeric) data. 
The wide-spread use of the terminologies like ``quantitative research'' and ``qualitative research'' creates confusion, because either paradigm for acquiring knowledge can use either numeric or non-numeric forms of data. 
The only relationship, at best, is the historical tendency that most post-positivist research focused on collection and analysis of quantitative data, while most constructivist research collected and analyzed qualitative data. 
However, this is not a rule at all. There is nothing to prevent a constructivist study from using quantitative data, or vice versa.
What exacerbates the problem is that, in most cases, quantitative data and qualitative data are convertible to each other, though the conversion process might result in loss of information. The distinction between quantitative and qualitative is thus almost meaningless. As a result, the title of Creswell's book \cite{Creswell:2003} would be much more self-evident and accurate if it would have been called \textit{``Research Design: Post-positivism, Constructivism, and Mixed Methods Approaches''} instead of \textit{``Research Design: Qualitative, Quantitative, and Mixed Methods Approaches.''}

For the sake of clarity, I will avoid the use of ``qualitative'' and ``quantitative'' when discussing my research, and instead use more precise terms for my methods (e.g., grounded theory) and data (e.g., questionnaire).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                       %
%                   S E C T I O N                       %
%                                                       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Software Project Telemetry Evaluation Design}
\label{EvaluationStrategy:EvaluationStategy}

Generally speaking, the post-positivist paradigm is more suitable for natural science inquiry, while the constructivist paradigm is more suitable for social science exploration. Software engineering is neither a pure natural science nor a pure social science. It lies somewhere on a continuum between the two. Therefore, in setting up the evaluation of software project telemetry, I considered both options:

\begin{itemize}
	\item If I followed the post-positivist paradigm, my evaluation would start with some hypotheses about software project telemetry, such as how it might affect the project decision-making process. An experiment would then be set up to collect the relevant data, and statistical procedures would be used to analyze them. 
I would try to control the software development environment in which the experiment was conducted through the use of control groups and random assignments. My goal would be to test a theory about the use of software project telemetry that would be broadly applicable in most software development environments, if not all of them.
	
	\item If I followed the constructivist paradigm, my evaluation would start with open-ended data collection. Knowledge about software project telemetry would be acquired \textit{a posteriori} after the data collection was complete. I would emphasize the importance of understanding the software development environment in which software project telemetry was adopted, rather than trying to control the environment through control groups and random assignments. My goal would be to gain a much deeper understanding about the use of the technology within the particular environment in which the study would be carried out, and perhaps even generate a theory from the data that would explain what I observed in that context.
\end{itemize}

The two paradigms provide a trade-off between breadth and depth with respect to the knowledge to be acquired about the use of software project telemetry. The post-positivist paradigm aims to yield broadly generalizable conclusions. But, at very best, it can elicit only a few and probably superficial guidance about how to use the technology effectively. On the other hand, the constructivist paradigm aims to include many more detailed insights. But such insights might be limited in the extent to which they apply beyond the specific software development environment in which they are generated.

It is this trade-off that determined my strategy for the evaluation of software project telemetry. The post-positivist paradigm requires at least some basic level of experience with the technology, so that meaningful hypotheses could be specified \textit{a priori}. In case where there is little experience, the constructivist paradigm would be more appropriate. It would allow me to gain a sharpened understanding within the particular software development environment in which the technology is deployed, so that hypotheses could be generated from the events occurred in that environment. This could, in turn, provide me with valuable clues in deciding what might be important to study more extensively in the future. 

Software project telemetry is a brand-new approach to metrics-based project management and process improvement. Up to now, only its theoretical properties are clear. They are the principles upon which the approach is developed (see Chapter \ref{Chapter:Telemetry}).
To reiterate, software project telemetry is designed to address the \textit{``metrics collection cost problem''} through highly automated measurement machinery: software sensors are written to collect metrics automatically and unobtrusively. Sensors keep metrics collection cost low by eliminating the chronic ``context-switch'' overhead.
Software project telemetry is also designed to address the \textit{``metrics decision-making problem''} through a domain-specific language for the representation of telemetry trends for different aspects of software development. Project management and process improvement decisions are made by detecting changes in telemetry trends and comparing trends in two different periods of the same project, which not only eliminates the need to build statistical models that require frequent calibration but also enables empirically-guided in-process control of a project that is still being developed.

The theoretical properties of software project telemetry appear promising as it is described on paper, since it overcomes many limitations in existing metrics-based approaches to project management and process improvement. But what will happen when it is used in ``real world'' settings? Software project decision-making is a very complicated phenomenon. It involves not only the software product being developed and the process being followed, but also human behaviors and interactions among the developers. 
At this early stage of research, there is little empirical experience with respect to the real world use of software project telemetry. Many questions remain to be answered.
For example, will software project telemetry actually be useful to a software development team in practice? What impact will it have on project decision-making? What are the best practices? What are the obstacles? Which obstacle can be fixed, and which might become technology adoption barrier? 
%For example, it is not obvious how mangers and developers make project management and process improvement decisions. It is not obvious what impact software project telemetry will have on a development team. It is not even obvious whether a software development organization will even want to adopt the technology.

While it would be possible to set up a controlled experiment in the post-positivist paradigm to compare the decision-making value of software project telemetry to those of other competing metrics-based approaches, such as PSP, TSP and CMM, I feel it is not the most useful form of research at this point, because I am not even sure whether a software organization will want to use the technology if it is given the opportunity.
Instead, what would be most fruitful at this stage is to conduct research in the constructivist paradigm, which has techniques for generating the appropriate kind of understanding of software project telemetry in and of itself. By exploring how the technology is used in some real software development environments, I can gather detailed information about how it helps developers and managers make decisions and learn from these experiences. 
A comparative study is best performed after this initial understanding has been acquired. 
For example, if it turns out that software project telemetry is indeed adoptable and useful in the environment in which it is tried, then the experience from that study could be used to guide the design of further evaluation of software project telemetry, which might be a comparative study in the post-positivist paradigm.

The major disadvantage of following the constructivist paradigm in evaluating software project telemetry is the generalizability of the results. Since a constructivist study will focus on the particular software development environment in which the technology is adopted, the knowledge acquired in that environment may not be applicable in other environments. The reality is that software development environments are diverse, and each may have different development processes and constraints on metrics collection and analysis. For example, in COCOMO II, the post-architecture model has 17 effort multipliers and 5 scale factors to approximate this diversity. Achieving some degree of generalizability is important to wide adoption of software project telemetry in the future. An approach to mitigate this disadvantage is to conduct evaluations in different environments with complementary characteristics. The idea is that by comparing and contrasting the similarities and differences of the experiences from different environments, one can ``interpolate'' and ``extrapolate'' the results to gain further insights that might generalize to other software development environments.

My final choice is to follow the mixed-methods paradigm. The use of multiple methods has the advantage of using the strength in one method to make up for the weakness in another method. The primary goal of my evaluation is to assess metrics collection cost and decision-making value of software project telemetry. The secondary goal is to discover obstacles the developers might encounter during their use of the technology, and to gain insights about software project telemetry best practices and possible technology adoption barriers. The two software development environments are:

\begin{itemize}
	\item \textbf{Classroom} --- This is the two software engineering classes taught by Dr. Philip Johnson at the University of Hawaii in Spring 2005: one class for senior-level undergraduate students, and the other for introductory-level graduate students. By curriculum design, the students were divided into groups of 2 - 4 members collaborating on group projects and introduced to use software project telemetry to collect metrics and perform analyses on their own data. There were 25 students participating the study: 9 from the undergraduate session, and 16 from the graduate session. The details of the classroom setting will be described in Section \ref{EvaluationInClassroom:Setting}.
	
	\item \textbf{CSDL} --- This is the Collaborative Software Development Lab at the University of Hawaii. It is a software engineering research lab. The study was conducted in Spring 2006 when a large scale software system (i.e., the Hackystat itself) with almost 300,000 lines of code was being developed and maintained by a team of five on-site developers and a project manager. Three of the developers were Ph.D. students (including me) in software engineering. They were hired by the lab working 20 hours a week. The other two were undergraduate students in their final semester. They were top students from the undergraduate software engineering class. They were working for the lab in exchange for personal development and course credit. The details of the CSDL setting will be described in Section \ref{EvaluationInCSDL:Setting}.

\end{itemize}

The software development environments in the classroom and CSDL were quite different. In the classroom, there were a relatively large number of participants (25 students). They were working on small scale class projects. In CSDL, there were a relatively small number of participants (five developers and one project manager). However, the project under development was much larger in scale. It contained almost 300,000 lines of code in total, and had been under development for five years. The CSDL developers had significantly more software engineering experience and process maturity compared to the average student in the classroom.

As a result, the way that software project telemetry was introduced in the two environments was different.
The classroom study was \textit{``passive''} in nature: though the students were asked to use software project telemetry to collect metrics and perform analyses on their own data, I did not make any deliberate attempts to help them improve their software development processes. On the other hand, the CSDL study was \textit{``active''} in nature: I introduced software project telemetry as a metrics-based process improvement program; I helped the project manager institute changes to improve project management practices; I also helped the developers gain insights into their development process.

Consequently, different data collection and analysis techniques were used in the two studies. 
The classroom study was relatively simple. My goal was to gather insights from a relatively large number of developers in a relatively short period of time. I distributed a questionnaire at the end of the semester to collect the student's opinions about software project telemetry. To increase my confidence in the validity of their self-reported opinions, I also analyzed their telemetry analysis invocation pattern to determine the extent to which their opinions were based on the actual system usage. 
In the CSDL study, I pursued a much more in-depth data collection and analysis strategy over a much longer period of time. I collected data from observations and interviews. I generated hypotheses from the data. I also tested the hypotheses in a limited way by making changes to the telemetry system or implementing new facilities to see whether the hypothesized outcome would come true or not. 
%To some extent, this hypothesis testing procedure could be viewed as the simplest and uncontrolled form of experiment. The difference is that most experiments rely on statistical analysis to draw conclusions, but mine does not.
%I stayed in the lab almost everyday working with the developers. I attended every project status update meeting. I kept detailed notes of observations. I conducted frequent interviews. I analyzed CSDL product and process metrics. A ``modified'' grounded theory approach was followed to generate hypotheses.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                       %
%                   S E C T I O N                       %
%                                                       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Chapter Summary} \label{EvaluationStrategy:Summary}

In this chapter, I have provided a review of research methods. The most important distinguishing factor among different methods is their underlying philosophy about knowledge. Post-positivism and constructivism have very different view on the nature of knowledge and thus very different approaches to acquire knowledge. 
My evaluation of software project telemetry was carried out in two case studies following the mixed-methods approach. The next two chapters reports on the details of the two studies.