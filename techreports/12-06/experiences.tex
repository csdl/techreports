%\newpage
\section{Experiences}

To better understand the strengths and weaknesses of the Makahiki+WattDepot software stack, we have been designing and implementing an ``Energy Challenge'' called the Kukui Cup.  Development of the Kukui Cup challenge began in 2009, and the first Kukui Cup challenge was held in 2011 for over 1,000 first year students living in the residence halls at the University of Hawaii (UH) in Fall, 2011.  In Fall 2012, the second Kukui Cup challenge was held at the University of Hawaii using Makahiki+WattDepot.  In addition, Hawaii Pacific University (HPU) held a Kukui Cup challenge using Makahiki+WattDepot. Finally, an international organization called the East-West Center (EWC) held a Kukui Cup challenge using just Makahiki (their energy data was manually gathered by reading meters and entering the data by hand, so WattDepot was not needed for their challenge).    

The successful creation of four challenges by three different organizations over two years provides evidence that the software stack can be tailored to the differing needs of separate organizations.  First, UH uses meters by Electro-Industries Inc., while HPU uses meters by EGauge Inc., and EWC collected their energy data manually. Second, while UH and HPU challenges involved only energy consumption data, the EWC challenge involved both energy and water consumption data (which was also collected manually).  Third, the IT infrastructure at UH and HPU provided authentication services using CAS and LDAP, while EWC used the built-in Django authentication. Fourth, the user interface was customized to ``brand'' each challenge with the logo and other thematic elements of the sponsoring organization. 

On the other hand, it should be recognized that these organizations are in other ways quite similar: they are all institutions of post-secondary education, and they are all based in Hawaii.  These organizational similarities are mostly due to the desire by the 2012 challenges to reuse a significant amount of the content developed in 2011, which was oriented toward the Hawaii-based, college-aged demographic. For 2013 and beyond, we hope to expand our experiences with the software stack  ``downward'' into primary and secondary schools, and well as ``outward'' into residences and businesses. 

User response to the 2011 UH Kukui Cup challenge was positive, and provided evidence regarding the software stack's usability, functionality, and performance characteristics.   Over 400 students participated, for an adoption rate of approximately 40\%.  In a user survey conducted near the end of the challenge, over 90\% of users said they would participate in the challenge again if offered an opportunity.  60\%  said ``ease of use'' was the thing they liked best about the website.  40\% responded ``Nothing'' when asked what was confusing about the website, and 32\% responded ``Nothing'' when asked what they would change about the website.  The survey did yield insights into what could be improved, including the ability to introduce new games at points during the challenge, to provide better access to other player data, and to simplify navigation.  There was virtually no downtime during the 2011 challenge, and only one significant bug in the system (affecting scoring) was discovered during the challenge, which was fixed within a day of its discovery.  Finally, a pre- and post-challenge survey questionnaire yielded statistically significant evidence that participants in the challenge learned more about energy concepts than those not participating, demonstrating that the approach can serve to improve consumer knowledge of energy as needed for active engagement with the Smart Grid.

The 2012 challenges are ongoing as of the time of writing, so the following results must be viewed as preliminary, but our current experience is similarly positive to 2011.  The UH challenge participation rate so far appears to be slightly lower than last year, at about 33\%, though the HPU challenge participation rate so far is higher (approximately 50\%), and the EWC participation rate is much lower (around 6\%). None of the challenge instances have experienced significant downtime, and so far only 1 significant bug (affecting scoring) has been reported (and has again been fixed within a day).  Load testing of the software stack just prior to the 2012 challenge indicates a hypothetical throughput of around 200 concurrent users with acceptable page loading times, though we have not experienced that level of load in the current challenges. 

Our experiences over the past two years has provided many lessons learned, and some of the most important regarding the Makahiki+WattDepot software stack are:

{\em Collecting energy data is challenging.} As alluded to in our discussion of WattDepot, collecting accurate energy data requires significant planning and effort. The process of installing meters for the 2011 UH Kukui Cup started over one year before the meters were finally installed and ready for use, despite the cooperation and goodwill of all involved parties. Gaining an understanding of the electrical infrastructure of the residence halls proved crucial in the success of the UH Kukui Cup, as a renovation project led to the installation of additional distribution panels and thereby doubled the number of meters that were needed to measure electricity use. Due to delays in the installation of the meters for the 2011 UH Kukui Cup, a meter installation problem that led to inflated energy readings for one floor was not discovered until after the competition was complete and an energy audit of the building could be performed. Manual data collection also poses a variety of challenges. Existing meters for electricity and water may be configured for coarse monthly readings rather than the daily readings that are needed for a competition. Existing meters may also be installed in dirty or difficult to reach areas that make daily data collection unpleasant. If the challenge administrators wish to examine energy or water use after the challenge is complete, to determine if behavior changes made during the challenge are sustainable, daily manual data collection requires a long-term commitment. The lesson learned is for challenge administrators to start planning how they will obtain energy or water data as early as possible, since they are likely to encounter many challenges in collecting the data.

{\em Cloud-based hosting simplifies installation.}  During 2012, we have gained experience with both cloud-based hosting as well as local installation for the Makahiki+WattDepot software stack.  We have found that cloud-based hosting significantly simplifies the installation process and avoids certain types of installation-related bugs from occurring, particularly when system administrators are not familiar with the stack components that Makahiki+WattDepot depend upon (Django, Java, Python, git, etc.)  On the other hand, cloud-based hosting incurs costs (in our experience, between \$50-\$100/month for these challenges) and may incur constraints (for example, the Heroku hosting platform currently has minimal support for LDAP authentication).  The Makahiki Manual \cite{MakahikiManual} provides instructions for both cloud-based and local installation, providing some idea of the differences between the two approaches.  The lesson learned is to use cloud-based hosting when possible, or allow plenty of time for administrators to work through the software stack installation issues. Makahiki+WattDepot is not yet a ``plug-and-play'' system.

{\em Challenge design and administration is time consuming.} Despite the freely providing the Makahiki+WattDepot software stack to HPU and EWC, along with content developed specifically for college-age residents of Hawaii, the administrators still expressed surprise at the how time consuming it was to design and administrate the running of their respective challenges.  This appears to be due to the fact that the software stack enables a variety of game mechanics (such as the Smart Grid Game, Raffle Game, Badges, and point-based Prizes) not present in more simplistic energy challenges.  For example, the Smart Grid Game requires configuration of the widget including what activities to include and when/where they appear in the game.  The Raffle Game and point-based awards requires the collection of appropriate prizes. While we provided a library of almost 100 activities from 2011, all of the 2012 challenges required the definition of at least a few new events.  Thus, although the result is a more sophisticated experience for the participants, the up front design and overhead during execution was generally surprising to the administrators. The Kukui Cup Challenge Planning Guide \cite{KukuiCupChallengePlanningGuide} provides more details on this process.  The lesson learned is to make sure that potential organizational sponsors understand that the use of this software technology is not intended to make it more simple for them to run an energy challenge, but rather to enable them to create a more sophisticated energy challenge than would otherwise be possible.

{\em Scalability cuts across both design and implementation.}  So far, the use of the Makahiki+WattDepot software stack has been limited to relatively small user communities of 1,000 participants or less.  We believe that the system and approach would scale relatively well to some small number of multiples of that number, say to a maximum of 10,000 challenge participants.  On the other hand, there are both design and implementation challenges in scaling the software stack to communities of significantly larger than 10,000 participants.

On the design side, Makahiki currently requires administrators to approve each submission by a participant in order for that participant to receive points.   In the UH challenges, that results in administrative approval of around 4,000 individual submissions over the course of the challenge.  This incurs administrative overhead, but makes it easier to verify that players are actually taking part in activities and improves the sense of fairness in the game.  On the other hand, we do not believe this approach would be practical if there were an order of magnitude more submissions to process.  To scale, the current manual approval process must be automated, and must be done in a manner that preserves essential game mechanics.  For example, simply changing the current short answer verification format by multiple choice could result is players just randomly selecting values until they find the right one.  Multiple choice also does not support certain types of activities where the submission is a link, a photo, or even a poem.  So, scaling up by an order of magnitude might affect the types of activities that can be supported in the challenge. Peer review of action submissions is one possible solution, but would require careful design and testing to ensure the competitive nature of the challenge does not encourage unfair evaluation of submissions.

On the implementation side, our current performance testing indicates a maximal throughput of approximately 200 concurrent users.  Interestingly, increasing the number of server/web resources available through cloud-based hosting does not appear to appreciably increase maximal throughput.  Thus, it does not appear to be true that cloud-based hosting will magically ``solve'' the scalability problem for the Makahiki+WattDepot software stack.  Because the current level of throughput is adequate for the communities we are current targeting, we have not investigated this issue further.  The lesson learned is that if an organization wants to perform an energy challenge for a community of more than 10,000 users, significant design and implementation challenges must be addressed.
