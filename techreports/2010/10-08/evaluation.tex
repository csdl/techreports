\chapter{Evaluation}
\label{cha:evaluation}

This chapter describes the way I evaluated the 2011 UH Kukui Cup challenge and associated software system described in \autoref{cha:system-description}. First, I cover the overall experimental design, followed by details on the three primary experiments I conducted: challenge participation, energy literacy, and energy use. The research questions the evaluation is intended to address are:

\begin{enumerate}
	\item \emph{To what extent did residents participate in the challenge?} I ask this question because without significant participation in the challenge, there would be insufficient data to answer the rest of the questions.
	\item \emph{How did energy literacy change after the challenge?} We designed the challenge to increase the energy literacy of participants, so this question assesses one aspect of the challenge's effectiveness.
	\item \emph{How did energy use change during the challenge?} A standard measure for energy competitions, the expected result is that energy is conserved during the competition.
	\item \emph{How did energy use change after the challenge?} Understanding changes in energy use after the challenge is over gives insight into whether changes during the challenge were sustainable. Existing research focuses primarily on the challenge itself, not examining the reasons why energy usage might rebound after the challenge is over.
	\item \emph{What is the relationship between energy literacy and energy usage?} I hypothesize that more energy literate participants will conserve more energy; therefore, I examined the relationship both during the challenge and afterwards.
	\item \emph{How effective were the \emph{actions} available via the website?} Are the actions that players complete during the challenge effective at improving energy literacy?
	\item \emph{How appropriate were the point values assigned to actions?} The points assigned to actions are intended to motivate participants to perform the actions, but the values were assigned without any participant data.
	\item \emph{How important was lounge-level near-realtime feedback?} There are good reasons to believe that lounge-level near-realtime feedback will lead to increased energy conservation, but they also greatly increase the challenge budget and logistical complexity. Is the trade-off worth it?
\end{enumerate}

\section{Experimental Design}

I have pursued a largely quantitative approach to the evaluation of my research questions~\cite{Creswell2003}. From this perspective, the participants in the study are all the residents in the Hale Aloha towers, and the entire Kukui Cup challenge can be viewed as the intervention. To produce a \emph{true experiment}, I would need to create control and treatment groups and assign participants to the groups randomly. Unfortunately, the logistics and design of the game experience led to complications for the experimental design. In designing the game, we felt that it would be unfair to residents to create a control group that was not allowed to play, especially because players could earn prizes. We also worried that if we created a control group that could not play, this decision could create a negative backlash against the challenge, with players in the control group encouraging those in the treatment group to not play. Creating a control group would have also created logistical issues around preventing access to the game, because we held public events such as workshops and award parties that were open to all Hale Aloha residents. Finally, we felt that our partners in Student Housing would not be supportive of a Kukui Cup challenge in which some residents could not participate only for the purposes of research design.

Since random assignment to control and treatment groups was not feasible in the 2011 UH Kukui Cup, I use a quasi-experimental design with non-randomized group assignment. While all Hale Aloha residents were able to participate in the challenge, I had no expectation that all of them would participate. Since participation in the challenge is the treatment, in effect residents self-selected whether they were in the treatment or control group by whether or not they participated in the challenge.

Unlike some interventions, the 2011 UH Kukui Cup was a dynamic experience that included direct interactions with participants by myself and other researchers both online in responding to emailed questions and in person at events held during the challenge. My research's combination of researcher involvement, attempting to ``improve'' the participants of the study, while simultaneously generating knowledge is similar to the \emph{Action Research} approach~\cite{kock2013}. Action Research commonly involves an organizational client that is trying to solve a problem. However, in the case of the Kukui Cup, the impetus for the change came from our identification of the problem rather than the participants. The challenge itself also changed during the study, such as the addition of referral bonus (\autoref{sec:referral-bonus}).

The following sections describe the individual experiments I conducted in an effort to answer my research questions.


\section{Challenge Participation Experiment}
\label{sec:participation-exp}

Research question \#1 is ``to what extent did residents participate in the challenge?'' First, I must define what it means to participate in the challenge.

\subsection{Participation Definition}
\label{sec:participation}

Participation in the Kukui Cup challenge was a critical measure for the evaluation of the impact of the system. All residents were indirectly participating in the energy competition because their electricity use was being monitored in aggregate, regardless of their awareness of the competition itself. However, I use the term participation here to indicate a conscious participation in the Kukui Cup, which can be measured in a variety of ways.

I use the score of each user as the metric for participation in the Kukui Cup. The challenge website was its focal point. The website provided the only way to earn points, and the primary way to see scoreboards and information about events. When logging into the website for the first time, users are funneled through a first-login process where they must view and accept the consent form and choose a nickname. All users who complete the first-login process earn a minimum of 5 points, so any users that used the challenge website had a non-zero score. The first-login process also displays a short introductory video and prompts the user to answer a simple question about the video to earn an additional 20 points. So most first-time users will have earned 25 points by the time they arrive at the home page of the challenge website. Therefore, I classify any user with 25 points or more as a participant in the challenge, which is conservative threshold because it only requires a single visit and no activity beyond those mandated by the first-login process.

It is possible for resident of Hale Aloha to have participated in aspects of the Kukui Cup without earning points. For example, residents could have attended events by accompanying friends or come upon them serendipitously, without submitting the paper attendance code that would allow them to earn points for attendance. Residents also could have participated by discussing sustainability topics with active participants or been lobbied to reduce energy use to improve their lounge's standings in the energy competition. Neither of these activities would have generated any evidence in the form of points in the challenge. Despite these caveats, I believe a 25 point threshold is a good, minimal measure of participation.

\subsection{Challenge Participation Experimental Design}

The assessment of challenge participation does not include a control group, because the dependent variable is whether residents participated or not. In Creswell's terminology, this experiment is a one-shot case study~\cite[pg. 168]{Creswell2003}. Using the notation from Campbell and Stanley~\cite{Campbell1963}, the challenge participation experiment can be diagramed as shown in \autoref{fig:participation-exp-diagram}, where X represents exposure to the treatment and O represents a measurement.

\begin{figure}[htbp]
	\centering
	\begin{tabular}{l c}
		Residents & X -------- O \\
	\end{tabular}
	\caption{Diagram of participation experiment}
	\label{fig:participation-exp-diagram}
\end{figure}

The data on participants are collected continuously, but the measurement made is the total of all data collected through the challenge period. Use of the website generated two different sets of data: an SQL database, and a log file. The SQL database (generated by MySQL) represents the entire state of the game: the configuration and the record of all player actions. The log file contains a single line of text for each user action (i.e., mouse clicks) on the website, including the user who initiated the action and the time of the action.

Using the website data, I can determine how many users met the 25 point threshold described earlier. Once logged in, the primary interactive feature of the website is the challenge action system. The number of actions completed per participant is another player participation. The data were extracted from the database using SQL queries, and then further analysis was performed in Microsoft Excel 2011 for OS X.


\section{Energy Literacy Experiment}
\label{sec:energy-literacy-exp}

Research question \#2 is ``how did energy literacy change after the challenge?'' I hypothesized that the experience of participating in the Kukui Cup challenge would increase participants' energy literacy. To address this question, I used a quasi-experimental design with non-equivalent (non-randomized) control group assignment~\cite{Cook1979}. Using the notation from Campbell and Stanley, the challenge participation experiment can be diagramed as shown in \autoref{fig:literacy-exp-diagram}, where X represents exposure to the treatment and O represents a measurement, and the dashed line represents groups not assigned by random selection.

\begin{figure}[htbp]
	\centering
	\begin{tabular}{l c}
		Challenge participants & O -------- X -------- O \\
		                       & - - - - - - - - - - - - - - \\
		Non-challenge participants & O ------------------- O
	%	Challenge participants & O \rule{5em}{0.5pt} X \rule{5em}{0.5pt} O \\
	%	Non-challenge participants & O \rule{10em}{0.5pt} O
	\end{tabular}
	\caption{Diagram of quasi-experimental design of energy literacy experiment}
	\label{fig:literacy-exp-diagram}
\end{figure}

Note that participants self-select whether they belong to the treatment or control group by choosing whether or not to participate in the challenge.

\subsection{Questionnaire Development}
\label{sec:questionnaire-dev}

In answering research question \#2, I used the definition of energy literacy introduced earlier in \autoref{sec:energy-literacy}, consisting of attitudes, behaviors, and knowledge regarding energy. To assess energy literacy in participants, I developed an energy literacy questionnaire. The complete version of the questionnaire can be found in \autoref{app:energy-literacy}.

The first section of the questionnaire I developed was the energy knowledge scale. While others have designed measures of energy knowledge, such as the one developed by DeWaters and Powers~\cite{DeWaters2011}, I found the existing instruments inappropriate for use in the Kukui Cup for three reasons. First, energy knowledge instruments designed for use in contiguous United States include information that is not accurate for \Hawaii. For example, the DeWaters and Powers instrument has a question that asks what activity uses the most energy in the average American home, the answer being heating and cooling rooms. However, for homes in \Hawaii, the largest consumer of energy is usually heating water (though not in homes that have a solar hot water heater). \Hawaii's energy situation has many differences from the other 49 States, and in the Kukui Cup we wished to emphasize \Hawaii's unique problems and solutions. Second, the DeWaters and Powers energy knowledge instrument was designed for high school students, and so some questions assessed energy knowledge of the type that might be learned in a class, but are not of practical use. Finally, the DeWaters and Powers energy knowledge instrument was quite long, consisting of 38 multiple choice questions.

Finding other energy knowledge instruments inappropriate for my needs, I developed my own energy knowledge instrument. It includes both generally applicable questions such as converting between power and energy, and \Hawaii-specific questions such as the sources of \Hawaii's energy. I piloted the energy knowledge instrument with fellow members of the CSDL research group, and with students in ICS 414 (Software Engineering II) and some graduate students taking ICS 699 (Directed Reading/Research) at the University of \Hawaii at \Manoa in May 2010. Based on the results of the pilot and feedback from Professor Johnson and members of CSDL, I revised the instrument to remove some less relevant questions.

For the energy attitudes section of the questionnaire, I used the DeWaters and Powers affective subscale with permission from the authors. The affective subscale asks participants to rate how they feel about statements on a five-point Likert-type scale from strongly agree to strongly disagree. I made two changes from the DeWaters and Powers affective scale. The wording of Statement 11 (``America should develop more ways of using renewable energy, even if it means that energy will cost more.'') was changed from ``using'' to ``generating'', clarifying that there is no problem using renewable energy. The other change was the addition of Statement 18 (``Many of my everyday decisions are affected by my thoughts on energy use.''), which was part of the behavior subscale for DeWaters and Powers but matched the attitude questions here better than the behavior items.
 
For the behavior section of the questionnaire, I started with the DeWaters and Powers behavior subscale, which listed behaviors with a five-point Likert-type scale ranging from almost always/always to hardly ever/never. However, the content of the subscale was inappropriate for Kukui Cup use because it included behaviors inappropriate for \Hawaii (such as turning down the heat at night), as well as certain behaviors less relevant to college students living in a residence hall. Instead of using the DeWaters and Powers behavior subscale, I used the format, but picked behaviors that were appropriate to the Hale Aloha residents. I developed the commitments available in the Kukui Cup point competition (\autoref{sec:commitments}) with the same requirements in mind. Therefore, I based the behavior items in the questionnaire around the list of commitments available in the challenge (see \autoref{sec:commitment-list} for a complete list).

In addition to energy literacy, I wanted to assess how much participants identified with their lounge team, and assess their connectedness to nature, since the CNS scale had been claimed to be a good predictor of energy conservation. I used the Arrow-Carini Group Identification Scale 2.0~\cite{Henry1999} and the Connectedness to Nature Scale (CNS)~\cite{MayerFrantz2004} unmodified as additional sections in the questionnaire.

The questionnaire did not include any demographic questions such as asking participants their gender, intended major, or whether they were new to \Hawaii or had lived in \Hawaii before. These type of demographic questions were left out in an attempt to make the questionnaire simpler and shorter, but in retrospect they would have provided additional useful data.


\subsection{Questionnaire Administration}

My original plan administering the questionnaire was to present it to all players as part of the first login process. However, as discussed in \autoref{sec:first-login}, the critical player onboarding process is very sensitive, and adding a mandatory 20 minute energy questionnaire was completely infeasible. Also, administering the questionnaire as part of the first login process would not provide any data on the control group of non-challenge participants.

I settled on administering the questionnaire online using the SurveyGizmo web service~\cite{surveygizmo}. Like many other online survey websites, SurveyGizmo allows researchers to design a questionnaire, invite participants to fill out the questionnaire, and export the results in a variety of ways. The email addresses of potential questionnaire participants were randomly selected from a roster provided by UH \Manoa Student Housing using the \texttt{rl} software package \cite{rl-website}, which randomly selects lines from an input text file. The roster included the RAs who were living in the Hale Aloha towers, who were not first-year students, so questionnaire participants could potentially include RAs. Only those individuals that participated in the pre-challenge questionnaire were emailed to participate in the post-challenge questionnaire. 

The order of the questions in the attitude and behavior sections was randomized for each participant using functionality provided by SurveyGizmo. For the energy knowledge section, within each page of questions, the order of the questions was randomized, as was the order of the multiple choice answers. The group identification and CNS sections were not randomized, since they have multiple items that test the same concept, which could be awkward if placed together.

Questionnaire participants were compensated for their participation by a payment of \$10 in cash for each of the pre- and post-challenge questionnaires.


\subsection{Questionnaire Data Analysis}

I analyzed the data from the questionnaire responses using SurveyGizmo, SPSS 20, and Excel 2011 for OS X. Initially, for some exploratory data analysis, I exported data from SurveyGizmo in Excel format, and performed some initial analyses in Excel. Later, I exported data from SurveyGizmo directly in SPSS format, and pre-processed it using SPSS's command language, to perform tasks such as converting reverse-scored items into the overall scoring direction.

Once the data were prepared, I used SPSS to perform mixed-model design ANOVA  with the pre- and post-challenge questionnaire repeated measure as the within-participants variable, and challenge participation as the between-participants variable.


\subsection{Threats to Internal Validity}
\label{sec:internal-validity-threats}

In this section, I address possible threats to the validity of conclusions drawn through analysis. By internal validity, I mean the ``the approximate validity with which we infer that a relationship between two variables is causal or that the absence of a relationship implies the absence of cause''~\cite[p. 37]{Cook1979}. In the case of the energy literacy experiment, internal validity refers to whether there are alternative explanations for changes in pre- and post-challenge energy literacy scores between challenge participants and non-challenge participants.

Because questionnaire participants self-select whether to receive the treatment (by playing or not playing the game), one alternative explanation for differences in energy literacy changes between the treatment and control groups is that those groups differed in their interest or aptitude in learning about energy. Cook and Campbell term this a \emph{selection-maturation} threat~\cite[p. 53]{Cook1979}. It could also be the case that individuals who participate in the challenge are also more likely to take classes related to energy, sustainability, or the environment, and thereby, any increase in energy literacy is due to class work and not the Kukui Cup.

Participation in the questionnaire was voluntary, and attrition in questionnaire responses from pre- to post-challenge is to be expected. However, the reasons for attrition could be a threat to validity, if those participants that consider their energy literacy to be poor after the pre-challenge questionnaire decide to not participate in the post-challenge questionnaire. Conversely, questionnaire participants with a particular aptitude or interest in energy might be more likely to complete both questionnaires. Cook and Campbell refer to this as a \emph{mortality} threat.

Since selection between treatment and control groups was performed by participating in the challenge, members of the two groups were potentially in close proximity to each other: they could even be roommates! The members of the two experimental groups had the potential to interact and treatment group members could convey information they learned as part of the Kukui Cup to control group members, because they were potentially in close proximity. This \emph{diffusion of treatments} effect would act to reduce the observed difference between the two groups.


\section{Energy Use Experiment}
\label{sec:energy-use-exp}

Research questions \#3 and \#4 are ``how did energy use change during the challenge?'' and ``how did energy use change after the challenge?'' respectively. Based on results from other residence hall energy competitions, I hypothesized that energy use during the challenge period would decrease as compared to a baseline of energy use computed from energy use prior to the challenge. While most energy competition research does not examine long-term impacts on energy use, I hypothesized that energy use after the challenge would be higher than during the challenge, but lower than the baseline.

%Using the notation from Campbell and Stanley, the challenge participation experiment can be diagramed as shown in \autoref{fig:energy-exp-diagram}, where X represents exposure to the treatment and O represents a measurement, and the dashed line represents groups not assigned by random selection.
%
%\begin{figure}[htbp]
%	\centering
%	\begin{tabular}{l c}
%		Challenge participants & O -- O -- O -- O -- X -- O -- O -- O -- O \\
%		                       & - - - - - - - - - - - - - - - - - - - - - - - - - \\
%		Non-challenge participants & O -- O -- O -- O -- O -- O -- O -- O -- O
%	%	Challenge participants & O \rule{5em}{0.5pt} X \rule{5em}{0.5pt} O \\
%	%	Non-challenge participants & O \rule{10em}{0.5pt} O
%	\end{tabular}
%	\caption{Diagram of quasi-experimental design of energy use experiment}
%	\label{fig:energy-exp-diagram}
%\end{figure}

As described in \autoref{sec:energy-data-collection}, I was able to obtain energy data only at the granularity of pairs of floors. I recorded both instantaneous power and cumulative energy consumed on a lounge by lounge basis for each residence hall at roughly 15 second intervals. Analyses can only be performed at an aggregated level, because the energy data corresponds to aggregations of participants. 


\subsection{Energy Baselines for Analysis}
\label{sec:baselines-for-analysis}

\autoref{sec:baseline-computation} describes the methods and baselines used for the Daily Energy Goal Game. As discussed in \autoref{sec:energy-baselines}, baselines can also be used as a means of assessing the success of an energy competition. The energy baselines used for assessment of lounges' energy use are substantially simpler. The Campus Conservation Nationals competition recommended that participating schools compute the baseline using the two weeks immediately before a three week competition~\cite{conservation-nationals-website}. To smooth out any anomalous energy use, I used an average of three weeks of data before the challenge. Because of the late and problematic installation of Lokelani's meters, I was not able to produce a useful baseline for Lokelani.


\subsection{Energy Data Analysis}

For the analysis of energy data, I used the WattDepot system to calculate the energy used for a lounge for a period of time. I developed a command-line utility written in Java that creates table of weekly energy use for each lounge for all the weeks from the start of the fall 2011 semester (August 22) until the end of finals in the spring 2012 semester (May 11). I used weekly data because weekend energy use differs significantly from weekday usage.

I imported the table of weekly energy use for each lounge into Excel 2011 for OS X. In Excel I noted special weeks (such as Thanksgiving and winter break) and computed average energy used, and comparisons to baselines.

%The addition of energy feedback has been shown over several studies to lead to conservation values from 5\% to 15\% (see \autoref{sec:energy-feedback}). We expect the average energy use for each building during the challenge to be reduced by at least 10\%. However, energy usage on an individual floor may or may not be reduced compared to the pre-challenge period, as some floors may not actively participate in the challenge. We expect average energy use during the challenge to be greater than 10\% for the floors that are actively participating.

%We hypothesize that the energy usage will be higher after the challenge is over, as the incentives will have been removed and overall focus on energy by the participants will be greatly reduced. However, some habits started during the challenge may persist, and the website will still provide residents with energy usage feedback, which has been shown to reduce consumption.


\section{Energy Literacy and Energy Use}

Research question \#5 is ``what is the relationship between energy literacy and energy usage?'' I hypothesize that more energy literate participants will conserve more energy. This hypothesized relationship is one of the goals of energy literacy: to make students understand the reasons for being concerned about energy use, and the techniques they can use to reduce their energy usage. This question can be broken down into three sub-questions:

\begin{enumerate}
	\item Do lounges with higher average pre-challenge energy literacy scores have lower average weekly energy use during the pre-challenge period?
	\item Do lounges with higher average pre-challenge energy literacy scores have a greater reduction in average weekly energy use during the challenge?
	\item Do lounges with higher average post-challenge energy literacy scores have a lower sustained energy usage in the post-challenge period?
\end{enumerate}

The first sub-question investigates whether participants who were already more energy literate were already using less energy before the challenge started. This hypothesis neglects the possibility of participants improving their energy literacy through means outside the challenge during the pre-challenge period (e.g., classes, involvement in campus organizations), but this seems a reasonable assumption.

The second sub-question examines whether those participants who started the challenge with higher energy literacy scores used less energy during the challenge, independently of any change of literacy during the challenge.

The third sub-question looks at the critical question of the sustainability of behavior changes in the wake of the challenge. Sustainability is the ultimate goal of any attempt at behavior change.

The data required to answer these questions will already be gathered as part of the energy literacy and energy use experiments described earlier.


\section{Action Effectiveness Evaluation}

Research question \#6 is ``how effective were the actions available via the website?'' The design of the website (described in \autoref{sec:point-competition}) and the actions it makes available to participants are specifically intended to increase the energy literacy of those that participate in them.

The data required to answer this question was gathered as part of the challenge participation experiment and the energy literacy experiment. The website data provides the number of points earned and actions completed for each challenge participant, and the energy literacy data provides a measure of both total energy literacy and change in energy literacy for participants that completed both pre and post-challenge questionnaires.


\section{Point Value Appropriateness Evaluation}
\label{sec:exp-point-values}

Research question \#7 is ``how appropriate were the point values assigned to actions?'' Beyond just making actions available to participants, the challenge assigns point values to each action. We assigned point values by hand based on several factors:

\begin{itemize}
	\item The expected difficulty of the action,
	\item The expected time required for the action,
	\item A guess as to how useful the action is to increasing energy literacy and/or reducing energy consumption, and
	\item The degree to which verification is possible (e.g., commitments, which are self-verified, are worth less than activities and events).
\end{itemize}

I measured the appropriateness of the point value of actions through website data showing the rate of action completion compared to action rejection (by challenge administrators). This set of data was supplemented by informal feedback from challenge participants on the relative merits of the different actions available.


\section{Importance of Lounge-Level Real-Time Feedback Evaluation}
\label{sec:exp-lounge-level}

Research question \#8 is ``how important was lounge-level near-realtime feedback?'' Many energy competitions only use building-level energy feedback, and update at a relatively low frequency, such as once per day. The 2011 UH Kukui Cup used near-realtime energy feedback on a per-lounge level. Providing feedback at the lounge level enables challenge between lounges, allows individual participants to see their behavior changes reflected in electricity usage (which would be swamped by the level of activity if measured at the building level). Near-realtime feedback allows participants to perform their own `experiments' and see how their behavior changes electricity usage.

Unfortunately, the logistics of lounge-level near-realtime electricity metering provide some of the most significant challenges to the research: the cost of purchasing the meters, the time and effort required to have them installed by electricians, and the lead time required to have the meters in place before the challenge can begin.

Thus it is reasonable to ask whether deploying lounge-level near-realtime electricity metering is worth the effort. All lounges received the near-realtime feedback, so I must use indirect indications of the utility of the metering. One source of data is the popularity of actions (based on website logs) that make use of the lounge-level near-realtime metering.

In order to obtain data on challenge participants' experiences with the Kukui Cup, we devised an in-game feedback questionnaire. \autoref{app:in-game-questionnaire} lists the contents of the questionnaire. Since it was only feasible to provide one questionnaire to participants, each member of the Kukui Cup research team wrote their own questions, which were placed in separate sections of the questionnaire.

The questionnaire was made available to challenge participants through the Smart Grid Game as part of the Overall Round of the challenge. Participants earned 40 points for participating in the questionnaire. Like the energy literacy questionnaire, the feedback questionnaire was administered using SurveyGizmo. Obviously, the in-game questionnaire only reached challenge participants, and only those that were still playing the game in the third week of the challenge.

I believe the importance of lounge-level near-realtime monitoring would be demonstrated if:

\begin{itemize}
	\item Residents participate in the challenge in significant numbers;
	\item Of those participants that completed at least one action, 25\% completed an action that required either lounge-level monitoring or near-realtime monitoring; and
	\item Respondents to the feedback questionnaire agree on average that having lounge-level near-realtime monitoring was helpful in the challenge.
\end{itemize}

Ultimately, the decision to use lounge-level near-realtime metering in future energy challenges will be a based on a cost/benefit analysis, and the answer for one institution or situation might not be appropriate for all.


\section{Threats to External Validity}
\label{sec:external-validity}

Like most research, my work is intended to be applicable outside the specific context of the 2011 UH Kukui Cup. External validity refers to the generalization of results to other populations and settings. This section covers some of the potential threats to the external validity of my results.

I have emphasized \Hawaii's rather unique energy situation as a core part of the 2011 UH Kukui Cup experience. It is possible that this unique situation leads to more (or less) interest in the challenge among players than would be found at other institutions outside of \Hawaii.

The energy measurement in the 2011 UH Kukui Cup required aggregation of energy data across a large group (54 people in a lounge) who may not identify as a group. Energy competitions in other circumstances including smaller team sizes and/or more close knit group identities might lead to different levels of participation in the challenge.

A university residence hall is a fairly unique setting in which the residents are presumably amenable to learning, since they are in this setting to learn. This potentially stands in contrast to another setting such as an office building, where occupants (like dorm residents) might not be aware of or pay for their energy use, but might not be as eager to play a game to learn about energy.


\section{Summary}

To address the eight research questions I posed at the start of this chapter, I have conducted three experiments on: challenge participation, energy literacy, and energy use. The challenge participation experiment used data generated from the website to determine how many residents actually participated in the challenge, using 25 points as the threshold for participation.

The energy literacy experiment used a quasi-experimental design with non-equivalent control group assignment. A randomly selected group of residents were sent a energy literacy questionnaire both before the challenge and after the challenge. Those residents that chose to participate in the challenge self-selected to the treatment group, while those that did not end up participating in the challenge remained as the control group.

The energy use experiment used continuously collected energy data from each lounge to compare energy use during and after the challenge to a three week average baseline of energy use before the challenge.

The remaining research questions were addressed primarily using data collected as part of the three experiments, with the addition of an in-game questionnaire that was provided to challenge participants as part of the actions available in the final round of the challenge.
