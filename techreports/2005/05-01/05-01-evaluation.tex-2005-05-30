%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 05-01-evaluation.tex -- Thesis proposal - PRI 
%% Author          : Aaron A. Kagawa
%% Created On      : Mon Sep 23 11:52:28 2004
%% Last Modified By: Aaron Kagawa
%% Last Modified On: Tue May 31 10:22:55 2005
%% RCS: $Id$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 2004 Aaron A. Kagawa
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Evaluation Methodology}
\label{chapter:evaluation}
This chapter discusses the proposed evaluation methodology of this
research. The main thesis of this proposed research is that Priority Ranked
Inspection (PRI) can distinguish documents that are more in need of
inspection (MINI) from those less in need of inspection (LINI). This
chapter will describe how the main thesis will be evaluated.

%%One approach of implementing PRI is through Hackystat, thus I will create a
%%Hackystat Extension called hackyPRI. This extension will provide a
%%Hackystat analysis, which will distinguish MINI documents from LINI
%%documents. This determination is based on a ranking function of different
%%process and product measures. Some measures include: reported defects, unit
%%tests, test coverage, active time, and number of changes.  Each measure
%%will implement a different ranking function and will be individually
%%calibrated. See Chapter 4: The Hackystat PRI Extension for more details.



\section{Subjects Used in the Evaluation}
In this evaluation, I will study the implementation and inspection process
of the Hackystat System \cite{Johnson05} developed in the Collaborative
Software Development Laboratory (CSDL). CSDL is a research laboratory
within the Department of Information and Computer Sciences at the
University of Hawaii. Currently, CSDL is comprised of Professor Dr. Philip
Johnson and seven graduate Computer Science students, including myself. Our
mission is to provide a physical, organization, technological, and
intellectual environment conducive to collaborative development of
world-class software engineering skills. CSDL's current focus is on the
development of Java software systems that support Software Development
research. Hackystat \cite{Johnson05}, hackyPRI, Jupiter \cite{Jupiter},
LOCC \cite{Locc} are examples of software we have developed. All eight
members are highly experienced Java programmers and have been practicing
high quality software development. We use tools such as Eclipse, Apache
Ant, and CVS. In addition, we practice several development techniques such
as Extreme Programming and Software Inspection.

In my evaluation of the Priority Ranked Inspection process I will focus on
evaluating PRI's effectiveness in aiding CSDL's inspection of Hackystat
related software code. Like most organizations, CSDL's inspection resources
are limited and therefore inspections are conducted, if at all, on a weekly
basis regardless of the number of ``ready'' documents. CSDL primarily
inspects source code grouped by Java packages; therefore, I will use the
term 'packages' when referring to CSDL's use of PRI. I will use the term
'documents' when referring to the general idea of inspections.

Although I am a member of CSDL and have been contributing to Hackystat, I
will minimize any possible data contamination by doing two things. First, I
will ensure that the inspection participants are ``blind'' to the document
selection method. There are two methods of selection that will be used in
this evaluation, selection with and without aid of PRI. I will work with
individual authors to select documents based on their subjective selection
or with the aid of PRI and keep that decision a secret from the rest of the
participants. Second, I obviously will not participate in the inspections
themselves.

It has been advised by my Thesis Committee, that the inspection requests
should be ``double blind''. ``Double blind'' means that the experimenter
should not know the PRI determination of MINI or LINI.  The use of this
technique prevents any sort of conscious or unconscious hints via body
language, speech, or any other action that will give the impression of
whether the experimenter wants the reviewer to find defects in the
document. However, it is my belief that randomly selecting documents for
inspection would be both detrimental for CSDL and my research. Therefore,
in the evaluation methodology in this research I will not use the double
blind technique.

CSDL has been conducting and studying inspections since the early 1990's.
CSDL's inspection process has gone through the use of many different tools
and processes. The current inspection guidelines are published in the
Hackystat Developer Documentation: Software Review Guidelines
\cite{SoftwareReviewGuidelines}. The term ``review'' is used in CSDL's
process equates to the term ``inspection''. The primary goals of the
current process includes creating an educational process that allows
participants to learn new techniques and practices about developing high
quality software design and implementation and to remove defects. The
process is lightweight and includes 5 simple steps.

\begin{enumerate}
\item \textbf{Announcement (or Review Request)} - In this step, an author
  sends an email requesting that the group inspect the specified software.
  In addition, the author lists several questions to help direct the
  participants' attention to what the author thinks is most important. This
  announcement should be sent 24 hours before the meeting.
\item \textbf{Preparation} - In the hours between the announcement and the
  meeting, the review participants must individually review the software
  listed in the announcement. Preparation time is limited to no more than
  one hour.
\item \textbf{Meeting} - At the scheduled time the group gathers to discuss
  the issues that have been discovered in the preparation step.
\item \textbf{Revision} - After the review meeting the valid issues that
  was discovered must be fixed. In this step, the author or developer
  assigned must resolve these issues.
\item \textbf{Verification} - After the revision a quick determination is
  required to ensure that all the issues have been resolved.
\end{enumerate}

Note that the CSDL inspection process does not specify how to determine
what software should be inspected. The process simply starts with an
announcement. This missing step is evident in all traditional software
inspection processes. 

The Jupiter Eclipse Review Plugin \cite{Jupiter} is currently used to
support the CSDL inspection process. Takuya Yamashita, who is also a CSDL
member, developed the Jupiter software. Jupiter is a lightweight tool that
collects data regarding review issues generated in a inspection
process.



\section{Evaluation Limitations}
The use of CSDL resources in my study indicates a major limitation on this
research. The most accurate and thorough evaluation of PRI should inspect
\textit{all documents} to evaluate if PRI correctly classifies MINI and
LINI documents. However, because I am using CSDL's inspection resources,
which are limited, this is not possible.

Currently, Hackystat and its extensions are comprised of 218 packages. At
best this will take 2 hours per inspection per member, therefore totaling
3,488 hours of inspection. Requiring the use of that many hours is an
unrealistic demand on CSDL resources. Therefore, my proposed evaluation
will investigate a small percentage of the system in hopes that a
cross-section will provide adequate and acceptable results. Furthermore,
CSDL conducts inspections to increase quality and spread knowledge. It
would be detrimental to this development group, if I required the
inspection of many packages that did not provide that return on investment.

[TODO: add paragraph about not using Double Blind]

%%As I previously stated, an accurate and thorough evaluation of PRI requires
%%the inspection of all packages within the PRI rankings. However, because of
%%CSDL's limited resources this is not possible.

It is important to note two other limitations of this research. First, I am
not defining a set of PRI measures and PRI indicators that represent the
PRI ranking function for all software projects. Instead, by using hackyPRI
I will be able to go through a methodology to best calibrate the measures
to accurately reflect the determination for the project I am studying.
Second, PRI is more beneficial for organizations that have limited
inspection resources. PRI is of less use for organizations that have the
necessary resources to thoroughly inspect every document, although this is
yet to be studied.

In this evaluation, I will only evaluate one software project. This by no
means will validate that PRI works for all software projects. In addition,
even after completing this research I believe that the Priority Ranked
Inspection process will still be in its infancy. There are many more
theoretical and practical issues that must be addressed. 



\section{Evaluation of Thesis Claims}
To evaluate this thesis, I have separated it into three claims based upon
the three intended benefits of PRI.

\begin{enumerate}
\item PRI can enhance the volunteer-based document selection process. 
\item PRI can identify documents that need to be inspected that are not
  typically identified by volunteering.
\item MINI documents will generate more critical defects than LINI
  documents.
\end{enumerate}

To evaluate my thesis claims, I have created a seven-part evaluation
methodology. The evaluation includes; questionnaires, working with authors
to select documents for inspection, and the analysis of an inspection log
and results. The different portions of the evaluation methodology do not
necessarily correlate one-to-one with the three thesis claims. Instead,
each methodology will provide supporting evidence for all of my thesis
claims. The following is a short summary of the steps of the evaluation
methodology. The following sections will detail each of the steps in the
evaluation methodology.

\begin{enumerate}
\item \textbf{Pre-Selection Questionnaire}: to obtain the developers
  subjective feelings assessing the usefulness of inspection and the
  methods they use to select documents for inspection. In addition, I will
  ask each developer to provide rankings, based on their current subjective
  rankings, for three different sets of workspaces. First, they will rank
  each top-level module within the Hackystat system (ie, hackyKernel,
  hackyStdExt, hackyReview, etc). Second, the will identify the top five
  MINI and LINI packages throughout the whole Hackystat system. Last, I
  will ask them to rank packages they have authored based on their
  subjective feeling of what documents are MINI and LINI.
\item \textbf{Package Selection}: work with individual developers to select
  a package for inspection. The selection of packages can be made with or
  without the aid of PRI.
\item \textbf{Post-Selection Questionnaire}: if PRI was used to aid the
  document selection process, explained in the previous step, then I will
  ask the developer to complete a Post-Selection Questionnaire. This
  questionnaire will help assess the usefulness of PRI and help validate
  the PRI rankings generated by hackyPRI.
\item \textbf{Request for Inspection}: the author will send an email-based
  request for inspection to our fellow Hackystat developers. I will ensure
  that this email will ``blind'' the selection method.
\item \textbf{Inspection of the Selected Package}: using the CSDL code
  review (inspection) process, the inspection participants will inspect the
  package individually and meet to discuss the issues that were found.
\item \textbf{Post-Inspection Questionnaire}: following the inspection I
  will administer a questionnaire that will ask the participants whether
  they believe the package was MINI or LINI.
\item \textbf{Record Results of Inspection}: I will record the results of
  the inspection and the PRI ranking of the package before the inspection.
\end{enumerate}




\subsection{Part 1 - Pre-Selection Questionnaire}
\label{subsection:pre-selection-questionnaire}
The first evaluation methodology that will be used is a qualitative
questionnaire. The goal of the questionnaire to obtain the authors'
subjective feelings about inspections in general, their document selection
process, and their subjective rankings of the modules, packages, and
packages that they have authored.

Appendix \ref{appendix:pre-selection-questionnaire} contains the
Pre-Selection Questionnaire. This questionnaire contains three different
sections; two general inspection questions about CSDL's inspection process,
four questions assessing the developers' document selection method, and
three tasks which will gather the developers' subjective rankings of
various packages.

The first section contains general questions about the CSDL inspection
process. These questions do not directly correlate to my thesis claims.
However, I will use this information to help validate the data that I
collect. For example, if the developers find an insignificant number of
issues in both MINI and LINI documents, then I can correlate that finding
with their enthusiasm towards inspection. In addition, one of the questions
asks whether finding defects are the most important outcome of the CSDL
inspection process and the data collected will aid future directions of
this research. It is my future-hypothesis that PRI can also aid the
selection of documents for other purposes than finding the most defects.
For example, an inspection process can be used as training or education and
PRI could aid the selection of documents that best suit that goal.

The second section contains questions about the developers' current
document selection method. This section provides important information on
the process in which developers select documents for inspection. This will
provide supporting qualitative data for the quantitative data provided in
the last section. This evaluation will provide insights into the
developers' selection process.
%%[MENTION ANALYSIS OF DATA AND POSSIBLE RESULTS, PROVIDE EXCEL CHARTS].



The last section of the questionnaire will ask the developers of Hackystat
to provide a numerical ranking, based on their subjective feelings, of
three different sets of packages. First, they will be asked to rank the
top-level workspaces, or modules, within Hackystat according to their
subjective opinion of the quality of the modules. Hackystat contains many
different modules that can interchange depending on the situation of use.
See the Hackystat Developer Website (http://www.hackystat.org) for a
listing of the modules. Second, they will rank the top five MINI and LINI
packages. I will provide a list of all packages within the Hackystat system
so that the developers can choose the five packages they think are MINI and
the five they think are LINI. Last, they will rank the packages that they
would volunteer for inspection. The packages used in this last set are
packages that the developer has authored.

After the participant completes their subjective rankings, I will be able
to compare the developers' subjective rankings against the PRI ranking.
This comparison will indicate whether PRI is really needed. The findings
could indicate that developers can correctly distinguish, using their own
subjective reasoning, what packages need to be inspected. There are three
possible results from this evaluation. First, I may find that developers
automatically have a sense of what code is MINI and what code is LINI. This
would indicate that PRI provides little added value. Alternatively, I might
find that, developers have no idea what code needs to be inspected. The
third possible result represents a middle ground between the two previous
results, sometimes the developers are correct and sometimes they are wrong.
The last two results will indicate that PRI provides some benefit. Of
course, these results will need to be validated with the actual inspection
of the document to validate both the developers' subjective rankings and
the PRI rankings.

%%[MENTION ANALYSIS OF DATA AND POSSIBLE RESULTS, PROVIDE EXCEL CHARTS].


\subsection{Part 2 - Package Selection}
\label{subsection:package-selection}
The second evaluation methodology that will be used is the selection of
packages for inspection. The goal of this methodology is to evaluate the
effectiveness of the MINI and LINI determinations and PRI's ability to help
the selection process.

In this evaluation, I will work closely with the various authors who
contribute to the Hackystat project to select a package for inspection. To
accomplish this, I will create a weekly inspection schedule. Each week a
different Hackystat developer will be required to work closely with me to
select one package for inspection. This selection process will have the
following steps:

\begin{enumerate} 
\item I explain to the developer that the goal of this collaboration is to
  find the document that is more in need of inspection. Therefore, using
  PRI is not required.
\item Ask the developer if they have a package they would like to be
  inspected. If so, record the package name and the package's MINI or LINI
  determination and skip to step 6. If not, continue to the next step.
\item Present the developer with a list of PRI MINI packages that he/she has
  authored. Work with author to select a package from this listing. If a
  document is selected, then move to step 6. If not, continue to the next
  step.
\item Present the developer with a list of PRI LINI packages that he/she
  has authored. Work with author to select a package from this listing. If
  a document is selected, then move to step 6. If not, continue to the next
  step.
\item If we have reached this step, then it can be determined that the
  author does not believe he/she has authored any packages that are more in
  need of inspection. Therefore, I will select a document from the PRI MINI
  listing. According to the author this package should not generate many
  critical issues. However, according to PRI this package should generate
  critical issues. The results will be recorded.
\item Once a document has been selected; the author is required to send a
  request for inspection to the inspection participants (generally all
  present CSDL members).
\end{enumerate}

This process was designed to ``blind'' the method used in selecting the
package. The inspection participants, who include all CSDL members
excluding the author of the package and myself, will not know how the
package was selected. This ``blinding'' of the selection method was created
to ensure that the participants will not consciously or unconsciously
persuade the results of the inspection.


\subsection{Part 3 - Post-Selection Questionnaire}
\label{subsection:post-selection-questionnaire}
The third evaluation methodology that will be used is another quantitative
questionnaire. The goal of this questionnaire is to evaluate the usefulness 
that PRI provides in aiding the document selection process. 

Appendix \ref{appendix:post-selection-questionnaire} contains the
Post-Selection Questionnaire. This questionnaire contains two different
sections: four questions addressing the developer's document selection
method and one task to determine if developers would change their
subjective rankings if PRI information were provided.

The first section contains three questions that appeared on the
Pre-Selection Questionnaire. This will help determine if the developers'
selection process has changed after being introduced to PRI. The last of
the four questions directly asks if the developers' would consider using
PRI to aid the selection of their next document. The data from this section
will be gathered and compared to data gathered from the Pre-Selecting
Questionnaire. This comparison will assess PRI's ability to change the
developers' subjective understanding of what is MINI and LINI documents.
Also, it will provide evidence that will indicate whether the developers
believe that PRI is useful.

%%[MENTION ANALYSIS OF DATA AND POSSIBLE RESULTS, PROVIDE EXCEL CHARTS].

In the second section, I will present each developer with the results of
the hackyPRI Project Workspace Ranking analysis, which provides the PRI
determination of MINI and LINI and it's ranking. In addition, I will
provide each developer with the subjective ranking they have already filled
out in the Pre-Selection Questionnaire. Then, I will ask the developers to
re-rank the packages based on the new PRI information and provide reasons
for any changes in the rankings. This is done evaluation is done after Step
2, Package Selection, to minimize the persuasion during the package
selection. 

%%[MENTION ANALYSIS OF DATA AND POSSIBLE RESULTS, PROVIDE EXCEL CHARTS].


\subsection{Part 4 - Request for Inspection}
After a package has been selected in Part 1, the author is required to send
an email request for inspection. Again, this email will ``blind'' the
selection method from the participants. It will simply state that the
author requests the inspection of a particular package. This request
announcement will be congruent with CSDL's inspection process
\cite{SoftwareReviewGuidelines}.


\subsection{Part 5 - Inspection of Selected Package}
This part of the evaluation methodology requires little change from CSDL's
original inspection process defined in the Hackystat Software Review
Guidelines \cite{SoftwareReviewGuidelines}. The participants will conduct
the Preparation and Meeting phases of the inspection process.

The Jupiter review tool \cite{Jupiter} will be used to gather the issues
generated in the Preparation phase. In addition, the Jupiter tool is used
in the Meeting phase to record the validity and severity of the issues.


\subsection{Part 6 - Post-Inspection Questionnaire}
The sixth part of the evaluation methodology is a quantitative
questionnaire. Appendix \ref{appendix:post-inspection-questionnaire} contains
the Post-Inspection Questionnaire. The goal of this questionnaire is to
obtain the developers' opinions of the MINI or LINI determination. The
results of the inspection and the developers' opinions will help evaluate
if the PRI ranking for the package was correct.


\subsection{Part 7 - Record Results of Inspection}
There are two possible results of this evaluation. First, the packages that
were selected were correctly categorized by PRI. Second, the packages that
were selected did not reflect the PRI ranking function. These findings will
provide evidence for claim 3 of my thesis statement.

During the evaluations of the previous two claims, CSDL will have conducted
at least eight inspections. In total, I believe I will have data on 10 to
15 inspections and information on the PRI ranking functions.

Throughout my evaluation of PRI, I will monitor the validity of the PRI
ranking function, adjusting the calibration as necessary, throughout each
inspection. To accomplish this, I will collect specific pieces of
information when conducting inspections. The following is a specific list
of the information collected:

\begin{itemize}
\item Inspection date
\item Hackystat module, package, and inspection ID
\item PRI determination (MINI or LINI)
\item PRI measure values and PRI indicator ranking and weighting
\item Subjective discussion of the validity of the PRI ranking function
  before the inspection
\item Number of issues generated and the categorization of these issues
  according to severity
\item Retrospective discussion after the inspection was conducted to
  indicate possible areas of improvement. 
\end{itemize}

This information will help me keep track of the progress of the inspections
and the validity of the PRI ranking function. See Appendix
\ref{appendix:log} for a copy of the full log. As I previously stated, the
calibration of the PRI ranking function is an ongoing and evolving process.
This information will help keep track of that evolution. The end goal of
this evaluation is to create a best practices recommendation of the types
of process and product measures and their calibration that will provide the
best PRI results for different projects.

\section{Evaluation Timeline}
The following timeline provides a timeline for the evaluation of this thesis:
\begin{table}[htbp]
  \begin{center}
    \label{tab:eval-timeline}
    \caption{Evaluation Timeline}
    \begin{tabular}{|p{5.0cm}|p{8.0cm}|} \hline
      {\bf Timeline} & {\bf Evaluation Activity} \\ \hline
March 30, 2005 & Pre-Selection Questionnaire: CSDL \\ \hline
April 6, 2005 & Package Selection: Christoph Lofi \newline
Post-Selection Questionnaire: Christoph Lofi \newline
Review Request: Christoph Lofi \newline
Review of Selected Code: CSDL \newline
Post-Inspection Questionnaire: CSDL \\ \hline

April 13, 2005 & Package Selection: Philip Johnson \newline
Post-Selection Questionnaire: Philip Johnson \newline
Review Request: Philip Johnson \newline
Review of Selected Code: CSDL \newline
Post-Inspection Questionnaire: CSDL \\ \hline

April 20, 2005 & Package Selection: Burt Leung \newline
Post-Selection Questionnaire: Burt Leung \newline
Review Request: Burt Leung \newline
Review of Selected Code: CSDL \newline
Post-Inspection Questionnaire: CSDL \\ \hline

April 27, 2005 & Package Selection: Hongbing Kou \newline
Post-Selection Questionnaire: Hongbing Kou \newline
Review Request: Hongbing Kou \newline
Review of Selected Code: CSDL \newline
Post-Inspection Questionnaire: CSDL \\ \hline

May 4, 2005 & Package Selection: Takuya Yamashita \newline
Post-Selection Questionnaire: Takuya Yamashita \newline
Review Request: Takuya Yamashita \newline
Review of Selected Code: CSDL \newline
Post-Inspection Questionnaire: CSDL \\ \hline

May 11 - 18, 2005 & END OF SEMESTER \\ \hline

May 25, 2005 & Package Selection: Cedric Zhang \newline
Post-Selection Questionnaire: Cedric Zhang \newline
Review Request: Cedric Zhang \newline
Review of Selected Code: CSDL \newline
Post-Inspection Questionnaire: CSDL \\ \hline

June 1, 2005 & Package Selection: Mike Paulding \newline
Post-Selection Questionnaire: Mike Paulding \newline
Review Request: Mike Paulding \newline
Review of Selected Code: CSDL \newline
Post-Inspection Questionnaire: CSDL \\ \hline

June 8, 2005 & Package Selection: Aaron Kagawa \newline
Review of Selected Code: CSDL \newline
Post-Inspection Questionnaire: CSDL \\ \hline

June 15, 2005 & Finished analyzing the results.  \\ \hline
    \end{tabular}
  \end{center}
\end{table}


\section{Initial Results of Evaluation}
\label{sec:intialresults}
The use of PRI to provide the determination of MINI and LINI has been
promising. The initial implementation of the system has proven that it is
technically possible to do what I have envisioned. In addition, I have
already recommended the inspection of a few package that were ``more in
need of inspection'' and the defects and issues identified have confirmed
that the PRI ranking was correct. See the inspection log (Appendix
\ref{appendix:log}) for a detailed description of the inspection results.

I will continue to discover new measures to add to the PRI ranking
function, fine tune the numerical weights associated with the measures, and
continue to recommend inspections.















