\chapter{Overview}

\section{Why is Software Quality Important?}

Between 1985 and 1987 two people died and four were seriously injured when
they received massive radiation overdoses delivered by the Therac-25
radiation therapy machine.  Subsequent investigations uncovered many
complex factors leading to these accidents, including poor user interface
design, problems with race conditions, and other software bugs
\cite{Leveson93}.

The Denver International Airport officially opened in March 1995 - 16
months late and more than 100 million dollars over budget.  One major reason was
the infamous automated baggage handling system. Political, mechanical and
electrical problems all contributed to its failure, but the presence of
major bugs in the controlling software was a primary factor\cite{Glass98}.

In June 1996 the maiden flight of the Ariane 5 rocket launcher failed about
40 seconds after lift-off.  The unmanned rocket veered off course and
automatically self-destructed, completely destroying both the rocket and
the four scientific satellites on board. The total cost was about 2.5
billion dollars.  The immediate cause was traced to a software error in
converting a 64-bit floating point number to 16 bit signed integer
\cite{Jezequel97}. However, the report by the Inquiry Board goes deeper and
blames this error on ``specification and design errors in the software''
and inadequate analysis and testing of the failed subsystems
\cite{Flight501}.

\section{Tackling the Problems}     

As these recent incidents illustrate, producing high-quality software on
schedule is a major issue in the computer industry today. However, this is
nothing new - ever since the beginning of computer programming, bugs and
behind-schedule projects have been persistent problems.

Over the decades, the software industry has taken various approaches to
addressing these challenges.  Into the 1960's, there was a general feeling
that programmers just needed to ``try harder''.  In the mid-70's, the
importance of testing was emphasized. Eventually it became clear that
although testing is very important, it is only a partial solution since it
is impossible to test exhaustively. In fact, this gave rise to the software
engineering adage that, ``You can't test in quality.'' By the mid-80's the
software engineering community began to realize that without a high-quality
process it is difficult to produce high-quality software, especially for
large or complex projects.  Standards such as the ISO 9000 for
organizations and the Capability Maturity Model (CMM) for organization-wide
software processes were developed. In the end, however, high-quality
software is produced by individuals. These organization-level processes
are, not surprisingly, more helpful to organizations than individuals. In
the mid-90's the focus has begun to shift back to the individual developer
with the introduction of the Personal Software Process (PSP)
\cite{Humphrey95}.

\section{The Personal Software Process}

The PSP is a self-improvement process for programmers. In effect, each
programmer performs a longitudinal experiment in which there is only one
subject.  Each new program written can benefit from data collected about
past projects, and can in turn provide new insights to improve planning,
productivity, and quality for future work.  But the programmer must adhere
to a rigorous and complicated process to make this happen.

The PSP has two main goals.  The first is to produce high-quality programs
as efficiently as possible.  By paying close attention to every defect made
as well as the overall patterns of errors, PSP users become more aware of
quality issues.  The PSP provides them with structured mechanisms such as
code review that can help them to prevent similar defects in future
projects.  Additionally, by tracking when and where each defect is injected
and removed and the time required for removal, developers are continually
reminded that finding and removing defects early in the process is much
less time-consuming and less costly than waiting to remove defects during
testing.  

The second goal of the PSP is to improve accuracy in time, size, and
quality estimation.  If the size of a program can be accurately predicted,
then the developer can often make a good estimate of the total time
required for completion.  This, of course, improves the quality of
schedules and budgets.  Programmers do size and time estimation at the
beginning of each project.  As soon as they complete some preliminary
planning, they select a similar set of past projects.  Then they use
various statistical techniques to compute likely size and time values for
the current project.

When a programmer uses the PSP, he or she starts by doing planning work
using a set of predefined worksheet-type forms.  Then, while moving through
the design, code, compile, and test phases, he or she uses other forms to
keep detailed records about the time spent in each phase and defects
injected and removed.  When the project is completed there is is a final
``postmortem'' phase in which the programmer analyzes all the data
collected about the project and computes values like {\it Lines of Code
  (LOC) per Hour} and {\it Defects per Thousand Lines of Code (KLOC)}.  He
or she calculates such values for the current project; and then calculates
them again as ``to date'' values, including not only the current project,
but the entire set of similar projects used in planning.  Therefore, at the
most basic level, the PSP involves two main activities: collecting primary
data such as size, defect, and time measures; and analyzing this data to
produce derived or to-date measures.

\section{Motivation for this Research}

Humphrey and others provide data from the use of PSP in a classroom setting
that shows positive trends in various measures of the software process,
including defect density, yield (percentage of defects actually removed),
and time estimation.  For example, a 1997 study done at Carnegie-Mellon
University showed a reduction of size estimation error by a factor of 2.5,
a reduction of time estimation error by a factor of 1.75 or more, and a
dramatic reduction in the number of defects injected \cite{CMU97}.
Unfortunately, most of the data used to illustrate these positive trends
about the PSP is actually data produced by the PSP itself.

In January 1997 I had been using the PSP for a full year for both academic
and professional work.  Dr. Philip Johnson (my thesis advisor) was also using
the PSP and had twice taught a full-semester class on the PSP. Generally,
the standard good results of using the PSP had been replicated in his
classes.  However, we were aware by this time of the complexity of the PSP, the
difficulty of some of the calculations, and the personal commitment
required to do a good job of collecting primary data.  We began to wonder
just how many errors people made while using the PSP and what sort of
effect these errors would have on the measures produced.
     
To guide our understanding of data quality problems in the PSP, we devised
a simple two stage model of PSP data, as illustrated in Figure
\ref{fig:model}.  The model begins with ``Actual Work''---the developer
efforts devoted to a software development project.  As part of these
efforts, the developer {\em collects} a set of primary measures on defects,
time, and work product characteristics---the ``Records of Work''. Based on
these primary measures, the developer performs additional {\em analyses},
many of which result in secondary (i.e.  derived) measures which are
themselves inputs for further analyses.  The secondary, derived measures
and associated analyses are presented in various PSP forms---the ``Analyzed
Work''---and hopefully yield insights into ways to improve future
software development activities -- the ``Insights about Work''.

\ls{1}
\begin{figure}[h] 
    {\centerline{\psfig{figure=graphic2.eps}}}
    \caption[A Simple Model for PSP Data Quality]{\label{fig:model} 
      {\em A simple model for PSP data quality. Through 
      a process of {\em collection}, the developer generates an initial
      empirical representation (``Records of Work'') of his or her personal
      process (``Actual Work'').  Through additional {\em analyses}, the developer
      augments this initial empirical representation with derived data
      (``Analyzed Work'') intended to enable process improvement using
      ``Insights about Work''.}}
\end{figure}
\ls{1.5}

We based this model upon the PSP as presented in {\it A Discipline for
  Software Engineering} \cite{Humphrey95} and as practiced by the students
in Dr. Johnson's classes - what we termed ``manual PSP''.  This means that
although students had various helping tools ranging from calculators to
spreadsheets to a size estimation applet, they had to fill out all forms by
hand and had no computerized guidance in following the outlined sequence of
process steps.  In contrast, what we termed ``automated PSP'' is done using
some kind of software package that performs all possible calculations for
the user, inserts and maintains the correct calculated values in the
appropriate places in the forms, guides the user through the process steps,
and aids in the collection of primary data. Note that although an
``automated'' PSP can essentially automate all of the analysis state
calculations, there are limits to its ability to automate the collection
stage work.  The collection stage is still quite ``manual'' in nature.

(At the time Dr. Johnson taught this class, there was no integrated software 
support for the PSP.  Since then, integrated tools have become available,
including spreadsheets available at the Addison-Wesley FTP site which print 
out the project summary forms, and the Personal Software Process Studio
tool produced by East Tennessee State University.)

\section{Hypothesis of this Research}

From this model, we isolated two areas that could have a negative impact on
PSP data quality: collection and analysis.  Unless the collected data
reflects the actual behavior of a programmer, the derived measures will be
based upon an inaccurate model of the work done. Furthermore, analyses
performed on the collected data must be done correctly in order to provide
meaningful insights into the programming process.

Therefore, our model of the PSP led to the following two hypotheses:

\begin{enumerate}
\item The PSP suffers from a collection data quality problem.
\item Manual PSP suffers from an analysis data quality problem.
\end{enumerate}

\section{Case Study}

In order to test these hypotheses, we decided to do a case study to
evaluate PSP data quality, using data collected from the next PSP class
taught by Dr.  Johnson.  We wanted to determine what kinds of errors were
made and how often they occurred.  Of course, no human being can do a
perfect job at all times of either collection or analysis -- a certain
number of errors is to be expected.  Therefore, we felt it was important to
evaluate not only the numbers and kinds of errors, but their effect on
important derived measures. Given the nature of the data, we knew it would
be impossible to correct all errors with complete accuracy, but we wanted
to see if even partial correction was enough to observe any substantial
differences between original and corrected data.

Even before teaching the PSP class that produced the projects evaluated by
this case study, Dr. Johnson had concerns about the quality of PSP data.
Therefore, he made four main modifications to the standard PSP curriculum:
(1) increased process repetition, (2) added four worksheets to help
students through the most difficult analyses, (3) implemented in-class
technical reviews, and (4) provided tool support.

Once the class was completed and all the projects were available for review,
I wrote two database applications: one to automate a large part of the PSP
and another to track errors made while using the PSP.  Then I took the 90
software projects (9 projects each by 10 students) completed during the PSP
class and entered all the primary values into the PSP application.  I then
compared every derived value on the hand-completed forms with the values
generated by the computer.  Whenever there was a discrepancy, I recorded
the error in the error-tracking tool.  (However, I only recorded errors at
their source.  For example, if a derived measure was incorrectly
calculated, and then was used itself to produce other derived measures, I
only counted one error even though multiple derived measures were
incorrect.)  Finally, I formulated a set of correction rules, attempted to
repair all the detected errors, and then compared the original and
corrected values for some important derived measures.

\section{Results}

When this research project started, Dr. Johnson and I expected to find
between 50 and 100 errors in the class data.  This estimate was way off: we
found 1539 errors.  When I analyzed the errors by type, the most common
error types were errors in calculations, blank fields, and inter-project
transfer errors.  There were also 90 errors that indicated deeper problems
in the collection of primary data measures.

Another way of classifying errors was by severity. In other words, was an
incorrectly calculated value isolated, or was it used in other
calculations, thereby corrupting other fields?  If it did corrupt other
fields, were the errors confined to the current form or project, or were
the fields used by calculations in future projects?  44\% of the errors were 
confined to a single bad value on a single form.  However, 34\% of the
errors resulted in multiple bad fields on multiple forms for multiple
projects.

One could argue that many errors were made simply as a natural by-product
of the learning process and would ``go away'' as students gained experience
with the various techniques in the PSP.  To evaluate this, I assigned each
error an ``age'' corresponding to the number of projects since the
introduction of the field in which the error occurred.  When looking at all
errors, the average age was 2.8 projects.  When looking only at errors with
an age greater than 0, the average age was 3.5 projects.

One might also hypothesize that these errors simply constitute ``noise''
and do not substantially impact upon the overall analysis results.  To test
this hypothesis, I recalculated some of the major metrics using the
(partially) corrected data.  I found clear differences for such measures
as {\it Yield} and {\it Cost-Performance-Index}.  When looking at the
eighth project, these values were substantially affected for at least half
the students.

\section{Implications}

This case study shows that PSP users can make substantial numbers of errors
in both the collection and analysis stages, and that these errors can have
a clear impact upon measures of quality and productivity.  However, these
results do not imply that the PSP method is wholly unuseful in improving
time estimation and software quality. Instead, these results could be
useful in motivating two essential types of improvement to the PSP process:
attention to measurement dysfunction issues and integrated automated tool
support.  Until questions raised by this study with respect to PSP data
quality can be resolved, PSP data should not be used to evaluate the PSP
method itself.  

\section{Organization of this Document}

Chapter Two will provide a summary of the Personal Software Process,
including its goals and the methods used to achieve them.

Chapter Three takes a look at related works, focusing on published results
about the PSP, automation of the PSP, human error, and measurement 
dysfunction.

Chapter Four will describe the case study - how I evaluated the PSP data
from 90 software projects, the rules I exercised to correct errors in the
PSP data, and the method I used to record results.

Chapter Five will describe the two software tools I wrote to automate the PSP
and to record and analyze the errors I found while evaluating the student
projects.

Chapter Six will present the results of the case study, including
summaries of error types, error severity levels, age of errors, error
detection methods, and effects of data correction.  It will also give a 
closer look at the most severe errors.

Chapter Seven will cover the conclusions of this research and explore
ideas for future research.




