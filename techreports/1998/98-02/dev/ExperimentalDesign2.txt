Experimental Design
1 Evaluating the Leap toolkit a Reflective Software Engineering tool
1.1 Reflective Software Engineering implies improvement in Software Engineering skills
Reflective software engineering is a new term invented by Dr. Philip Johnson.  Reflective Software Engineering focuses on the individual software developer and tries to provide them with the insights they need to improve their development process.
 Reflective software engineering starts with the assumption that the engineer is motivated to become a professional, highly skilled, perhaps even world class software engineer. They don't have to be one yet---they just have to have the desire and commitment to grow in that direction. Every concept in reflective software engineering is oriented around their personal growth as a technology professional. 
Reflective software engineering is based upon an extremely simple and obvious idea: people learn best from their own experience. To some extent, every professional software developer learns from experience. But not all software developers learn equally well or equally efficiently from experience. Some developers seem to "plateau" at a certain point in their development, while others take much longer than others to acquire basic proficiency in an application area, language, or environment. Reflective software engineering teaches a simple set of skills along with simple tool support that facilitate your ability to learn from your own experience.

1.2 Manual Reflective Software Engineering
The most familiar Reflective Software method is the Personal Software Process (PSP)1.  The PSP is a self-improvement process for software developers.  The developer conducts a longitudinal case study of their own software development process.  The developers historical data about size, effort, and defects can aid current and future software projects.  Each software project provides more data and possible insights into the developer's own processes.  These insights can lead to improved planning, productivity and quality.  To help insure successful improvement the PSP requires that the developer follow very strict rules for development, data collection and data analysis.  The PSP defines seven different development processes, PSP 0, PSP 0.1, PSP 1.0, PSP 1.1, PSP 2.0, PSP 2.1, and PSP 3.0.  Each process builds upon the previous process adding more steps, requirements, data collection and analyses.  The PSP processes all follow the classic waterfall model of  software development.  When the developer finishes a phase they do not go back to that phase again.  There are scripts for the developer to follow at each step along the development process.  The scripts describe the tasks, entry and exit criteria, data collection and the analyses to perform.  
The PSP has two primary improvement goals produce higher quality software more efficiently and to increase the developer's size and effort estimation accuracy.  First, by recording the defects introduced into the work product the developers learn what types of problems they typically make an possibly areas to focus their quality efforts.  The higher PSP process also introduce software quality improvement phases such as design and code reviews.  These phases help detect and fix defects earlier in the development process, when it is less expensive to fix defects.  Second, the developer using PSP records their planned size and effort and the actual size and effort for each project.  The PSP describes a time estimation method that uses linear regression or averages to predict the effort of new projects based upon historical data.
At the end of each project the developer performs a "Post Mortem" of the project.  These Post Mortems focus on the two primary goals of the PSP.  They show the developer what the quality of the project was with respect to the developers historical projects and also compares the plan and the actual size and  efforts. During the Post Mortem any Process Improvement Proposals (PIPs) raised during the development or prior developments are evaluated based upon the data collected from the project and historical data.  The Post Mortem for each PSP process is fully defined and when the developer performs the Post Mortem they are automatically reflecting on their past performance.  This reflection is intended to improve either the quality, efficiency or prediction of the developer.  If these are not the goals of the developer then the Post Mortem reflection is of little use.  Also, since often this reflection is done by rote the developer may not realize the significance of the analyses.  They miss some valuable trend in their data.
 During the PSP training course as described in the book "A Discipline for Software Engineering", the PSP student also produces a defect analysis report called the R3 report.  This report analyses the cost to fix the defects based upon the phase of development that they were injected and the phase of development that they were removed.  This report helps motivate the developer to remove as many defects as possible as soon as possible.  The R3 report also shows the developer what type of defects are the most common and which are the most expensive to fix.
One of the problems with manual Reflective Software Engineering is the overhead of conducting analysis on historical data.  The files and files of raw data must be processed by hand and this greatly reduces the types of analysis that is possible.  It is very unreasonable to ask the developer to spend hours combing through their old PSP data files calculating their productivity based upon different size values.  More complex filtering and grouping is also very difficult to perform.  In general data manipulation is very difficult with manual paper data.  If the data were stored in a database then many more complex analyses could be performed on the data.  The costs of these analyses would be greatly reduced.
Another problem with the PSP is that the developer must closely follow the PSP processes.  Many developers do not follow the waterfall model.  This process does not work well for some types of development like rapid prototyping or user interface development where a more cyclical process is more natural.
1.3 Automated support for Reflective Software Engineering
Researchers at the University of Tennessee have developed a software tool that automates the PSP.  Their tool automates collection of time, size and defect data.  The tool follows the PSP processes exactly.  When the user starts a project they choose the PSP process that they are going to follow.  The tool then presents them with the correct script and asks them to provide all the data that is necessary to start the PSP process.  During the project the Tool keeps track of what phase the developer is in.  When the project is finished the tool performs the Post Mortem for the user and gives them the Post Mortem report.  
The automated PSP tool greatly reduces the overhead of using the PSP.  However, it still has the same problems as the PSP, fixed processes, fixed analyses, less reflection on the development process.  Since the tool accurately automates the PSP processes, all of them, the user cannot change the phases used or the analyses used. (Deficiencies of just automating the PSP and forcing the developer to use a defined process. )

Discuss some of the problems of automated support some of the Goals of Leap
L ight weight
E mpirically based
A anti-measurement dysfunction
P ortable

The LEAP project takes a process neutral position.  We do not want to impose any development process on the developer.  We will facilitate the recording of the developers current process.  Based upon the data collected LEAP will provide as many useful analyses as possible.
The LEAP toolkit provides the developer with a toolkit which helps them to structure and record their insights and experiences. The kinds of structured insights and experiences they can record include: the size of                  the work product; the time it took to develop it; the defects that they or others found in it; the patterns that they discovered during the development of it; checklists that they used during or designed as a result of this development; estimates for time or size that they generated or revised during the development; and the goals, questions, and measures they used to motivate the data recording.
1.4 Evaluation of Leap's ability to support Reflective Engineering by studying time estimation methods 
To evaluate Leap's ability to support Reflective Software Engineering I am going to evaluate fourteen different quantitative time estimations given historical project size and time data.  The twelve primary estimation methods can be described by three orthogonal  axes, planned vs actual size data, lines of code vs methods, and model.  Figure 1 shows the 12 primary estimation methods and the two additional estimation methods.  The PSP defines a process for deciding which method to use either A, B, or C depending on the number and correlation of the historical data.  The student may choose any of the provided estimates or they may produce their own.




























We are going to evaluate these different methods to determine if there is a better way of effort estimation from size.  Since we can do this Leap is a success.  Even if we find that there is no significant difference between the estimation methods we still learn that Leap is a valuable tool for Reflective Software Engineering.  It is also a good tool for investigating individual development.
2 GQM solution for the research
2.1 Goals
2.1.1 (G1) A quantitative comparison of different time estimation methods including the PSP.
2.1.2 (G2) Working out the individual strengths and weaknesses of the different estimation methods.
2.1.3  (G3) A comparison of the student's estimate to the other time estimation methods.
2.2 Questions
2.2.1 (Q1)  What are the different estimated time values including the student's estimate?
2.2.2 (Q2)  How did the student come up with their estimate?
2.2.3 (Q3)  What is the actual time spent on the project?
2.2.4 (Q4)  How effective are the different estimating methods?
2.2.5 (Q5)  How effective are the students' estimates?  Are the students better estimaters than the different methods?
2.2.6 (Q6)  What is the most effective estimation method?
2.2.7 (Q7)  What is the amount of error in the estimates?  Can students accurately estimate their time spent?
2.2.8 (Q8)  Does the grainsize of the size estimate matter?  If so is a larger grainsize better?
2.2.9 (Q9)  Are there patterns in the estimates such that different methods should be used at different times?
2.2.10 (Q10)  To what degree do the student's notice their own Hawthorne affect?
2.2.11 (Q11) Are methods a better way to estimate size thus time?
2.3 Metrics
2.3.1 (M1) Estimated sizes for the project in both size measures.
2.3.2 (M2) Estimated times for the different time estimation methods.
2.3.3 (M3) Student's estimated time.
2.3.4 (M4) The method the student used to develop their estimate.
2.3.5 (M5) The student's feelings about the completed project. 
2.3.6 (M6) The student's feelings about the process of monitoring their work.





3 Estimation techniques
3.1 PSP
Use the standard PSP approach to time estimation using LOC and the flow chart.  LOCAveActvAct, LOCRegActvAct, LOCRegPlanvAct
3.2 All twelve possibilities
LOCAvePlanvAct, LOCAveActvAct, LOCRegPlanvAct, LOCRegActvAct, LOCExpPlanvAct, LOCExpActvAct,
METHAvePlanvAct, METHAveActvAct, METHRegPlanvAct, METHRegActvAct, METHExpPlanvAct, METHExpActvAct,

3.3 Anology closest n Projects
Choose a value for n, e.g 1,3,5.  Find the n historical projects that have the closest planned size to the estimated size.  Use their actual time to produce an estimate for the current project.  
Ways to use the closest projects to come up with an estimate for the current project.
* Weighted average based upon distance from the estimated project.  There are two different methods for using weighted average.  Example data (size, time): (90,300), (110, 400), (120, 360). Size estimate is 100.
1. Simple weighted average.     Estimated time = ??(actual timei * (%i / sum(%))).  E.g. Estimated time = 300 * (0.9/2.6) + 400 * (0.9/2.6) + 360 * (0.8/2.6) 
                         = 103.8 + 138.5 + 110.8
                         =  353
This method works if the estimate is bracketed by the closest projects and if the projects are actually close to the estimate.  If the estimate is smaller or larger than the closest projects then the weighted average will be low or high, since this method just averages the actual time spent on each close project.
2. Weighted rates.   Estimated time = estimated size * ??(ratei * (%i / sum(%))).  E.g.
Estimated time = 100 * ((300/90*0.9/2.6) + (400/110*0.9/2.6) + (360/120*0.8/2.6))
                         = 100 * (1.15 + 1.25 + 0.92)
                         = 332
This method should work even if the estimate is larger or smaller than the closest projects since it weighs the rate of work.  This estimate does assume a linear relationship between the size of the project and the amount of time it will take to complete the project.
* Average time for the three projects as long as the projects are very close to the estimated project.  May require that the estimated project is between the closest projects.  For the above values the Estimated time = (300 + 400 + 360) / 3
                         = 353
* Average rate of the estimates times the estimated size of the project. For the above values the Estimated time = 100 * (300/90 + 400/110 + 360/120)/3
                         = 100 * (3.32)
                         = 332

3.4 Exponential Model not linear
Similar to the COCOMO model  (http://sunset.usc.edu/COCOMOII/cocomo.html) except that we are not going to use the other cost drivers just size.  Also the COCOMO model uses KLOC and not LOC so we have to modify the exponent to make it work.  My proposed model looks like:

Estimated time = M * (Estimated size) B + C

Where M = either the historical average or beta0.  There is a problem with this model since the average and beta are in the middle and the value for M should be < than the average or beta0.
C = 0 for average and  beta1 for regression.
B = 1.016, 1.04, or 1.067.  These values come from COCOMO and are 1/3 the magnitude to factor for using LOC instead of KLOC.

I'm not sure how to get the M value correctly there must be some way to do curve matching to the data set, but I don't know how do do this.
  
Calculating M:  
Where 	M is desired value for exponential function
	B is exponent
	Z is slope of linear aproximation (average or beta1)
Assume that the exponential model crosses the linear model at the Middle x value for balance. 

M*(Mid x)B + C  = Z * (Mid x) + C

M = (Z * (Mid x)) /  ((Mid x)B))


Don't know about CART, OSR, Stepwise ANOVA, OLS-Regression and Robust Regression.

New method for calculating M.  Use curve matching and reducing the sum of the squares of the error.  I've implemented this algorithm in Leap and it now uses an exponent of 1.12. It uses an itercept of  the Linear Regression variable beta1.  It then matches the curve the best it can.




4 The Experiment
4.1 Introduction 
This experiment will evaluate the different quantitative estimation processes.  I am comparing many different quantitative time estimation processes.
4.2 Experimental environment
The experiment will be performed in a student environment in the Introduction to Reflective Software Engineering course at the University of Hawaii Manoa.  The students in the class will be developing 11 (software) projects and recording their software processes in the Leap toolkit.  By reflecting on their experiences and the data they collect about their software development processes they should learn how to improve their development processes.  During the development process they will be asked to estimate the size and amount of effort each of each software project.  The Leap toolkit provides an automated tool for looking at historical development data and deriving effort estimations based upon historical size and effort data.  The Leap Time estimation tool provides students with 10 different effort estimates based upon the students historical data.  The student will the make their own estimate of how long the project will be.

4.3 Experimental variables
4.3.1 Independent and Dependent variables
Since the objective is to evaluate the different quantitative time estimation techniques, the independent variable will be the estimation technique.  This means that there is one independent variable that can take on 14 different values: the 12 method values, the PSP value and the student's.

As the accuracy of the estimation technique applies both for the estimation of the mean value and for the standard deviation, there are two dependent variables in this experiment.  The relative prediction error will be calculated for both the mean and the standard deviation.   The following two variables will be calculated for each of the 14 different estimation techniques for each student and for the entire class:
* | estimated mean - actual mean | / actual mean
* | estimated std - actual std | / actual std
These measures cannot be measured until after the task has been completed.  The different estimates must be calculated/chosen for each project before the project is started.  The Leap toolkit will provide 13 of the 14 estimates automatically. The students will record their estimate and the method they use to obtain their estimate.
4.3.2 Block
In many experiments there are outside factors that influence the relationship between the independent variable and the dependent variable.   One such influence is the complexity of the software projects P1-P11.  Some projects will be easier to predict than others.  To account for this effect this design uses the assignment number as a blocking variable. 
4.4 The Design
The design for this experiment has two parts, the class as a whole and each individual student.  
First, to evaluate the 14 estimation methods in general I am using a randomized block design.  For every project after the third (block #3P - #11P),  the effort is estimated according to the different alternatives (treatment, alt 1 - alt 14).  The relative prediction error for the mean and standard deviation will be calculated for each alternative for the entire class.  
Second, for each student the 14 estimation methods will be compared.  Again, for every project after the third (block #3P - #11P), the student's effort is  estimated using the different alternatives (treatment, alt1 - alt14).  The relative prediction error for the mean and the standard deviation will be calculated for each alternative.
We cannot use the data from the first three projects since the quantitative estimation methods require at least three data points.  With eleven projects we will still have enough data points to evaluate the different estimation methods.  Since the estimates are independently generated except for the students' estimate there is no problem with the order of the alternatives.  
When each student makes their own estimate, they will record the method they used to develop this estimate.
4.5 Analysis
I am using the following relationship to model the experiment yi = µi + ßi + ei where:
yi = the relative prediction error for alternative i
µi = coefficient of the intercept for the ith treatment
ßi = mean difference for the ith treatment
ei = residual for the ith treatment,  
This model can be analyzed with standard analysis of variance (ANOVA) procedures with the null hypothesis: 
	H0 = ß1 = ß2 = ß3 = ... = ß14
The null hypothesis states that there is no effect of estimation methods on the prediction error.
"The analysis of the described design is based on the relationship yij = µ + ti + ßj + eij  where yij is the relative prediction error for prediction alternative i and assignment j.  µ is an overall mean, ti is the effect of the ith treatment (estimation alternative, i = 1,2,...,14), ßj is the effect of the jth block (assignment, j = 1, 2,..., 11) and eij  are independent random error terms equally normally distributed with a mean of 0.  The sum of all treatment effects, as a the sum of all block effects is 0.  This model can be analyzed with standard analysis of variance (ANOVA) procedures with the null hypothesis
	H0: µ1 = µ2 = ... = µ14
Where µi = µ + ti.  The null hypothesis states that there is no effect of the estimation technique on the prediction error.  Rejecting the null hypothesis does not say which method is better it just says that they are different.  To distinguish between the different alternative estimation techniques I will use the Least Significant Method or Duncans's Multiple Range Test.  In the experiment the former was used."
For the general comparison of the 14 methods the entire class' data will be compared in the above manner with the blocking factor for assignment.  For each individual student I will remove the blocking factor and just consider the difference between the 14 methods.  The relationship for this portion of the experiment is yi = µ + ti  + ei.  Again this model can be analyzed with standard analysis of variance (ANOVA) procedures with a similar null hypothesis
	H0: µ1 = µ2 = ... = µ14
Where µi = µ + ti.  The null hypothesis states that there is no effect of the estimation technique on the prediction error.
4.6 Threats to Validity
4.6.1 Threats to Internal Validity
One common internal threat is due to maturation, which is concerned with the effect that the participants' attitude to the experiment changes during the experiment.  Since this experiment takes a whole semester this is an important threat.  One of the goals of Reflective Software Engineering is to change the attitude of the participants.  The direct result of this is that the students' own estimate may be drastically affected.  This will have no effect on the other quantitative estimation methods that depend upon historical data not the participants attitude.  The students will also be graded in the class on their data so they will be motivated to collect accurate data for the entire semester.

4.6.2 Threats to External Validity
There are two primary threats to external validity, the development projects the developers are doing and the developers themselves.  Fist the development projects tend to be small and only take about a week to complete.  This is not representative of industrial projects, however many industrial project may be reduced to smaller subprojects with a similar time frame.  The language and domain of the problems are also unique to the experiment and may need to be addressed by replication of  this experiment in different domains and languages.

Second, the developers will all be graduate students with little or no industrial experience.  They will soon be graduating and then will be junior developer in industry.  These results might be applicable to junior programmers.  Since some of the results are focussed on the individual the same experiment may have to be replicated to determine if the results apply to other individuals.
4.7 Possible Results 
4.7.1 Null hypothesis supported for the class and for each student
This result implies that there is no preferred method for estimating time from size.  This would be a very interesting result because it means that developers do not need to choose between methods for estimation.  They can choose the easiest method.  This result would tend to invalidate the PSP's time estimation method since it is complex and would be no better than any other method.
4.7.2 Null hypothesis supported for the class but rejected for some or all students
This result implies that there is not a generic best method for estimating effort from size for all developers, but individual developers may find benefits from some methods more than others.   This would tend to invalidate the PSP's time estimation method since it is generic for all developers.
4.7.3 Null hypothesis rejected for the class but supported for each student
This result is very odd.  It implies that there is a generic method for estimating the effort for the combination of developers but for each individual developer they cannot determine which estimation technique is best for them.
4.7.4 Null hypothesis rejected for the class and rejected for some or all students 
This result implies that there is a better method for all developers and that there is a best method for each individual developer.  This result might support the PSP's time estimation method. 
5 Plan
5.1 
6 Tasks
6.1 Develop estimated sizes for the project
6.2 Record the method estimates 
6.2.1 If less than 3 estimates can't do regression
6.2.2 For first project can't do plan.
6.2.3 Mark PSP estimate.
6.3 Record student estimate
6.4 Develop software
6.5 Record actual size and time
6.6 
1 Watts Humphry 1995
