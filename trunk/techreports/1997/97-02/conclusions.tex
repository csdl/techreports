\section{Conclusions}

\subsection{Concerning review meetings}

The UH and UM experiments shared a common motivation: to assess the 
contributions of meetings to software review. However, their design
and enactment differed in substantial ways. The UH subjects were
junior-level undergraduates; the UM subjects were graduate students
and professionals. The UH artifacts were source code; the UM artifacts
were requirements documents. The UH environment was entirely on-line,
using a computer-supported cooperative work environment; 
the UM environment was entirely manual, using paper and pencil. 
The UH design used two treatments, while the UM design used three. 

Despite these differences, we were able to find five 
hypotheses that could be tested on both data sets, and both data sets
confirmed or denied the hypotheses in the same way. This striking 
convergence of findings leads us to the following two conjectures about 
the {\em typical} outcome of meetings in software review:

\begin{itemize}
  
\item With respect to defect detection effectiveness, typical
  meeting-based software review methods are neither substantially more
  effective nor less effective than non-meeting-based software review
  alternatives.
      
\item Individual defect detection typically generates far more issues than
  group-based defect detection, yet has the cost of higher false positive
  rates and (when review roles are not specialized) higher issue
  duplication.
      
\end{itemize}

In addition to these conjectures, both studies also found evidence that
meeting-based review may be potentially useful for detecting certain
classes of defects.  We are far less confident of this finding than of the
preceding two, because the precision of our analysis method is limited
by the number of data points we have.

While the comparative analysis of these two studies and their subsequent
close agreement in findings suggests that our two conjectures are generally
true in traditional situations, it is still quite possible that different
outcomes would result in non-traditional situations.  For example, the 
Cleanroom Development method has achieved extremely high defect removal 
rates through a rigorous, formal process, of which meeting-based review is an
integral component. It is possible that removing review meetings in the
context of Cleanroom development could have an unanticipated ``ripple
effect'' through other aspects of the process, leading to a significant
decrease in defect detection effectiveness. On the other hand, a
geographically distributed development organization may find that
non-meeting-based review substantially outperforms meeting-based review,
since it enables greater participation and interaction between developers
who are not physically co-located.

\subsection{Concerning comparative analysis}

We are satisfied with the comparative analysis process we designed
and its results.  The reconciliation process strikes a balance
between the limitations of a literature-based comparison and the
constraints of full meta-analysis.  

Unlike a literature-based comparison, reconciliation forced us to reanalyze
the original raw data for both studies. The search for common variables and
hypotheses led us to new analyses of both data sets that were not 
performed during the original experiments.  These new analyses
significantly strengthened the results beyond what would have been possible
had we attempted to compare the studies based purely upon the original
published findings.

Unlike full meta-analysis, reconciliation did not require us to ensure that
our studies were so similar in design that merging of raw data was
possible. In fact, our studies differed in so many ways that we are
skeptical that traditional meta-analysis could be applied successfully to these
studies.  Instead, reconciliation enabled us to perform a ``side-by-side''
comparison of the new hypotheses and results, and to observe clear
similarities between the reconciled outcomes. 

\subsection{Concerning future research}

This study suggests useful future directions for research in experimental
software engineering in general, and formal technical review in particular.

First, we hope that this example of comparative analysis using the
reconciliation approach will spur other experimental software engineering
researchers to consider its application to their own research areas.
Many experimental studies could be, but haven't been compared in this
way. Since controlled experiments are time-consuming and expensive,  
comparative analysis may provide a way to obtain higher scientific
``return-on-investment'' from this valuable raw data.

Second, although the results from this comparative analysis increase our
confidence in our two conjectures concerning typical review practice, we
believe substantial value can still accrue from replication of this
comparative analysis on prior or future review experiments.  It
is important to determine if these two conjectures continue to hold widely 
for industrial practitioners, and across other artifact types, and with other
variations on meeting and non-meeting-based review methods.  Such analyses
will help us to precisely distinguish the ``typical'' from ``atypical'' 
review situations, and design and apply methods appropriately. 

Third, this analysis suggests that reviewer specialization should be
further investigated as a way to increase the effectiveness of (at least)
non-meeting-based review methods~\cite{PVB:TSE94}. Review specialization can 
increase
overall defect detection effectiveness by reducing the issue duplication
rate. More research needs to be done concerning the most effective ways to
specialize the tasks of reviewers for particular domains 
(See Porter et al. ~\cite{PVB:TSE94}).

Finally, this analysis provides no definitive answer to the tantalizing
question of whether or not there are classes of defects that are
predictably better found using meetings (or, conversely, better found {\em
  not} using meetings).  The analysis does show that certain individual
defects appeared to be found more readily in the specific meeting-based
reviews of the specific artifacts of these studies. However, we were unable
to abstract away from these isolated instances to a class of defects for
which this property of meeting sensitivity might be expected to hold.
Resolving this question more conclusively is an important task for the
experimental review community.  If we determine that some defects can be
found significantly more easily using meetings than via other approaches,
then we could design special-purpose review meetings for detection of just
those issues, and use non-meeting-based approaches for others.

