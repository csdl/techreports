%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% introduction.tex -- 
%% Author          : Philip Johnson
%% Created On      : Tue Oct 29 08:14:15 1996
%% Last Modified By: Philip Johnson
%% Last Modified On: Tue Oct 29 10:02:54 1996
%% RCS: $Id$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 1996 Philip Johnson
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 

\section{Introduction}

The value of software review as a mechanism for software quality
improvement has been demonstrated repeatedly for over twenty years.
Beginning with the landmark work of Michael Fagan at IBM in 1976,
structured review mechanisms such as inspection have been shown repeatedly
to be an extremely effective means to find work product defects early in
the software development process. 

As the benefits of such structured review processes (typically referred to
as ``Formal Technical Review'' or FTR) became more visible, researchers and
practitioners began to devise variations on Fagan's original method.  For
example, Tom Gilb developed a comprehensive inspection method with
precisely defined phases, metrics, and suggested process rates for optimum
defect removal effectiveness \cite{Gilb93}.

With few exceptions, these variations never challenged a fundamental
premise of Fagan's original method: that a face-to-face meeting of the
entire review team is essential to the review's success. While researchers
have proposed changing the manner in which reviewers prepared for the 
meeting, or even the manner in which the meeting was conducted, the need 
for a meeting was never questioned. Fagan, Gilb, and others have argued 
that meetings enable a kind of ``synergy'' among participants, in which 
defects not found by reviewers working individually suddenly come to light.
They also argue that meetings educate the participants, clarify 
requirements, and provide milestones that facilitate progress.

Unfortunately, meetings have demonstrated and substantial costs. They 
require the simultaneous attendance of all participants. Their effectiveness
depends on satisfying many conditions, such as adequate preparation, 
readiness of the work product for review, high quality moderation, 
and cooperative interpersonal relationships.
Meeting-based review appears to add 15-20\% new overhead onto development
costs \cite{Russel:LargeInspections}, and simple scheduling issues have been shown to
lengthen the start-to-finish interval for review by almost one third
\cite{votta.1993}.

The costs of meeting-based review have stimulated more recent research
designed to investigate whether new review methods can be devised that 
minimize or eliminate the cost of meetings while 
preserving the remaining benefits of review. Such research has ranged from
the design of computer-supported cooperative work systems that implement
an asynchronous, non-meeting-based review procedure \cite{Johnson94}, to 
alternative manual methods that also shift the process away from reliance
on meetings \cite{PVB:TSE94}.  

In addition to this research, a few studies have tried to directly
assess the value of inspection meetings. These experimental studies
attempt to quantify the actual benefits (and in some cases, the costs)
associated with software review meetings.  Each provides
some insight into the question of meeting-based review, but each also
suffers from the inevitable limitations of controlled experimental studies.
First, it is difficult to assess the generality of the results, and whether
they would apply to industrial practice. Second, it is unclear what
they indicate in aggregate about the appropriate future directions for
research on this important issue.

This paper describes a detailed comparative analysis of two such
experiments, one performed at the University of Maryland and one performed
at the University of Hawaii.  The experiments had a similar motivation: to
assess the true contributions of meetings to software review. They differed
in their designs, instruments, review documents, procedures, and
measurements. Despite these differences, a comparative analysis revealed
striking similarities in the outcomes. After reanalyzing both studies
according to a common experimental design framework, five hypotheses were
developed and tested against both experimental data sets. In each case,
both studies confirmed or rejected the hypothesis in the same direction,
which increases our confidence in the generality of the findings.
Furthermore, the comparative analysis of the methods employed provides
insights into the design of useful experimental research on
software review, and suggests important next steps for research.

In the next section we review prior research on meeting-based review 
and comparative experimental analysis techniques. We then summarize 
the two studies chosen for this analysis. After that we present the 
comparative analysis, and, finally, we discuss our conclusions and 
recommendations for future research.
