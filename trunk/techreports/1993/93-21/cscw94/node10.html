<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">
<!--Converted with LaTeX2HTML 96.1 (Feb 5, 1996) by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds -->
<HTML>
<HEAD>
<TITLE>Issues in CLARE-based collaborative learning</TITLE>
<META NAME="description" CONTENT="Issues in CLARE-based collaborative learning">
<META NAME="keywords" CONTENT="cscw94">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<LINK REL=STYLESHEET HREF="cscw94.css">
</HEAD>
<BODY LANG="EN">
 <A NAME="tex2html125" HREF="node11.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="http://cbl.leeds.ac.uk/nikos/figs/next_motif.gif"></A> <A NAME="tex2html123" HREF="node8.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="http://cbl.leeds.ac.uk/nikos/figs/up_motif.gif"></A> <A NAME="tex2html119" HREF="node9.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="http://cbl.leeds.ac.uk/nikos/figs/previous_motif.gif"></A>   <BR>
<B> Next:</B> <A NAME="tex2html126" HREF="node11.html">Discussion</A>
<B>Up:</B> <A NAME="tex2html124" HREF="node8.html">Results</A>
<B> Previous:</B> <A NAME="tex2html120" HREF="node9.html">Viability/usability of CLARE</A>
<BR> <P>
<H3><A NAME="SECTION00032200000000000000">Issues in CLARE-based collaborative learning</A></H3>
<P>
Detailed analysis of the outcome and process data revealed a number of
interesting issues regarding collaborative learning using CLARE.  These
issues are discussed fully in [<A HREF="node15.html#csdl9314">24</A>], here we present four of
the most significant: mis-interpretations of RESRA, failures in
summarization, summarization strategies, and collaboration in CLARE.
<P>
First, RESRA was interpreted in a wide variety of ways among the learners.
Despite the presence of hands-on training, detailed user documentation, and
online examples, many subjects still seemed to fail to grasp the semantics
of RESRA primitives, as evidenced by a substantial number of times in which
RESRA nodes and links were used incorrectly.  For example, though <EM>
theory</EM> is defined as ``a systematic formulation about a particular
problem domain...'', the following use of the primitive clearly does not
satisfy this definition:
<P>
<PRE>   TYPE: theory
   SUBJ: No single development improves
         the situation
   DESC: No single development aids in
         improving the software problem,
         at least not with respect to
         productivity, reliability or
         simplicity.</PRE>
<P>
Other typical errors in using RESRA include evidence nodes
containing no evidence, suggestions containing no proposals from the
learner, claims that are ``neutral,'' evidence stated as claims,
explanations or predictions identified as theories, problems treated as
learner's disagreements with the author's claims instead of what the author
attempts to address, and so forth.
<P>
Second, although subjects spent about 66% of their time on summarization,
they frequently failed to adequately summarize the artifact by correctly
identifying major themes and relationships and filtering out the minor
ones.  For example, Figure <A HREF="node3.html#figfagan"><IMG  ALIGN=BOTTOM ALT="gif" SRC="http://cbl.leeds.ac.uk/nikos/figs/cross_ref_motif.gif"></A> provides an expert summary of
[<A HREF="node15.html#Fagan76">8</A>] using 11 nodes. The 16 subjects analyzing this artifact
generated an average of 19 nodes. Given this relatively large number, one
would expect that all major themes would be covered, as well as a few minor
ones.  However, analysis of representations reveals that: (a) none of the
16 learners correctly identified the problem; (b) only seven learners
correctly identified one or two of the three major claims; (c) only ten
learners had the evidence right; and (d) only six learners had one of the
two methods right. On the other hand, many minor themes of the paper were
found in the learners' representations.
<P>
Third, the process data also reveals a set of stereotypical strategies used
by learners in summarizing the content of an artifact. The strategies are
characterized by the sequencing of summarative node and link instance
creation:
<P>
<UL><LI> <I>Nodes only:</I> Create summarative nodes only. No attempt is made
  to connect them together using RESRA link primitives.<LI> <I>Nodes for an entire document, then links:</I> First create
  summarative nodes for the entire artifact, and then link them together.<LI> <I>Nodes, then links, but one section at a time:</I> Create
  summarative nodes for a single source node and/or its adjacent source
  nodes, and then create links between them; repeat the same process until
  all source node are summarized.<LI> <I>(2) first, then (3):</I> A combination of the first and second
  strategy. First create summarative nodes for the entire artifact,
  followed by a wave of link creation. Next, selectively create additional
  summarative nodes, immediately followed by the link creation.
</UL>
<P>
Excluding the 36% of learners/sessions who adopted the first
strategy, i.e., creating no summarative links, there was no noticeable
correlation found between the strategy used and the quality of
summarization.
<P>
Finally, in the SECAI model, explicit collaboration among learners takes
place in the form of comparing their representations, deliberating
reasonings behind them, and ultimately, integrating them into a coherent
whole. Figure <A HREF="node10.html#figargexample"><IMG  ALIGN=BOTTOM ALT="gif" SRC="http://cbl.leeds.ac.uk/nikos/figs/cross_ref_motif.gif"></A> shows an example collaborative
representation network generated by four first-time CLARE users. Of a total
of 92 nodes in the network, 34 were created during the argumentation phase.
Most of these nodes (32 of 34) are <I>evaluative </I> in nature, which in
turn can be categorized into two groups: pointing out the correct use of
RESRA primitives and identifying ambiguities/inaccuracies in other
learners' representations. In ``critique642,'' for instance, Mary points
out that, in ``claim528,'' Scott has totally mis-interpreted the original
authors' meaning. To assess the accuracy of Scott's representation, the
process data shows that Mary in fact verifies the node content with the
source from which Scott's node was derived.
<P>
Figure <A HREF="node10.html#figargexample"><IMG  ALIGN=BOTTOM ALT="gif" SRC="http://cbl.leeds.ac.uk/nikos/figs/cross_ref_motif.gif"></A> also shows the presence of <I>
constructive</I> (as opposed to <I>evaluative</I>) argumentation, in which
learners do not merely critique or question each other's positions but
engage in active knowledge-building by formulating new problems, proposing
alternative claims, supplying additional evidence, and so on. In
``evidence662,'' for example, Chris counters Mary's claim (``claim522'')
with new evidence.
<P>
Another noticeable feature about Figure <A HREF="node10.html#figargexample"><IMG  ALIGN=BOTTOM ALT="gif" SRC="http://cbl.leeds.ac.uk/nikos/figs/cross_ref_motif.gif"></A> is the
absence of integration activities, which turns out to be quite typical
across CLARE sessions. A few learners elected to add explicit integrative
links between their representations or vote for best representations. As a
result, the group knowledge base consists of substantial amount of
redundancy and inconsistency.
<P>
<P><P><A NAME="figargexample">&#160;</A><P><P><HR><A NAME="tex2html125" HREF="node11.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="http://cbl.leeds.ac.uk/nikos/figs/next_motif.gif"></A> <A NAME="tex2html123" HREF="node8.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="http://cbl.leeds.ac.uk/nikos/figs/up_motif.gif"></A> <A NAME="tex2html119" HREF="node9.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="http://cbl.leeds.ac.uk/nikos/figs/previous_motif.gif"></A>   <BR>
<B> Next:</B> <A NAME="tex2html126" HREF="node11.html">Discussion</A>
<B>Up:</B> <A NAME="tex2html124" HREF="node8.html">Results</A>
<B> Previous:</B> <A NAME="tex2html120" HREF="node9.html">Viability/usability of CLARE</A>
<P><ADDRESS>
<I>Philip Johnson <BR>
Fri Apr  5 07:51:00 HST 1996</I>
</ADDRESS>
</BODY>
</HTML>
