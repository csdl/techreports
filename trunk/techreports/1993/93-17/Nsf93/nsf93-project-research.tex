%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% nsf93-project-research.tex -- 
%% RCS:            : $Id: nsf93-project-research.tex,v 1.2 93/09/01 17:21:02 johnson Exp $
%% Author          : Philip Johnson
%% Created On      : Thu Aug 12 16:30:04 1993
%% Last Modified By: Philip Johnson
%% Last Modified On: Wed Sep  1 17:20:51 1993
%% Status          : Unknown
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 1993 University of Hawaii
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%% History
%% 12-Aug-1993		Philip Johnson	
%%    

\subsection{Proposed Research}
\label{sec:proposed-research}

As noted previously, this project involves four major activities:
continuing development of CSRS; empirical studies of FTR; public release of
CSRS; and development of an on-line CSRS Metric Database.  The next sections
detail each of these activities.

\subsubsection{Continuing development of CSRS}

While CSRS has matured substantially during the past two years of
development, ongoing effort will be required to broaden its applicability
to different review processes, review artifacts, and implementation
platforms.  The most important development activities are the following:

\begin{itemizenoindent}
\item {\em New language-specific support, beginning with C and C++.} As a
  result of our prior focus of attention on quality assurance for the Lisp
  component of Egret, we developed a variety of useful CSRS support tools
  specialized to this language. We are now turning our attention to quality
  assurance of the underlying C++ server as well, and will provide
  language-specific tools for this family of languages.  

  \item {\em Support for non-ASCII artifacts.}  CSRS is currently
  restricted to review of ASCII artifacts.  We intend to investigate other
  document formats, such as SGML, in order to facilitate review of
  non-ASCII artifacts such as design diagrams.  
  
\item {\em Quality assurance.} Continued quality assurance and
  improvement to both CSRS and our overall software development process is
  an ongoing goal in our laboratory.  Based upon informal self-assessment,
  we believe ourselves to be near or at Level 2 of the Capability Maturity
  Model. We intend to strive over the next several years to reach Level 3.

\end{itemizenoindent}

These continuing development activities are most crucial to providing the
necessary infrastructure to support the other three major activities:
empirical studies, external release, and the CSRS Metric Database.  We
believe these goals can be achieved with very low risk of failure.  Many
other enhancements to CSRS would be useful, such as an improved user
interface and tighter integration with integrated project support
environments (IPSEs), but we do not view these latter enhancements as
crucial to the success of this project.

\subsubsection{Empirical studies of FTR}

Our research paradigm is heavily influenced by recent calls to put software
research on a more empirically-based, scientifically sound footing
\cite{Tichy93,Berry92,Cohen88,Basili86,Basili84}.  In this light, an
important contribution of this project will be the execution of a set of
empirical studies intended to provide new perspectives on the process and
products of FTR, enabled by the unique forms of empirical data that CSRS
collects.  This section overviews four studies we plan to carry out over
the next two years, as space limitations preclude a complete description of
their experimental design.

\begin{itemizenoindent}
  
\item {\em Predictive measures of review effort.} One empirical research
  objective is to develop predictive measures based upon relationships
  between review outcome data, review process data, and review artifact data.
  
  As discussed above, analyzing the relationship between program
  complexity and review effort, for example, is a promising approach to
  estimating review effort based upon program complexity.  Analysis of
  other review factors such as the number of participants or the
  programming language (in the case of source code artifacts) may lead to
  a composite predictor of review effort (or other review outcomes, such
  as the number or type of defects found).
  
  Predictive measures of review outcome values will be extremely useful
  to organizations, since they provide both a planning tool (by
  estimating the future cost of review based upon some current measure of
  the artifact) as well as a process-improvement tool (by revealing
  organizational changes that can improve review outcomes, such as
  changing to a different source language, structuring artifacts for
  better review, and so forth.)
  
  This empirical study will be an ongoing concern as data is produced
  from our internal quality assurance activities using CSRS.  As we begin
  to amass data on review in the C++ language, we will look for
  differences between C++ and Lisp with respect to this relationship.
  These initial conclusions will be organization, application, and
  language specific.  As CSRS is adopted externally, we will investigate
  whether the relationships discovered within our specific context apply
  more generally. 

  
\item {\em Investigation of review method variations on review outcome.}
  CSRS provides an excellent framework within which to experiment upon the
  impact of variations in review method on review outcome.  The objective
  of such research is to provide empirically-based understanding of the
  differences between review methods, with the goal of discovering new,
  more efficient and effective methods for computer-based software review.
  
  Review method variations can occur within the current process model by
  varying the specific method employed within any single phase.  For
  example, CSRS can be used to assess the differences between a
  ``selective test case'' review style and a ``verification-based ''
  review style in terms of their impact upon review.  This study will be
  carried out as part of a Ph.D.  thesis currently under development in
  our laboratory \cite{csdl-ro-93-05}.
  
  Review method variations can also be examined by changing the current
  CSRS process model.  For example, better understanding of the actual
  impact of asynchronous interaction upon review could be gained by
  comparing outcomes from a set of reviews using a method involving only a
  face-to-face, synchronous version of CSRS (i.e. a version of CSRS that
  provides only support for the group review meeting) with a set of reviews
  using a method involving only an asynchronous version of CSRS.  
  
  Such studies will be carried out initially through experiments
  involving upper-level undergraduates and graduate students in software
  engineering at the University of Hawaii.  A repeated measures
  experimental design can provide insight into the effect of review method
  on review outcome.  Once CSRS is released for external use, larger
  studies involving professional software development organizations become
  possible.
  
\item {\em Investigation of syntax-driven review checklists for C++.} As
  part of our development activities with the Hyperbase, we discovered the
  existance of recently published literature containing rules and
  recommendations for high quality C++ systems
  \cite{Murray93,Ellemtel92,Meyers92,Cargill92,Coplien92}.  This literature
  contains over 150 different recommendations, most of which are
  syntactically context-sensitive (for example, rules pertaining to high
  quality C++ {\tt class} declarations; rules pertaining to correct use of
  {\tt []} following the {\tt delete} function, and so forth.)  These rules
  present a problem: there are too many for inclusion in a standard
  checklist. They also present an opportunity: it should be possible to
  filter the list based upon syntactic characteristics of the C++ program
  entity under review.
  
  This third empirical study involves the design and evaluation of a version
  of CSRS specialized to C++, where reviewers are presented with a
  checklist of items specific to the characteristics of the actual C++
  program entity under review.  The effectiveness of this approach to
  review can be assessed empirically in several ways, either through a
  repeated measures experimental design, or through a two-pass review
  experiment where the first pass is performed without the checklist,
  followed by a second pass involving the same review team where the
  checklist is present.

  
\item {\em Technology transfer of CSRS through graduate student
  internships.} The final empirical study involves a case-study, protocol
  analysis experiment involving the placement of graduate students from our
  lab with one or more corporations for a several month period as interns.

  These students will provide training and system support necessary for trial
  usage of CSRS with the organization.  The empirical data collected, as well
  as the observations of the interns, will provide valuable insight into the
  transfer, effectiveness, and adoption of CSRS in a non-academic
  setting. Currently, representatives from SUN Microsystems in Mountain View,
  CA., Andersen Consulting in Chicago, IL, Sakura Global Capital in New
  York, NY., and Knowledge Data Systems in Palo Alto, CA. have expressed an
  interest in both CSRS and this internship program.
  
  This study will also serve as a pilot project to uncover both
  requirements for public release of CSRS, and training materials needed
  for independent installation and adoption of CSRS by external sites.

\end{itemizenoindent}

Empirical studies will be an ongoing activity throughout the life of this
project.  The first two studies involving review factors and method
variations have already begun.  The latter two studies involving
syntax-driven review checklists and the internship program are planned to
begin approximately one year into the project.  We expect that these
empirical studies have relatively low risk of failure within the proposed
funding period.

\subsubsection{Public release of CSRS}

A major goal of this project, planned to occur during the third or fourth
year of funding, is unlimited public release of CSRS.  We currently plan
for CSRS to become freely accessable via FTP for installation on any Unix
system supporting other freely available packages such as g++ (the GNU C++
compiler), Lucid Emacs, and X windows.

Porting to other platforms (Macintosh, Windows, Windows/NT, etc.) will be
considered, but commitment to any platform other than Unix and X Windows is
premature at this point.

While public release of CSRS is certainly achievable by the third or fourth
year of funding, a significant risk remains that {\em adoption}\/ of CSRS
within an organization will not be possible without on-site training.  We
intend to utilize the internship program as a source of data on the
potential problems that can prevent adoption, and to support the design of
efficient supplementary materials (potentially including videotape, on-line
documentation, a Usenet newsgroup, and so forth) to allow minimally aided
CSRS technology trial, insertion, and adoption.

\subsubsection{Development of an on-line CSRS Metric Database}

Success in achieving relatively widespread, unaided CSRS adoption is
required to achieve the most long-range, high risk, but perhaps most
exciting activity of all: the development of an automatically maintained,
on-line CSRS Metric Database.

The Metric Database is intended to serve as a mechanism for users of CSRS
to share appropriately sanitized information about the process and products
of review with each other.  Our current vision of this system involves
obtaining an agreement with organizations to allow installation of CSRS in
such a manner that measurements from their review are set up automatically
for e-mail to a central database server process under our support. (The
organization would always have control over when and if metric information
is provided.)  Outcome data, process data, and even method data (such as
the set of checklists used by a particular organization for a particular
artifact type) could be shared through this database.

Organizations would then be able to query the database server to learn
about the review outcomes of other organizations.  For example, such a
database can allow organizations to determine empirically founded answers
to such questions as: ``Based upon the current data, what is a good review
team composition, and how much effort has it historically taken to review a
2.5 KLOC C++ system? Finally, what organizational characteristics appear to
impact upon these values?''

Such a Metric Database will vastly increase the rate of evolution and
maturation in CSRS.  It can even lead to collaborative research efforts,
where several small organizations with similar characteristics might band
together into a partnership to collectively explore the impact of different
CSRS-based review methods on outcomes within their organization.


\subsection{Conclusions}

Formal technical review is widely believed to be effective, but empirical
research to explain this effectiveness or improve upon it is hard to
compare, thin in scope, and often conflicting in results.  Furthermore,
existing methods are almost entirely manual in nature, leading to high
cost, high overhead, and problems in adoption.  

This research project is designed to make a significant impact upon both
the practice of software review and the research paradigm used to
understand and improve it.  By further refining and releasing our current
system, we will make freely available a sophisticated environment for
review that automates many time-consuming clerical features and addresses
many current process-level problems, thus facilitating more widespread
adoption of the FTR method for software quality assurance.  By
instrumenting this environment and providing an avenue for sharing of this
data, we intend to create a research paradigm whereby organizations have
``direct access'' to research data of direct use to improving their own FTR
practice.  The implications of success in this project go beyond software
review to a new paradigm of software engineering research, whereby the use
of instrumented, standardized environments allow experimentation and
empirical analysis in a form not previously possible.



