%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ftr93-project-research.tex -- 
%% RCS:            : $Id: nsf93-project-research.tex,v 1.5 93/10/08 11:35:52 johnson Exp $
%% Author          : Philip Johnson
%% Created On      : Thu Aug 12 16:30:04 1993
%% Last Modified By: Philip Johnson
%% Last Modified On: Tue Oct 12 12:51:33 1993
%% Status          : Unknown
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 1993 University of Hawaii
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 
%% History
%% 12-Aug-1993		Philip Johnson	
%%    

\subsection{Proposed Research}
\label{sec:proposed-research}

In this research agenda, we propose to continue our work on predicting
review effort from artifact review complexity, visualization tools for
process analysis, and information characterization during the project
period.  In addition, we propose the following research in support of the
five major project objectives described earlier.

\subsubsection{Empirically-based evaluation of FTR methods}

Our research paradigm is heavily influenced by recent calls to put software
research on a more empirically-based, scientifically sound footing
\cite{Tichy93,Berry92,Cohen88,Basili86,Basili84}.  In this light, an
important contribution of this project will be the execution of a set of
empirical studies intended to provide new knowledge about the process and
products of FTR, enabled by the unique forms of empirical data that CSRS
collects.

Our experimental studies will be based upon the following framework, 
whereby various review factors are classified along the following
orthogonal dimensions:

\begin{itemizenoindent}
\item {\em Synchronicity.} This dimension refers to the amount of
  synchronous interaction between reviewers.  CSRS provides a broad
  spectrum of choices for the degree of synchronicity, ranging from pure
  asynchronous (where all review is accomplished without any synchronous,
  face-to-face interaction), to mixed (where review effort involves both
  synchronous and asynchronous interaction), to pure synchronous (all review
  effort is performed face-to-face). 
  
\item {\em Review strategy.} This dimension refers to the specific
  technique to be used by reviewers while analyzing review artifacts.  For
  example, \cite{Fagan76} specifies that reviewers refer to a checklist of
  common errors.  An alternative approach is to generate hypothetical test
  cases and use them to evaluate the software.  A third technique,
  verification-based review, involves checking the code against a formal
  specification during review. The most common technique is called free
  review, where reviewers simply analyze the code in an unconstrained
  fashion.
  
\item {\em Group size.} This dimension refers to the size
  and characteristics of the individuals within the review group.
  Important group size values are 1 (individual review), 4, 6, 8 (typical
  group sizes), 10, and 20 (atypically large group sizes).  
  
\item {\em Reviewer characteristic.} This dimension refers to the
  characteristics of the individual reviewers, and includes their
  familiarity with the artifact under review, experience with FTR, overall
  software engineering experience, and so forth.
  
\item {\em Review artifact type.} This dimension characterizes both the
  general class of artifact (such as design document, source code, test plan)
  as well as characteristics within each class (source code complexity,
  design technique, etc.)
  
\item {\em Review outcome.} This dimension refers to various outcome
  measures resulting from FTR.  Quantitative outcome measures include the
  number type, and severity of defects found, and reviewer effort.
  Qualitative outcome measures include subjective measures of reviewer
  satisfaction and review quality.

\end{itemizenoindent}

One example of empirical research using CSRS is now under execution within
our laboratory as part of a Ph.D. dissertation \cite{csdl-ro-93-05}.  The
goal of this single-factor study is to assess the impact of (code) review
strategy on review outcome.  The independent variable is review strategy,
which will be systematically varied across a set of review groups.
Synchronicity and group size are controlled variables to be held constant,
and reviewer characteristics will be controlled through randomization. The
dependent variable is review outcome, which will be measured through CSRS
instrumentation and post-treatment questionnaires.  This study will use
subjects drawn from the pool of upper-level undergraduates and graduate
students in software engineering.

We propose to perform several other single-factor studies of this kind
during the project period in order to assess such issues as the impact of
group size and synchronicity upon review outcome.  We also propose to
perform two-factor experiments to assess the interaction between review
factors.  For example, an experiment in which both synchronicity and group
size are varied systematically will reveal information about the effects of
spatial-temporal proximity on the most effective group size for review.

This particular two-factor experiment is important and significant because
most FTR methods constrain group size to 6-8 participants
\cite{Freedman90,Fagan76}.  However, we hypothesize that this size
constraint is primarily due to the synchronous, face-to-face nature of
traditional FTR.  Asynchronous communication in other domains has been
shown to support larger group sizes \cite{Nunamaker91}, and we hypothesize
that this result will also hold for asynchronous, computer-mediated FTR.

\subsubsection{FTR process improvement}

The framework described in the prior section can be viewed in another
fashion: as a {\em space to be searched} for improvements to an
organization's FTR method. A prescriptive, robust strategy for searching
this space of possible review methods defines an FTR process improvement
method.

For example, the single-factor experiments discussed in the prior section
constitutes a primitive process improvement method.  Each single-factor
experiment detects optimal values (with respect to review outcome) for a
given review factor, given specific values for other review factors.  If
review factors are independent of each other, then an organization can
determine their optimal review method through a series of single factor
experiments.  If review method effectiveness is independent of
organizational context, then the optimal review method within one
organization applies to all organizations.

However, we hypothesize the review factors are neither independent of each
other nor constant across organizations.  Therefore, we propose to define
an FTR process improvement method through a combination of multi-factor
experimentation within our laboratory with controlled and uncontrolled data
collection from external sites.  Our laboratory experiences have suggested
several different ``seed'' review methods.  Additional controlled and
uncontrolled usages of CSRS from external sites will further populate the
space of FTR methods with experimental usages.  These externally collected
data will be fed back into the laboratory setting as a basis for further
controlled experimentation.  This laboratory/industrial cycle of usage will
be used to incrementally define and evaluate an organization-specific FTR
process improvement method.


\subsubsection{Domain-specific support for FTR of C++ software} 

As part of our development activities with the Hyperbase, we discovered the
existance of recently published literature containing rules and
recommendations for high quality C++ systems
\cite{Murray93,Ellemtel92,Meyers92,Cargill92,Coplien92}.  This literature
contains several hundred discrete recommendations, most of which are
syntactically context-sensitive (for example, rules pertaining to high
quality C++ {\tt class} declarations; rules pertaining to correct use of
{\tt []} following the {\tt delete} function, and so forth.)
These rules and recommendations form a valuable knowledge base for
improving the quality of C++ software.  However, the rules are too
numerous, and in some cases, too complex for representation as a standard
review checklist.

We propose to design and evaluate of a version of CSRS specialized to C++.
This version will incorporate a database of C++ rules and recommendations
and respond in a context-sensitive manner to the syntactic (and perhaps
semantic) characteristics of the program entity under review.

The effectiveness of such a domain-specific review system will be assessed
empirically through two kinds of experiments.  First, a repeated measures
experimental design will be used to compare review outcomes for two groups,
where each group reviews C++ systems with and without the guideline
library.  Second, a two-pass review method will be tested, where the first
pass is performed without the guideline library and the second pass
introduces it.  

This design and evaluation of this system will result in significant new
information about the cost and benefits of using rich, domain-specific
knowledge during review.  If successful, the system itself will constitute
a unique and powerful tool for producing high quality software using the
most rapidly growing programming language community of the 1990's.

\subsubsection{Case study-based evaluation of guided CSRS technology transfer}

A recent article on the state of software engineering research contains a
call to replace the traditional {\em research-then-transfer}\/ paradigm,
where research efforts are essentially disconnected from industrial
practice, with an {\em industry-as-laboratory}\/ paradigm, where industry
forms an active and integral partnership with researchers \cite{Potts93}.  

We propose to enter into partnership with a small number of software
development organizations.  This partnership will involve our in-depth
involvement in the transfer of CSRS into the external organization,
supplying training in both formal technical review and CSRS, providing
technical support, and collecting and analyzing the process and outcome
data.  Representatives from various organizations have expressed an
interest in this partnership.
  
Case study-based evaluation will elicit new requirements for industrial
adoption of CSRS, and will provide additional process and outcome data on
FTR.  It will serve as a crucial external evaluation of this technology,
providing data on the utility of the system and barriers to transfer to the
commercial sector.  Finally, these experiences will provide requirements
for unguided release of CSRS, where organizations can obtain materials
sufficient for independent installation, evaluation, and adoption.

More details about this technology transfer are presented in Appendix
\ref{sec:tech-transfer}.

\subsubsection{The CSRS Consortium for collaborative, industrial FTR research}

We propose to use the experiences from case studies to develop CSRS and its
supporting training and documentation materials into a form allowing large
scale evaluation and adoption of this technology.

We believe that the simple availability of a free, validated, empirically
founded collaborative tool for FTR will provide a significant new enabling
technology for organizations motivated to increase the quality of their
software.

A more fundamental motivation for widespread distribution and adoption is
the awareness that each explicit user of CSRS is an implicit researcher on
FTR.  Since CSRS gathers valuable process and outcome data automatically
and unobtrusively, a broad-based CSRS user community constitutes a
extraordinary research opportunity, and a unique means by which
organizations can collaboratively improve not only their own software
quality, but that of the entire community.

The consortium version of CSRS will provide tool support for e-mail of FTR
information to a central database server maintained in our laboratory.
(Each organization will retain ultimate control over when and if this
information is provided to us, and any proprietary information will be
expunged.)  Outcome data, process data, and even method data (such as the
set of checklists used by a particular organization for a particular
artifact type) will be shared through this database.

Any organization can query the database server to learn about review
outcomes.  For example, the database will allow queries such as: ``Provide
a summary of team composition, team size, effort, and outcome for reviews
of C++ systems of size between 10 and 15 KLOC.''  Our laboratory will focus
on detailed analysis of the data, issuing periodic reports on interesting
new data trends or process improvements.

A CSRS consortium will substantially increase the rate of improvement in
formal technical review practice and software quality assurance.  It can
easily support explicit collaborative industrial research efforts, where
several small organizations with similar characteristics might band
together to perform controlled research experiments.  


\subsection{Conclusions}

Formal technical review is widely believed to be effective, but empirical
research to explain this effectiveness or improve upon it is hard to
compare, thin in scope, and often conflicting in results.  Existing methods
are almost entirely manual in nature, leading to high cost, high overhead,
and problems in adoption.  While FTR has been used for over 15 years to
improve software quality, only a handful of collaborative support
environments exist, and all of these have been in existance for only a
short time.

This research agenda proposes a carefully constructed mixture of laboratory
studies, field studies, development efforts, data collection, and data
analysis that is designed to provide substantial new knowledge about formal
technical review.  This knowledge will differ qualitatively as well as
quantitatively from the current state of knowledge about FTR.  The high
quality, fine grained instrumentation will reveal more detailed and precise
information about the process and products of FTR than any previous
research.  The CSRS consortium will generate a completely unique body of
comparable, quantitative data on FTR across a spectrum of organizations.
The lessons learned from this project may well transcend the domain of FTR,
providing insights into effectively instrumented software engineering
environments, and a new approach to industrial research collaboration.





