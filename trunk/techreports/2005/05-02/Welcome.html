<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>
  <head>
    <title>NSF CyberInfrastructure Proposal</title>
  </head>
<body text="#330066">
<font face="verdana">

    <h1 align="center">NSF CyberInfrastructure Proposal</h1>
    <p align="center"><a href="http://csdl.ics.hawaii.edu/~johnson/">Philip
    Johnson</a><br>
    <a href="http://csdl.ics.hawaii.edu/">Collaborative Software Development
    Laboratory</a><br>
    <a href="http://www.hawaii.edu/">University of Hawaii&nbsp;</a></p>


    <p align="center">&nbsp;</p>

    <h3>Change Log</h3>

    <p><b>12-May-2005</b></p>

    <ul>
      <li>Latest proposal draft: <a href="nsf.pdf">nsf.pdf</a></li>
      <li>Proposal LaTeX files: <a href="nsf.tex">nsf.tex</a>, <a href="nsf.bib">nsf.bib</a>,
        <a href="project-overview.tex">project-overview.tex</a>, <a href="project-relatedwork.tex">project-relatedwork.tex</a>,
        <a href="project-researchplan.tex">project-researchplan.tex</a>, <a href="project-contributions.tex">project-contributions.tex</a></li>
    </ul>

    <h4>21-April-2005</h4>

    <ul>
      <li>Only one day past the already delayed proposal draft date:&nbsp; <a href="nsf.04-21-2005.pdf">nsf.04-21-2005.pdf</a></li>
    </ul>

    <h4>12-April-2005</h4>

    <ul>
      <li>&quot;Participants&quot; section now includes Martha, who has agreed
        to participate. Yeah!&nbsp;</li>
      <li>&quot;Background Readings&quot; section includes a link to Brian's
        paper on &quot;Organizations as Networks of Action&quot;, which proposes
        an alternative representation that may be well suited to our approach.</li>
      <li>&quot;Funding&quot; section now proposes either a 3 year or a 4 year
        approach.</li>
      <li>&quot;Notes on the solicitation&quot; has a new section (&quot;Since
        12-April-2005&quot;)</li>
      <li>Initial proposal draft date changed to April 20.</li>
    </ul>

    <h3>Overview</h3>

    <p>Greetings. This page is intended to support the collaborative development
    of a proposal to the &quot;<a href="http://www.nsf.gov/funding/pgm_summ.jsp?pims_id=13553&amp;org=CISE&amp;from=home">Next
    Generation Cybertools</a>&quot; program. While you will, of course, want to
    read the full solicitation, the following excerpt from the synopsis is
    enough to get oriented:</p>
    <hr>
    <p>Researchers in the social and behavioral sciences and computer and
    information sciences have many important synergistic relationships. One way
    in which this is manifest is in the development and utilization of data. On
    the one hand, social and behavioral scientists find new ways to create and
    analyze data in their endeavors to describe human and organizational
    behavior. On the other hand, computer and information scientists conduct
    research that yields new ways to improve both domain-specific and
    general-purpose tools to analyze and visualize scientific data -- such as
    improving processing power, enhanced interoperability of data from different
    sources, data mining, data integration, information indexing and data
    confidentiality protection - or what we have termed cybertools.</p>
    <p>This solicitation invites proposals for &quot;information infrastructure
    testbeds&quot;, each of which would include the development of the next
    generation of cybertools applied to data from various sources collected in
    two areas of research fundamental to social and behavioral scientists:
    organizations and individuals. The tools that are developed on these
    platforms must not only change ways in which social and behavioral
    scientists research the behavior of organizations and individuals, but also
    serve sciences more broadly.</p>
    <p>It is envisioned that proposals for the &quot;organization information
    testbed&quot; will address three specific components:</p>
    <ol>
      <li>The development of tools that facilitate the integration of
        qualitative and quantitative information from heterogeneous sources,
        multiple media, and/or multiple modes; </li>
      <li>Investment in basic research that addresses the protection of the
        confidentiality of respondents in computerized, widely accessible
        databases; and </li>
      <li>The development of incentives, standards and policies for collecting,
        storing, archiving, accessing, and publishing research results using
        organization-relevant information.</li>
    </ol>
    <hr>
    <p>I have omitted the portion of the synopsis regarding the &quot;individual
    information testbed&quot;, because I believe we are much better suited to
    compete for the organization information testbed. </p>
    <h3>Participants</h3>
    <p>One of the things I find exciting about this solicitation is its
    interdisciplinary nature, and the opportunity to work with colleagues both
    within and apart from computer science and software engineering.&nbsp;&nbsp;
    Here is a bit of information about the current set of principal
    investigators for this proposal: </p>
    <ul>
      <li><a href="http://csdl.ics.hawaii.edu/~johnson/">Philip Johnson</a>,
        Professor, Information and Computer Sciences, University of Hawaii. My
        research interests focus mainly on the development of tools and
        techniques to support low-cost measurement and modeling of software
        development.&nbsp; Since 2001, I have been leading the development of <a href="http://www.hackystat.org/">Hackystat</a>,
        an open source framework for software metrics collection and analysis. <br>
        &nbsp;</li>
      <li><a href="http://www.cs.umd.edu/~basili/">Victor Basili</a>, Professor,
        Department of Computer Science and Institute for Advanced Computer
        Studies, University of Maryland. Vic has done <a href="http://www.cs.wustl.edu/icse05/ConferenceProgram/Tracks/VicBasiliSymposium.shtml">quite
        a bit of research in software engineering</a>, to put it mildly.&nbsp; <br>
        &nbsp;</li>
      <li><a href="http://www.msu.edu/~pentlan2/">Brian Pentland</a>, Professor,
        Department of Accounting and Information Systems, Michigan State
        University.&nbsp; Brian's <a href="http://www.msu.edu/~pentlan2/btp-resume.pdf">research</a>
        focuses on the understanding of organizational routines.&nbsp; He brings
        experience in business process modeling and sequential analysis of
        qualitative data.<br>
        &nbsp;&nbsp; </li>
      <li> <a href="http://www.seweb.uci.edu/faculty/feldman/">Martha
    Feldman</a>, Professor, School of Social Ecology, UC Irvine. Martha's <a href="http://www.seweb.uci.edu/faculty/feldman/curriculum_vitaeuci.doc">research</a>
        also focuses on organizational routines, and &quot;uses practice theory
        to understand the role of organizational routines in organizational
        learning and adaptation.&quot;&nbsp; </li>
    </ul>
    <h3>Background Reading</h3>
    <p>Here is a minimal set of papers that can provide a kind of frame around
    the proposal and also indicate some ways in which we can leverage our
    current research directions. </p>
    <ul>
      <li><a href="http://csdl.ics.hawaii.edu/techreports/04-11/04-11.pdf">Improving
        Software Development Management through Software Project Telemetry</a>,
        Philip Johnson et al.&nbsp; This paper provides an introduction to the
        Hackystat framework for automatic collection and analysis of objective,
        quantitative software engineering measurements.&nbsp; Software project
        telemetry is a relatively simple analysis mechanism for making
        measurement trends available for decision making. </li>
      <li><a href="http://csdl.ics.hawaii.edu/techreports/05-02/docs/OwnershipOfData-032405.pdf">Ownership
        of data, testbeds, and artifacts</a> (White Paper), Victor Basili et
        al.&nbsp; Last year at a meeting of the International Software
        Engineering Research Network, Vic led a session on privacy issues in
        software project data.&nbsp; More recently, Vic has initiated the joint
        writing of a position paper on these issues along with several of the
        participants in that session. This paper is clearly 'under
        construction', but provides some insight into these issues from the
        perspective of software engineering researchers. </li>
      <li><a href="http://csdl.ics.hawaii.edu/techreports/05-02/docs/RoutineHandbook-03-24-05.pdf">Issues
        in Empirical Field Studies of Organizational Routines</a>, Martha
        Feldman and Brian Pentland. This paper presents issues in observing,
        distinguishing, comparing, and counting organizational routines.&nbsp; </li>
      <li><a href="docs/networks.pdf">Organizations as Networks of Action</a>,
        Brian Pentland. This paper presents a 'network' representation for
        organizational routines that contrasts with conventional, linear
        time-step based representations.&nbsp; </li>
    </ul>
    <h3>Funding</h3>
    <p>The solicitation indicates that they intend to make two awards of $2M
    each.&nbsp; I propose either (1) a four year grant for $2M, resulting in each PI having
    a budget of $125K/year, or a 3 year grant for $2M, resulting in a budget of
    approximately $165K each per year. </p>
    <h3>Process</h3>
    <p>I spoke with Julia Lane at NSF, and it appears that the evaluation
    procedure will have two gates:</p>
    <ul>
      <li>May 30, 2005: Proposals are due at NSF.</li>
      <li>July, 2005: Finalists are invited to NSF in Washington to present
        their proposals. </li>
    </ul>
    <p>Funding would start in Fall of 2005. </p>
    <p>This leaves us with two months to write the proposal.&nbsp; I propose to
    act as editor for the proposal and coordinate its development. Here is one
    possible plan:</p>
    <ul>
      <li>April 20:&nbsp; Circulation of an initial proposal draft with
        'assignments' to co-authors.&nbsp;&nbsp; This first iteration would
        provide the general 'architecture' of the proposal with sections to be
        assigned to various individuals.&nbsp; Each person's material would be
        due by the end of April.</li>
      <li>May 1: Revisions to initial draft received by me.&nbsp; I incorporate
        them into proposal and perform editing pass for consistency. </li>
      <li>May 7:&nbsp; Circulation of second draft of the document.&nbsp;&nbsp; </li>
      <li>May 9-13: If needed, we might consider having a teleconference this
        week to go over the second draft and talk about what remains to be
        accomplished.&nbsp; (Note that Vic and I have a conference May 15-20, so
        it would be good to get the second draft reviewed prior by May 13). </li>
      <li>May 23:&nbsp; Revisions to second draft received by me. I will provide
        immediate turn-around of a third draft of the proposal that can be used
        as a placeholder version for use in initiating our individual
        institutional grant submission procedures. </li>
      <li>May 23-25:&nbsp; I am putting together the final version of the
        proposal; we are all doing institutional submission bureaucracy. </li>
      <li>May 25:&nbsp; Final version of proposal is available. </li>
    </ul>
    <h3>Notes on the solicitation</h3>
    <p>The remainder of this page contains some of my initial reactions to
    aspects of the solicitation.&nbsp;&nbsp;&nbsp; The italicized sections are
    quotes from the solicitation, and following each of these sections is my
    perspective on how we relate to the issue. </p>
    <p><i>On the one hand, social and behavioral scientists find new ways to
    create and analyze data in their endeavors to describe human and
    organizational behavior. On the other hand, computer and information
    scientists conduct research that yields new ways to improve both
    domain-specific and general-purpose tools to analyze and visualize
    scientific data..</i></p>
    <p>Our prior research fits well into this model of the disciplines.&nbsp;
    Martha and Brian have done substantial research on how to describe
    organizational behavior.&nbsp; Vic and I have done substantial research on
    how to collect and analyze scientific (i.e. software engineering) data. </p>
    <p><i>Proposed projects should combine elements of each of the following
    three areas, although consideration will be given to outstanding proposals
    that address one or two of the areas.</i></p>
    <p>We should address all three of the following areas, of course.</p>
    <p><i>(1) The development of tools that combine information on organizations
    from multiple media – both qualitative and quantitative.</i></p>
    <p>My work on Hackystat has provided me with practical experience in the
    development of a configurable framework for the collection of quantitative
    information from heterogeneous sources.&nbsp;&nbsp; I suggest we propose to
    extend Hackystat into the domain of qualitative data collection.&nbsp; The
    research by Martha and Brian provide guidance on what form that might take
    and some of the design issues that should be taken into account. </p>
    <p><i>(2) Basic research that addresses the protection of the
    confidentiality of individual and organizational data providers and survey
    respondents, and </i></p>
    <p><i>(3) The development of incentives, standards and policies for
    collecting, storing, accessing, and publishing research results using the
    data and information, as well as including appropriate protections of
    confidentiality and security.</i></p>
    <p>The White paper that Vic is organizing provides a perspective on what
    some of the important issues might be for these two areas.&nbsp; In the
    proposal, we can present some of these perspectives, and then propose a
    research program to generate new results with respect to confidentiality,
    incentives, standards, and policies. </p>
    <p>In speaking with Julia Lane, she indicated that they were interested in
    innovative approaches to the issue of confidentiality. This might mean
    approaches that provide different levels of confidentiality in different
    circumstances.&nbsp; In the domain of software engineering, we have already
    seen that the less you know about the context of the work, the harder it is
    to interpret its external validity. </p>
    <p><i>Testbed I. information collected on organizations from a variety of
    heterogeneous, independently developed data sources, such as administrative
    and survey data, temporal, spatial and image data or textual data. The goal
    is to free users from having to locate the data sources, interact with each
    data source in isolation, and manually combine data from multiple formats
    and multiple sources. This could be achieved through the creation of new and
    more accurate and efficient ways to collect, code and analyze qualitative
    information from case studies, and other sources, and to enable the linking
    of this information with repositories of quantitative data, while protecting
    fundamental privacy and confidentiality concerns. The research should be
    designed to show how appropriate cybertools can lead to multiple advances in
    the empirical understanding of how organizations emerge, develop, thrive or
    weaken.</i></p>
    <p>One part of our proposal should discuss the <u>design</u> of the testbed:
    how we are going to build off of the approach to quantitative information
    collection and analysis represented by Hackystat to support qualitative
    information as well.&nbsp; One issue that Brian and I have discussed is the
    need to support &quot;perspectives&quot; with respect to qualitative
    information (which is not necessarily required in the case of the more
    &quot;objective&quot; quantitative information that Hackystat currently
    collects.) There are many other interesting issues we need to address with
    respect to the design. </p>
    <p>Another part of our proposal should discuss the <u>implementation</u> of
    the testbed: how will the construction be managed?&nbsp; For this, I suggest
    something similar to the open source style of development already in place
    for Hackystat.&nbsp; I don't see us needing to spend too much time on this,
    other than to make clear that we recognize the need to do significant
    development and that we have the ability to do so. </p>
    <p>A third part of our proposal should discuss the <u>evaluation</u> of the
    testbed. I propose that we consider two case studies (or field work) as our
    evaluation mechanism.&nbsp; One case study can be in the area
    &quot;traditional&quot; to software engineering/computer science, and the
    other could be in the area &quot;traditional&quot; to the social/behavioral
    sciences. Brian and I have also discussed this issue, and one idea would be
    to do one case study in the domain of high performance computing, which
    leverages research and relationships that Vic and I have already developed
    as part of our participation in the <a href="http://www.highproductivity.org/">DARPA
    High Productivity Systems</a> program. The second case study would be in the
    area of accounting, which leverages research and relationships from Brian
    and Martha.&nbsp; </p>
    <p>The evaluation needs to be both technical and social in nature.&nbsp; We
    want to see if the infrastructure is gathering useful data from the
    perspective of both the organizations (i.e. does it help their decision
    making?) and from the perspective of the researchers (i.e. does it help us
    gain new knowledge about scientific questions?)&nbsp; We also want to see if
    our privacy policies can be put forth as standards, if we can define
    confidentiality mechanisms that still facilitate external use of the data,
    and so forth. </p>
    <h3>Since 12-April-2005 </h3>
    <p><i>Proposals must address the protection of data providers from
    identification, exploitation, and other misuses of personal or
    organizational information. Such misuses present a perpetual challenge to
    the melding of data and media of different types in a tool for widespread
    use. Proposals in response to this solicitation must show a sophisticated
    understanding of this sociotechnical problem and must propose to advance
    fundamental knowledge of effective privacy protections during the
    development of the analytical tools and in their later use by various
    research communities.</i> </p>
    <p>Current approaches to privacy for organizational research tends to be
    binary: the original researcher has total access; the public has anonymized
    access in which contextual (i.e. identifying) information is deleted.&nbsp;
    This poses a fundamental problem for non-original researchers who wish to
    leverage the datasets, as the contextual information can be critical for
    replication, meta-analysis, and so forth. </p>
    <p>Brian also commented in an email: I was also thinking about the privacy
    thing. One simple answer is to stay within the basic framework of informed
    consent, but do it better. So, for &quot;consent&quot;, establish levels of
    &quot;opting in&quot; that individuals can choose and modify. And for
    &quot;informed&quot;, it may be possible to keep track of (a) what has been
    collected about person x and (b) how that information has been
    accessed/used. So person x could be &quot;informed&quot; far better than a
    typical research subject, and could adjust his or her level of
    &quot;consent&quot; at any time. You'd have to keep track of a lot of stuff,
    but in principle, I think it's workable. I've got more notes on this, but no
    time to write it down at the moment. </p>
    <p><i>Proposals must demonstrate potential long-term sustainability,
    usability, and impact. This could be achieved for the organizational &quot;testbed&quot;,
    for example, by documenting proposed collaboration with firms in an
    industry, attracting support from foundations or developing replicable
    incentive-compatible policies for collecting, storing, accessing, and
    disseminating data while continuing to utilize and advance relevant
    cybertechnology.</i> </p>
    <p>We can collaborate with Sun Microsystems at a minimum, and that might
    serve as a good site for the software engineering case study.&nbsp; Another
    approach would be Marv's &quot;economics&quot; based model. </p>
    <p><i>Unifying Data Models and System Descriptions: There is a need to
    develop stronger theoretical foundations for the representation and
    integration of information of various types from extant data models (e.g.,
    temporal, spatial and image data, textual data, administrative and survey
    data) as well as the scientific literature into conceptually coherent views.</i> </p>
    <p>Our approach could be to unify quantitative and qualititative data using
    a combination of temporal mechanisms (i.e. hidden markov models) with
    non-temporal mechanisms (Network, N-dimensional representations). </p>
    <p><i>Reconciling heterogeneous formats schemas and ontologies: The
    fundamental problem in any data sharing application is that systems are
    heterogeneous in many different aspects, such as different ways of
    representing data and/or knowledge about the world, different representation
    mechanisms (e.g., relational databases, legacy systems, XML schemas,
    ontologies), different access methods and policies. In order to share data
    among heterogeneous sources, approaches to form a semantic mapping of their
    respective representations are needed to avoid manual intervention in each
    step of converting and merging data resources.</i> </p>
    <p>I see multiple ways we can try to address this. (1) Hackystat uses XML as
    backend representation, which facilitates data sharing.&nbsp; (2) We've
    recently designed and I am now in the process of implementing a declarative
    representation for schema evolution, based upon the problems we have
    observed over the past three years with Hackystat.&nbsp; (3) I propose that
    instead of thinking of a gimoungous centralized database, what we should
    propose instead is a federated set of databases that can provide information
    with various levels of privacy. </p>
    <p><i>Web semantics: Data on the web needs to be defined and linked in a way
    that it can be used by machines not just for display purposes, but also for
    automation, integration and reuse of data across various applications.
    Supported research topics will include frameworks for describing resources,
    methods of automating inferences about web data and resources, and the
    development of interoperable ontologies, mark up languages and
    representations for specific social, behavioral and other scientific
    domains.</i> </p>
    <p>The current way we think about this in Hackystat is that the set of
    available commands forms the 'semantics' of the system. (Each command can be
    invoked programmatically as well as manually). We could recast this as
    saying that each Hackystat configuration implements a &quot;domain specific
    language&quot; which constitutes its semantics.&nbsp; Once we expand the
    vision to federated networks of Hackystat servers, the question is how can
    two servers communicate/share information if they are different
    configurations with different domain specific languages?&nbsp; A generic
    approach to this problem is <a href="http://www.w3.org/2001/sw/">The
    Semantic Web</a>. We might propose a two phase approach: a first phase
    consists of creation of domain specific languages (i.e. configurations) for
    specific situations, and domain-specific privacy mechanisms. We do this for
    two very different domains (software engineering/high performance computing
    and accounting).&nbsp; The second phase is the generalize this using
    Semantic Web (for representation) and <a href="http://shibboleth.internet2.edu/">Shibboleth</a>
    (for access control). </p>
    <p><i>Decentralized data-sharing: Traditional data integration systems use a
    centralized mediation approach, in which a centralized mediator, employing a
    mediated schema, accepts user queries and reformulates them over the schemas
    of the different sources. However, mediated schemas are often hard to agree
    upon, construct and maintain. For example, researchers conducting social and
    behavioral research share their experimental results with each other, but
    may do it in an ad hoc fashion. A similar scenario is found in data sharing
    among government agencies. Architectures and protocols that enable
    large-scale sharing of data with no central control are needed.</i> </p>
    <p>The semantic web includes a resource discovery mechanism.&nbsp; Another
    way of decentralizing is the use of P2P, which is described by a reasonably
    good <a href="http://en.wikipedia.org/wiki/Peer-to-peer">Wikipedia entry on
    &quot;Peer-to-peer&quot;</a>. For privacy purposes, the approach that sounds
    best is &quot;Friend-to-friend&quot;. We can leverage technology like <a href="http://www.jxta.org/">JXTA</a>
    to get going quickly. </p>
    <p><i>Data-sharing on advanced cyberinfrastructure: Research topics will
    include models for federating information resources in advanced grid
    computing and/or Web services, integration and understanding of sensor
    information, the collection of metadata from sensors including models and
    tools to cope with the scale, pervasiveness, concurrency and redundancy of
    sensor data. Effective integration of network management information will be
    critical to enable basic networking functions such as routing, overlay node
    placement, denial-of-service detection, and fault recovery. The integration
    of network management information will facilitate adapting network resources
    to changing conditions.</i> </p>
    <p>I think it's too ambitious for us to get into things like custom
    approaches to denial-of-service attacks, routing, etc.&nbsp;&nbsp; I suggest
    we just note that these are issues that will occur with scalability and we
    will resort to whatever generic mechanisms are available (firewalls, etc.). </p>
    <p><i>On-the-fly integration: Currently, data integration systems rely on
    relatively static configurations with a set of long-lived data sources.
    On-the-fly integration refers to scenarios where one wants to integrate data
    from a source immediately after discovering it. The challenge is to
    significantly reduce the time and skill needed to integrate data sources so
    that scientists can focus on domain problems instead of information
    technology challenges.</i> </p>
    <p>This is something we can already address in two ways: (a) support
    evolution in data schemas, and (b) support dynamic creation of data schemas.
    Both of these are already available or nearly available in Hackystat.&nbsp;
    There are still usability issues that can be improved. </p>
    <p>&nbsp; </p>
    <p>&nbsp; </p>
    <p>&nbsp; </p>
    <p>&nbsp; </p>
    <p>&nbsp; </p>
    <p>&nbsp; </p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>
    <p>&nbsp;</p>


</font>
</body>
</html>
