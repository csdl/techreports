%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 05-01-intro.tex -- Priority Ranked Software Inspection
%% Author          : Aaron A. Kagawa
%% Created On      : Mon Sep 23 11:52:28 2004
%% Last Modified By: Aaron Kagawa
%% Last Modified On: Thu Apr 14 22:45:15 2005
%% RCS: $Id$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 2004 Aaron A. Kagawa
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Introduction}
Software inspection is defined as: ``A formal evaluation technique in which
software requirements, design, or code are examined in detail by a person
or group other than the author to detect faults, violations of development
standards, and other problems...'' \cite{Gilb93}. Software inspection, or
software review as it is sometimes called, can have fantastic results:
``Rigorous inspection can remove up to 90 percent of errors from a software
product before the fist test case is run'' \cite{Glass03, Bush90}.

Since Michael Fagan invented the inspection technique in 1976, there have
been many variations on the general concept of inspection. We now have
Fagan Inspection \cite{Fagan76}, Software Inspection \cite{Gilb93},
High-Impact Inspection [CITE], Phased Inspection [CITE], ``regular''
software inspection, software reviews, code walkthroughs, inspections
without meetings, and many more different twists on the original concept.
Each of these techniques claim to be the best inspection method for their
certain circumstances. For example, some argue that the inspection meeting
is a waste of time and resources \cite{Johnson97, Johnson98, Votta93}.
Others argue that the inspection meeting is critical for supporting social
and educational aspects of inspection \cite{Johnson98}.

My research is drastically different from traditional inspection research.
Instead of asking how to conduct the inspection process, I ask how to
determine what to inspect, when to conduct inspections, and more
importantly if inspection is really needed for a particular piece of code.
In this thesis, I describe how the selection of a document for inspection
can create a problem for organizations with limited inspection resources.
To solve this problem, I have invented a new inspection document selection
technique called Priority Ranked Inspection.

\section{The Problem of Limited Resources for Software Inspections}
The use of software inspection has reported outstanding results in
improving productivity and quality. One study has found that when the
inspection process is followed correctly, up to 95 percent of defects can
be removed before entering the testing phase \cite{Bush90}. In another
success story, the Jet Propulsion Laboratory (JPL) adopted inspection to
identify defects. After conducting 300 inspections they experienced a
savings of 7.5 million dollars \cite{Bush90a}. This statistic is very
impressive. However, what is not emphasized is each inspection had an
average total cost of 28 hours. Using that average cost, the total cost for
JPL's 300 inspections was 8,400 hours or roughly 4 years of work.

The study of JPL's inspection experience illustrates a fundamental problem
with inspections: better results come from substantial investment
\cite{Gilb93}. Not all organizations have the time or the money to invest
in full or complete inspections. In most cases, organizations have limited
funds, or resources, that can be devoted to inspections. For example, a
manager may only have 200 hours of a project schedule to allocate towards
quality assurance including inspections. Such organizations must decide how
to best utilize their limited inspection resources. This realistic
management of inspections directly contradicts the classical inspection
adage of ``when a document is ready, you should inspect it''. The bottom
line is that most organizations cannot inspect every document.

As an example, consider the following scenario:
\begin{quotation}
  \textit{An organization has enough resources available to conduct two
    inspections a week. However, this organization creates and finishes 10
    different documents each week. How do they select 2 documents to
    inspect from the possible 10? To be fair to all developers, they use a
    round-robin type approach by allowing a different developer to
    volunteer a document for inspection. This approach is fairly successful
    and at least they are conducting inspections. But, are they inspecting
    the right documents? Obviously, this organization is unavoidably
    letting 8 documents slip through the inspection-crack and could be
    releasing documents that have critical defects.}
\end{quotation}

The traditional inspection process begins with the initiation phase, or
sometimes called the planning stage, in which authors volunteer their
documents for inspection \cite {Gilb93}. A inspection leader checks the
document against entry criteria to determine if the document is ready for
inspection \cite{Ebenau94, Gilb93}. Again this process works very well for
organizations, like JPL, that have the resources to inspect every document
after every significant change. However, I believe that this phase of
inspection is a major problem for organizations that do not have the
necessary resources, because the process does not consider that some
documents are ``better'' to inspect than others. A simple illustration of
this fact is that 80 percent of defects come from 20 percent of the system
\cite{Boehm01}.  Thus, volunteering a document from the defect-prone 20
percent will likely be ``more in need of inspection'' than any other part
of the system.

Furthermore, the current literature \cite{Ebenau94, Wiegers02, Gilb93} on
inspections does not provide specific insights into the trade-offs between
inspecting some documents and not inspecting others.  However, Tom Gilb and
Dorothy Graham provide two recommendations to use when inspection resources
are limited; sampling and emphasizing up-stream documents \cite{Gilb93}.
The use of sampling involves inspecting various areas of a system to
identify areas of interest. Up-stream documents are documents that define
high-level requirements or designs.  Inspecting up-stream documents ensures
that the requirements are correct before any implementation is started.
Although, these are very useful recommendations, they do not provide much
specific guidance of how best to use limited inspection resources.




%%Inspections are supposed to be the silver bullet for software quality
%%insurance. Yet, its acceptance in the mainstream software development
%%community has been slow. 

%%Inspections are generally views as a ``gate'' that must be passed through
%%before software code is completed. 



\section{The Priority Ranked Inspection Approach}
To address some of the problems associated with conducting inspections with
limited resources, I propose a new inspection process called ``Priority
Ranked Inspection'', (PRI). The primary goal of PRI is to optimize the
selection of documents for inspection by distinguishing what documents are
``more in need of inspection'' (MINI) versus documents that are ``less in
need of inspection'' (LINI). In addition, PRI ranks each document according
to this determination in hopes of prioritizing the documents that need to
be inspected. The converse is also true: PRI identifies documents that
might not need to be inspected.

As I have shown in the previous section, it is extremely difficult for
organizations with limited inspection resources to inspect every document
before it exits the development process. Therefore, unlike traditional
inspection process, PRI does not require that all documents be inspected.
Instead, PRI is intended to help these organizations in two ways. First,
PRI is intended to identify documents in the current development process
that need to be inspected. This will allow organizations to make an
educated guess at what documents need to be inspected and what documents
can be skipped. Second, it is unavoidable that some documents with critical
defects will finish the development process without being inspected.
Therefore, PRI is also intended to identify documents for inspection
regardless if a document is currently in the development process or not.

%%In the same ways that Software Inspection \cite{Gilb93} is an inspection
%%process, Priority Ranked Inspection is also an inspection
%%process. However, the differences between the two inspection processes lie
%%in the recognition that not all organizations have the necessary resources 
%%to inspect everything. Therefore, PRI is tailored to the organizations with 
%%limited resources. 

There are four primary steps in the Priority Ranked Inspection (PRI)
process. The following list is short description of each of the steps. The
following sub-sections provide a summary description of each step.

\begin{enumerate}
\item The creation of the PRI ranking function, which distinguishes
  MINI documents from LINI documents. The ranking function design
  includes two steps: 
\begin{enumerate}
\item Selection of product and process measures to use in the PRI
  ranking function.
\item The calibration of indicators, which includes determining thresholds
  that provide the ranking of each indicator.
\end{enumerate}
\item The selection of a document for inspection based on the PRI
  ranking.
\item The actual inspection of the selected document.
\item Adjustment of product and process measure selection and calibration
  of PRI indicators based on the results of the inspection.
\end{enumerate}


\subsection{Step 1a: Selection of Product and Process Measures}
The PRI ranking function which distinguishes MINI documents from LINI
documents is generated automatically from various product and process
measures. Product measures are usually obtainable from direct analysis of
source code.  For example, lines of code, complexity, and number of
children are a few examples of product measures. On the other hand, process
measures are collected from the actual software development process. The
amount of developer 'effort' and the number of defects are examples of
process measures. One might ask, what specific measures should PRI
consider? The answer: it depends on the specific situation. Different
projects and organizations could have a different set of measures in
defining the optimum PRI ranking function. Therefore, a major component of
the PRI process is the selection of the measures.

Software quality measures are one example of the type of product and
process measures that could be used in PRI. Software inspection has two
primary goals; increase quality and productivity. For this research I am
primarily concerned with increasing quality. The successful inspection of a
document has two main results: finding defects which, once removed,
increases software quality or not finding defects thus indicating high
software quality. Software quality is vaguely defined as ``the degree to
which software possesses a desired combination of attributes''
\cite{IEEEGlossary83}. Some of the possible measures of quality include:
portability, reliability, efficiency, usability, testability,
understandability, and modifiability \cite{Glass03}. Some other widely
accepted measures of quality include defect density and complexity.
Whatever definition used for quality, inspections aim to increase or
validate the level of quality in software.  Therefore, the same measures of
software quality also provide good indications of what documents need
inspection. For example, finding documents that have low portability,
reliability, efficiency, usability, testability, understandability, and
modifiability would provide a good indication that the documents are MINI.

Based on the previous example, the quality-specific product and process
measures can be extracted and used in the PRI ranking function. Table
\ref{table:step1a} is an example of the PRI ranking of a software project
that contains three documents.  Presented in the table are the measures and
values that are used in the PRI ranking. Due to constraints of the paper
size, the table presents only a couple of the measures discussed above.
However, any number of measures can be used in the PRI ranking function.

\begin{table}[htbp]
  \caption{Step 1a - Example PRI ranking - After Measure Selection}
  \label{table:step1a}
  \begin{center}
    \begin{tabular}{|l|l|l|l|l|l|l|} \hline
      {\bf Document} & {\bf PRI Ranking} & {\bf Reliability} & 
      {\bf Efficiency} & {\bf Testability} & {\bf ...} \\ \hline
Foo.java & MINI & 3 & 4 & 2 & ...  \\ \hline
Bar.java & LINI & 4 & 2 & 6 & ...  \\ \hline
Baz.java & LINI & 1 & 2 & 3 & ...  \\ \hline
    \end{tabular}
  \end{center}
\end{table}

Table \ref{table:step1a} is an illustration of a fictitious PRI ranking.
See Chapter \ref{chapter:system}: Implementing PRI with the Hackystat
system for more details about the exact calculations necessary to create a
PRI ranking function.


\subsection{Step 1b: Calibration of Indicators}
Only selecting what measures to be used in the PRI ranking function is
not adequate, because some measures are more important than others. For
example, an organization may find that testability has a greater positive
impact on the PRI ranking function than efficiency. Therefore, Step 1b of
the PRI process is the calibration of the measures' importance. The
calibration of the measures is based on a numerical weighting system. Each
measure will be assigned a numerical weight and will be individually
calibrated. The numerical weighting system and the calibration creates a
PRI ranking, which provides a priority ranking of the documents.

Using the same example (Table \ref{table:step1a}) from the previous
section, imagine that the organization has found testability to be a
leading indicator in defect prevention. Therefore, the calibration is
adjusted and the values of testability are given a higher weight than the
other measures. This finding changes the PRI ranking function and
ranking. The following table (Table \ref{table:step1b}) shows the new PRI
ranking after the calibration.

\label{table:step1b_trial}
\begin{table}[htbp]
  \caption{Step 1b - Example PRI ranking - After Measure Calibration}
  \label{table:step1b}
  \begin{center}
    \begin{tabular}{|l|l|l|l|l|l|l|} \hline
      {\bf Document} & {\bf PRI Ranking} & {\bf Reliability} & 
      {\bf Efficiency} & {\bf Testability} & {\bf ...} \\ \hline
Bar.java & MINI & 4 & 2 & 6 & ...  \\ \hline
Foo.java & MINI & 3 & 4 & 2 & ...  \\ \hline
Baz.java & LINI & 1 & 2 & 3 & ...  \\ \hline
    \end{tabular}
  \end{center}
\end{table}

Notice that, as a result of the calibration, the PRI ranking for Bar.java
has changed from LINI to MINI. This illustrates that the PRI ranking
function can be flexible and that it has the potential to reflect
different development processes within different organizations.


\subsection{Step 2: Selecting a Document for Inspection Based on the PRI
  Ranking} After the PRI ranking function is in place, an organization may
use PRI to select documents for inspection. To select a document for
inspection they simply consult the PRI ranking and find a MINI document (a
document deemed more in need of inspection). This ranking will help
constrain the number of possible documents that can be considered for
inspection.

For example, in the example presented in Table \ref{table:step1b}, an
organization should select Bar.java for the inspection, because it ranked
the highest of the three documents. During the next inspection meeting,
Foo.java should be inspected. However, Baz.java could be skipped, thus
saving inspection resources.

Using the PRI ranking to select documents for inspection has three primary
benefits. First, it can enhance the selection, or the volunteering process,
of a document for inspection. Second, it can identify documents for
inspection that a volunteering process typically does not. Third,
inspecting a MINI document will generate more critical defects than
inspecting a LINI document.


\subsection{Step 3: Conducting an Inspection of the Selected Document}
Once the document is selected, a traditional inspection process can begin.
PRI does not have any special processes for this step. An organization can
choose to use any traditional inspection process (i.e., Software
Inspection, Fagan Inspection, In-Process Inspection). In other words, the
PRI process is an outer layer that wraps around an already established
inspection process to enhance the selection of documents.  Therefore, in
this research I will not discuss or evaluate traditional inspection
concepts like; inspection leaders, preparation time, etc.


\subsection{Step 4: Adjustment of the Measure Selection and Calibration}
After the inspection of a document, the results can be used to further
improve the PRI ranking function. For example, if the PRI
ranking function appears to be incorrect, because it ranked a document as
MINI but no major defects were found, then the PRI ranking function should
be adjusted to classify this document as LINI. This adjustment can be
achieved in two ways. First, one could add more product and process
measures to make the PRI ranking function more robust. Alternatively, one
could calibrate the current indicators to refine and correct the PRI
ranking function. In either case, an incorrect PRI ranking function
provides data to help make future PRI ranking functions better. This
process should be an ongoing evolving activity.

For example, consider the example presented with Foo.java, Bar.java, and
Baz.java. If an organization has found results that suggest that efficiency
is a leading indicator of defects, then it should be calibrated with a
higher weight.



\section{Implementing PRI with Hackystat}
To successfully use PRI, the determination of MINI and LINI must be
obtainable for a very low cost. In other words, if the ranking function
takes three months to generate, a software project will have long past the
need for those specific recommendations. Therefore, this determination must
be obtained in real-time.

One way of obtaining ranking function values in real-time is through the
use of the Hackystat system \cite{Johnson05}. Therefore, I have decided to
use the Hackystat system to implement and evaluate the PRI process in this
research.  Hackystat is a framework for collecting and analyzing software
product and development process metrics in real-time. For more information
about the Hackystat system see Chapter \ref{chapter:hackystat}. For this
research, I have created an extension to the Hackystat system called the
Hackystat PRI Extension (hackyPRI for short). hackyPRI provides a real-time
PRI ranking.  Figure \ref{fig:intro-WorkspacePRIAnalysis} demonstrates the
PRI ranking function for a software project that is obtainable from the
Hackystat PRI Extension.

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=1.00\textwidth]{figs/2004-12-01-all_Page_01.eps}
  \caption[The Workspace PRI analysis]{Workspaces are listed with its
  respective PRI ranking and measures.}
  \label{fig:intro-WorkspacePRIAnalysis}
\end{figure*}

The Hackystat PRI Extension is implemented to fully support all 4 steps of
the PRI process (See Chapter \ref{chapter:system}). It is important to
note that PRI is a proposed \textit{process}, therefore many different
tools can support it.  Using the Hackystat PRI Extension is not required to
conduct PRI inspections.

[ADD MORE HERE; Provide examples of the implemented PRI measures and PRI
indicators]



\section{Thesis Statement}
The thesis statement of this research is as follows; Priority Ranked
Inspection can distinguish documents that are more in need of inspection
(MINI) from others that need inspection less (LINI). This thesis statement
can be decomposed into the following three main claims, which are based on
the intended benefits of PRI.

\begin{enumerate}
\item PRI can enhance the volunteer-based document selection process.
\item PRI can identify documents that need to be inspected that are not
  typically identified by volunteering.
\item Documents that are deemed more in need of inspection (MINI) will
  generate more critical defects than documents deemed less in need of
  inspection (LINI).
\end{enumerate}

\subsection{Thesis Claim 1}
My first claim states that PRI can enhance the selection process. In the
traditional inspection process, the selection process is based on a
developer selecting and volunteering a document for inspection. In most
cases, developers select documents to volunteer to remove any critical
defects before it is released. However, the current literature does not
provide much guidance on which documents should be volunteered.

This claim is an intended benefit of PRI, because in the traditional
inspection process the number of documents that a developer must select
from can vary widely. If PRI can provide the MINI documents, then the
developer can focus his selection on a smaller set of documents.
Therefore, PRI enhances the volunteering process by providing suggestions
on what should be inspected. PRI can do this in two ways. First, it can
minimize the number of documents that should be considered for inspection.
Second, it provides a priority ranking of what documents would be most
beneficial to inspect.

\subsubsection{Minimize the Number of Possible Documents}
PRI can minimize the number of documents that should be considered for
inspection. In Software Inspection \cite{Gilb93}, the number of possible
inspection includes \textit{all} the documents currently moving through the
development cycle.  (This technique tends to emphasize only current
documents and not the highest priority documents for inspection. Claim 2
addresses this issue.)  In PRI, the number of possible documents is
minimized to MINI documents. This reduces the number of possible
inspections and can be advantageous for organizations that cannot inspect
every document, because it will eliminate the need and more importantly it
limits the possibility of inspecting LINI documents.

As an example of how PRI benefits an organization with limited resources
consider the following fictitious scenario:

\begin{quotation}
  \textit{ An organization has enough resources available to conduct
    inspections at least once a week. Because this organization produces
    more code than is possible to inspect, they use a round-robin approach
    by allowing a different developer to volunteer a piece of code to
    inspect. This developer must pick a small portion of the code he/she is
    currently working on and this decision is primarily based solely on
    his/her subjective opinions of the code.  }
\end{quotation}

This method works well if the developer can be trusted to pick the right
code to inspect. However, developers often do not know where every critical
defect will appear. In other words, leaving this decision up to the
subjective understanding of a developer maybe error prone. PRI provides an
alternative solution to this limited resource problem.  Instead of leaving
the decision of what code to inspect entirely up to the developer, PRI can
minimize the number of possibilities by providing a smaller area of
selection. For this fictional organization, the developer can find the MINI
documents and choose code from this smaller list.

\subsubsection{Priority Ranking of Documents}
PRI provides a priority ranking of what documents would be most beneficial
to inspect. This advantage supports the volunteering process by allowing
the developer to prioritize his/her selection of documents. The previous
discussion showed how PRI can minimize the number of documents; and now
that the number is reduced the developer still must select from this
smaller number. To support this selection, PRI ranks the documents
according to the calibration and numerical ranking. For example consider
this scenario:

\begin{quotation}
  \textit{ A developer is currently working on 10 different documents and
    he wants to volunteer one of them for inspection. He has a rough idea
    of what documents he thinks would be most beneficial for inspection but
    he isn't sure. He consults the PRI ranking and finds that 6 of his
    documents appear to be LINI. In addition, he is able to use the
    rankings to select a MINI document that he believes would generate the
    most critical defects.}
\end{quotation}

This scenario illustrates how PRI can enhance the volunteering process by
first minimizing the number of documents that should be considered for
inspection and then prioritizing them.

\subsection{Thesis Claim 2}
My second claim states that PRI can identify documents that have slipped
through the cracks in the development process. For an organization with
limited inspection resources it is not possible to inspect every document.
Therefore, it is inevitable that some documents that require inspection
have not been.

Another intended benefit of PRI is it can find MIN documents that are not
typically identified using a volunteer-based document selection process.
If organizations with limited inspection resources blindly volunteer
documents for inspection they could be missing some areas of the system
that need inspection. A real example of this benefit is illustrated in the
following scenario:

\begin{quotation}
  \textit{ Not all Hackystat packages have experts. Instead, there are some
    packages that I consider to be orphans. Orphaned-packages are usually
    packages that are considerably old code or code that has been written
    by developers who have left CSDL. In addition, these packages are
    usually never inspected and are considered to be in working order.  }
\end{quotation}

This situation is quite dangerous, because as we all know a software system
evolves and outdated packages may become error prone. Therefore, it is
important to realize that old packages can also be MINI. Software
Inspection \cite{Gilb93} does not address this issue of outdated documents.
The common adage of Software Inspection is to inspect documents as they
move through the development cycle. This process tends to ignore documents
that have already finished the development cycle. In addition, because
organizations with limited resources can not inspect every document moving
through the development cycle, it is very likely that some documents will
finish the development cycle with major defects.  Therefore, ensuring that
``finished'' documents are included as potential inspection candidates is
very important.

\subsection{Thesis Claim 3}
My third and last claim states that the inspection of MINI documents will
generate more critical defects than LINI documents. This claim is very
important to the PRI process because if this claim is proven to be false,
then the PRI process cannot solve the limited inspection resource problem.

The last benefit of PRI is MINI documents will generate more critical
defects than LINI documents. This claim is critically important for PRI's
success. However, if a package is identified as LINI and yields many
critical defects, then PRI ranking function is flawed. I will use this
information to refine the PRI ranking function. It is my hope that in the
end of the study I will have been able to successfully calibrate the PRI
ranking function for the Hackystat project.



\section{Evaluation}
This section provides a short description of the methodologies used to
evaluate my thesis claims. Chapter \ref{chapter:evaluation}, Evaluation
Methodology provides a detailed explanation of the methodologies and
procedures that were used in the evaluation of PRI.

I have evaluated the main thesis of this proposed research by testing each
of my three claims. In this evaluation, I will be studying the inspection
process of the Hackystat system developed by the Collaborative Software
Development Laboratory. I will also be using the developers of Hackystat as
subjects in my evaluation.

[NEED TO CHANGE]
My first claim states that PRI enhances the volunteer-based document
selection process. To evaluate this claim, I will conduct a qualitative and
quantitative evaluation.  First, I will assess the developers' current
selection process by asking them to rank a few documents based on what
documents they think are more in need of inspection. Then I will provide
them with the PRI ranking of those same documents and ask them which
rankings would they change. After this qualitative evaluation, I will ask
CSDL to inspect a few documents to evaluate the validity of the developers'
subjective ranking and the PRI ranking.

[NEED TO CHANGE]
My second claim states that PRI can identify MINI documents that are not
typically identified by the volunteering process. To evaluate this claim, I
will ask CSDL to inspect a few documents that have not been identified in
the previous evaluation.

[NEED TO CHANGE]
My third and last claim states that the inspection of MINI documents will
generate more critical defects than LINI documents. Throughout the
previous two studies I have collected information about approximately
20 inspections. By quantitatively analyzing the results of these
inspections I will be able to provide supporting evidence for this claim.

\section{Results}
[ADD MORE HERE WHEN RESULTS CHAPTER IS DONE]


\section{Structure of the Proposal}
The remainder of this proposed research is as follows. Chapter
\ref{chapter:relatedwork} discusses previous studies that influenced this
research. Chapter \ref{chapter:hackystat} and Chapter \ref{chapter:system}
contains a detailed description of the Hackystat system and the Priority
Ranked Inspection (PRI) Hackystat extension. Chapter
\ref{chapter:evaluation} discusses the evaluation methodology that has been
implemented to evaluate the claims and benefits of PRI. Chapter
\ref{chapter:results} discusses the results of my evaluation of PRI and
hackPRI. Finally, Chapter \ref{chapter:contribution} discusses the
contributions and future directions of this research.














% LocalWords:  Kagawa Sep










