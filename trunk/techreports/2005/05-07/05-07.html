<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>
  <head>
    <title>Telemetry Plate Lunch Contest Results</title>
  </head>
<body text="#330066">
<font face="verdana">

    <h1 align="center">Telemetry Plate Lunch Contest Results</h1>
    <p align="center"><a href="http://csdl.ics.hawaii.edu/~johnson/">Philip
    Johnson</a><br>
    <a href="http://csdl.ics.hawaii.edu/">Collaborative Software Development
    Laboratory</a><br>
    <a href="http://www.hawaii.edu/">University of Hawaii&nbsp;</a></p>


    <p align="center">Last Update: <!--webbot bot="Timestamp" startspan
    S-Type="EDITED" S-Format="%m/%d/%Y %I:%M %p" -->06/29/2005 11:05 AM<!--webbot
    bot="Timestamp" i-CheckSum="26144" endspan -->
    </p>


    <h3>Introduction</h3>


    <p>In June of 2005, Cedric and Hongbing implemented dual axis telemetry,
    which inspired me to organize a &quot;Telemetry Plate Lunch Contest&quot;
    and send out the following email:</p>

    <p>Greetings, hackers,</p>
    <p>Cedric sent me email indicating that dual axis telemetry is now available
    on the public server, and within five minutes I obtained this absolutely
    stunning example of co-varying sensor data:</p>
    <p><img border="0" src="05-07.1.jpg" width="910" height="1014"></p>
    <p>Some particularly cool things to note:</p>
    <p>- I used Expert Mode, but the definitions are very straightforward. Six
    lines of code! (well, to be honest, the 'draw' command which is clipped in
    the figure makes seven.)</p>
    <p>- The chart layout is just about perfect. Note how the axis colors align
    with the telemetry stream colors.</p>
    <p>- The best part of all is the data! We're displaying real live data:
    build failures vs. code churn for the hackystat project over about a four
    month period. These are completely different sensor data types, but look how
    amazingly well they co-vary with each other.</p>
    <p>Kudos to Hongbing for the JFreeChart/hackyReport hacking, and to Cedric
    for the telemetry language improvements.</p>
    <p><b>TELEMETRY PLATE LUNCH CONTEST</b></p>
    <p>Now that we've got this new facility, I'm curious to see what you guys
    can come up with. So, for the next week only, I'll buy a plate lunch for
    every hackystat hacker who can generate a similarly interesting multi-axis
    telemetry chart! (Note that 'interesting' could mean data that co-varies
    together, such as this chart, or data that goes in opposite directions. And
    you're not just limited to two axes or data streams!)</p>
    <p>To enter, please use 'real' data such as that available on the public
    server, though it can be any project. Send me a pointer to a .jpg file
    illustrating your results.</p>
    <p>I will send out email with the contest results late next week once all
    the submissions are in.</p>
    <p>(Hackystat hackers not in Hawaii can still enter: I'll send you some
    macadamia nut cookies or something :-)</p>
    <p>Cheers, Philip</p>
    <h3>Winner #1: Hongbing Kou</h3>
    <p>Hi, Hackers,</p>
    <p><b>Entry #1: Production Active Time vs Unit Test Failures (Zorro)&nbsp;</b></p>
    <p><img border="0" src="05-07.2.jpg" width="1266" height="1006"></p>
    <p>It's a telemetry chart that compares production code active time and unit
    test failures. Zorro has high code coverage. I believe most of my work are
    either Test-First or Test-Last.</p>
    <p><b>Entry #2: Production Active Time vs Unit Test Failures
    (hacky2004-all)&nbsp;</b></p>
    <p><img border="0" src="05-07.3.jpg" width="1266" height="1006"></p>
    <p>Note that scale of unit test count axis is different from entry #1. In
    most days active time on production code is above unit test failure counts.
    I think it tells us that we either did not have enough tests or that we were
    good at passing unit tests.</p>
    <p>Below is my telemetry definition. Hope you will find it of interest to
    your project.</p>
    <p>streams ProductionActiveTimeStream() = {&quot;Production Active
    Time&quot;, &quot;Production Hours&quot;, ActiveTime(&quot;**/*.java&quot;)
    - ActiveTime(&quot;**/Test*.java&quot;)};</p>
    <p>streams TestActiveTimeStream() = {&quot;Test Active Time&quot;,
    &quot;Test Hours&quot;, ActiveTime(&quot;**/Test*.java&quot;)};</p>
    <p>streams UnitTestStream() = {&quot;Unit Test&quot;, &quot;Unit Test
    Counts&quot;, UnitTest(&quot;TotalCount&quot;)-UnitTest(&quot;SuccessCount&quot;)};</p>
    <p>chart PilotChart() = {&quot;Production Active Time v.s. Unit Test Failure
    Counts&quot;, ProductionActiveTimeStream(), UnitTestStream()};</p>
    <p>chart PilotChart2() = {&quot;Test Active Time v.s. Unit Test Failure
    Counts&quot;, TestActiveTimeStream(), UnitTestStream()};</p>
    <p>report PilotReport() = {&quot;Active Time vs Unit Test&quot;, PilotChart(),
    PilotChart3()};</p>
    <p>draw PilotChart();</p>
    <p>Cheers, Hongbing</p>
    <h3>Winner #2: Aaron Kagawa</h3>
    <p><i>(Editor's note: Aaron's entry obeyed the spirit if not the letter of
    the contest rules, so he wins!)</i></p>
    <p>I've spent a little while looking at Philip's telemetry example. And I'm
    not totally convinced that the BuildFailureStream is defined
    &quot;correctly&quot; in order to obtain meaningful information in terms of
    build failures and improving build failure rates.</p>
    <p>After looking at Philip's telemetry chart, I quickly noticed that we had
    138 build failures in the week of March 13. Wow! Now, I know Cedric said
    that we had only 88 nightly build failures during 2004. So, why the heck is
    one weeks build failures so high? The answer is that the Stream defined in
    Philip's example is from all developers including the nightly build.</p>
    <p>I changed the BuildFailureStream to only look at nightly builds on
    HackyDev and now chart looks like the following, with almost _no_
    co-variance.&nbsp;</p>
    <p><img border="0" src="05-07.4.jpg" width="1284" height="998"></p>
    <p>Based on this result, it seems that Code Churn has little effect on
    whether the nightly build will fail. One would think that the nightly builds
    are more meaningful in terms of our overall process, because developers
    could be doing TDD, have small little compile errors, minor junit problems,
    and other things that are just part of their personal development process;
    which will all hopefully be worked out before they commit the code.</p>
    <p>I'm not saying that Philip's example is bogus. It its totally OK.
    Philip's Chart shows that the developers have more build failures when more
    code is checked in and vice versa. But, what does that mean? Using the total
    build count, instead of the total build failure count, shows another good
    co-variance:</p>
    <p><img border="0" src="05-07.5.jpg" width="1284" height="998">And&nbsp;</p>
    <p>I bet, if you only look the total build success count you'll also see a
    good fit. So, all build results co-vary with code churn.... again, what does
    that mean?</p>
    <p>After studying the data used in Philip's telemetry chart, I would have to
    say, &quot;yeah that makes sense, no surprise there&quot;. I say that
    because the two trends are somewhat directly related in our development
    process. For example, a week with a lot of churn probably means that the
    developers were working a lot. Which in our development process would
    require building and testing (ie ant quickStart, ant junitAll, etc) the
    system a lot. And it seems that there is some consistency in the number of
    build failures and successes in our personal development. So, I would think
    in our development process, Code Churn and Build (Failure, Success, and
    total Builds) should co-vary. If it doesn't then that could indicate that we
    aren't following our development process well.</p>
    <p>I think the moral of the story is that we should be careful about
    claiming co-variance without saying whether it is expected or not expected.
    Or whether its a good thing or a bad thing. Its one thing to say that two
    trends co-vary that are usually dependent on one-another; for example
    increasing active time and increasing lines of code. Its another thing to
    say two trends co-vary that do not have a direct connection; for example
    increasing complexity and decreasing coverage. In the first example (active
    time and lines of code), it could be the case that co-variance is expected
    and a large variance between the two trends would indicate something bad. In
    the second example (complexity and coverage), co-variance might not be
    expected and variance might be something good.</p>
    <p>------------------------</p>
    <p>Various other telemetry related comments that popped into my head while
    doing this:</p>
    <p>1) Other things that could be interesting is threshold limits; things
    that only co-vary when a certain threshold is reached. What is the mean code
    churn for the past 8 months? What is the mean build failure count for the
    past 8 months?</p>
    <p>2) Could it be possible to exclude a developers data from a telemetry
    stream? With some sort of NOT, &quot;!&quot;, language construct.</p>
    <p>For example, when analyzing build failures for Cedric's research it seems
    that it might be best to exclude new Hackystat developers from a certain
    portion of his evaluation. Or exclude experience Hackystat developers from
    other portions of his evaluation. In other words, if Cedric introduces a new
    Feedback mechanism that tailored towards education of Hackystat's
    development process then it might be more beneficial to look at the new
    developers' data instead of every ones.</p>
    <p>Another example, looking at the build failures from developers only,
    excluding the hackystat-l user.</p>
    <p>2) cvsUpdateAll is considered to be a build event. I'm not sure why that
    is. At least for me, I can have up to 5 cvsUpdateAll's a day when I'm
    hacking, which could throw off the failure percentage because cvsUpdateAlls
    never really fail. Not to mention, cvsUpdateAll's aren't really building
    anything.</p>
    <p>3) I noticed that the Unit Test Coverage telemetry report on HackyDev
    &lt;http://hackystat.org/hackyDevSite/telemetry/DailyCoverage.0.png&gt;
    appears to indicate that we are at 100% coverage:</p>
    <p><img border="0" src="05-07.6.jpg" width="800" height="505"></p>
    <p>Which is obviously not correct, but how can that be? Are we using the
    wrong project for coverage data?</p>
    <p>4) zero data points shouldn't be plotted &lt;http://hackystat.org/hackyDevSite/telemetry/DailyIntegrationBuild.0.png&gt;,
    &lt;http://hackystat.org/hackyDevSite/telemetry/DailyOpenIssues.0.png&gt;..
    Well, it is hard to determine whether between the sensor not running and the
    value actually equaling zero.</p>
    <p>5) Is aggregate active time useful in telemetry? It is only going to
    increase. Similarly, the total number of issues only increases. What does
    that mean?</p>
    <p>6) It would be very useful to have alerts that tell you when telemetry
    trends stop co-varying and when they start to. I don't think this would take
    a lot of computing power.. and it seems that it is quite labor intensive (it
    is taking a plate lunch and a week) for us to look for interesting trends.
    For example, an alert that processes and compares all streams for a standard
    duration to determine if the latest data point is within an acceptable range
    based on previous ranges.</p>
    <p>7) what ever happened to the telemetry wall? I think the telemetry wall
    could be a little more &quot;general&quot; to provide an overall concept of
    the project. NASA's control center doesn't just have telemetry screens....
    Think Project Status wall instead of just telemetry.. It can show (1) the
    Daily Project Details information, (2) recent source code from the system
    (or the highest priority MINI document!!!!!!! haha!!!), (3) a commit log,
    (4) how many hits Hackystat had yesterday, (5) the remaining Jira Issues for
    the upcoming release, (6) christoph's visual project graph, (7) a satisfied
    or failed CGQM goal, (8) a successful SDSA classification, and finally (9)
    then a bunch of interesting multi-axis telemetry charts.</p>
    <p>thanks, aaron</p>
    <h3>Winner #3: Mike Paulding</h3>
    <p>Hi Philip,</p>
    <p>Below is a link to my entry for the &quot;Telemetry Plate Lunch
    Contest&quot;:</p>
    <p><img border="0" src="05-07.7.jpg" width="788" height="840"></p>
    <p>This chart indicates the introduction and progress of parallelism within
    a HPC project. Specifically, it shows when parallel files/constructs first
    made an appearance in the project and quantifies how the parallel files grew
    over time, measured in SLOC.</p>
    <p>It also compares the total SLOC within the HPC project against the
    parallel SLOC, so the observer is provided a visual ratio of the
    parallel/sequential composition of the project.</p>
    <p>It can be generated with data on the public server from the Truss
    problem.</p>
    <p>Thanks and best regards, Mike</p>
    <h3>Winner #4: Cedric Zhang</h3>
    <p><b>Hackystat Local System Build Time</b></p>
    <p>The local build of Hackystat modules is interesting. The build time is
    not short enough so that it's ignorable. The build time is not long enough
    so that the developer can take a coffee break or engage other parallel
    activities. Under most cases, the developer cannot make use of the idle time
    but waiting for the build result. One minute taken by the local build is one
    minute wasted on the developer's part.</p>
    <p>The following telemetry charts are used to study local system build time
    by individual developers.</p>
    <p>streams MyActiveTime(member) = { &quot;d&quot;, &quot;hours&quot;,
    MemberActiveTime(&quot;**&quot;, &quot;false&quot;, member) };&nbsp;</p>
    <p>streams MyBuildTime(member) = { &quot;d&quot;, &quot;hours&quot;,
    Build(&quot;BuildTime&quot;, &quot;false&quot;, member) };&nbsp;</p>
    <p>streams MyFailedBuildTime(member) = { &quot;d&quot;, &quot;hours&quot;,
    Build(&quot;BuildTime&quot;, &quot;false&quot;, member) -
    Build(&quot;SuccessTime&quot;, &quot;false&quot;, member) };&nbsp;</p>
    <p>chart MyChart(member) = { &quot;chart&quot;, MyActiveTime(member),
    MyBuildTime(member), MyFailedBuildTime(member) };&nbsp;</p>
    <p>draw MyChart(&quot;???@hawaii.edu&quot;);</p>
    <p>Some developers only spend 0.25 - 0.5 hours daily waiting for local
    system build results. But other developers spend considerable more time.
    &quot;Lofi&quot; spends around 1 hours; &quot;Kagawaa&quot; seems addicted
    to building system locally. If these developers can change their development
    habits, they can have more time enjoying life.</p>
    <p><img border="0" src="05-07.8.jpg" width="3000" height="505"></p>
    <p><img border="0" src="05-07.9.jpg" width="3000" height="505"></p>
    <p><img border="0" src="05-07.10.jpg" width="3000" height="505"></p>
    <p><img border="0" src="05-07.11.jpg" width="3000" height="505"></p>
    <p><img border="0" src="05-07.12.jpg" width="3000" height="505"></p>
    <p><img border="0" src="05-07.13.jpg" width="3000" height="505"></p>
    <h3>Disqualified Entry: Philip Johnson</h3>
    <p>My own entry was disqualified, since employees of the Telemetry Plate
    Lunch Contest organization are prohibited from participating. :-)&nbsp;
    However, the contest did inspire me to take another look at Unit Test
    Dynamics, with what I think are some interesting results:</p>
    <p>&lt;<a href="http://csdl.ics.hawaii.edu/~johnson/UnitTestDynamics.ppt">http://csdl.ics.hawaii.edu/~johnson/UnitTestDynamics.ppt</a>&gt;</p>
    <p>I'll show a couple of charts to give you the idea.&nbsp; For details on
    UTD and the telemetry definitions used to get these charts, please check out
    the powerpoint.&nbsp; </p>
    <p>The following chart shows that in HackyKernel, coverage has been
    decreasing while the percentage of test code has been increasing! This
    cannot be a good thing!</p>
    <p><img border="0" src="05-07.14.jpg" width="1156" height="427"></p>
    <p>The following chart shows that in HackyZorro, at the beginning of the
    module's life when Hongbing was doing TDD, coverage, test code, and test
    time was all very high.&nbsp; When he stopped doing TDD, everything
    plummeted!&nbsp; Also probably not good!</p>
    <p><img border="0" src="05-07.15.jpg" width="1156" height="427"></p>
    <p>&nbsp;</p>
    <h3>Conclusions and Questions</h3>
    <p>First, I have to say that I'm very pleased with the results.&nbsp; The
    entries show that this technology is allowing people to begin to think more
    deeply about the meaning, implications, and inter-relationships of the
    metrics they generate.&nbsp;&nbsp;&nbsp; </p>

    <p>Here are some thoughts on the submissions: </p>

    <p>Production Active Time vs. Unit Test Failures (Zorro).&nbsp; This chart
    is interesting because from 16-March to 02-April, the two measures co-vary
    'in phase', while after that the two measures co-vary 'out of phase'. I
    wonder if this 'inversion' in the relationship has to do with the switch
    from test-first to test-last design? </p>

    <p>Although I agree with Aaron that, in retrospect, the fact that code churn
    correlates with total build attempts/failures seems
    &quot;obvious&quot;.&nbsp; But, that doesn't make it uninteresting or not
    useful. For example, does the correlation hold up when looked at for
    individual developers?&nbsp; If it doesn't, does that indicate that some
    developers are not building when they should?&nbsp; </p>

    <p>Other comments by Aaron are also interesting.&nbsp; The fact that
    cvsUpdates are counted as &quot;build events&quot; may or may not be bad,
    but at least indicate that we may want to investigate streams that filter
    out some of the build events.&nbsp; We definitely need to fix the daily
    telemetry chart that shows 100% coverage. </p>

    <p>Mike's entry appears to use 'cumulative' data. After looking at that, I
    am worried that 'cumulative' data might be very susceptible to distortion
    when using multiple axes such that things appear to co-vary when they in
    fact do not. The reason is that the axes are drawn so that the scale
    includes just the lowest and highest value.&nbsp; Well, with cumulative
    data, the lowest value is generally on the left and the highest value is
    generally on the right.&nbsp; If those to points are fixed at about the same
    point, then it's likely the middle part of the trend lines will appear to
    co-vary.&nbsp; So, that's something we need to watch out for: we shouldn't
    use cumulative data if we can avoid it. </p>

    <p>Cedric's entry shows that we need a way to show project-specific build
    timing data. I think that might need to wait until evolutionary sensor data
    types are implemented.&nbsp; In any case, investigating local build time is
    a really neat idea.&nbsp; It's not at all clear to me that low local build
    times are better than high local build times. What we need to do is relate
    this data to other trends, such as integration build failures, experience
    level of developers, and so forth. </p>

    <p>All in all, lots of interesting food for thought.&nbsp; Please send any
    further comments you might have to me. </p>

    <p>&nbsp; </p>

    <p>&nbsp; </p>

    <p>&nbsp; </p>

    <p>&nbsp; </p>

    <p>&nbsp; </p>

    <p>&nbsp; </p>

      </font>
<p>&nbsp;</p>
<p>&nbsp;</p>
</body>
</html>
