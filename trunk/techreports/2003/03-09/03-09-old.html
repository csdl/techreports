<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta name="GENERATOR" content="Microsoft FrontPage 4.0">
<meta name="ProgId" content="FrontPage.Editor.Document">
<title>Eclipse Innovation Grant 2004</title>
</head>

<body>

<h2 align="center"><b>EclipseView: Improving Open Source Software Development&nbsp;<br>
 through Agile,
Autonomous Software Review&nbsp;</b></h2>
<p align="center">Philip Johnson<br>
Collaborative Software Development Laboratory<br>
Department of Information and Computer Sciences<br>
University of Hawaii<br>
<a href="mailto:johnson@hawaii.edu">johnson@hawaii.edu
</a></p>
<p align="center">CSDL-03-09</p>
<p align="center"><a href="http://csdl.ics.hawaii.edu/techreports/03-09/03-09.html">http://csdl.ics.hawaii.edu/techreports/03-09/03-09.html</a></p>
<p align="center"><b>Last update: <!--webbot bot="Timestamp" S-Type="EDITED"
S-Format="%m/%d/%Y %I:%M:%S %p" startspan -->10/31/2003 11:00:35 AM<!--webbot bot="Timestamp" i-CheckSum="29031" endspan -->
&nbsp;</b></p>
<p align="center">A proposal to the <a href="http://www-3.ibm.com/software/info/university/products/eclipse/eig.html">Eclipse
Innovation Grant Program</a></p>
<p align="center">&nbsp;</p>
<h3 align="left"><b>Background and Objectives</b></h3>

Collaborative review of software designs and code has been shown repeatedly to be an efficient and effective approach to defect removal and quality
assurance. Beginning with the ground-breaking work of Michael Fagan on Software Inspection at IBM in the
1970's, a diverse body of knowledge has
been accumulated regarding the different review procedures and their
properties.  The majority of review techniques share the following
characteristics. First, a review leader invites a group of technical
personnel to participate in a review, and arranges for them to receive the
artifacts to be reviewed.  The review participants then meet face-to-face
to discuss the review artifact along with its author.  Finally, the author uses the information gathered from the review
meeting to improve
the quality of the artifacts. Perhaps the most rigorous application of
software review occurs in the Cleanroom method, in which software review is
made so effective that it replaces unit testing. Review also provides other
collateral benefits outside of defect removal: it disperses knowledge about the product to
team members; helps junior developers to learn techniques and best practices
from more senior developers, and provides management with information regarding
the state of product development.&nbsp;&nbsp;<p>
Agile methods, such as Extreme Programming, take a different path to
achieving the benefits of software review. Instead of alternating periods
of development with periods of review, XP blends review into the
development activity itself through the practice of pair programming.  The
approach yields a kind of "continuous" review of the software as it is
developed.&nbsp; Like more conventional review techniques, the pair programming
approach to review also disperses product knowledge and development techniques
across the group, but without the process overhead involved in organizing and
carrying out the review.&nbsp; Pair programming also tends to result in thorough
review, in the sense that it essentially guarantees that all code
is reviewed at the time it is written as well as during any enhancement
activities. <p>Unfortunately, open source software development projects find it
difficult to adopt either traditional software review mechanisms or pair
programming.&nbsp; There are two principal obstacles. First, the geographically
distributed nature of an open source development team makes it problematic for
such developers to meet and work face-to-face on a regular basis. This prevents
the use of pair programming, as well as face-to-face review meetings.&nbsp;
Second, open source development tends to have a decentralized management
structure:&nbsp; developers tend to work on the areas of the system that interest
them, and management-level resources and interest in organizing and sustaining
software review processes are rare.&nbsp; The result is not only the possibility
of reduced quality, but also reduction in the collateral benefits: skill and product
knowledge transfer, and improved insight into the state of product development.
While open source development is particularly problematic, similar barriers to
effective use of review or pair programming can occur in any geographically
distributed software development context, both in industry and even in
educational settings.&nbsp;&nbsp;<p>To
address these problems, we propose to implement and evaluate an &quot;agile,
autonomous&quot; approach to software review called EclipseView. The primary
technical objective of the EclipseView project is to move the responsibilities
for management aspects of software review--deciding who to invite, what to review,
how to review, and when to review--from a human team member and place them
instead into the software development infrastructure.&nbsp; In order to make
these review management decisions effectively, EclipseView includes the use of
Hackystat (http://hackystat.ics.hawaii.edu/), a client-server system that supports unobtrusive,
in-process collection and analysis of
fine-grained software process and product data by adding &quot;sensors&quot; to
development tools such as Eclipse and Ant.&nbsp; Such data includes the
time spent by each developer working on each file in a project, size metrics
associated with Java files and how they change over time, JUnit invocations and
results, and the coverage associated with the test suite. Achieving the primary
technical objective creates a mechanism to achieve our primary social objective:
improving the coordination, efficiency, and cohesiveness of open source
development communities and the quality of the software they
develop.&nbsp;&nbsp;&nbsp;<p>A central component of EclipseView is a rule-based Review
Manager that uses process and product data to determine: (a) when to initiate an
online, asynchronous software review; (b)&nbsp; which files in the system should
be included in the review; and (c) which developers to invite to participate in
the review; and (d) what the developers should focus on accomplishing during the
review.&nbsp; &nbsp;Once the Review Manager determines that a review is
necessary, it emails the chosen set of developers with an invitation to
participate in the review and instructions on how to participate (or
decline).&nbsp; Participating developers perform the review using an
Eclipse plug-in for software review under development in our lab. Finally, data
concerning the
review process and outcome data are collected and can be used by the Review Manager
in addition to the Hackystat process and product data to help guide future review
management decisions.&nbsp;<p>EclipseView can generate
interesting feedback loops in development. As a simple example, assume that the
rules are set up so that Java packages whose test cases fail more frequently
after initially succeeding and/or whose coverage is low are scheduled for
review.&nbsp; As developers work, hackystat sensors collect process and product
data.&nbsp; Eventually, a package is identified for review, developers focus
their attention on it, and suggestions for design, implementation, and testing
improvements result. The review results in new effort by the author on this
package, raising its quality, which lowers the frequency of test case failure
and raises its coverage.&nbsp;&nbsp; As a result, the Review Manager will no
longer give this package a high ranking as a candidate for review, and the focus
of review effort will shift to a different area of the system.&nbsp;<p>EclipseView
is
&quot;agile&quot; because it is lightweight and does not impose a particular
development methodology or even review technique on a development team. In
keeping with the agile manifesto, it values and promotes individual
interactions, and responsiveness to change during development. It is
&quot;autonomous&quot; because project developers, after initial configuration
of the Review Manager, no longer need to manage review; it becomes a feature of
the development environment.&nbsp;&nbsp;<p>The EclipseView project builds upon
and integrates together two streams of research: automated software review and
automated software metrics collection and analysis.&nbsp;&nbsp; For almost ten
years, the Collaborative Software Development Laboratory (http://csdl.ics.hawaii.edu/)
has investigated tools and techniques for software review.&nbsp; CSRS, a system
based upon C++ and Emacs, provides a declarative high level language for
defining software review processes as well as instrumented facilities for
gathering and analyzing review data.&nbsp; A second research initiative resulted
in the JavaJam system, which was built as an extension to JavaDoc and allowed
annotation of both Java designs and code.&nbsp; Finally, we have implemented an
Eclipse plug-in that provides asynchronous review to any group of developers
using the Eclipse platform. Our plug-in allows developers to both generate
issues (that are saved in XML format in a &quot;review&quot; project folder), as
well as view and react to issues posted by other developers in the project.<p>A
second stream of research involves automated software metrics collection and
analysis. Our first research project, LEAP, provided tool support for collection
and analysis of measurement data similar to that specified in the Personal
Software Process. However, we found that the PSP is quite
&quot;heavyweight&quot; and that the context-switching between work and
collecting-data-about-work, even with tool support, created substantial barriers
to adoption.&nbsp; To address these issues while preserving the benefits of
measurement, we began work in 2001 on Hackystat, a framework for unobtrusive
metrics collection and analysis. To use Hackystat, developers download and
install &quot;sensors&quot; in development tools such as editors, testing tools,
configuration management systems, and so forth. These sensors collect data and
send it via Soap and XML to a server, which analyzes the data to provide
insights back to developers to support improvements in their work products and
processes. The Hackystat architecture is modular, and we currently build and
maintain separate configurations to support: (1) classroom use, (2) the Mission
Data System development group at Jet Propulsion Lab,&nbsp; and (3) a
constructive cost modeling research project involving COCOMO.&nbsp; The insights
we have gained into product and process data representation and analysis through
these efforts form a basis for EclipseView.&nbsp;<p>Our prior research and
development efforts make us well positioned to achieve the objectives of the
EclipseView research project. The next section provides a high-level overview of
the methods we will use.
<h3>
Methodology and Milestones</h3>
<p>To pursue our technical and social objectives, we will leverage the open
source and agile software development practices and technologies (http://hackydev.ics.hawaii.edu/)
we use in the Hackystat project, and augment them with a combination of
industrial and classroom case studies.&nbsp;</p>
<p>Our first milestone will be the initial public release of the Eclipse plug-in
for software review. This plug-in provides support for review that is tightly
integrated with the Eclipse platform. We will gather feedback from the Eclipse
community regarding the plug-in and use it to enhance its usability.</p>
<p>Our second milestone will be the initial public release of the EclipseView
system, including the Review Manager and an initial set of rules. Rules are
specified as condition-action pairs, when satisfying the condition triggers an
action for consideration by the Review Manager.&nbsp; A substantial set of rules
are already under consideration. For example, to decide the set of files to
review, rules can trigger based upon the files for which defects have been
reported, files that have been edited since the time of their last review, or
files exceeding a certain size or complexity measure.&nbsp; To decide when a
review should be scheduled, rules can trigger based upon: when there are
sufficient developers available for review; when a file is no longer appears to
be under active modification; or when a threshold level of defects have been
posted against a file or package. To decide who should be involved in a review,
rules can trigger based upon the set of developers actively contributing to the
project; developers who have edited these files in the past, developers with
experience with the APIs used (i.e. for Java, that means the imported packages);
developers with experience with specialized language constructs used (i.e. for
Java, that means constructs such as &quot;synchronized&quot;). To decide how the
review should be conducted, rules can orient the review toward searching for
specific defect types (i.e. for Java, files with synchronized keywords indicate
that concurrency errors should be checked); toward spending a delimited period
of time on review (such as no more than one hour); or until a specific date and
time have been reached.&nbsp;</p>
<p>Our third milestone will be classroom use and evaluation of the EclipseView
system as part of a unit on software review in our graduate and undergraduate
software engineering courses at the University of Hawaii.&nbsp; Laurie Williams,
at North Carolina State University, has also expressed interest in evaluating
EclipseView for possible use in teaching software review in her courses.&nbsp;
We will gather qualitative and quantitative data regarding the effectiveness of
the Review Manager in managing the review process, and the resulting impact on
the quality of the systems reviewed. The results will help us improve the set of
review rules and the way they are employed by the Review Manager. It will also
generate a new teaching tool for software review using Eclipse.</p>
<p>Our fourth milestone will be the trial use of the system within the Eclipse
development community.&nbsp; As a large, geographically distributed, open source
community, the Eclipse developer base forms an ideal community in which to
evaluate and refine the EclipseView system.&nbsp; We plan to solicit trial usage
of the system by a small number of Eclipse projects, and use their feedback to
further improve the review management process.&nbsp; Our goal is to
incrementally improve the functionality and usability of the system through such
feedback until it becomes an important and valuable tool in the development of
open source software.&nbsp;</p>
<h3>
Personnel and Collaborators</h3>
<p>This project will be managed by Philip Johnson, Professor of Information and
Computer Sciences at the University of Hawaii. Two graduate students will also
be involved in this project. Laurie Williams at North Carolina State University
is a potential collaborator on assessing the use of EclipseView for teaching
software review.&nbsp;</p>
<h3>
Current and Requested Funding&nbsp;</h3>
<p>
We request $30,000 for this project. There is no current funding for the
EclipseView project. Support for the Hackystat project is provided in part by a
grant from the National Science Foundation.
<h3>
Long term impact to the information/computing industry and Eclipse</h3>
<p>The long term of impact of EclipseView on the IT industry can potentially
occur on two levels. At the basic level, EclipseView provides a way to improve
the efficiency and effectiveness of open source software development, by
providing a mechanism for software review that is compatible with the contextual
constraints of open source development. The improvements to open source software
include not only the direct benefits of review---defect removal--but also the
collateral benefits: improved skill and product
knowledge transfer, and improved insight into the state of product development.&nbsp;
At a meta-level, EclipseView presents an approach to &quot;smart&quot; software
development environments that automatically acquire data about the process and
products of development, and use that data to reduce certain types of overhead
on developers.&nbsp; If successful, our approach will produce software
infrastructure and techniques that can be adapted to other aspects of
development outside review.</p>
<p>The long term impact of EclipseView on the Eclipse community can also
potentially occur on two levels. At the basic level, EclipseView provides yet
another reason for Eclipse to be the preferred IDE for developers.&nbsp; Only
with Eclipse will the full benefits of the EclipseView environment be
realized.&nbsp;&nbsp; In addition, our evaluation of EclipseView in a classroom
setting will yield curriculum materials to support teaching of software review
using Eclipse.&nbsp; At a meta-level, EclipseView will generate new requirements
on the design of Eclipse and on the analysis tools available within it, as
developers begin designing rules that require increasingly sophisticated data
regarding development.&nbsp;</p>
<h3>
Planned use for cash

</h3>
<p>Research assistantships for the two graduate students at $15,000 per year
each. </p>
<p>&nbsp;</p>

</body>

</html>
