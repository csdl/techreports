\section{Apriori algorithm}
We have seen a broad application of the Apriori algorithm while reviewing temporal patterns for symbolic time-points and time-interval series. AprioriAll algorithm was proposed in 1995 by Agrawal \& Srikant in \cite{citeulike:775528} and is based on the naive approach of Apriori association rule stating that \textit{any sub-pattern of a frequent pattern must be frequent}. In the published work, authors has shown application of the algorithm to the mining of sequential patterns from a database of purchase transactions mining recurrent behavior patterns. 

The pattern support function used by authors in their algorithm implementation is defined as the fraction of the customers supporting such a pattern. By using this definition the problem can be stated formally: given a database of customer transactions, the problem is to find the set of maximal sequences among all others that have at least user-specified support.

Naive apriori algorithm starts by building maximal sequences through finding all ``candidate'' patterns of size 1 with support greater or equal to the minimal support value. On the next step algorithm generates successive set of candidate patterns by extending each of the candidate patterns by 1 and testing it against the database for sufficient support. Algorithms iterates over this second step until it terminates when no further extension is possible yielding a set of maximal sequences. While being extremely simple and producing a correct solution, naive approach is extremely inefficient due to the high time cost of the scanning process which is the product of a time needed for a single pass over the database and the number of generated candidates.

\begin{table}
\begin{center}
    \begin{tabular}{ | c | c | c |}
    \hline
    Large 3-sequences & Candidate 4-sequences                     & Candidate 4-sequences \\ 
                      & after join                                & after pruning \\ 
    \hline
    $\left\{ 1, 2, 3 \right\} $ & $ \left\{ 1, 2, 3, 4 \right\} $ & $ \left\{ 1, 2, 3, 4 \right\} $ \\ 
    \hline
    $\left\{ 1, 2, 4 \right\} $ & $ \left\{ 1, 2, 4, 3 \right\} $ & \\ 
    \hline
    $\left\{ 1, 3, 4 \right\} $ & $ \left\{ 1, 3, 4, 5 \right\} $ & \\ 
    \hline
    $\left\{ 1, 3, 5 \right\} $ & $ \left\{ 1, 3, 5, 4 \right\} $ & \\ 
    \hline
    $\left\{ 2, 3, 4 \right\} $  &                                & \\ 
    \hline
    \end{tabular}
    \caption{Illustration of 4-sequences candidate generation from large 3sequences and pruning of the generated 4-sequences set.}
    \label{fig:apriori}
    \end{center}
\end{table}

The significant improvement of the naive approach was a main contribution of Agrawal \& Srikant. First of all, they designed a clever generative function which excludes non-existing sequences of length $n+1$ just by looking on the existing set on sequences of length $n$ without sacnning. This generative function leverages the efficiency of an in-memory hash-tree and a breadth-first search. Further improvement of the naive algorithm made by authors is that a database of transactions is getting transformed on the each iterative step. During the transformation each of the individual transactions within single sequence is replaced by the ``set of all litemsets contained
in that transaction. If a transaction does not contain any litemset, it is not retained in the transformed sequence.'' The ``litemset'' here refers to the itemset with a minimum support.

AprioriAll by Agrawal \& Srikant was the very first algorithm for sequential pattern mining built upon the Apriori principle. While being far more efficient than a naive implementation, it still requires many passes over the database while testing candidate sequences. Many other algorithms based on this implementation were proposed. In 1996 Srikant \& Agrawal extended their original work with GSP (Generalized Sequential Pattern) algorithm. GSP allows time constraints and relaxes the definition of transaction, additional improvement was added by considering the knowledge of taxonomies which improves pruning by excluding non-interesting sequences. Wang et al in 2001 proposed a GSP based MFS (Mining Frequent Sequences) \cite{citeulike:5164952} algorithm based on the concept of \textit{pre-large sequences} which further reduces the amonut of rescanning.