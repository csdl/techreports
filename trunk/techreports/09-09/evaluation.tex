\chapter{Experimental evaluation} \label{experiments}
I propose to conduct three case studies: a pilot study, a classroom case study, and a public data case study in order to empirically evaluate the capabilities and performance of Software Trajectory framework. The main difference among these experiments lies in the structure of the data used and in the approaches for evaluation. 

My intent behind this studies is to assess the ability of the Trajectory to recognize well known recurrent behavioral patterns (for example Test Driven Development), as well as its ability to discover useful software processes. In addition, these studies will support a classification and extension of the current Hackystat sensor family in order to improve Trajectory's performance. It is quite possible that some of the currently collected sensor data will be excluded from the Trajectory Analysis datasets, while some new ones will be designed and developed in order to capture important features from the studied software development data streams.

The exploratory, evaluative pilot study consists of a set of a small research experiments run on small, custom datasets, and is ongoing with a primary goal to help in the architectural design and development of Trajectory framework. As the secondary goal, these experiments are helping to outline the boundaries of applicability of my approach to certain problems. Section \ref{pilot.evaluation} discusses some of the insights yielded by the pilot study.

The public data case study is based on the use of publicly available Software Configuration Management (SCM) audit trails of the big ongoing software projects such as Eclipse, GNOME etc. Mining of the SCM repositories is a well-developed area of research with much work published \cite{citeulike:5043676}. SCM repositories contain coarse software product artifacts which usually mined with a purpose of discovering various characteristics enlightening software evolution and software process. I am using a mixed approach in this study. In the first phase of this study, I plan to perform SCM audit trail data mining using Trajectory as a tool and following published work as a roadmap in order to discover confirmed patterns in software process artifacts, and thus quantitatively evaluate Trajectory's performance when compared to existing tools. In the second phase, I will develop my own pre-processing and taxonomy mapping of software process artifacts into temporal symbolic series. By using this mapping and Trajectory, I plan to develop a new approach for SCM audit trail mining and possibly discover new evolutionary behaviors within software process. These discovered knowledge will be evaluated through the peer-reviewed publication submitted for the annual MSR challenge \cite{citeulike:5043676}.

The classroom case study is based on the most sophisticated data set. This data will be collected by the Hackystat from Continuous Integration and from individual developers and will contain a fine-grain information about performed software process. The approach I am taking in this study is very similar to the public data case study. I will develop my own taxonomy for mapping of software process artifacts into symbolic temporal data and will apply Trajectory analyses to the low-level software process artifacts in order to discover recurrent behaviors. In turn, these discovered knowledge will be evaluated through surveys for usfulness and meaningfulness. Results of surveys will be augmented in the Software Trajectory system and will constitute part of my thesis and publication.

As mentioned, both case studies: public data case study, and classroom case study will involve empirical evaluation. The necessity for this is dictated by the exploratory nature of my research. 

At this point of my research, I can only see that the properties of my approach and it's current implementation in the Software Trajectory framework appear to be very promising. The wealth of developed techniques for temporal symbolic data mining and recent development of the SAX approximation allow to overcome many computational limitations in existing approaches for mining of software process artifacts. Current state of the art implementation of Hackystat provides ability to capture fine-grain software product and process metrics providing previously not-existing richness of data, which, potentially, might reveal new insights. Up to date research in software process discovery indicates the overall feasibility of proposed goals in the discovery of unknown recurrent behaviors in software process. 

Nevertheless, at this early stage of my research, it is impossible to foresee if this new recurrent behaviors will be discovered or assess their meaningfulness or usefulness for real world application. It is possible that this part of research will fail, and I will not be able to discover any novel meaningful knowledge about software process. If so, I will apply every effort to investigate and explain pitfalls of my approach to the software process data mining. Whether it will happen due to the specificity of domain, or due to the insufficiency of the information enclosed in the collected artifacts, or maybe because of inefficiency of augmented methods, through the thorough analyses of failed experiments and collection of the feedback, I will outline boundaries of approach taken in this work and possible future development.
