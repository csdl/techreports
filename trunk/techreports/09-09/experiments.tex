\section{Planned evaluation in the classroom}
Aiming a discovery of novel recurrent behavioral patterns in the software process, I am planning to conduct a classroom case study. The approach I am taking is based on the daily re-indexing and mining of the software process data collected by Hackystat from the classroom software project development during the Fall'09 and Spring'10 Software Engineering classes and following interaction with students. 

After collecting a certain amount of data I expect to see some recurrent patterns gaining enough support to be considered as ``candidate patterns''. The function I am considering as support will be a product of two metrics: one is based on the support function from AprioriAll algorithm and quantifies the fraction of the developers demonstrating the same pattern, and the second one is based on the total frequency of pattern appearance. The pool of these candidate patterns will be built and reviewed on the daily basis. While reviewing candidate patterns I am planning to fulfill two goals: first is to identify truly useful and interesting patterns, and second is to enhance a knowledge base of the data-mining algorithm limiting the amount of reported unmeaningful or trivial patterns. The ability to capture patterns and communicate with students in real-time will be extremely helpful in this process providing mechanism for validation of my own guesses.


\section{Planned evaluation using public data}
In addition to the classroom experiments, I am planning to validate my research through the use of publicly available repositories. This validation is aiming to assess the ability of my approach to reproduce already published results indicating correctness and similar to other tools performance. If I will be able to find some novel patterns within this data, it will prove the contribution of my research.

As the main source of the data for the validation, I am planning to use public SCM repositories whose mining is traditionally used in the ``MSR Challenges'' \cite{citeulike:5043676} and published in proceedings of ``IEEE International Conference on Mining Software Repositories''. Following this popular approach I will try to apply my framework to SCM repository artifacts aiming reproducing some of the published results and ultimately participating in the challenge aiming two categories: the process analysis, and change impact. Secondly, there are various public data hosted by the ``PROMISE software engineering repository'' \cite{Sayyad:2005} which contains two kinds of the data: the software product datasets used for the building of the predictive software models. And some ``universal'' data sets representing SACM repository transaction. Most of this datasets were used for a number of publications and I am planning to evaluate my framework reproducing these results. 