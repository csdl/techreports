@article{citeulike:11020197,
    abstract = {Software applications developed within the {OSS} community have enjoyed tremendous success and forprofit organizations are keen to tap into this significant pool of software development talent. These companies seek to benefit from the talent of a global and sometimes voluntary workforce by paying some employees to contribute to {OSS} projects. This merging of open and traditional software development may cause developer stress based on conflicting {OSS} community and traditional software development norms. Specifically, developers must balance company intellectual property concerns with the reciprocal and community-based norms that drive {OSS} development. When these values are not in sync, contributors that aim to abide by conflicting values may exhibit dysfunctional attitudes. Employee stress with respect to their role can be destructive to organizational outcomes. This study develops an {OSS} context specific model that describes the relationship between clashing software development cultures and employee organizational commitment. We leverage the rich {OSS} literature and the research that focuses on organizational-professional conflict ({OPC}) to develop hypotheses linking clashing cultures and organizational commitment. These hypotheses are tested using a combination of archival data and a survey of 127 {GNOME} developers. The findings presented in this paper contribute to {OSS} literature and},
    author = {Daniel, Sherae and Maruping, Likeobe and Cataldo, Marcelo and Herbsleb, James D.},
    citeulike-article-id = {11020197},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.206.3894},
    posted-at = {2012-08-06 04:52:20},
    priority = {2},
    title = {When Cultures Clash: Participation in Open Source Communities and Its Implications For Organizational Commitment},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.206.3894},
    year = {2011}
}

@article{citeulike:712058,
    abstract = {Between June 1985 and January 1987, the Therac-25 medical electron accelerator was involved in six massive radiation overdoses. As a result, several people died and others were seriously injured. A detailed investigation of the factors involved in the software-related overdoses and attempts by users, manufacturers, and government agencies to deal with the accidents is presented. The authors demonstrate the complex nature of accidents and the need to investigate all aspects of system development and operation in order to prevent future accidents. The authors also present some lessons learned in terms of system engineering, software engineering, and government regulation of safety-critical systems containing software components.>},
    address = {Los Alamitos, CA, USA},
    author = {Leveson, N. G. and Turner, C. S.},
    citeulike-article-id = {712058},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=161477.161479},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/MC.1993.274940},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/MC.1993.274940},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=274940},
    doi = {10.1109/MC.1993.274940},
    institution = {Dept. of Comput. Sci. \& Eng., Washington Univ., Seattle, WA},
    issn = {0018-9162},
    journal = {Computer},
    month = jul,
    number = {7},
    pages = {18--41},
    posted-at = {2012-08-05 07:28:03},
    priority = {2},
    publisher = {IEEE},
    title = {An investigation of the Therac-25 accidents},
    url = {http://dx.doi.org/10.1109/MC.1993.274940},
    volume = {26},
    year = {1993}
}

@inproceedings{citeulike:693466,
    abstract = {George Santayana's statement, "Those who cannot remember the past are condemned to repeat it," is only half true. The past also includes successful histories. If you haven't been made aware of them, you're often condemned not to repeat their {successes.In} a rapidly expanding field such as software engineering, this happens a lot. Extensive studies of many software projects such as the Standish Reports offer convincing evidence that many projects fail to repeat past {successes.This} paper tries to identify at least some of the major past software experiences that were well worth repeating, and some that were not. It also tries to identify underlying phenomena influencing the evolution of software engineering practices that have at least helped the author appreciate how our field has gotten to where it has been and where it {is.A} counterpart Santayana-like statement about the past and future might say, "In an era of rapid change, those who repeat the past are condemned to a bleak future." (Think about the dinosaurs, and think carefully about software engineering maturity models that emphasize {repeatability.)This} paper also tries to identify some of the major sources of change that will affect software engineering practices in the next couple of decades, and identifies some strategies for assessing and adapting to these sources of change. It also makes some first steps towards distinguishing relatively timeless software engineering principles that are risky not to repeat, and conditions of change under which aging practices will become increasingly risky to repeat.},
    address = {New York, NY, USA},
    author = {Boehm, Barry},
    booktitle = {Proceedings of the 28th international conference on Software engineering},
    citeulike-article-id = {693466},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1134285.1134288},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1134285.1134288},
    doi = {10.1145/1134285.1134288},
    isbn = {1-59593-375-1},
    keywords = {thesis-phd},
    location = {Shanghai, China},
    pages = {12--29},
    posted-at = {2011-11-22 14:38:50},
    priority = {2},
    publisher = {ACM},
    series = {ICSE '06},
    title = {A view of 20th and 21st century software engineering},
    url = {http://dx.doi.org/10.1145/1134285.1134288},
    year = {2006}
}

@article{citeulike:3716342,
    abstract = {To mark {IEEE} Software's 25th anniversary, Software Technology column editor Christof Ebert presents a review and road map of major software technologies, starting with the magazine's inauguration, 1984. Learning from the many hypes and often long introduction cycles, he provides some timeless principles of technology evaluation and introduction.},
    author = {Ebert, Christof},
    booktitle = {Software, IEEE},
    citeulike-article-id = {3716342},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1477273},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/MS.2008.141},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4670707},
    doi = {10.1109/MS.2008.141},
    journal = {Software, IEEE},
    keywords = {thesis-phd},
    number = {6},
    pages = {22--25},
    posted-at = {2011-11-22 14:37:07},
    priority = {2},
    title = {A Brief History of Software Technology},
    url = {http://dx.doi.org/10.1109/MS.2008.141},
    volume = {25},
    year = {2008}
}

@book{naur1976software,
  title={Software engineering: concepts and techniques : proceedings of the NATO conferences},
  author={Naur, P. and Randell, B. and Buxton, J.N. and NATO Science Committee},
  lccn={75044008},
  url={http://books.google.com/books?id=HSYuAAAAIAAJ},
  year={1976},
  publisher={Petrocelli/Charter}
}

@article{citeulike:7679414,
    abstract = {We discuss the  software crisis' as a social and cultural phenomenon, arguing that it can be viewed as (one more) manifestation of postmodernism. We illustrate our argument with a range of examples taken from software engineering, demonstrating software engineering's roots in (and commitment to) modernism and the nature of its fin de siecle predicament. We argue that current attempts within software engineering to respond to the software crisis have not been adequate and that a new, more humble, approach to software development is required. 10.1093/comjnl/41.6.363},
    author = {Robinson, H. and Hall, P. and Hovenden, F. and Rachel, J.},
    citeulike-article-id = {7679414},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/comjnl/41.6.363},
    citeulike-linkout-1 = {http://comjnl.oxfordjournals.org/content/41/6/363.abstract},
    citeulike-linkout-2 = {http://comjnl.oxfordjournals.org/content/41/6/363.full.pdf},
    citeulike-linkout-3 = {http://comjnl.oxfordjournals.org/cgi/content/abstract/41/6/363},
    day = {01},
    doi = {10.1093/comjnl/41.6.363},
    issn = {1460-2067},
    journal = {The Computer Journal},
    keywords = {thesis-phd},
    month = jan,
    number = {6},
    pages = {363--375},
    posted-at = {2011-11-22 14:31:00},
    priority = {2},
    publisher = {Oxford University Press},
    title = {Postmodern Software Development},
    url = {http://dx.doi.org/10.1093/comjnl/41.6.363},
    volume = {41},
    year = {1998}
}

@book{citeulike:10055914,
    citeulike-article-id = {10055914},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/026269087X},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/026269087X},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/026269087X},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/026269087X},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/026269087X/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/026269087X},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/026269087X},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN026269087X},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=026269087X\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/026269087X},
    howpublished = {Paperback},
    isbn = {026269087X},
    keywords = {thesis-phd},
    posted-at = {2011-11-22 09:16:21},
    priority = {2},
    publisher = {MIT Press (MA)},
    title = {Models of Bounded Rationality, Volume 2: Behavioral Economics and Business Organization (v. 2)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/026269087X}
}

@article{citeulike:6708618,
    abstract = {Based on an invited address, "Behaving Like a Manager," as part of the All Academy {Centennial/Anniversary} Symposium of the national, annual meeting of the Academy of Management, this paper by Simon addresses the popular topic of the "rational" and "non-rational" components in the behavior of effective managers. Previous discussion of this topic has been hampered by the lack of a precise characterization of the nonrational components--specifically a characterization of the mechanisms of managerial judgment and intuition. Simon provides a description of intuitive and judgmental processes and a sketch of the evidence that is available to support this description. Further, his paper shows how intuition and judgment rest on extensive experience and knowledge; how, in fact, they can be understood in terms of the recognition of cues and the consequent evocation from memory of relevant experiences. In a final section of the paper, Simon discusses some of the pathologies commonly encountered in managerial behavior, both those produced by emotions and stress and those arising from the lack of appropriate habits--that is to say, of appropriate intuitive responses. This diagnosis leads Simon to some rather specific conclusions about the kinds of intuitions that need to be cultivated and habituated in organizations, and some of the ways in which they can be developed.},
    author = {Simon, Herbert A.},
    citeulike-article-id = {6708618},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/4164720},
    citeulike-linkout-1 = {http://www.jstor.org/stable/4164720},
    doi = {10.2307/4164720},
    issn = {08963789},
    journal = {The Academy of Management Executive (1987-1989)},
    keywords = {thesis-phd},
    number = {1},
    pages = {57--64},
    posted-at = {2011-11-22 08:39:37},
    priority = {2},
    publisher = {Academy of Management},
    title = {Making Management Decisions: The Role of Intuition and Emotion},
    url = {http://dx.doi.org/10.2307/4164720},
    volume = {1},
    year = {1987}
}

@book{citeulike:1414171,
    abstract = {Most of Barnard's career was spent in executive practice. A Mount Hermon and
Harvard education, cut off short of the bachelor's degree, was followed by
nearly forty years in the American Telephone \& Telegraph Company. His career
began in the Statistical Department, took him to technical expertness in the
economics of rates and administrative experience in the management of
commercial operations, and culminated in the presidency of the New Jersey Bell
Telephone Company. He was not directly involved in the Western Electric
experiments conducted chiefly at the Hawthorne plant in Cicero, but his
association with Elton Mayo and the latter's colleagues at the Harvard
Business School had an important bearing on his most original ideas.

Barnard's executive experience at {AT}\&T was paralleled and followed by a career
in public service unusual in his own time and hardly routine today. He was at
various times president of the United Services Organization (the {USO} of World
War {II}), head of the General Education Board and later president of the
Rockefeller Foundation (after Raymond Fosdick and before Dean Rusk), chairman
of the National Science Foundation, an assistant to the Secretary of the
Treasury, a consultant to the American representative in the United Nations
Atomic Energy Committee, to name only some of his public interests. He was a
director of a number of companies, a fellow of the American Association for
the Advancement of Science and of the American Academy of Arts and Sciences.
He was a lover of music and a founder of the Bach Society of New Jersey.},
    author = {Barnard, Chester I.},
    citeulike-article-id = {1414171},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0674328035},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0674328035},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0674328035},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0674328035},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0674328035/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0674328035},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0674328035},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0674328035},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0674328035\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0674328035},
    day = {01},
    edition = {30 Anv},
    howpublished = {Paperback},
    isbn = {0674328035},
    keywords = {thesis-phd},
    month = jan,
    posted-at = {2011-11-22 08:17:11},
    priority = {2},
    publisher = {Harvard University Press},
    title = {The Functions of the Executive: 30th Anniversary Edition},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0674328035},
    year = {1971}
}

@article{citeulike:10055684,
    author = {Simon, Herbert A.},
    citeulike-article-id = {10055684},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/27850429},
    citeulike-linkout-1 = {http://www.jstor.org/stable/27850429},
    doi = {10.2307/27850429},
    issn = {00030996},
    journal = {American Scientist},
    keywords = {thesis-phd},
    number = {3},
    posted-at = {2011-11-22 08:02:18},
    priority = {2},
    publisher = {Sigma Xi, The Scientific Research Society},
    title = {Studying Human Intelligence by Creating Artificial Intelligence: When considered as a physical symbol system, the human brain can be fruitfully studied by computer simulation of its processes},
    url = {http://dx.doi.org/10.2307/27850429},
    volume = {69},
    year = {1981}
}   

@article{citeulike:6095377,
    abstract = {A core set of concepts for the software process is defined. These
concepts are intended to facilitate communications and to provide a
framework for further definitions. The definitions focus on essential
concepts; however, they do not represent a comprehensive glossary of
common software process terms. Following an initial overview, the basic
process concepts which underlie the definitions are outlined. The
definitions are grouped in four sets: a framework for process
definition, an engineering of process, an enactment of process, and
process properties. The use of these concepts in several domains is
illustrated. Some observations on the definition process are offered},
    author = {Feiler, P. H. and Humphrey, W. S.},
    booktitle = {Software Process, 1993. Continuous Software Process Improvement, Second International Conference on the},
    citeulike-article-id = {6095377},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/SPCON.1993.236824},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=236824},
    day = {06},
    doi = {10.1109/SPCON.1993.236824},
    isbn = {0-8186-3600-9},
    journal = {Software Process, 1993. Continuous Software Process Improvement, Second International Conference on the},
    keywords = {thesis-phd},
    month = feb,
    pages = {28--40},
    posted-at = {2011-11-15 13:38:50},
    priority = {2},
    publisher = {IEEE},
    title = {Software process development and enactment: concepts and
definitions},
    url = {http://dx.doi.org/10.1109/SPCON.1993.236824},
    year = {1993}
}

@article{citeulike:10004032,
    abstract = {The paper is adapted from a presentation at a symposium on advanced programming methods for digital computers sponsored by the Navy Mathematical Computing Advisory Panel and the Office of Naval Research in June 1956. The author describes the techniques used to produce the programs for the {Semi-Automatic} Ground Environment ({SAGE}) system.},
    author = {Benington, Herbert D.},
    citeulike-article-id = {10004032},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/MAHC.1983.10102},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4640770},
    doi = {10.1109/MAHC.1983.10102},
    issn = {0164-1239},
    journal = {Annals of the History of Computing},
    keywords = {thesis-phd},
    month = oct,
    number = {4},
    pages = {350--361},
    posted-at = {2011-11-08 08:47:16},
    priority = {2},
    publisher = {IEEE},
    title = {Production of Large Computer Programs},
    url = {http://dx.doi.org/10.1109/MAHC.1983.10102},
    volume = {5},
    year = {1983}
}

@article{citeulike:10004037,
    abstract = {The paper is adapted from a presentation at the 1957 Eastern Joint Computer Conference. The authors give details of the {Semi-Automatic} Ground Environment ({SAGE}) system and how it developed.},
    address = {Los Alamitos, CA, USA},
    author = {Everett, Robert R. and Zraket, Charles A. and Benington, Herbert D.},
    citeulike-article-id = {10004037},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/MAHC.1983.10096},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/MAHC.1983.10096},
    doi = {10.1109/MAHC.1983.10096},
    issn = {1058-6180},
    journal = {IEEE Annals of the History of Computing},
    keywords = {thesis-phd},
    pages = {330--339},
    posted-at = {2011-11-08 08:44:05},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {{SAGE}-A Data Processing System for Air Defense},
    url = {http://dx.doi.org/10.1109/MAHC.1983.10096},
    volume = {5},
    year = {1983}
}

@article{citeulike:10004001,
    abstract = {Events leading to the adoption of voice telephone lines for air-defense operational messages are described. This process paved the way for the use of operational data lines in the {SAGE} ({Semi-Automatic} Ground Environment) system. The paper describes the early considerations leading to the use of a digital computer in {SAGE}, and how Whirlwind was chosen to be that computer. The context of the development of magnetic core memory is illuminated. The attitudes of engineering professionals toward digital equipment are reviewed. The author reveals how the name "Ground Environment" was created.},
    author = {Valley, George E.},
    citeulike-article-id = {10004001},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/MAHC.1985.10030},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4640733},
    doi = {10.1109/MAHC.1985.10030},
    issn = {0164-1239},
    journal = {Annals of the History of Computing},
    keywords = {thesis-phd},
    month = jul,
    number = {3},
    pages = {196--226},
    posted-at = {2011-11-08 08:16:43},
    priority = {2},
    publisher = {IEEE},
    title = {How the {SAGE} Development Began},
    url = {http://dx.doi.org/10.1109/MAHC.1985.10030},
    volume = {7},
    year = {1985}
}

@article{citeulike:10002165,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {Sommerville, Ian},
    citeulike-article-id = {10002165},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=234420},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/234313.234420},
    doi = {10.1145/234313.234420},
    issn = {0360-0300},
    journal = {ACM Comput. Surv.},
    keywords = {thesis-phd},
    month = mar,
    pages = {269--271},
    posted-at = {2011-11-07 21:12:03},
    priority = {2},
    publisher = {ACM},
    title = {Software process models},
    url = {http://dx.doi.org/10.1145/234313.234420},
    volume = {28},
    year = {1996}
}

@article{citeulike:3996892,
    abstract = {An abstract is not available.},
    address = {New York, NY, USA},
    author = {McCracken, Daniel D. and Jackson, Michael A.},
    citeulike-article-id = {3996892},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1005937.1005943},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1005937.1005943},
    doi = {10.1145/1005937.1005943},
    issn = {0163-5948},
    journal = {SIGSOFT Softw. Eng. Notes},
    keywords = {thesis-phd},
    month = apr,
    number = {2},
    pages = {29--32},
    posted-at = {2011-11-07 21:09:21},
    priority = {2},
    publisher = {ACM},
    title = {Life cycle concept considered harmful},
    url = {http://dx.doi.org/10.1145/1005937.1005943},
    volume = {7},
    year = {1982}
}

@misc{Boehm95anchoringthe,
    author = {Boehm, Barry and Usc, Barry B.},
    citeulike-article-id = {10002136},
    keywords = {*file-import-11-11-07},
    posted-at = {2011-11-07 21:02:07},
    priority = {2},
    title = {Anchoring the Software Process},
    year = {1995}
}

@article{citeulike:10002126,
    abstract = {A short description is given of software process models and the issues they address. An outline is given of the process steps involved in the spiral model, an
evolving risk-driven approach that provides a framework for guiding the software process, and its application to a software project is shown. A summary is given of the primary
advantages and implications involved in using the spiral model and the primary difficulties in using it at its current incomplete level of elaboration.},
    address = {Los Alamitos, CA, USA},
    author = {Boehm, Barry W.},
    citeulike-article-id = {10002126},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=45801},
    issn = {0018-9162},
    journal = {Computer},
    keywords = {thesis-phd},
    month = may,
    pages = {61--72},
    posted-at = {2011-11-07 20:59:41},
    priority = {2},
    publisher = {IEEE Computer Society Press},
    title = {A Spiral Model of Software Development and Enhancement},
    url = {http://portal.acm.org/citation.cfm?id=45801},
    volume = {21},
    year = {1988}
}

@article{citeulike:1986013,
    abstract = {First Page of the Article},
    address = {Los Alamitos, CA, USA},
    author = {Brooks, F. P.},
    booktitle = {Computer},
    citeulike-article-id = {1986013},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=26441},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/MC.1987.1663532},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/MC.1987.1663532},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1663532},
    day = {07},
    doi = {10.1109/MC.1987.1663532},
    issn = {0018-9162},
    journal = {Computer},
    keywords = {thesis-phd},
    month = apr,
    number = {4},
    pages = {10--19},
    posted-at = {2011-11-03 05:48:23},
    priority = {2},
    publisher = {IEEE},
    title = {No Silver Bullet Essence and Accidents of Software Engineering},
    url = {http://dx.doi.org/10.1109/MC.1987.1663532},
    volume = {20},
    year = {1987}
}

@article{citeulike:4384552,
    abstract = {New myths about formal methods are gaining tacit acceptance both
outside and inside the system-development community. The authors address
and dispel these myths based on their observations of industrial
projects. The myths include: formal methods delay the development
process; they lack tools; they replace traditional engineering design
methods; they only apply to software; are unnecessary; not supported;
and formal methods people always use formal methods},
    address = {Los Alamitos, CA, USA},
    author = {Bowen, J. P. and Hinchey, M. G.},
    booktitle = {Software, IEEE},
    citeulike-article-id = {4384552},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=625488},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/52.391826},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=391826},
    doi = {10.1109/52.391826},
    issn = {0740-7459},
    journal = {Software, IEEE},
    keywords = {thesis-phd},
    month = jul,
    number = {4},
    pages = {34--41},
    posted-at = {2011-11-03 05:45:42},
    priority = {2},
    publisher = {IEEE},
    title = {Seven more myths of formal methods},
    url = {http://dx.doi.org/10.1109/52.391826},
    volume = {12},
    year = {1995}
}

@inproceedings{citeulike:9982731,
    author = {Royce, Winson W.},
    booktitle = {IEEE WESCON},
    citeulike-article-id = {9982731},
    citeulike-linkout-0 = {http://citeseer.ist.psu.edu/showciting?cid=68128},
    keywords = {thesis-phd},
    location = {New York},
    month = aug,
    posted-at = {2011-11-03 05:26:03},
    priority = {2},
    title = {Managing The Development Of A Large Software System},
    url = {http://citeseer.ist.psu.edu/showciting?cid=68128},
    year = {1970}
}

@book{citeulike:900855,
    author = {Kernighan, Brian W. and Plauger, P. J.},
    citeulike-article-id = {900855},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0070342075},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0070342075},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0070342075},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0070342075},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0070342075/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0070342075},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0070342075},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0070342075},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0070342075\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0070342075},
    day = {01},
    edition = {2},
    howpublished = {Paperback},
    isbn = {0070342075},
    month = jan,
    posted-at = {2011-10-29 22:08:11},
    priority = {2},
    publisher = {Computing Mcgraw-Hill},
    title = {The Elements of Programming Style},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0070342075},
    year = {1978}
}

@book{citeulike:9962027,
    author = {Kirchmer, Mathias},
    citeulike-article-id = {9962027},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/3540655751},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/3540655751},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/3540655751},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/3540655751},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/3540655751/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3540655751},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/3540655751},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN3540655751},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=3540655751\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/3540655751},
    day = {14},
    edition = {2nd},
    howpublished = {Hardcover},
    isbn = {3540655751},
    month = apr,
    posted-at = {2011-10-29 21:59:42},
    priority = {2},
    publisher = {Springer},
    title = {Business Process Oriented Implementation of Standard Software: How to Achieve Competitive Advantage Efficiently and Effectively},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3540655751},
    year = {1999}
}

@book{citeulike:9962022,
    author = {Bpo0999},
    citeulike-article-id = {9962022},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0769509991},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0769509991},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0769509991},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0769509991},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0769509991/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0769509991},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0769509991},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0769509991},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0769509991\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0769509991},
    day = {27},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0769509991},
    month = nov,
    posted-at = {2011-10-29 21:56:39},
    priority = {2},
    publisher = {Wiley-IEEE Computer Society Pr},
    title = {Software Process Improvement},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0769509991},
    year = {2001}
}

@book{citeulike:9962021,
    author = {Humphrey, Watts S.},
    citeulike-article-id = {9962021},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0201180952},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0201180952},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0201180952},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0201180952},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0201180952/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201180952},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0201180952},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0201180952},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0201180952\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0201180952},
    day = {11},
    howpublished = {Hardcover},
    isbn = {0201180952},
    month = jan,
    posted-at = {2011-10-29 21:53:54},
    priority = {2},
    publisher = {Addison-Wesley Professional},
    title = {Managing the Software Process},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0201180952},
    year = {1989}
}

@article{citeulike:5203446,
    abstract = {Certain principles long considered fundamental to software engineering are examined and found wanting.},
    address = {Los Alamitos, CA, USA},
    author = {DeMarco, Tom},
    booktitle = {Software, IEEE},
    citeulike-article-id = {5203446},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/MS.2009.101},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/MS.2009.101},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5076468},
    doi = {10.1109/MS.2009.101},
    issn = {0740-7459},
    journal = {Software, IEEE},
    keywords = {thesis-phd},
    month = jul,
    number = {4},
    pages = {96},
    posted-at = {2011-10-29 05:12:27},
    priority = {2},
    publisher = {IEEE},
    title = {Software Engineering: An Idea Whose Time Has Come and Gone?},
    url = {http://dx.doi.org/10.1109/MS.2009.101},
    volume = {26},
    year = {2009}
}

@book{citeulike:9958822,
    author = {Carpenter, Gaylene and Blandy, Doug},
    citeulike-article-id = {9958822},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0736065644},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0736065644},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0736065644},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0736065644},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0736065644/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0736065644},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0736065644},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0736065644},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0736065644\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0736065644},
    day = {03},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0736065644},
    keywords = {thesis-phd},
    month = mar,
    posted-at = {2011-10-28 21:53:19},
    priority = {2},
    publisher = {Human Kinetics},
    title = {Arts and Cultural Programming: A Leisure Perspective},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0736065644},
    year = {2008}
}

@article{citeulike:9928907,
    abstract = {Is computer programming an art requiring craftsmanship, or is it a science requiring the disciplined application of best practices? This letter argues in favor of
craftsmanship without ignoring best practices. Discussion includes the progression of a programmer from apprentice to journeyman to master craftsman within the telecommunications
domain. {\copyright} 2003 Lucent Technologies Inc.},
    author = {Pyritz, Bill},
    citeulike-article-id = {9928907},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/bltj.10079},
    doi = {10.1002/bltj.10079},
    journal = {Bell Labs Tech. J.},
    keywords = {thesis},
    number = {3},
    pages = {101--104},
    posted-at = {2011-10-20 21:13:26},
    priority = {2},
    publisher = {Wiley Subscription Services, Inc., A Wiley Company},
    title = {Craftsmanship versus engineering: Computer {programming—An} art or a science?},
    url = {http://dx.doi.org/10.1002/bltj.10079},
    volume = {8},
    year = {2003}
}

@misc{SDTimes,
    Author = {David Rubinstein},
    Title = {Standish Group Report: There's Less Development Chaos Today},
    howpublished = {\url{http://www.sdtimes.com/link/30247}} }

@book{citeulike:9758924,
    author = {van der Aalst, Wil M. P.},
    citeulike-article-id = {9758924},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/3642193447},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/3642193447},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/3642193447},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/3642193447},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/3642193447/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3642193447},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/3642193447},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN3642193447},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=3642193447\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/3642193447},
    day = {12},
    edition = {1st Edition.},
    howpublished = {Hardcover},
    isbn = {3642193447},
    keywords = {thesis-phd},
    month = apr,
    posted-at = {2011-10-09 17:55:13},
    priority = {2},
    publisher = {Springer},
    title = {Process Mining: Discovery, Conformance and Enhancement of Business Processes},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3642193447},
    year = {2011}
}

@inproceedings{citeulike:9114115,
    abstract = {The development of Open Source systems produces a variety of software artifacts such as source code, version control records, bug reports, and email discussions. Since the development is distributed across different tool environments and developer practices, any analysis of project behavior must be inferred from whatever common artifacts happen to be available. In this paper, we propose an approach to characterizing a project's behavior around the time of major and minor releases; we do this by partitioning the observed activities, such as artifact check-ins, around the dates of major and minor releases, and then look for recognizable patterns. We validate this approach by means of a case study on the {MySQL} database system; in this case study, we found patterns which suggested {MySQL} was behaving consistently within itself. These patterns included testing and documenting that took place more before a release than after and that the rate of source code changes dipped around release time.},
    address = {Washington, DC, USA},
    author = {Hindle, Abram and Godfrey, Michael W. and Holt, Richard C.},
    booktitle = {Proceedings of the Fourth International Workshop on Mining Software Repositories},
    citeulike-article-id = {9114115},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1269033},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/MSR.2007.28},
    doi = {10.1109/MSR.2007.28},
    isbn = {0-7695-2950-X},
    posted-at = {2011-04-07 18:25:23},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {MSR '07},
    title = {Release Pattern Discovery via Partitioning: Methodology and Case Study},
    url = {http://dx.doi.org/10.1109/MSR.2007.28},
    year = {2007}
}

@book{citeulike:7706819,
    citeulike-article-id = {7706819},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0803913710},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0803913710},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0803913710},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0803913710},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0803913710/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0803913710},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0803913710},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0803913710},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0803913710\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0803913710},
    day = {01},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0803913710},
    keywords = {thesis-phd},
    month = nov,
    posted-at = {2011-04-07 16:27:01},
    priority = {2},
    publisher = {Sage Publications, Inc},
    title = {Reliability and Validity Assessment (Quantitative Applications in the Social Sciences)},
    url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0803913710},
    year = {1979}
}

@inproceedings{citeulike:9112798,
    abstract = {In this paper, we present the method we have developed to analyze socio-technical  aspects of software problem management in {F/OSS} communities, based on large  corpora of problem reports; and we report on early results we obtained using our  framework. Given the amount of data available, computational techniques to  scalably extract event data and model the collectives\&\#039; behaviors are needed. We are  using a variety of techniques that couple human-based qualitative analysis with  computational extraction and modeling to generate models of the processes involved  in software problem management.},
    author = {Oss, For U. and Ripoche, Gabriel and Gasser, Les},
    booktitle = {in Proceedings of the 16 th International Conference on Software \&amp; Systems Engineering and their Applications},
    citeulike-article-id = {9112798},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.4.2887},
    keywords = {thesis-phd},
    pages = {2--4},
    posted-at = {2011-04-07 14:03:33},
    priority = {2},
    title = {Scalable Automatic Extraction of Process Models},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.4.2887},
    year = {2003}
}

@article{citeulike:421438,
    abstract = {Many successful free/open source software ({FOSS}) projects start with the premise that their contributors are rarely colocated, and as a consequence, these projects are cases of global software development ({GSD}). This article describes how the {GNOME} Project, a large {FOSS} project, has tried to overcome the disadvantages of {GSD}. The main goal of {GNOME} is to create a {GUI} desktop for Unix systems, and encompasses close to two million lines of code. More than 500 individuals (distributed across the world) have contributed to the project. This article also describes the software development methods and practices used by the members of the project, and its organizational structure. The article ends by proposing a list of practices that could benefit other global software development projects, both {FOSS} and commercial. Copyright \&copy; 2004 John Wiley \&amp; Sons, Ltd.},
    author = {German, Daniel M.},
    citeulike-article-id = {421438},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/spip.189},
    citeulike-linkout-1 = {http://www3.interscience.wiley.com/cgi-bin/abstract/109630255/ABSTRACT},
    day = {22},
    doi = {10.1002/spip.189},
    issn = {1077-4866},
    journal = {Software Process: Improvement and Practice},
    keywords = {thesis-phd},
    month = oct,
    number = {4},
    pages = {201--215},
    posted-at = {2011-04-07 10:21:54},
    priority = {2},
    title = {The {GNOME} project: a case study of open source, global software development},
    url = {http://dx.doi.org/10.1002/spip.189},
    volume = {8},
    year = {2004}
}

@inproceedings{citeulike:9007622,
    abstract = {Often stakeholders, such as developers, managers, or buyers, want to find out what software development processes are being followed within a software project. Their reasons include: {CMM} and {ISO} 9000 compliance, process validation, management, acquisitions, and business intelligence. Recovering the software development processes from an existing project is expensive if one must rely upon manual inspection of artifacts and interviews of developers and their managers. Researchers have suggested live observation and instrumentation of a project to allow for more measurement, but this is costly, invasive, and also requires a live running project. Instead, we propose an after the fact analysis: software process recovery. This approach analyzes version control systems, bug trackers and mailing list archives using a variety of supervised and unsupervised techniques from machine learning, topic analysis, natural language processing and statistics. We can combine all of these methods to recover process events that we map back to software development processes like the Unified Process. We can produce diagrams called Recovered Unified Process Views ({RUPV}) that are similar to the Unified Process diagram, a time-line of effort per parallel discipline occurring across time. We then validate these methods using case studies of multiple open source software systems.},
    author = {Hindle, Abram},
    citeulike-article-id = {9007622},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/WCRE.2010.46},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5645491},
    doi = {10.1109/WCRE.2010.46},
    keywords = {thesis-phd},
    location = {Beverly, MA, USA},
    month = oct,
    pages = {305--308},
    posted-at = {2011-03-17 10:58:07},
    priority = {2},
    title = {Software Process Recovery: Recovering Process from Artifacts},
    url = {http://dx.doi.org/10.1109/WCRE.2010.46},
    year = {2010}
}

@inproceedings{citeulike:9006886,
    abstract = {{We have mined the Eclipse bug and version databases to map failures to Eclipse components. The resulting data set lists the defect density of all Eclipse components. As we demonstrate in three simple experiments, the bug data set can be easily used to relate code, process, and developers to defects. The data set is publicly avail-able for download.}},
    author = {Schr\"{o}ter, Adrian and Zimmermann, Thomas and Premraj, Rahul and Zeller, Andreas},
    booktitle = {In Proceedings of the 5th International Symposium on Empirical Software Engineering, Volume II: Short Papers and Posters},
    citeulike-article-id = {9006886},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.114.7244},
    keywords = {thesis-phd},
    pages = {18--20},
    posted-at = {2011-03-17 07:47:22},
    priority = {2},
    title = {{If your bug database could talk}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.114.7244},
    volume = {2006},
    year = {2006}
}

@electronic{citeulike:9004378,
    abstract = {{Version control systems (VCSs) are used to store and reconstruct past versions of program source code. As a by-product they also capture a great deal of contextual information about each change. We will illustrate some ways to use this information to better understand a program\&\#039;s development history. 1}},
    author = {Ball, Thomas and Kim, Jung-min and Porter, Adam A. and Siy, Harvey P.},
    citeulike-article-id = {9004378},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.8653},
    keywords = {thesis-phd},
    posted-at = {2011-03-16 19:46:51},
    priority = {2},
    title = {{Abstract If Your Version Control System Could Talk...}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.8653}
}

@incollection{citeulike:6185797,
    abstract = {{Modulators of G protein-coupled receptors (GPCRs) form a key area for the pharmaceutical industry, representing ˜27\% of all Food and Drug Administration (FDA)-approved drugs. Consequently, there are a wide variety of in vitro plate-based screening technologies that enable the measurement of compound affinity, potency, and efficacy for almost every type of GPCR. However, to maximize success it is prudent to ensure that (i) the most suitable assay formats are identified, (ii) they are configured optimally to detect the desired compound activity, and (iii) that they form a basis for predicting clinical effects. To achieve this, an understanding of the pathways and mechanisms of receptor activation relevant to the disease mechanism, as well as the benefits and/or limitations of the specific techniques, is key.}},
    address = {Totowa, NJ},
    author = {Williams, Christine and Hill, Stephen J.},
    booktitle = {G Protein-Coupled Receptors in Drug Discovery},
    chapter = {3},
    citeulike-article-id = {6185797},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-1-60327-317-6\_3},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19513640},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19513640},
    citeulike-linkout-3 = {http://www.springerlink.com/content/k6626211005lq75r},
    doi = {10.1007/978-1-60327-317-6\_3},
    editor = {Walker, John M. and Leifert, Wayne R.},
    isbn = {978-1-60327-316-9},
    issn = {1064-3745},
    journal = {Methods in molecular biology (Clifton, N.J.)},
    pages = {39--50},
    pmid = {19513640},
    posted-at = {2011-03-15 09:25:53},
    priority = {2},
    publisher = {Humana Press},
    series = {Methods in Molecular Biology™},
    title = {{GPCR Signaling: Understanding the Pathway to Successful Drug Discovery}},
    url = {http://dx.doi.org/10.1007/978-1-60327-317-6\_3},
    volume = {552},
    year = {2009}
}

@incollection{citeulike:8979205,
    address = {Berlin, Heidelberg},
    author = {Schultz, G\"{u}nter and Schaefer, Michael},
    booktitle = {Encyclopedia of Molecular Pharmacology},
    chapter = {143},
    citeulike-article-id = {8979205},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-38918-7\_143},
    citeulike-linkout-1 = {http://www.springerlink.com/content/m55x7682590qm896},
    doi = {10.1007/978-3-540-38918-7\_143},
    editor = {Offermanns, Stefan and Rosenthal, Walter},
    isbn = {978-3-540-38916-3},
    pages = {1236--1242},
    posted-at = {2011-03-11 10:29:49},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {{Transmembrane Signaling}},
    url = {http://dx.doi.org/10.1007/978-3-540-38918-7\_143},
    year = {2008}
}

@electronic{citeulike:5058462,
    abstract = {{All analyses of version archives have one phase in common: the preprocessing of data. Preprocessing has a direct impact on the quality of the results returned by an analysis. In this paper we discuss four essential preprocessing tasks necessary for a fine-grained analysis of CVS archives: (a) data extraction, (b) transaction recovery, (c) mapping of changes to fine-grained entities, and (d) data cleaning. We formalize the concept of sliding time windows and show how commit mails can relate revisions to transactions. We also present two approaches that map changes to the affected building blocks of a file, e.g. functions or sections.}},
    author = {Zimmermann, Thomas},
    citeulike-article-id = {5058462},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.9987},
    keywords = {th, thesis-phd},
    pages = {2--6},
    posted-at = {2011-03-02 19:13:54},
    priority = {2},
    title = {{Preprocessing CVS data for fine-grained analysis}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.9987},
    year = {2004}
}

@article{Masse:2009p34032,
    abstract = {{In both insect and vertebrate olfactory systems only two synapses separate the sensory periphery from brain areas required for memory formation and the organisation of behaviour. In the Drosophila olfactory system, which is anatomically very similar to its vertebrate counterpart, there has been substantial recent progress in understanding the flow of information from experiments using molecular genetic, electrophysiological and optical imaging techniques. In this review, we shall focus on how olfactory information is processed and transformed in order to extract behaviourally relevant information. We follow the progress from olfactory receptor neurons, through the first processing area, the antennal lobe, to higher olfactory centres. We address both the underlying anatomy and mechanisms that govern the transformation of neural activity. We emphasise our emerging understanding of how different elementary computations, including signal averaging, gain control, decorrelation and integration, may be mapped onto different circuit elements.}},
    author = {Masse, Nicolas Y. and Turner, Glenn C. and Jefferis, Gregory S. X. E.},
    citeulike-article-id = {7248783},
    citeulike-linkout-0 = {http://www.cell.com/current-biology/retrieve/pii/S0960982209013013},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.cub.2009.06.026},
    doi = {10.1016/j.cub.2009.06.026},
    journal = {Curr Biol},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors, odorants},
    local-url = {file://localhost/Users/Walton/Dropbox/Libraries/Papers/Curr\%20Biol\%202009\%20Masse.pdf},
    month = aug,
    number = {16},
    pages = {R700--13},
    posted-at = {2011-02-25 17:03:07},
    priority = {2},
    title = {{Olfactory information processing in Drosophila}},
    url = {http://www.cell.com/current-biology/retrieve/pii/S0960982209013013},
    volume = {19},
    year = {2009}
}

@article{citeulike:8861859,
    abstract = {{Ants rely heavily on olfaction for communication and orientation. Here we provide the first detailed structure–function analyses within an ant's central olfactory system asking whether in the carpenter ant, Camponotus floridanus, the olfactory pathway exhibits adaptations to processing many pheromonal and general odors. Using fluorescent tracing, confocal microscopy, and 3D-analyses we demonstrate that the antennal lobe (AL) contains up to ≈460 olfactory glomeruli organized in seven distinct clusters innervated via seven antennal sensory tracts. The AL is divided into two hemispheres regarding innervation of glomeruli by either projection neurons (PNs) with axons leaving via the medial (m) or lateral (l) antennocerebral tract (ACT). M- and l-ACT PNs differ in their target areas in the mushroom-body calyx and lateral horn. Three additional ACTs project to the lateral protocerebrum only. We analyzed odor processing in AL glomeruli by retrograde loading of PNs with Fura-2 dextran and fluorimetric calcium imaging. Odor responses were reproducible and comparable across individuals. Calcium responses to pheromonal and nonpheromonal odors were very sensitive (10−11 dilution) and patterns were partly overlapping, indicating that processing of both odor classes is not spatially segregated within the AL. Response patterns to the main trail-pheromone component nerolic acid remained stable over a wide range of intensities (7–8 log units), while response durations increased indicating that odor quality is maintained by a stable pattern and intensity is mainly encoded in response durations. The structure–function analyses contribute new insights into important aspects of odor processing in a highly advanced insect olfactory system. J. Comp. Neurol. 506:425–441, 2008. {\copyright} 2007 Wiley-Liss, Inc.}},
    author = {Zube, Christina and Kleineidam, Christoph J. and Kirschner, Sebastian and Neef, Jakob and R\"{o}ssler, Wolfgang},
    citeulike-article-id = {8861859},
    citeulike-linkout-0 = {http://dx.doi.org/10.1002/cne.21548},
    doi = {10.1002/cne.21548},
    journal = {J. Comp. Neurol.},
    keywords = {odorants},
    number = {3},
    pages = {425--441},
    posted-at = {2011-02-21 15:58:12},
    priority = {2},
    publisher = {Wiley Subscription Services, Inc., A Wiley Company},
    title = {{Organization of the olfactory pathway and odor processing in the antennal lobe of the ant Camponotus floridanus}},
    url = {http://dx.doi.org/10.1002/cne.21548},
    volume = {506},
    year = {2008}
}

@article{citeulike:2680015,
    abstract = {{In insects, each olfactory sensory neuron expresses between one and three ligand-binding members of the olfactory receptor (OR) gene family, along with the highly conserved and broadly expressed Or83b co-receptor1, 2, 3, 4, 5, 6, 7, 8, 9. The functional insect OR consists of a heteromeric complex of unknown stoichiometry but comprising at least one variable odorant-binding subunit and one constant Or83b family subunit10, 11, 12, 13, 14, 15, 16. Insect ORs lack homology to G-protein-coupled chemosensory receptors in vertebrates17 and possess a distinct seven-transmembrane topology with the amino terminus located intracellularly10, 18. Here we provide evidence that heteromeric insect ORs comprise a new class of ligand-activated non-selective cation channels. Heterologous cells expressing silkmoth, fruitfly or mosquito heteromeric OR complexes showed extracellular Ca2+ influx and cation-non-selective ion conductance on stimulation with odorant. Odour-evoked OR currents are independent of known G-protein-coupled second messenger pathways. The fast response kinetics and OR-subunit-dependent K+ ion selectivity of the insect OR complex support the hypothesis that the complex between OR and Or83b itself confers channel activity. Direct evidence for odorant-gated channels was obtained by outside-out patch-clamp recording of Xenopus oocyte and HEK293T cell membranes expressing insect OR complexes. The ligand-gated ion channel formed by an insect OR complex seems to be the basis for a unique strategy that insects have acquired to respond to the olfactory environment.}},
    author = {Sato, Koji and Pellegrino, Maurizio and Nakagawa, Takao and Nakagawa, Tatsuro and Vosshall, Leslie B. and Touhara, Kazushige},
    citeulike-article-id = {2680015},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature06850},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature06850},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18408712},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18408712},
    day = {13},
    doi = {10.1038/nature06850},
    issn = {0028-0836},
    journal = {Nature},
    keywords = {odorant},
    month = apr,
    number = {7190},
    pages = {1002--1006},
    posted-at = {2011-02-21 14:16:39},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {{Insect olfactory receptors are heteromeric ligand-gated ion channels}},
    url = {http://dx.doi.org/10.1038/nature06850},
    volume = {452},
    year = {2008}
}

@article{citeulike:2680014,
    abstract = {{From worm to man, many odorant signals are perceived by the binding of volatile ligands to odorant receptors1 that belong to the G-protein-coupled receptor (GPCR) family2. They couple to heterotrimeric G-proteins, most of which induce cAMP production3. This second messenger then activates cyclic-nucleotide-gated ion channels to depolarize the olfactory receptor neuron, thus providing a signal for further neuronal processing. Recent findings, however, have challenged this concept of odorant signal transduction in insects, because their odorant receptors, which lack any sequence similarity to other GPCRs4, are composed of conventional odorant receptors (for example, Or22a), dimerized with a ubiquitously expressed chaperone protein5, such as Or83b in Drosophila6. Or83b has a structure akin to GPCRs, but has an inverted orientation in the plasma membrane4, 7. However, G proteins are expressed in insect olfactory receptor neurons8, and olfactory perception is modified by mutations affecting the cAMP transduction pathway9. Here we show that application of odorants to mammalian cells co-expressing Or22a and Or83b results in non-selective cation currents activated by means of an ionotropic and a metabotropic pathway, and a subsequent increase in the intracellular Ca2+ concentration. Expression of Or83b alone leads to functional ion channels not directly responding to odorants, but being directly activated by intracellular cAMP or cGMP. Insect odorant receptors thus form ligand-gated channels as well as complexes of odorant-sensing units and cyclic-nucleotide-activated non-selective cation channels. Thereby, they provide rapid and transient as well as sensitive and prolonged odorant signalling.}},
    author = {Wicher, Dieter and Schafer, Ronny and Bauernfeind, Rene and Stensmyr, Marcus C. and Heller, Regine and Heinemann, Stefan H. and Hansson, Bill S.},
    citeulike-article-id = {2680014},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature06861},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature06861},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18408711},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18408711},
    day = {13},
    doi = {10.1038/nature06861},
    issn = {0028-0836},
    journal = {Nature},
    keywords = {odorants},
    month = apr,
    number = {7190},
    pages = {1007--1011},
    posted-at = {2011-02-21 14:15:42},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {{Drosophila odorant receptors are both ligand-gated and cyclic-nucleotide-activated cation channels}},
    url = {http://dx.doi.org/10.1038/nature06861},
    volume = {452},
    year = {2008}
}

@article{citeulike:6296216,
    abstract = {{We have taken advantage of the availability of a large amount of Drosophila genomic DNA sequence in the Berkeley Drosophila Genome Project database ( approximately 1/5 of the genome) to identify a family of novel seven transmembrane domain encoding genes that are putative Drosophila olfactory receptors. Members of the family are expressed in distinct subsets of olfactory neurons, and certain family members are restricted to distinct portions of the olfactory system. This pattern of expression has interesting similarities to and differences from the expression patterns observed for olfactory receptors in vertebrates. The Drosophila olfactory system is simpler than mammalian systems, yet it is complex enough to present a fascinating system in which to study neural information processing. Moreover, the powerful genetic manipulations available in Drosophila, when combined with electrophysiological and behavioral analyses, make this an attractive model system in which to study olfactory discrimination.}},
    author = {Gao, Q. and Chess, A.},
    citeulike-article-id = {6296216},
    citeulike-linkout-0 = {http://dx.doi.org/10.1006/geno.1999.5894},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/10458908},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=10458908},
    day = {15},
    doi = {10.1006/geno.1999.5894},
    issn = {0888-7543},
    journal = {Genomics},
    keywords = {odorant},
    month = aug,
    number = {1},
    pages = {31--39},
    posted-at = {2011-02-21 14:10:32},
    priority = {2},
    title = {{Identification of candidate Drosophila olfactory receptors from genomic DNA sequence.}},
    url = {http://dx.doi.org/10.1006/geno.1999.5894},
    volume = {60},
    year = {1999}
}

@article{citeulike:6287036,
    abstract = {{By analogy to mammals, odorant receptors (ORs) in insects, such as Drosophila melanogaster, have long been thought to belong to the G-protein coupled receptor (GPCR) superfamily. However, recent work has cast doubt on this assumption and has tentatively suggested an inverted topology compared to the canonical Nout − Cin 7 transmembrane (TM) GPCR topology, at least for some Drosophila ORs. Here, we report a detailed topology mapping of the Drosophila OR83b receptor using engineered glycosylation sites as topology markers. Our results are inconsistent with a classical GPCR topology and show that OR83b has an intracellular N-terminus, an extracellular C-terminus, and 7TM helices.}},
    author = {Lundin, C. and Kall, L. and Kreher, S. and Kapp, K. and Sonnhammer, E. and Carlson, J. and Vonheijne, G. and Nilsson, I.},
    citeulike-article-id = {6287036},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.febslet.2007.11.007},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0014579307011465},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18005664},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18005664},
    day = {11},
    doi = {10.1016/j.febslet.2007.11.007},
    issn = {00145793},
    journal = {FEBS Letters},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors},
    month = dec,
    number = {29},
    pages = {5601--5604},
    posted-at = {2011-01-24 16:09:27},
    priority = {2},
    title = {{Membrane topology of the Drosophila OR83b odorant receptor}},
    url = {http://dx.doi.org/10.1016/j.febslet.2007.11.007},
    volume = {581},
    year = {2007}
}

@article{citeulike:2446040,
    abstract = {{The contributions of measurement and experimentation to the state of the art in software engineering are reviewed. The role of measurement in developing theoretical models is discussed, and concerns for reliability and validity are stressed. Current approaches to measuring software characteristics are presented as examples. In particular, software complexity metrics related to control flow, module interconnectedness, and Halstead's Software Science are discussed. The use of experimental methods in evaluating cause-effect relationships is also discussed. Example programs of experimental research which investigated conditional statements and control flow are reviewed. The conclusion argues that many advances in software engineering will be related to improvements in the measurement and experimental evaluation of software techniques and practices.}},
    author = {Curtis, B.},
    booktitle = {Proceedings of the IEEE},
    citeulike-article-id = {2446040},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/PROC.1980.11813},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1456082},
    doi = {10.1109/PROC.1980.11813},
    issn = {0018-9219},
    journal = {Proceedings of the IEEE},
    keywords = {msr, msr-2011},
    number = {9},
    pages = {1144--1157},
    posted-at = {2011-01-18 18:58:30},
    priority = {2},
    title = {{Measurement and experimentation in software engineering}},
    url = {http://dx.doi.org/10.1109/PROC.1980.11813},
    volume = {68},
    year = {1980}
}

@article{citeulike:5969736,
    author = {Benton, Richard and Vannice, Kirsten S. and Gomez-Diaz, Carolina and Vosshall, Leslie B.},
    citeulike-article-id = {5969736},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cell.2008.12.001},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0092867408015614},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/19135896},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=19135896},
    day = {09},
    doi = {10.1016/j.cell.2008.12.001},
    issn = {00928674},
    journal = {Cell},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors, g\_proteins},
    month = jan,
    number = {1},
    pages = {149--162},
    posted-at = {2011-01-18 11:47:56},
    priority = {2},
    title = {{Variant Ionotropic Glutamate Receptors as Chemosensory Receptors in Drosophila}},
    url = {http://dx.doi.org/10.1016/j.cell.2008.12.001},
    volume = {136},
    year = {2009}
}

@article{citeulike:5969737,
    author = {Spletter, Maria L. and Luo, Liqun},
    citeulike-article-id = {5969737},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cell.2008.12.031},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0092867408016371},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/19135885},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=19135885},
    day = {09},
    doi = {10.1016/j.cell.2008.12.031},
    issn = {00928674},
    journal = {Cell},
    keywords = {g\_proteins, odorant\_binding\_protein, pheromone},
    month = jan,
    number = {1},
    pages = {23--25},
    posted-at = {2011-01-18 11:45:35},
    priority = {2},
    title = {{A New Family of Odorant Receptors in Drosophila}},
    url = {http://dx.doi.org/10.1016/j.cell.2008.12.031},
    volume = {136},
    year = {2009}
}

@article{citeulike:620314,
    abstract = {{G protein-coupled receptors (GPCRs) constitute a large superfamily involved in various types of signal transduction pathways triggered by hormones, odorants, peptides, proteins, and other types of ligands. The superfamily is so diverse that many members lack sequence similarity, although they all span the cell membrane seven times with an extracellular N and a cytosolic C terminus. We analyzed a divergent set of GPCRs and found distinct loop length patterns and differences in amino acid composition between cytosolic loops, extracellular loops, and membrane regions. We configured GPCRHMM, a hidden Markov model, to fit those features and trained it on a large dataset representing the entire superfamily. GPCRHMM was benchmarked to profile HMMs and generic transmembrane detectors on sets of known GPCRs and non-GPCRs. In a cross-validation procedure, profile HMMs produced an error rate nearly twice as high as GPCRHMM. In a sensitivity-selectivity test, GPCRHMM's sensitivity was about 15\% higher than that of the best transmembrane predictors, at comparable false positive rates. We used GPCRHMM to search for novel members of the GPCR superfamily in five proteomes. All in all we detected 120 sequences that lacked annotation and are potentially novel GPCRs. Out of those 102 were found in Caenorhabditis elegans, four in human, and seven in mouse. Many predictions (65) belonged to Pfam domains of unknown function. GPCRHMM strongly rejected a family of arthropod-specific odorant receptors believed to be GPCRs. A detailed analysis showed that these sequences are indeed very different from other GPCRs. GPCRHMM is available at http://gpcrhmm.cgb.ki.se.}},
    address = {Center for Genomics and Bioinformatics, Karolinska Institutet, S-17177 Stockholm, Sweden.},
    author = {Wistrand, Markus and K\"{a}ll, Lukas and Sonnhammer, Erik L.},
    citeulike-article-id = {620314},
    citeulike-linkout-0 = {http://dx.doi.org/10.1110/ps.051745906},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/16452613},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=16452613},
    doi = {10.1110/ps.051745906},
    issn = {0961-8368},
    journal = {Protein science : a publication of the Protein Society},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors, g\_proteins},
    month = mar,
    number = {3},
    pages = {509--521},
    posted-at = {2011-01-18 08:09:29},
    priority = {2},
    title = {{A general model of G protein-coupled receptor sequences and its application to detect remote homologs.}},
    url = {http://dx.doi.org/10.1110/ps.051745906},
    volume = {15},
    year = {2006}
}

@article{citeulike:6286506,
    abstract = {{Drosophila olfactory sensory neurons (OSNs) each express two odorant receptors (ORs): a divergent member of the OR family and the highly conserved, broadly expressed receptor OR83b. OR83b is essential for olfaction in vivo and enhances OR function in vitro, but the molecular mechanism by which it acts is unknown. Here we demonstrate that OR83b heterodimerizes with conventional ORs early in the endomembrane system in OSNs, couples these complexes to the conserved ciliary trafficking pathway, and is essential to maintain the OR/OR83b complex within the sensory cilia, where odor signal transduction occurs. The OR/OR83b complex is necessary and sufficient to promote functional reconstitution of odor-evoked signaling in sensory neurons that normally respond only to carbon dioxide. Unexpectedly, unlike all known vertebrate and nematode chemosensory receptors, we find that Drosophila ORs and OR83b adopt a novel membrane topology with their N-termini and the most conserved loops in the cytoplasm. These loops mediate direct association of ORs with OR83b. Our results reveal that OR83b is a universal and integral part of the functional OR in Drosophila . This atypical heteromeric and topological design appears to be an insect-specific solution for odor recognition, making the OR/OR83b complex an attractive target for the development of highly selective insect repellents to disrupt olfactory-mediated host-seeking behaviors of insect disease vectors.}},
    author = {Benton, Richard and Sachse, Silke and Michnick, Stephen W. and Vosshall, Leslie B.},
    citeulike-article-id = {6286506},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pbio.0040020},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/16402857},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=16402857},
    day = {17},
    doi = {10.1371/journal.pbio.0040020},
    issn = {1545-7885},
    journal = {PLoS Biol},
    keywords = {g\_protein\_coupled\_receptors, g\_proteins, odorant\_binding\_protein},
    month = jan,
    number = {2},
    pages = {e20+},
    posted-at = {2011-01-18 08:08:14},
    priority = {2},
    publisher = {Public Library of Science},
    title = {{Atypical Membrane Topology and Heteromeric Function of Drosophila Odorant Receptors In Vivo}},
    url = {http://dx.doi.org/10.1371/journal.pbio.0040020},
    volume = {4},
    year = {2006}
}

@article{citeulike:423054,
    abstract = {{The mammalian olfactory system can recognize and discriminate a large number of different odorant molecules. The detection of chemically distinct odorants presumably results from the association of odorous ligands with specific receptors on olfactory sensory neurons. To address the problem of olfactory perception at a molecular level, we have cloned and characterized 18 different members of an extremely large multigene family that encodes seven transmembrane domain proteins whose expression is restricted to the olfactory epithelium. The members of this novel gene family are likely to encode a diverse family of odorant receptors.}},
    address = {Department of Biochemistry and Molecular Biophysics, College of Physicians and Surgeons, Columbia University, New York, New York 10032.},
    author = {Buck, L. and Axel, R.},
    citeulike-article-id = {423054},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/1840504},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=1840504},
    day = {5},
    issn = {0092-8674},
    journal = {Cell},
    keywords = {g\_protein\_coupled\_receptors, g\_proteins, odorant, odorant\_binding\_protein},
    month = apr,
    number = {1},
    pages = {175--187},
    posted-at = {2011-01-14 12:57:32},
    priority = {2},
    title = {{A novel multigene family may encode odorant receptors: a molecular basis for odor recognition.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/1840504},
    volume = {65},
    year = {1991}
}

@article{citeulike:1642785,
    abstract = {{Insects have an enormous impact on global public health as disease vectors and as agricultural enablers as well as pests and olfaction is an important sensory input to their behavior. As such it is of great value to understand the interplay of the molecular components of the olfactory system which, in addition to fostering a better understanding of insect neurobiology, may ultimately aid in devising novel intervention strategies to reduce disease transmission or crop damage. Since the first discovery of odorant receptors in vertebrates over a decade ago, much of our view on how the insect olfactory system might work has been derived from observations made in vertebrates and other invertebrates, such as lobsters or nematodes. Together with the advantages of a wide range of genetic tools, the identification of the first insect odorant receptors in Drosophila melanogaster in 1999 paved the way for rapid progress in unraveling the question of how olfactory signal transduction and processing occurs in the fruitfly. This review intends to summarize much of this progress and to point out some areas where advances can be expected in the near future.}},
    author = {R\"{u}tzler, M. and Zwiebel, L. J.},
    citeulike-article-id = {1642785},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00359-005-0044-y},
    citeulike-linkout-1 = {http://www.springerlink.com/content/g37492k14117774k},
    day = {1},
    doi = {10.1007/s00359-005-0044-y},
    issn = {0340-7594},
    journal = {Journal of Comparative Physiology A: Neuroethology, Sensory, Neural, and Behavioral Physiology},
    keywords = {g\_protein\_coupled\_receptors, g\_proteins, odorant, odorant\_binding\_protein, or},
    month = sep,
    number = {9},
    pages = {777--790},
    posted-at = {2011-01-14 12:23:46},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {{Molecular biology of insect olfaction:recent progress and conceptual models}},
    url = {http://dx.doi.org/10.1007/s00359-005-0044-y},
    volume = {191},
    year = {2005}
}

@article{citeulike:6890081,
    abstract = {{Pristionchus pacificus is a nematode model organism whose genome has recently been sequenced. To refine the genome annotation we performed transcriptome and proteome analysis and gathered comprehensive experimental information on gene expression. Transcriptome analysis on a 454 Life Sciences (Roche) FLX platform generated >700,000 expressed sequence tags (ESTs) from two normalized EST libraries, whereas proteome analysis on an LTQ-Orbitrap mass spectrometer detected >27,000 nonredundant peptide sequences from more than 4000 proteins at sub-parts-per-million (ppm) mass accuracy and a false discovery rate of <1\%. Retraining of the SNAP gene prediction algorithm using the gene expression data led to a decrease in the number of previously predicted protein-coding genes from 29,000 to 24,000 and refinement of numerous gene models. The P. pacificus proteome contains a high proportion of small proteins with no known homologs in other species ("pioneer" proteins). Some of these proteins appear to be products of highly homologous genes, pointing to their common origin. We show that >50\% of all pioneer genes are transcribed under standard culture conditions and that pioneer proteins significantly contribute to a unimodal distribution of predicted protein sizes in P. pacificus, which has an unusually low median size of 240 amino acids (26.8 kDa). In contrast, the predicted proteome of Caenorhabditis elegans follows a distinct bimodal protein size distribution, with significant functional differences between small and large protein populations. Combined, these results provide the first catalog of the expressed genome of P. pacificus, refinement of its genome annotation, and the first comparison of related nematode models at the proteome level.}},
    author = {Borchert, Nadine and Dieterich, Christoph and Krug, Karsten and Sch\"{u}tz, Wolfgang and Jung, Stephan and Nordheim, Alfred and Sommer, Ralf J. and Macek, Boris},
    citeulike-article-id = {6890081},
    citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.103119.109},
    citeulike-linkout-1 = {http://genome.cshlp.org/content/early/2010/04/21/gr.103119.109.abstract},
    citeulike-linkout-2 = {http://genome.cshlp.org/content/early/2010/04/21/gr.103119.109.full.pdf},
    citeulike-linkout-3 = {http://genome.cshlp.org/cgi/content/abstract/20/6/837},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/20237107},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=20237107},
    day = {17},
    doi = {10.1101/gr.103119.109},
    issn = {1549-5469},
    journal = {Genome research},
    keywords = {odorant, odorant\_binding\_protein},
    month = jun,
    number = {6},
    pages = {837--846},
    posted-at = {2011-01-14 09:47:37},
    priority = {2},
    title = {{Proteogenomics of Pristionchus pacificus reveals distinct proteome structure of nematode models.}},
    url = {http://dx.doi.org/10.1101/gr.103119.109},
    volume = {20},
    year = {2010}
}

@article{citeulike:8031121,
    abstract = {{BACKGROUND:Roche 454 pyrosequencing has become a method of choice for generating transcriptome data from non-model organisms. Once the tens to hundreds of thousands of short (250-450 base) reads have been produced, it is important to correctly assemble these to estimate the sequence of all the transcripts. Most transcriptome assembly projects use only one program for assembling 454 pyrosequencing reads, but there is no evidence that the programs used to date are optimal. We have carried out a systematic comparison of five assemblers (CAP3, MIRA, Newbler, SeqMan and CLC) to establish best practices for transcriptome assemblies, using a new dataset from the parasitic nematode Litomosoides sigmodontis.RESULTS:Although no single assembler performed best on all our criteria, Newbler 2.5 gave longer contigs, better alignments to some reference sequences, and was fast and easy to use. SeqMan assemblies performed best on the criterion of recapitulating known transcripts, and had more novel sequence than the other assemblers, but generated an excess of small, redundant contigs. The remaining assemblers all performed almost as well, with the exception of Newbler 2.3 (the version currently used by most assembly projects), which generated assemblies that had significantly lower total length. As different assemblers use different underlying algorithms to generate contigs, we also explored merging of assemblies and found that the merged datasets not only aligned better to reference sequences than individual assemblies, but were also more consistent in the number and size of contigs.CONCLUSIONS:Transcriptome assemblies are smaller than genome assemblies and thus should be more computationally tractable, but are often harder because individual contigs can have highly variable read coverage. Comparing single assemblers, Newbler 2.5 performed best on our trial data set, but other assemblers were closely comparable. Combining differently optimal assemblies from different programs however gave a more credible final product, and this strategy is recommended.}},
    author = {Kumar, Sujai and Blaxter, Mark},
    citeulike-article-id = {8031121},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2164-11-571},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/20950480},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=20950480},
    doi = {10.1186/1471-2164-11-571},
    issn = {1471-2164},
    journal = {BMC Genomics},
    keywords = {g\_protein\_coupled\_receptors, odorant, odorant\_binding\_protein},
    number = {1},
    pages = {571+},
    posted-at = {2011-01-14 09:47:18},
    priority = {2},
    title = {{Comparing de novo assemblers for 454 transcriptome data}},
    url = {http://dx.doi.org/10.1186/1471-2164-11-571},
    volume = {11},
    year = {2010}
}

@article{citeulike:8604053,
    abstract = {{Male moths are endowed with odorant receptors (ORs) to detect species-specific sex pheromones with remarkable sensitivity and selectivity. We serendipitously discovered that an endogenous OR in the fruit fly, Drosophila melanogaster, is highly sensitive to the sex pheromone of the silkworm moth, bombykol. Intriguingly, the fruit fly detectors are more sensitive than the receptors of the silkworm moth, although its ecological significance is unknown. By expression in the  ” empty neuron” system, we identified the fruit fly bombykol-sensitive OR as DmelOR7a (= DmOR7a). The profiles of this receptor in response to bombykol in the native sensilla (ab4) or expressed in the empty neuron system (ab3 sensilla) are indistinguishable. Both WT and transgenic flies responded with high sensitivity, in a dose-dependent manner, and with rapid signal termination. In contrast, the same empty neuron expressing the moth bombykol receptor, BmorOR1, demonstrated low sensitivity and slow signal inactivation. When expressed in the trichoid sensilla T1 of the fruit fly, the neuron housing BmorOR1 responded with sensitivity comparable to that of the native trichoid sensilla in the silkworm moth. By challenging the native bombykol receptor in the fruit fly with high doses of another odorant to which the receptor responds with the highest sensitivity, we demonstrate that slow signal termination is induced by overdose of a stimulus. As opposed to the empty neuron system in the basiconic sensilla, the structural, biochemical, and/or biophysical features of the sensilla make the T1 trichoid system of the fly a better surrogate for the moth receptor.}},
    author = {Syed, Zainulabeuddin and Kopp, Artyom and Kimbrell, Deborah A. and Leal, Walter S.},
    citeulike-article-id = {8604053},
    citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.1003881107},
    citeulike-linkout-1 = {http://www.pnas.org/content/early/2010/04/28/1003881107.abstract},
    citeulike-linkout-2 = {http://www.pnas.org/content/early/2010/04/28/1003881107.full.pdf},
    citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/20439725},
    citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=20439725},
    doi = {10.1073/pnas.1003881107},
    journal = {Proceedings of the National Academy of Sciences},
    keywords = {odorant, odorant\_binding\_protein, pheromone},
    posted-at = {2011-01-14 07:46:04},
    priority = {2},
    title = {{Bombykol receptors in the silkworm moth and the fruit fly}},
    url = {http://dx.doi.org/10.1073/pnas.1003881107}
}

@article{citeulike:8599306,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Bryant, A. and Kirkham, J. A.},
    citeulike-article-id = {8599306},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1010897},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1010891.1010897},
    doi = {10.1145/1010891.1010897},
    issn = {0163-5948},
    journal = {SIGSOFT Softw. Eng. Notes},
    keywords = {msr-2011},
    month = jul,
    pages = {44--60},
    posted-at = {2011-01-13 20:11:51},
    priority = {2},
    publisher = {ACM},
    title = {{B. W. Boehm software engineering economics: a review essay}},
    url = {http://dx.doi.org/10.1145/1010891.1010897},
    volume = {8},
    year = {1983}
}

@article{citeulike:8596983,
    abstract = {{The article examines a statistical analysis of a productivity
variation, involving a unique database containing 206 business software
projects from 26 Finnish companies. The authors examine differences in
the factors, explaining productivity in the banking, insurance,
manufacturing, wholesale/retail, and public administration sectors. The
authors provide productivity benchmarking equations that are useful both
for estimating expected productivity at the start of a new project and
for benchmarking a completed project for each business sector}},
    author = {Maxwell, K. D. and Forselius, P.},
    citeulike-article-id = {8596983},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/52.820015},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=820015},
    doi = {10.1109/52.820015},
    issn = {07407459},
    journal = {IEEE Software},
    keywords = {msr-2011},
    month = jan,
    number = {1},
    pages = {80--88},
    posted-at = {2011-01-13 14:18:52},
    priority = {2},
    title = {{Benchmarking software development productivity}},
    url = {http://dx.doi.org/10.1109/52.820015},
    volume = {17},
    year = {2000}
}

@article{citeulike:7019087,
    abstract = {{Time is an essential measure of performance in software
development because time delays tend to fall directly to the bottom
line. To address this issue, this research seeks to distinguish
time-based software development practices: those managerial actions that
result in faster development speed and higher productivity. This study
is based upon a survey of software management practices in Western
Europe and builds upon an earlier study we carried out in the United
States and Japan (Integrated Manufacturing Systems, vol. 7, no. 2,
1996). We measure the extent to which managers in the USA, Japan and
Europe differ in their management of software projects and also
determine the tools, technology and practices that separate fast and
slow developers in Western Europe}},
    author = {Blackburn, J. D. and Scudder, G. D. and Van Wassenhove, L. N.},
    citeulike-article-id = {7019087},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/32.553636},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=553636},
    doi = {10.1109/32.553636},
    issn = {00985589},
    journal = {IEEE Transactions on Software Engineering},
    keywords = {msr-2011},
    month = dec,
    number = {12},
    pages = {875--885},
    posted-at = {2011-01-13 14:17:37},
    priority = {2},
    title = {{Improving speed and productivity of software development: a global survey of software developers}},
    url = {http://dx.doi.org/10.1109/32.553636},
    volume = {22},
    year = {1996}
}

@article{citeulike:938392,
    abstract = {{The identification, combination, and interaction of the many
factors which influence software development productivity makes the
measurement, estimation, comparison and tracking of productivity rates
very difficult. Through the analysis of a European Space Agency database
consisting of 99 software development projects from 37 companies in a
European countries, the paper seeks to provide significant and useful
Information about the major factors which influence the productivity of
European space, military, and industrial applications, as well as to
determine the best metric for measuring the productivity of these
projects. Several key findings emerge from the study. The results
indicate that some organizations are obtaining significantly higher
productivity than others. Some of this variation is due to the
differences in the application category and programming language of
projects in each company; however, some differences must also be due to
the ways in which these companies manage their software development
projects. The use of tools and modern programming practices were found
to be major controllable factors in productivity improvement. Finally,
the lines-of-code productivity metric is shown to be superior to the
process productivity metric for projects in the authors' database}},
    author = {Maxwell, K. D. and Van Wassenhove, L. and Dutta, S.},
    citeulike-article-id = {938392},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/32.544349},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=544349},
    doi = {10.1109/32.544349},
    issn = {00985589},
    journal = {IEEE Transactions on Software Engineering},
    keywords = {msr-2011},
    month = oct,
    number = {10},
    pages = {706--718},
    posted-at = {2011-01-13 14:08:20},
    priority = {2},
    title = {{Software development productivity of European space, military, and industrial applications}},
    url = {http://dx.doi.org/10.1109/32.544349},
    volume = {22},
    year = {1996}
}

@inproceedings{citeulike:8596894,
    abstract = {{Various measures and methods have been developed to measure the sizes of different software entities produced throughout the software life cycle. Understanding the nature of the relationship between the sizes of these products has become significant due to various reasons. One major reason is the ability to predict the size of the later phase products by using the sizes of early life cycle products. For example, we need to predict the Source Lines of Code (SLOC) from Function Points (FP) since SLOC is being used as the main input for most of the estimation models when this measure is not available yet. SLOC/FP ratios have been used by the industry for such purposes even though the assumed linear relationship has not been validated yet. Similarly, FP has recently started to be used to predict the Bytes of code for estimating the amount of spare memory needed in systems. In this paper, we aim to investigate further the nature of the relationship between the software functional size and the code size by conducting a series of empirical studies.}},
    author = {Gencel, Cigdem and Heldal, Rogardt and Lind, Kenneth},
    citeulike-article-id = {8596894},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/APSEC.2009.51},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5358475},
    doi = {10.1109/APSEC.2009.51},
    keywords = {msr-2011},
    location = {Batu Ferringhi, Penang, Malaysia},
    month = dec,
    pages = {19--26},
    posted-at = {2011-01-13 14:06:07},
    priority = {2},
    title = {{On the Relationship between Different Size Measures in the Software Life Cycle}},
    url = {http://dx.doi.org/10.1109/APSEC.2009.51},
    year = {2009}
}

@article{citeulike:8596749,
    abstract = {{A simple method measuring new effective lines of code showed that between 19 and 40 percent of code written on three projects wasn't in the final release. Generally, productivity is a function of input effort and output size. A strong understanding of software productivity, coupled with a good estimate of software size, is key to predicting project effort and, ultimately, producing reliable project duration estimates, schedules, and resource needs. Project managers and engineers often measure or predict the size of released software-the volume of software in the marketed product. However, the final release doesn't include reworked code-code that was changed or deleted during development.}},
    author = {Morozoff, E.},
    citeulike-article-id = {8596749},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/MS.2009.160},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5232799},
    doi = {10.1109/MS.2009.160},
    issn = {0740-7459},
    journal = {IEEE Software},
    keywords = {msr-2011},
    month = jan,
    number = {1},
    pages = {72--77},
    posted-at = {2011-01-13 14:04:33},
    priority = {2},
    title = {{Using a Line of Code Metric to Understand Software Rework}},
    url = {http://dx.doi.org/10.1109/MS.2009.160},
    volume = {27},
    year = {2010}
}

@inproceedings{citeulike:6346098,
    abstract = {{Source lines of code (SLOC) is perhaps the oldest of software
metrics, and still a benchmark for evaluating new ones. Despite the
extensive experience with the SLOC metric, there are still a number of
misconceptions about it. The paper addresses three of them: (1) that the
format of SLOC is relevant to how to properly count it (a simple
experiment shows that, in fact, it does not matter), (2) that SLOC is
most useful as a predictor of software quality (in fact it is most
useful as a covariate of other predictors), and (3) that there is an
important inverse relationship between defect density and code size (in
fact, this is an arithmetic artifact of plotting bugs-per-SLOC against
SLOC)}},
    address = {Los Alamitos, CA, USA},
    author = {Rosenberg, J.},
    citeulike-article-id = {6346098},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/METRIC.1997.637174},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/METRIC.1997.637174},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=637174},
    day = {7},
    doi = {10.1109/METRIC.1997.637174},
    isbn = {0-8186-8093-8},
    journal = {Software Metrics Symposium, 1997. Proceedings., Fourth International},
    keywords = {msr-2011},
    location = {Albuquerque, NM, USA},
    month = nov,
    pages = {137--142},
    posted-at = {2011-01-13 13:23:13},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {{Some misconceptions about lines of code}},
    url = {http://dx.doi.org/10.1109/METRIC.1997.637174},
    volume = {0},
    year = {1997}
}

@article{citeulike:8484508,
    abstract = {{Odorant receptors comprise a unique family of G-protein-coupled seven-transmembrane receptors both in mammals and insects. In the fruit fly Drosophila melanogaster, all 61 candidate odorant receptor genes have been identified based on the complete genome sequence, and their expression patterns have been examined. A given odorant receptor is expressed in the antenna or maxillary palp, or not expressed at all. Here we have applied a set of statistical analyses to the length of the extra- and intracellular loops and terminals (LTs) of Drosophila odorant receptors to examine possible inter- and intramolecular relations at the population level. We have first provided some useful statistical information such as mean length values and length histograms to depict a general nature of Drosophila odorant receptors at the population level, after focusing on discrepancy on assigning transmembrane domains between researchers. In a preferable transmembrane assignment, all extracellular LTs, especially the second extracellular loops, were relatively large in length, suggesting their functional significance. Somewhat surprisingly, principle component analysis (PCA) indicated that the maxillary palp receptors were almost as diverse as the antenna receptors despite their much smaller population size. PCA together with histograms also revealed that receptors with an abnormal length configuration tended not to be expressed, suggesting that LT length deviations are related to transcriptional silencing of odorant receptor genes. Rank transformation tests pointed out possible LTs that could have different length between differently expressed receptors at the population level. Taken together, length analyses provide us with a general picture, i.e.  ” length configuration,” of Drosophila odorant receptors at the population level that could point out putatively important functional sites for experimental studies.}},
    author = {Otaki, J.},
    citeulike-article-id = {8484508},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0022-5193(03)00068-7},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0022-5193(03)00068-7},
    day = {07},
    doi = {10.1016/S0022-5193(03)00068-7},
    issn = {00225193},
    journal = {Journal of Theoretical Biology},
    keywords = {odorant, odorant\_binding\_protein, pheromone},
    month = jul,
    number = {1},
    pages = {27--37},
    posted-at = {2010-12-25 18:18:07},
    priority = {2},
    title = {{Length analyses of Drosophila odorant receptors}},
    url = {http://dx.doi.org/10.1016/S0022-5193(03)00068-7},
    volume = {223},
    year = {2003}
}

@article{citeulike:8484507,
    abstract = {{ In 1999, three groups independently identified a large family of candidate Drosophila odorant receptor genes ([2, 3 and 5]). These genes encode novel seven transmembrane domain receptor proteins that are selectively expressed in subsets of olfactory receptor neurons in the fruit fly. A total of 19 candidate odorant receptors were described in the initial reports, and these were named according to three different nomenclature systems, resulting in multiple names for a given receptor. With the recent completion of the euchromatic genome sequence of Drosophila ([1 and 4]), the number of identified genes with homology to the candidate odorant receptors has increased to a total of 60. These have been annotated by Celera Genomics in collaboration with the Berkeley Drosophila Genome Project using a fourth nomenclature system. To address this nomenclature problem, representatives of several laboratories met at the Association for Chemoreception Sciences meeting held in Sarasota, Florida, in April, 2000. Subsequently, representatives of FlyBase were consulted for their assistance in unifying the nomenclature. As a result of these discussions, a Drosophila Odorant Receptor Nomenclature Committee was formed to systematize and unify the Drosophila odorant receptor nomenclature. Table 1 presents a summary of the proposed nomenclature, which has recently been endorsed by a number of scientists working in the field. Rationale of the SystemGenes in Drosophila are typically named to convey functional information, usually reflecting a mutant phenotype. When mutants are not available, the gene name instead often conveys information about chromosomal position. The Drosophila genome has been divided into 102 numbered segments, based on characteristic banding patterns visible on polytene chromosomes. The cytogenetic positions of the 60 odorant receptors have been inferred by linkage to known mapped genes, but have not been precisely determined. Recognizing this inherent uncertainty, yet desiring to convey positional information in the unified nomenclature, the Committee proposes that each Drosophila odorant receptor be named according to its location within the primary numbered cytogenetic units. Where there is only one candidate receptor within a given numbered region, it is appended with the small letter  ” a.” In cases where there are multiple receptors within a numbered region, these are supplied with a small letter as a unique identifier according to relative position on the cytogenetic map. For instance, the two odorant receptors in division 43 on the second chromosome are named Or43a and Or43b, corresponding to map positions 43A1 and 43F5, respectively. In accordance with nomenclature standards developed by FlyBase, the letter  ” D” for Drosophila has been eliminated from the name and the generic symbol  ” Or,” for odorant receptor substituted. The benefit of this naming scheme is that general cytogenetic information is conveyed, thereby localizing receptors to within approximately 1\% of the genome. The omission of more specific number and letter subdivisions in the nomenclature insulates the new names from readjustments of cytological positions of Drosophila genes that will undoubtedly occur as more accurate alignments between the cytogenetic map and genomic sequence are made.Naming New SequencesA total of 60 Drosophila odorant receptors have been identified and named by members of the Committee. In the eventuality that additional genes are discovered, these should be named according to the scheme described above. Where possible, the assistance of FlyBase (flybase-help@morgan.harvard.edu) should be sought. Additional information on the odorant receptors in the fly genome is available at web sites maintained by FlyBase (http://flybase.bio.indiana.edu), the Berkeley Drosophila Genome Project (http://www.fruitfly.org), and the National Center for Biotechnology Information (http://www.ncbi.nlm.nih.gov). We recommend that this nomenclature be used in future publications. }},
    citeulike-article-id = {8484507},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0092-8674(00)00020-9},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0092-8674(00)00020-9},
    doi = {10.1016/S0092-8674(00)00020-9},
    issn = {00928674},
    journal = {Cell},
    keywords = {odorant\_binding\_protein, protein\_coupled\_receptors, receptor\_type, receptors},
    month = jul,
    number = {2},
    pages = {145--146},
    posted-at = {2010-12-25 18:16:41},
    priority = {2},
    title = {{A Unified Nomenclature System for the Drosophila Odorant Receptors}},
    url = {http://dx.doi.org/10.1016/S0092-8674(00)00020-9},
    volume = {102},
    year = {2000}
}

@article{citeulike:8484504,
    abstract = {{For most organisms, chemosensation is critical for survival and is mediated by large families of chemoreceptor proteins, whose expression must be tuned appropriately to changes in the chemical environment. We asked whether expression of chemoreceptor genes that are clustered in the genome would be regulated independently; whether expression of certain chemoreceptor genes would be especially sensitive to environmental changes; whether groups of chemoreceptor genes undergo coordinated rexpression; and how plastic the expression of chemoreceptor genes is with regard to sex, development, reproductive state, and social context. To answer these questions we used Drosophila melanogaster , because its chemosensory systems are well characterized and both the genotype and environment can be controlled precisely. Using customized cDNA microarrays, we showed that chemoreceptor genes that are clustered in the genome undergo independent transcriptional regulation at different developmental stages and between sexes. Expression of distinct subgroups of chemoreceptor genes is sensitive to reproductive state and social interactions. Furthermore, exposure of flies only to odor of the opposite sex results in altered transcript abundance of chemoreceptor genes. These genes are distinct from those that show transcriptional plasticity when flies are allowed physical contact with same or opposite sex members. We analyzed covariance in transcript abundance of chemosensory genes across all environmental conditions and found that they segregated into 20 relatively small, biologically relevant modules of highly correlated transcripts. This finely pixilated modular organization of the chemosensory subgenome enables fine tuning of the expression of the chemoreceptor repertoire in response to ecologically relevant environmental and physiological conditions.}},
    author = {Zhou, Shanshan and Stone, Eric A. and Mackay, Trudy F. C. and Anholt, Robert R. H.},
    citeulike-article-id = {8484504},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pgen.1000681},
    day = {9},
    doi = {10.1371/journal.pgen.1000681},
    journal = {PLoS Genet},
    keywords = {odorant, odorant\_binding\_protein, protein\_coupled\_receptors},
    month = oct,
    number = {10},
    pages = {e1000681+},
    posted-at = {2010-12-25 18:11:57},
    priority = {2},
    publisher = {Public Library of Science},
    title = {{Plasticity of the Chemoreceptor Repertoire in Drosophila melanogaster}},
    url = {http://dx.doi.org/10.1371/journal.pgen.1000681},
    volume = {5},
    year = {2009}
}

@article{citeulike:8484501,
    abstract = {{We identified a large family of putative odorant-binding protein (OBP) genes in the genome of Drosophila melanogaster. Some of these genes are present in large clusters in the genome. Most members are expressed in various taste organs, including gustatory sensilla in the labellum, the pharyngeal labral sense organ, dorsal and ventral cibarial organs, as well as taste bristles located on the wings and tarsi. Some of the gustatory OBPs are expressed exclusively in taste organs, but most are expressed in both olfactory and gustatory sensilla. Multiple binding proteins can be coexpressed in the same gustatory sensillum. Cells in the tarsi that express OBPs are required for normal chemosensation mediated through the leg, as ablation of these cells dramatically reduces the sensitivity of the proboscis extension reflex to sucrose. Finally, we show that OBP genes expressed in the pharyngeal taste sensilla are still expressed in the poxneuro genetic background while OBPs expressed in the labellum are not. These findings support a broad role for members of the OBP family in gustation and olfaction and suggest that poxneuro is required for cell fate determination of labellar but not pharyngeal taste organs.}},
    author = {Galindo, K. and Smith, D. P.},
    citeulike-article-id = {8484501},
    citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/11729153]},
    citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=11729153]},
    issn = {0016-6731},
    journal = {Genetics},
    keywords = {pheromone, protein\_coupled\_receptors},
    month = nov,
    number = {3},
    pages = {1059--1072},
    posted-at = {2010-12-25 18:08:49},
    priority = {2},
    title = {{A large family of divergent Drosophila odorant-binding proteins expressed in gustatory and olfactory sensilla.}},
    url = {http://view.ncbi.nlm.nih.gov/pubmed/11729153]},
    volume = {159},
    year = {2001}
}

@article{citeulike:8484488,
    abstract = {{Olfaction is of considerable importance to many insects in behaviors critical for survival and reproduction, including location of food sources, selection of mates, recognition of colony con-specifics, and determination of oviposition sites. An ubiquitous, but poorly understood, component of the insect's olfactory system is a group of odorant-binding proteins (OBPs) that are present at high concentrations in the aqueous lymph surrounding the dendrites of olfactory receptor neurons. OBPs are believed to shuttle odorants from the environment to the underlying odorant receptors, for which they could potentially serve as odorant presenters. Here we show that the Drosophila genome carries 51 potential OBP genes, a number comparable to that of its odorant-receptor genes. We find that the majority (73\%) of these OBP-like genes occur in clusters of as many as nine genes, in contrast to what has been observed for the Drosophila odorant-receptor genes. Two of the presumptive OBP gene clusters each carries an odorant-receptor gene. We also report an intriguing subfamily of 12 putative OBPs that share a unique C-terminal structure with three conserved cysteines and a conserved proline. Members of this subfamily have not previously been described for any insect. We have performed phylogenetic analyses of the OBP-related proteins in Drosophila as well as other insects, and we discuss the duplication and divergence of the genes for this large family. [The sequence data from this study have been submitted to FlyBase. Annotations for these sequences are available as supplementary material at http://www.genome.org.]}},
    author = {Hekmat-Scafe, Daria S. and Scafe, Charles R. and McKinney, Aimee J. and Tanouye, Mark A.},
    citeulike-article-id = {8484488},
    citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.239402},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/12213773]},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=12213773]},
    doi = {10.1101/gr.239402},
    issn = {1088-9051},
    journal = {Genome research},
    keywords = {odorant, odorant\_binding\_protein, pheromone, receptors},
    month = sep,
    number = {9},
    pages = {1357--1369},
    posted-at = {2010-12-25 17:57:42},
    priority = {2},
    title = {{Genome-wide analysis of the odorant-binding protein gene family in Drosophila melanogaster.}},
    url = {http://dx.doi.org/10.1101/gr.239402},
    volume = {12},
    year = {2002}
}

@article{citeulike:8420112,
    abstract = {{A better understanding of the individual developers' performance has been shown to result in benefits such as improved project estimation accuracy and enhanced software quality assurance. However, new challenges of distinguishing the individual activities involved in software evolution arise when considering collaborative development environments. Since Software repositories such as version control systems (VCS) and bug tracking systems (BTS) are available for most software projects and hold a detailed and rich record of the historical development information, this paper presents our experiences mining individual performance indicators in collaborative development environments by using these repositories. The base of our key idea is to identify the complexity metrics (in the code base) and field defects(from bug tracking system) at individual-level by incorporating the historical data from version control system. We also remotely measure and analyze these indicators mined from a libre project jEdit, which involves around one hundred developer. The results show that these indicators are feasible and instructive in the understanding of the individual performance.}},
    address = {Los Alamitos, CA, USA},
    author = {Zhang, Shen and Wang, Yongji and Xiao, Junchao},
    citeulike-article-id = {8420112},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/APSEC.2008.12},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/APSEC.2008.12},
    doi = {10.1109/APSEC.2008.12},
    issn = {1530-1362},
    journal = {Asia-Pacific Software Engineering Conference},
    keywords = {msr},
    pages = {247--254},
    posted-at = {2010-12-13 10:02:53},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {{Mining Individual Performance Indicators in Collaborative Development Using Software Repositories}},
    url = {http://dx.doi.org/10.1109/APSEC.2008.12},
    volume = {0},
    year = {2008}
}

@inproceedings{citeulike:797370,
    abstract = {{Over 200 CVS repositories representing the assignments of students in a second year undergraduate computer science course have been assembled. This unique data set represents many individuals working separately on identical projects, presenting the opportunity to evaluate the effects of the work habits captured by CVS on performance. This paper outlines our experiences mining and analyzing these repositories. We extracted various quantitative measures of student behaviour and code quality, and attempted to correlate these features with grades. Despite examining 166 features, we find that grade performance cannot be accurately predicted; certainly no predictors stronger than simple lines-of-code were found.}},
    address = {New York, NY, USA},
    author = {Mierle, Keir and Laven, Kevin and Roweis, Sam and Wilson, Greg},
    booktitle = {Proceedings of the 2005 international workshop on Mining software repositories},
    citeulike-article-id = {797370},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1083150},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1083142.1083150},
    doi = {10.1145/1083142.1083150},
    isbn = {1-59593-123-6},
    keywords = {msr},
    location = {St. Louis, Missouri},
    pages = {1--5},
    posted-at = {2010-12-13 09:33:41},
    priority = {2},
    publisher = {ACM},
    series = {MSR '05},
    title = {{Mining student CVS repositories for performance indicators}},
    url = {http://dx.doi.org/10.1145/1083142.1083150},
    year = {2005}
}

@article{citeulike:8383204,
    abstract = {{Abstract The insect chemoreceptor superfamily, consisting of the odorant receptor (Or) and gustatory receptor (Gr) families, exhibits patterns of evolution ranging from highly conserved proteins to lineage-specific gene subfamily expansions when compared across insect suborders and orders. Here their evolution across the timespan of 25 million years is examined which yield orthologous divergences ranging from 5?50\%. They also reveal the beginnings of lineage-specific gene subfamilies as multiple duplications of particular gene lineages in either or both Drosophila melanogaster and D. pseudoobscura (Frolova and Astaurov) (Diptera: Drosophilidae). Gene losses and pseudogenes are similarly evident in both lineages, and even in closer comparisons of D. melanogaster with D. yakuba, leaving these species with roughly similar numbers of chemoreceptors despite considerable gene turnover. The large range of divergences and gene duplications provide abundant raw material for studies of structure and function in this novel superfamily, which contains proteins that evolved to bind specific ligands that mediate much of the ecology and mating behavior of insects. Abstract The insect chemoreceptor superfamily, consisting of the odorant receptor (Or) and gustatory receptor (Gr) families, exhibits patterns of evolution ranging from highly conserved proteins to lineage-specific gene subfamily expansions when compared across insect suborders and orders. Here their evolution across the timespan of 25 million years is examined which yield orthologous divergences ranging from 5?50\%. They also reveal the beginnings of lineage-specific gene subfamilies as multiple duplications of particular gene lineages in either or both Drosophila melanogaster and D. pseudoobscura (Frolova and Astaurov) (Diptera: Drosophilidae). Gene losses and pseudogenes are similarly evident in both lineages, and even in closer comparisons of D. melanogaster with D. yakuba, leaving these species with roughly similar numbers of chemoreceptors despite considerable gene turnover. The large range of divergences and gene duplications provide abundant raw material for studies of structure and function in this novel superfamily, which contains proteins that evolved to bind specific ligands that mediate much of the ecology and mating behavior of insects.}},
    author = {Robertson, Hugh M.},
    citeulike-article-id = {8383204},
    citeulike-linkout-0 = {http://www.bioone.org/doi/abs/10.1673/031.009.1801},
    citeulike-linkout-1 = {http://dx.doi.org/10.1673/031.009.1801},
    day = {8},
    doi = {10.1673/031.009.1801},
    journal = {Journal of Insect Science},
    keywords = {lepidopteran, protein\_coupled\_receptors, receptor\_type, receptors},
    month = dec,
    number = {18},
    pages = {1--14},
    posted-at = {2010-12-08 10:37:30},
    priority = {2},
    publisher = {University of Wisconsin Library},
    title = {{The Insect Chemoreceptor Superfamily in Drosophila pseudoobscura: Molecular Evolution of Ecologically-Relevant Genes Over 25 Million Years}},
    url = {http://dx.doi.org/10.1673/031.009.1801},
    volume = {9},
    year = {2010}
}

@article{citeulike:8383133,
    abstract = {{Candidate olfactory receptors of the moth Heliothis virescens were found to be extremely diverse from receptors of the fruitfly Drosophila melanogaster and the mosquito Anopheles gambiae, but there is one exception. The moth receptor type HR2 shares a rather high degree of sequence identity with one olfactory receptor type both from Drosophila (Dor83b) and from Anopheles (AgamGPRor7); moreover, in contrast to all other receptors, this unique receptor type is expressed in numerous antennal neurons. Here we describe the identification of HR2 homologues in two further lepidopteran species, the moths Antheraea pernyi and Bombyx mori, which share 86–88\% of their amino acids. In addition, based on RT-PCR experiments HR2 homologues were discovered in antennal cDNA of the honey bee ( Apis mellifera; Hymenoptera), the blowfly ( Calliphora erythrocephala; Diptera) and the mealworm ( Tenebrio molitor; Coleoptera). Comparison of all HR2-related receptors revealed a high degree of sequence conservation across insect orders. In situ hybridization of antennal sections from the bee and the blowfly support the notion that HR2-related receptors are generally expressed in a very large number of antennal cells. This, together with the high degree of conservation suggests that this unique receptor subtype may fulfill a special function in chemosensory neurons of insects.}},
    author = {Krieger, J. and Klink, O. and Mohl, C. and Raming, K. and Breer, H.},
    citeulike-article-id = {8383133},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00359-003-0427-x},
    citeulike-linkout-1 = {http://www.springerlink.com/content/pcmvpay37891grk1},
    day = {1},
    doi = {10.1007/s00359-003-0427-x},
    issn = {0340-7594},
    journal = {Journal of Comparative Physiology A: Neuroethology, Sensory, Neural, and Behavioral Physiology},
    keywords = {lepidopteran, mellifera, receptor\_type, receptors},
    month = jul,
    number = {7},
    pages = {519--526},
    posted-at = {2010-12-08 10:22:38},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {{A candidate olfactory receptor subtype highly conserved across different insect orders}},
    url = {http://dx.doi.org/10.1007/s00359-003-0427-x},
    volume = {189},
    year = {2003}
}

@inproceedings{citeulike:8347594,
    abstract = {{Understanding a program and its evolution is not satisfied only by looking at a current snapshot of its source code. Thus, a developer often examines a sequence of its snapshots stored in repositories of versioning systems, and identifies differences between two successive snapshots. Unfortunately, such differences do not represent individual changes of the source code. This paper proposes a mechanism for recording all editing operations a developer has applied to source code on an integrated development environment. The paper also shows a running implementation of the mechanism built as an Eclipse plug-in, which is called OperationRecorder. The experimental results with a small-scale program substantiate that it has a practical use from the viewpoint of its performance.}},
    address = {New York, NY, USA},
    author = {Omori, Takayuki and Maruyama, Katsuhisa},
    booktitle = {Proceedings of the 2008 international working conference on Mining software repositories},
    citeulike-article-id = {8347594},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1370750.1370758},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1370750.1370758},
    doi = {10.1145/1370750.1370758},
    isbn = {978-1-60558-024-1},
    keywords = {msr, spi, thesis},
    location = {Leipzig, Germany},
    pages = {31--34},
    posted-at = {2010-12-02 10:13:39},
    priority = {2},
    publisher = {ACM},
    series = {MSR '08},
    title = {{A change-aware development environment by recording editing operations of source code}},
    url = {http://dx.doi.org/10.1145/1370750.1370758},
    year = {2008}
}

@inproceedings{citeulike:8347569,
    abstract = {{Software engineering process information extracted from version control systems and bug tracking databases are widely used in empirical software engineering. In prior work, we showed that these data are plagued by quality deficiencies, which vary in its characteristics across projects. In addition, we showed that those deficiencies in the form of bias do impact the results of studies in empirical software engineering. While these findings affect software engineering researchers the impact on practitioners has not yet been substantiated. In this paper we, therefore, explore (i) if the process data quality and characteristics have an influence on the bug fixing process and (ii) if the process quality as measured by the process data has an influence on the product (i.e., software) quality. Specifically, we analyze six Open Source as well as two Closed Source projects and show that process data quality and characteristics have an impact on the bug fixing process: the high rate of empty commit messages in Eclipse, for example, correlates with the bug report quality. We also show that the product quality - measured by number of bugs reported - is affected by process data quality measures. These findings have the potential to prompt practitioners to increase the quality of their software process and its associated data quality.}},
    author = {Bachmann, Adrian and Bernstein, Abraham},
    citeulike-article-id = {8347569},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/MSR.2010.5463286},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5463286},
    doi = {10.1109/MSR.2010.5463286},
    keywords = {msr, psi, thesis},
    location = {Cape Town, South Africa},
    month = may,
    pages = {62--71},
    posted-at = {2010-12-02 09:55:40},
    priority = {2},
    title = {{When process data quality affects the number of bugs: Correlations in software engineering datasets}},
    url = {http://dx.doi.org/10.1109/MSR.2010.5463286},
    year = {2010}
}

@inproceedings{citeulike:7465518,
    abstract = {{Reliably predicting software defects is one of software engineering's holy grails. Researchers have devised and implemented a plethora of bug prediction approaches varying in terms of accuracy, complexity and the input data they require. However, the absence of an established benchmark makes it hard, if not impossible, to compare approaches. We present a benchmark for defect prediction, in the form of a publicly available data set consisting of several software systems, and provide an extensive comparison of the explanative and predictive power of well-known bug prediction approaches, together with novel approaches we devised. Based on the results, we discuss the performance and stability of the approaches with respect to our benchmark and deduce a number of insights on bug prediction models.}},
    author = {D'Ambros, Marco and Lanza, Michele and Robbes, Romain},
    booktitle = {MSR},
    citeulike-article-id = {7465518},
    citeulike-linkout-0 = {http://dblp.uni-trier.de/rec/bibtex/conf/msr/DAmbrosLR10},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/MSR.2010.5463279},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5463279},
    doi = {10.1109/MSR.2010.5463279},
    isbn = {978-1-4244-6803-4},
    keywords = {msr, psi, thesis},
    location = {Cape Town, South Africa},
    month = may,
    pages = {31--41},
    posted-at = {2010-12-02 09:46:30},
    priority = {2},
    publisher = {IEEE},
    title = {{An extensive comparison of bug prediction approaches}},
    url = {http://dx.doi.org/10.1109/MSR.2010.5463279},
    year = {2010}
}

@incollection{citeulike:8347443,
    address = {New York},
    author = {Humphrey, Watts and Konrad, Michael},
    booktitle = {Software Process Modeling},
    chapter = {6},
    citeulike-article-id = {8347443},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/0-387-24262-7\_6},
    citeulike-linkout-1 = {http://www.springerlink.com/content/rx5035w62g170m7w},
    doi = {10.1007/0-387-24262-7\_6},
    editor = {Basili, Victor R. and Acu\~{n}a, Silvia T. and Juristo, Natalia},
    isbn = {0-387-24261-9},
    keywords = {spi, thesis},
    pages = {141--161},
    posted-at = {2010-12-02 08:14:15},
    priority = {2},
    publisher = {Springer US},
    series = {International Series in Software Engineering},
    title = {{Motivation and Process Improvement}},
    url = {http://dx.doi.org/10.1007/0-387-24262-7\_6},
    volume = {10},
    year = {2005}
}

@incollection{citeulike:8347363,
    abstract = {{The success of software process improvement (SPI) implementation initiatives depends fundamentally of the strategies adopted to support the execution of such initiatives. Therefore, it is essential to define adequate SPI implementation strategies aiming to facilitate the achievement of organizational business goals and to increase the benefits of process improvements. The objective of this work is to present an approach to support the execution of SPI implementation initiatives. We also describe a methodology applied to capture knowledge related to critical success factors that influence SPI initiatives. This knowledge was used to define effective SPI strategies aiming to increase the success of SPI initiatives coordinated by a specific SPI consultancy organization. This work also presents the functionalities of a set of tools integrated in a process-centered knowledge management environment, named CORE-KM, customized to support the presented approach.}},
    address = {Berlin, Heidelberg},
    author = {Montoni, Mariano A. and Cerdeiral, Cristina and Zanetti, David and Cavalcanti da Rocha, Ana R.},
    booktitle = {Software Process Improvement},
    chapter = {15},
    citeulike-article-id = {8347363},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-85936-9\_15},
    citeulike-linkout-1 = {http://www.springerlink.com/content/q425133441912512},
    doi = {10.1007/978-3-540-85936-9\_15},
    editor = {O'Connor, Rory V. and Baddoo, Nathan and Smolander, Kari and Messnarz, Richard},
    isbn = {978-3-540-85934-5},
    issn = {1865-0929},
    keywords = {spi, thesis},
    pages = {164--175},
    posted-at = {2010-12-02 07:55:47},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Communications in Computer and Information Science},
    title = {{A Knowledge Management Approach to Support Software Process Improvement Implementation Initiatives}},
    url = {http://dx.doi.org/10.1007/978-3-540-85936-9\_15},
    volume = {16},
    year = {2008}
}

@incollection{citeulike:8347349,
    abstract = {{Continuous improvement of software development capability is fundamental for organizations to thrive in competitive markets. Nevertheless, Software Process Improvement (SPI) initiatives have demonstrated limited results because SPI managers usually fail to cope with factors that have influence on the success of SPI. In this paper, we present the results of a multi-strategy approach aiming to identify critical success factors (CSF) that have influence on SPI. The study results were confirmed by the literature review. The CSF were identified through a combination of qualitative and quantitative analyses of the results of a survey we conducted with SPI practitioners involved in Brazilian software industry experiences. We also identified the relationships of major factors that emerged from the survey. We expect that the major CSF presented in this paper can be used by SPI managers in the definition of SPI strategies aiming to enhance SPI initiatives success.}},
    address = {Berlin, Heidelberg},
    author = {Montoni, Mariano and Rocha, Ana},
    booktitle = {Software Process Improvement},
    chapter = {16},
    citeulike-article-id = {8347349},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-75381-0\_16},
    citeulike-linkout-1 = {http://www.springerlink.com/content/hg76q55232134234},
    doi = {10.1007/978-3-540-75381-0\_16},
    editor = {Abrahamsson, Pekka and Baddoo, Nathan and Margaria, Tiziana and Messnarz, Richard},
    isbn = {978-3-540-74765-9},
    issn = {0302-9743},
    keywords = {spi, thesis},
    pages = {175--186},
    posted-at = {2010-12-02 07:54:35},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{A Methodology for Identifying Critical Success Factors That Influence Software Process Improvement Initiatives: An Application in the Brazilian Software Industry}},
    url = {http://dx.doi.org/10.1007/978-3-540-75381-0\_16},
    volume = {4764},
    year = {2007}
}

@incollection{citeulike:8347324,
    abstract = {{In small software companies the resources available for SPI are often limited. With limited resources, the motivation of the employees becomes one of the key factors for SPI. In this article, the motivational factors affecting a small company's SPI efforts are discussed. In the research, we carried out interviews and a survey in a small Finnish software company considering the motivation towards SPI. The results are presented here and compared with earlier motivation research. There were differences revealed while comparing the motivating factors of smaller companies to those of larger ones. In large companies the focus seems to be on the business related motivators and in small ones the motivators related to comfortability of work are emphasized. Motivation survey and the interviews proved to be useful tools in planning the future SPI strategy. A lot of valuable information was discovered for planning and implementing the next steps of SPI.}},
    address = {Berlin, Heidelberg},
    author = {Valtanen, Anu and Sihvonen, Hanna-Miina},
    booktitle = {Software Process Improvement},
    chapter = {14},
    citeulike-article-id = {8347324},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-85936-9\_14},
    citeulike-linkout-1 = {http://www.springerlink.com/content/w51225422g2521v3},
    doi = {10.1007/978-3-540-85936-9\_14},
    editor = {O'Connor, Rory V. and Baddoo, Nathan and Smolander, Kari and Messnarz, Richard},
    isbn = {978-3-540-85934-5},
    issn = {1865-0929},
    keywords = {spi, thesis},
    pages = {152--163},
    posted-at = {2010-12-02 07:46:42},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Communications in Computer and Information Science},
    title = {{Employees' Motivation for SPI: Case Study in a Small Finnish Software Company}},
    url = {http://dx.doi.org/10.1007/978-3-540-85936-9\_14},
    volume = {16},
    year = {2008}
}

@article{citeulike:8347320,
    abstract = {{Software organizations can significantly improve the quality of their output if they have a defined and documented software process, together with the appropriate techniques and tools to measure its effectiveness. Without a defined process it is impossible to measure success or focus on how development capability can be enhanced. To date, a number of software process improvement frameworks have been developed and implemented. However, most of these models have been targeted at large-scale producers. Furthermore, they have applied to companies who use traditional development techniques. Smaller companies and those operating in development areas where speed of delivery is paramount have not, as yet, had process improvement paradigms available for adoption.}},
    author = {Coleman, Gerry and Verbruggen, Renaat},
    citeulike-article-id = {8347320},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/A:1008856624790},
    citeulike-linkout-1 = {http://www.springerlink.com/content/m4314n53861651p7},
    day = {1},
    doi = {10.1023/A:1008856624790},
    issn = {09639314},
    journal = {Software Quality Journal},
    keywords = {spi, thesis},
    month = jul,
    number = {2},
    pages = {107--122},
    posted-at = {2010-12-02 07:45:42},
    priority = {2},
    publisher = {Springer Netherlands},
    title = {{A Quality Software Process for Rapid Application Development}},
    url = {http://dx.doi.org/10.1023/A:1008856624790},
    volume = {7},
    year = {1998}
}

@article{citeulike:8347315,
    abstract = {This paper provides the author's personal views and perspectives on software process improvement. Starting with his first work on technology assessment in IBM over 20 years ago, Watts Humphrey describes the process improvement work he has been directly involved in. This includes the development of the early process assessment methods, the original design of the CMM, and the introduction of the Personal Software Process (PSP)SM and Team Software Process (TSP){SM}. In addition to describing the original motivation for this work, the author also reviews many of the problems he and his associates encountered and why they solved them the way they did. He also comments on the outstanding issues and likely directions for future work. Finally, this work has built on the experiences and contributions of many people. Mr. Humphrey only describes work that he was personally involved in and he names many of the key contributors. However, so many people have been involved in this work that a full list of the important participants would be impractical.},
    author = {Humphrey, Watts S.},
    citeulike-article-id = {8347315},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/A:1020593305601},
    citeulike-linkout-1 = {http://www.springerlink.com/content/g52105122328w558},
    day = {1},
    doi = {10.1023/A:1020593305601},
    issn = {10227091},
    journal = {Annals of Software Engineering},
    keywords = {spi, thesis},
    month = dec,
    number = {1},
    pages = {39--72},
    posted-at = {2010-12-02 07:44:03},
    priority = {2},
    publisher = {Springer Netherlands},
    title = {{Three Process Perspectives: Organizations, Teams, and People}},
    url = {http://dx.doi.org/10.1023/A:1020593305601},
    volume = {14},
    year = {2002}
}

@article{citeulike:5969719,
    abstract = {{Olfaction, the sense of smell, depends on large, divergent families of odorant receptors that detect odour stimuli in the nose and transform them into patterns of neuronal activity that are recognised in the brain. The olfactory circuits in mammals and insects display striking similarities in their sensory physiology and neuroanatomy, which has suggested that odours are perceived by a conserved mechanism. Here I review recent revelations of significant structural and functional differences between the Drosophila and mammalian odorant receptor proteins and discuss the implications for our understanding of the evolutionary and molecular biology of the insect odorant receptors.}},
    author = {Benton, R.},
    citeulike-article-id = {5969719},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00018-006-6130-7},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/16786219},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=16786219},
    doi = {10.1007/s00018-006-6130-7},
    issn = {1420-682X},
    journal = {Cellular and molecular life sciences : CMLS},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors},
    month = jul,
    number = {14},
    pages = {1579--1585},
    posted-at = {2010-11-10 09:24:27},
    priority = {2},
    title = {{On the ORigin of smell: odorant receptors in insects.}},
    url = {http://dx.doi.org/10.1007/s00018-006-6130-7},
    volume = {63},
    year = {2006}
}

@article{citeulike:8227474,
    abstract = {{Abstract Insect odorant receptors are a large family of seven transmembrane proteins believed to be G-protein coupled receptors. The peptide sequences of two odorant receptors within a given species may share as little as 17\% identity, and there is limited similarity between receptors of divergent species. One exception is DmOr83b, which is found in Drosophila melanogaster and is highly conserved in at least ten other insect species. DmOr83b is broadly expressed in most of the olfactory sensory neurons of D. melanogaster at most developmental stages, while other odorant receptors tend to have more restricted and specific expression patterns. DmOr83b is critical for D. melanogaster olfaction, and it is involved in properly localizing other odorant receptors possibly by forming heterodimers with these receptors. The C-terminal region has been implicated as sites for such heterodimer formation. Multiple em for motif elicitation (MEME), a hidden markov model based program, was used to uncover three conserved motifs in the C-termini of a vast majority of the odorant receptor peptides from Anopheles gambiae, D. melanogaster, and Apis mellifera. These motifs are also found in DmOr83b and its orthologs and the order of these motifs is conserved as well. The conservation of these motifs among divergent odorant receptors in divergent species suggests functional importance. We propose that these motifs are involved in receptor- receptor protein interactions, contributing to the heterodimer formation between DmOr83b (or its orthologs) and other odorant receptors.}},
    author = {Miller, Raymond and Tu, Zhijian},
    citeulike-article-id = {8227474},
    citeulike-linkout-0 = {http://www.bioone.org/doi/abs/10.1673/031.008.5301},
    citeulike-linkout-1 = {http://dx.doi.org/10.1673/031.008.5301},
    day = {1},
    doi = {10.1673/031.008.5301},
    journal = {Journal of Insect Science},
    keywords = {g\_protein\_coupled\_receptor, g\_protein\_coupled\_receptors, g\_proteins},
    month = sep,
    number = {53},
    pages = {1--10},
    posted-at = {2010-11-10 09:22:51},
    priority = {2},
    publisher = {University of Wisconsin Library},
    title = {{Odorant Receptor C-Terminal Motifs in Divergent Insect Species}},
    url = {http://dx.doi.org/10.1673/031.008.5301},
    volume = {8},
    year = {2008}
}

@article{citeulike:8161676,
    abstract = {{BACKGROUND: The olfactory system plays an important role in the recognition of leaf volatiles during the search of folivore insects for a suitable plant host. For example, volatiles emitted by mulberry leaves trigger chemotaxis behavior in the silkworms Bombyx mori, and as a consequence, they preferentially reside on and consume mulberry leaves. Here, we aimed to identify natural chemoattractants and their corresponding olfactory receptors (Ors) involved in silkworm behavior to mulberry leaves. RESULTS: Chemotaxis behavioral assays for headspace volatiles detected by gas chromatography-mass spectroscopy analysis revealed that among the volatiles that were emitted by mulberry leaves, cis-jasmone was the most potent attractant for silkworms, working at a threshold of 0.3 pg from a 20 cm distance. Among a total of 66 Ors identified in the B. mori genome, we found that 23 were expressed in the olfactory organs during larval stages. Functional analysis of all the larvae-expressed Ors in Xenopus oocytes revealed that one Or, termed BmOr-56, showed a high sensitivity to cis-jasmone. In addition, the ligand-receptor activity of BmOr-56 reflected the chemotaxis behavioral response of silkworms. CONCLUSIONS: We identified cis-jasmone as a potent attractant in mulberry leaves for silkworms and provide evidence that a highly tuned receptor, BmOr-56, may mediate this behavioral attraction. The current study sheds light on the mechanism of the correlation between olfactory perception in folivore insects and chemotaxis behavior to a natural volatile emitted by green leaves.}},
    author = {Tanaka, Kana and Uda, Yusuke and Ono, Yukiteru and Nakagawa, Tatsuro and Suwa, Makiko and Yamaoka, Ryohei and Touhara, Kazushige},
    citeulike-article-id = {8161676},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cub.2009.04.035},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19427209},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19427209},
    day = {9},
    doi = {10.1016/j.cub.2009.04.035},
    issn = {1879-0445},
    journal = {Current biology : CB},
    keywords = {bombyx\_mori, odorant, pheromone},
    month = jun,
    number = {11},
    pages = {881--890},
    posted-at = {2010-11-01 10:15:36},
    priority = {2},
    title = {{Highly selective tuning of a silkworm olfactory receptor to a key mulberry leaf volatile.}},
    url = {http://dx.doi.org/10.1016/j.cub.2009.04.035},
    volume = {19},
    year = {2009}
}

@article{citeulike:1072363,
    abstract = {{Abstract Olfaction plays an important role in the life history of insects, including key behaviours such as host selection, oviposition and mate recognition. Odour perception by insects is primarily mediated by the large diverse family of odourant receptors (Ors) that are expressed on the dendrites of olfactory neurones housed within chemosensilla. However, few Or sequences have been identified from the Lepidoptera, an insect order that includes some of the most important pest species worldwide. We have identified 41 Or gene sequences from the silkworm (Bombyx mori) genome, more than double the number of published Or sequences from the Lepidoptera. Many silkworm Ors appear to be orthologs of the 17 published tobacco budworm (Heliothis virescens) Ors indicating that many Or lineages may be conserved within the Lepidoptera. The majority of the Or genes are expressed in adult female and male antennae (determined by quantitative real-time PCR analysis), supporting their probable roles in adult olfaction. Several Or genes are expressed at high levels in both male and female antennae, suggesting they mediate the perception of common host or conspecific volatiles important to both sexes. BmOrs 45–47 group together in the same phylogenetic branch and all three are expressed at moderate female-biased ratios, six to eight times higher in female compared to male moth antennae. Interestingly, BmOrs19 and 30 appear to be expressed predominantly in female antennae, opposite to that of the published silkworm pheromone receptors BmOrs 1 and 3 that are specific to male antennae. These results suggest that BmOr19 and 30 may detect odours critical to female behaviour, such as oviposition cues or male-produced courtship pheromones.}},
    author = {Wanner, K. W. and Anderson, A. R. and Trowell, S. C. and Theilmann, D. A. and Robertson, H. M. and Newcomb, R. D.},
    citeulike-article-id = {1072363},
    citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1365-2583.2007.00708.x},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/bsc/imb/2007/00000016/00000001/art00011},
    doi = {10.1111/j.1365-2583.2007.00708.x},
    issn = {0962-1075},
    journal = {Insect Molecular Biology},
    keywords = {odorant, pheromone},
    month = feb,
    number = {1},
    pages = {107--119},
    posted-at = {2010-10-31 14:38:26},
    priority = {2},
    publisher = {Blackwell Publishing Ltd},
    title = {{Female-biased expression of odourant receptor genes in the adult antennae of the silkworm, Bombyx mori}},
    url = {http://dx.doi.org/10.1111/j.1365-2583.2007.00708.x},
    volume = {16},
    year = {2007}
}

@article{Robertson:2006p8313,
    abstract = {{The honey bee genome sequence reveals a remarkable expansion of the insect odorant receptor (Or) family relative to the repertoires of the flies Drosophila melanogaster and Anopheles gambiae, which have 62 and 79 Ors respectively. A total of 170 Or genes were annotated in the bee, of which seven are pseudogenes. These constitute five bee-specific subfamilies in an insect Or family tree, one of which has expanded to a total of 157 genes encoding proteins with 15\%-99 amino acid identity. Most of the Or genes are in tandem arrays, including one with 60 genes. This bee-specific expansion of the Or repertoire presumably underlies their remarkable olfactory abilities, including perception of several pheromone blends, kin recognition signals, and diverse floral odors. The number of Apis mellifera Ors is approximately equal to the number of glomeruli in the bee antennal lobe (160-170), consistent with a general one-receptor/one-neuron/one-glomerulus relationship. The bee genome encodes just 10 gustatory receptors (Grs) compared with the D. melanogaster and A. gambiae repertoires of 68 and 76 Grs, respectively. A lack of Gr gene family expansion primarily accounts for this difference. A nurturing hive environment and a mutualistic relationship with plants may explain the lack of Gr family expansion. The Or family is the most dramatic example of gene family expansion in the bee genome, and characterizing their caste- and sex-specific gene expression may provide clues to their specific roles in detection of pheromone, kin, and floral odors.}},
    author = {Robertson, Hugh M. and Wanner, Kevin W.},
    citeulike-article-id = {7247598},
    citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.5057506},
    doi = {10.1101/gr.5057506},
    journal = {Genome Res},
    keywords = {g\_protein\_coupled\_receptor, odorant, protein\_coupled\_receptors},
    local-url = {file://localhost/Users/Walton/Dropbox/Libraries/Papers/Genome\%20Res\%202006\%20Robertson.pdf},
    month = nov,
    number = {11},
    pages = {1395--403},
    posted-at = {2010-10-31 14:14:33},
    priority = {2},
    title = {{The chemoreceptor superfamily in the honey bee, Apis mellifera: expansion of the odorant, but not gustatory, receptor family}},
    url = {http://dx.doi.org/10.1101/gr.5057506},
    volume = {16},
    year = {2006}
}

@article{citeulike:8151104,
    abstract = {{The European corn borer (ECB), Ostrinia nubilalis (Hubner), exists as two separate sex pheromone races. ECB(Z) females produce a 97:3 blend of Z11- and E11-tetradecenyl acetate whereas ECB(E) females produce an opposite 1:99 ratio of the Z and E isomers. Males of each race respond specifically to their conspecific female's blend. A closely related species, the Asian corn borer (ACB), O. furnacalis , uses a 3:2 blend of Z12- and E12-tetradecenyl acetate, and is believed to have evolved from an ECB-like ancestor. To further knowledge of the molecular mechanisms of pheromone detection and its evolution among closely related species we identified and characterized sex pheromone receptors from ECB(Z).}},
    author = {Wanner, Kevin W. and Nichols, Andrew S. and Allen, Jean E. and Bunger, Peggy L. and Garczynski, Stephen F. and Linn, Charles E. and Robertson, Hugh M. and Luetje, Charles W.},
    citeulike-article-id = {8151104},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0008685},
    day = {13},
    doi = {10.1371/journal.pone.0008685},
    journal = {PLoS ONE},
    keywords = {g\_protein\_coupled\_receptors, g\_proteins, pheromone, protein\_coupled\_receptors},
    month = jan,
    number = {1},
    pages = {e8685+},
    posted-at = {2010-10-31 12:46:30},
    priority = {2},
    publisher = {Public Library of Science},
    title = {{Sex Pheromone Receptor Specificity in the European Corn Borer Moth, Ostrinia nubilalis}},
    url = {http://dx.doi.org/10.1371/journal.pone.0008685},
    volume = {5},
    year = {2010}
}

@article{citeulike:8130921,
    abstract = {{This article discusses seven chiral odorants that demonstrate the enantioselectivity of odor sensation: carvone, Celery Ketone, camphor, Florhydral, 3-methyl-3-sulfanylhexan-1-ol, muscone, and methyl jasmonate. After a general introduction of the odorant−receptor interaction and the combinatorial code of olfaction, the olfactory properties of the enantiomers of these seven odorants, their occurrence in nature, industrial production, and application in perfumery are discussed. Finally, practical aspects of chirality and odor sensation are set forth and these odorants are proposed as examples for introductory courses on stereochemistry, natural products, or bioorganic chemistry.}},
    author = {Kraft, Philip and Mannschreck, Albrecht},
    citeulike-article-id = {8130921},
    citeulike-linkout-0 = {http://dx.doi.org/10.1021/ed100128v},
    citeulike-linkout-1 = {http://pubs.acs.org/doi/abs/10.1021/ed100128v},
    day = {1},
    doi = {10.1021/ed100128v},
    journal = {Journal of Chemical Education},
    keywords = {general\_introduction, gpcr},
    month = jun,
    number = {6},
    pages = {598--603},
    posted-at = {2010-10-27 09:59:24},
    priority = {2},
    title = {{The Enantioselectivity of Odor Sensation: Some Examples for Undergraduate Chemistry Courses}},
    url = {http://dx.doi.org/10.1021/ed100128v},
    volume = {87},
    year = {2010}
}

@article{citeulike:515227,
    abstract = {{PMID: 12627966 The α-factor receptor of the yeast Saccharomyces cerevisiae encoded by the STE2 gene is a member of the large family of G protein-coupled receptors (GPCRs) that mediate multiple signal transduction pathways. The third intracellular loop of GPCRs has been identified as a likely site of interaction with G proteins. To determine the extent of allowed substitutions within this loop, we subjected a stretch of 21 amino acids (Leu228−Leu248) to intensive random mutagenesis and screened multiply substituted alleles for receptor function. The 91 partially functional mutant alleles that were recovered contained 96 unique amino acid substitutions. Every position in this region can be replaced with at least two other types of amino acids without a significant effect on function. The tolerance for nonconservative substitutions indicates that activation of the G protein by ligand-bound receptors involves multiple intramolecular interactions that do not strongly depend on particular sequence elements. Many of the functional mutant alleles exhibit greater than normal levels of signaling, consistent with an inhibitory role for the third intracellular loop. Removal of increasing numbers of positively charged residues from the loop by site-directed mutagenesis causes a progressive loss of signaling function, indicating that the overall net charge of the loop is important for receptor function. Introduction of negatively charged residues also leads to a reduced level of signaling. The defects in signaling caused by substitution of charged amino acids are not caused by changes in the abundance of receptors at the cell surface.}},
    address = {Department of Biochemistry and Biophysics, P.O. Box 712, University of Rochester School of Medicine and Dentistry, Rochester, New York 14642, USA.},
    author = {\'{C}eli\'{c}, Andjelka and Martin, Negin P. and Son, Cagdas D. and Becker, Jeffrey M. and Naider, Fred and Dumont, Mark E.},
    citeulike-article-id = {515227},
    citeulike-linkout-0 = {http://dx.doi.org/10.1021/bi0269308},
    citeulike-linkout-1 = {http://pubs.acs.org/doi/abs/10.1021/bi0269308},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/12627966},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=12627966},
    day = {1},
    doi = {10.1021/bi0269308},
    issn = {0006-2960},
    journal = {Biochemistry},
    keywords = {g\_proteins, gpcr, pheromone},
    month = mar,
    number = {10},
    pages = {3004--3017},
    posted-at = {2010-10-27 09:54:26},
    priority = {2},
    title = {{Sequences in the Intracellular Loops of the Yeast Pheromone Receptor Ste2p Required for G Protein Activation{\dag}}},
    url = {http://dx.doi.org/10.1021/bi0269308},
    volume = {42},
    year = {2003}
}

@article{citeulike:8130912,
    abstract = {{PMID: 15667221 The α-factor receptor (Ste2p) stimulates mating of the yeast Saccharomyces cerevisiae. Ste2p belongs to the large family of G protein-coupled receptors that are characterized by seven transmembrane α-helices. Receptor activation is thought to involve changes in the packing of the transmembrane helix bundle. To identify residues that contribute to Ste2p activation, second-site suppressor mutations were isolated that restored function to defective receptors carrying either an F204S or Y266C substitution which affect residues at the extracellular ends of transmembrane domains 5 and 6, respectively. Thirty-five different suppressor mutations were identified. On their own, these mutations caused a range of phenotypes, including hypersensitivity, constitutive activity, altered ligand binding, and loss of function. The majority of the mutations affected residues in the transmembrane segments that are predicted to face the helix bundle. Many of the suppressor mutations caused constitutive receptor activity, suggesting they improved receptor function by partially restoring the balance between the active and inactive states. Analysis of mutations in transmembrane domain 7 implicated residues Ala281 and Thr282 in receptor activation. The A281T and T282A mutants were supersensitive to S. cerevisiae α-factor, but were defective in responding to a variant of α-factor produced by another species, Saccharomyces kluyveri. The A281T mutant also displayed 8.7-fold enhanced basal signaling. Interestingly, Ala281 and Thr282 are situated in approximately the same position as Lys296 in rhodopsin, which is covalently linked to retinal. These results suggest that transmembrane domain 7 plays a role in receptor activation in a wide range of G protein-coupled receptors from yeast to humans.}},
    author = {Lin, Jennifer C. and Duell, Ken and Saracino, Misty and Konopka, James B.},
    citeulike-article-id = {8130912},
    citeulike-linkout-0 = {http://dx.doi.org/10.1021/bi048050u},
    citeulike-linkout-1 = {http://pubs.acs.org/doi/abs/10.1021/bi048050u},
    day = {1},
    doi = {10.1021/bi048050u},
    journal = {Biochemistry},
    keywords = {gpcr, protein\_coupled\_receptors},
    month = feb,
    number = {4},
    pages = {1278--1287},
    posted-at = {2010-10-27 09:53:04},
    priority = {2},
    title = {{Identification of Residues that Contribute to Receptor Activation through the Analysis of Compensatory Mutations in the G Protein-Coupled α-Factor Receptor{\dag}}},
    url = {http://dx.doi.org/10.1021/bi048050u},
    volume = {44},
    year = {2005}
}

@article{citeulike:6964143,
    abstract = {{PMID: 15966721 All G protein-coupled receptors (GPCRs) share a common seven TM helix architecture and the ability to activate heterotrimeric G proteins. Nevertheless, these receptors have widely divergent sequences with no significant homology. We present a detailed structure−function comparison of the very divergent Class A and D receptors to address whether there is a common activation mechanism across the GPCR superfamily. The Class A and D receptors are represented by the vertebrate visual pigment rhodopsin and the yeast α-factor pheromone receptor Ste2, respectively. Conserved amino acids within each specific receptor class and amino acids where mutation alters receptor function were located in the structures of rhodopsin and Ste2 to assess whether there are functionally equivalent positions or regions within these receptors. We find several general similarities that are quite striking. First, strongly polar amino acids mediate helix interactions. Their mutation generally leads to loss of function or constitutive activity. Second, small and weakly polar amino acids facilitate tight helix packing. Third, proline is essential at similar positions in transmembrane helices 6 and 7 of both receptors. Mapping the specific location of the conserved amino acids and sites of constitutively active mutations identified conserved microdomains on transmembrane helices H3, H6, and H7, suggesting that there are underlying similarities in the mechanism of the widely divergent Class A and Class D receptors.}},
    author = {Eilers, Markus and Hornak, Viktor and Smith, Steven O. and Konopka, James B.},
    citeulike-article-id = {6964143},
    citeulike-linkout-0 = {http://dx.doi.org/10.1021/bi047316u},
    citeulike-linkout-1 = {http://pubs.acs.org/doi/abs/10.1021/bi047316u},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/15966721},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=15966721},
    day = {1},
    doi = {10.1021/bi047316u},
    issn = {0006-2960},
    journal = {Biochemistry},
    keywords = {g\_protein\_coupled\_receptors, gpcr},
    month = jun,
    number = {25},
    pages = {8959--8975},
    posted-at = {2010-10-27 09:51:31},
    priority = {2},
    title = {{Comparison of Class A and D G Protein-Coupled Receptors:  Common Features in Structure and Activation{\dag}}},
    url = {http://dx.doi.org/10.1021/bi047316u},
    volume = {44},
    year = {2005}
}

@article{citeulike:1137370,
    abstract = {{Odorant receptors belong to class A of the G protein-coupled receptors (GPCRs) and detect a large number of structurally diverse odorant molecules. A recent structural bioinformatic analysis suggests that structural features are conserved across class A of GPCRs in spite of their low sequence identity. Based on this work, we have aligned the sequences of 29 ORs for which ligand binding data are available. Recent site-directed mutagenesis experiments on one such receptor (MOR174-9) provide information that helped to identify nine amino-acid residues involved in ligand binding. Our modeling provides a rationale for amino acids in equivalent positions in most of the odorant receptors considered and helps to identify other amino acids that could be important for ligand binding. Our findings are consistent with most of the previous models and allow predictions for site-directed mutagenesis experiments, which could also validate our model.}},
    author = {Khafizov, Kamil and Anselmi, Claudio and Menini, Anna and Carloni, Paolo},
    citeulike-article-id = {1137370},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00894-006-0160-9},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/klu/894/2007/00000013/00000003/00000160},
    citeulike-linkout-2 = {http://www.springerlink.com/content/j30m651831ku77q2},
    day = {1},
    doi = {10.1007/s00894-006-0160-9},
    issn = {1610-2940},
    journal = {Journal of Molecular Modeling},
    keywords = {gpcr, ligand, or},
    month = mar,
    number = {3},
    pages = {401--409},
    posted-at = {2010-10-27 09:36:58},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    title = {{Ligand specificity of odorant receptors}},
    url = {http://dx.doi.org/10.1007/s00894-006-0160-9},
    volume = {13},
    year = {2007}
}

@inproceedings{csdl2-10-09,
    abstract = {{A process defines a set of routines which allow one to organize, manage and improve activities in order to reach a goal. With expert intuition and a-priori knowledge, software processes have been modeled for a long time, resulting in the Waterfall, Spiral and other development models. Later, with the wide use of SCM systems and the public availability of primitive software process artifact trails, formal methods such as Petri Nets, State Machines and others have been applied to the problem of recurrent process discovery and control. Recent advances in metrics effort, increased use of continuous integration, and extensive documentation of the performed process make information-rich fine-grained software process artifacts trails available for analysis. This fine-grained data has the potential to shed new light on the software process. In this work I propose to investigate an automated technique for the discovery and characterization of recurrent behaviors in software development - "programming habits" either on an individual or a team level.}},
    address = {Bolzano-Bozen, Italy},
    author = {Senin, Pavel},
    booktitle = {Proceedings of the Fifth International Doctoral Symposium on Empirical Software Engineering},
    citeulike-article-id = {7805992},
    citeulike-linkout-0 = {http://csdl.ics.hawaii.edu/techreports/10-09/10-09.pdf},
    month = sep,
    posted-at = {2010-09-23 08:56:42},
    priority = {2},
    title = {{Software Trajectory Analysis: An empirically based method for automated software process discovery}},
    url = {http://csdl.ics.hawaii.edu/techreports/10-09/10-09.pdf},
    year = {2010}
}

@incollection{citeulike:7691059,
    abstract = {{Software process improvement has been a focus of industry for many years. To assist with the implementation of process improvement, we provide an approach to recover process enactment data. The goal of our method is to uncover the actual process used and thereby provide evidence for improving the quality of a planned software process that is followed by an organization in the future. The recovered process model (or patterns) is presented at the same level of abstraction as the planned process model. This allows an easy and clear method to identify the distance between a planned process model and the actual project enactment. We investigate the enactment of a defined software process model from the view of understanding the opportunity for process model improvement from the viewpoint of the project managers in the context of a small software development organization. We collected data from one of our collaboration organizations and then applied our method to a case study. The consistencies between a planned process model and the project enactment were measured. The outcomes of our method provide precise information including qualitative and quantitative data to assist project managers with process improvement in future practice. The main contribution of our work is to provide a novel approach to assist software process improvement by recovering a model from process enactment data.}},
    address = {Berlin, Heidelberg},
    author = {Huo, Ming and Zhang, He and Jeffery, Ross},
    booktitle = {Making Globally Distributed Software Development a Success Story},
    chapter = {16},
    citeulike-article-id = {7691059},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-79588-9\_16},
    citeulike-linkout-1 = {http://www.springerlink.com/content/5144745744446878},
    doi = {10.1007/978-3-540-79588-9\_16},
    editor = {Wang,, Qing and Pfahl,, Dietmar and Raffo,, David},
    isbn = {978-3-540-79587-2},
    pages = {173-185--185},
    posted-at = {2010-08-23 14:49:13},
    priority = {2},
    publisher = {Springer Berlin / Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Detection of Consistent Patterns from Process Enactment Data}},
    url = {http://dx.doi.org/10.1007/978-3-540-79588-9\_16},
    volume = {5007},
    year = {2008}
}

@inproceedings{citeulike:7690766,
    abstract = {{Software process improvement has been a focus of industry for many years. To assist the procedure and implementation of process improvement we provide a software process recovery method based on mining project enactment data. The goal of the method is to uncover the actual process used in order to provide input to improve the quality of a defined software process. The recovered model (or patterns) is at the same level of abstraction as the predefined process model. This provides an easy and clear way to identify the gap between the planned process model and the real enactment. We investigate the enactment of a defined software process from the view of understanding the appropriateness and fitness for purpose of the process model from the viewpoint of the project managers in the context of a small software development organization. We collected data from organizations and applied our method to a pilot case study. The main contribution of our work is to provide a software process model recovery method which supports software process change and improvement.}},
    author = {Huo, Ming and Zhang, He and Jeffery, Ross},
    booktitle = {2006 13th Asia Pacific Software Engineering Conference (APSEC'06)},
    citeulike-article-id = {7690766},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/APSEC.2006.14},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4137443},
    doi = {10.1109/APSEC.2006.14},
    isbn = {0-7695-2685-3},
    location = {Bangalore, India},
    month = dec,
    pages = {401--410},
    posted-at = {2010-08-23 10:59:07},
    priority = {2},
    publisher = {IEEE},
    title = {{A Systematic Approach to Process Enactment Analysis as Input to Software Process Improvement or Tailoring}},
    url = {http://dx.doi.org/10.1109/APSEC.2006.14},
    year = {2006}
}

@article{citeulike:7622907,
    abstract = {{Olfactory stimulation induces an odor-guided crawling behavior of Drosophila melanogaster larvae characterized by either an attractive or a repellent reaction. In order to understand the underlying processes leading to these orientations we stimulated single olfactory receptor neurons (ORNs) through photo-activation within an intact neuronal network. Using the Gal4-UAS system two light inducible proteins, the light-sensitive cation channel channelrhodopsin-2 (ChR-2) or the light-sensitive adenylyl cyclase (Pacalpha) were expressed in all or in individual ORNs of the larval olfactory system. Blue light stimulation caused an activation of these neurons, ultimately producing the illusion of an odor stimulus. Larvae were tested in a phototaxis assay for their orientation toward or away from the light source. Here we show that activation of Pacalpha expressing ORNs bearing the receptors Or33b or Or45a in blind norpA mutant larvae induces a repellent behavior away from the light. Conversely, photo-activation of the majority of ORNs induces attraction towards the light. Interestingly, in wild type larvae two ligands of Or33b and Or45a, octyl acetate and propionic ethylester, respectively, have been found to cause an escape reaction. Therefore, we combined light and odor stimulation to analyze the function of Or33b and Or45a expressing ORNs. We show that the larval olfactory system contains a designated neuronal pathway for repellent odorants and that activation of a specific class of ORNs already determines olfactory avoidance behavior.}},
    author = {Bellmann, Dennis and Richardt, Arnd and Freyberger, Robert and Nuwal, Nidhi and Schw\"{a}rzel, Martin and Fiala, Andr\'{e} and St\"{o}rtkuhl, Klemens F.},
    citeulike-article-id = {7622907},
    citeulike-linkout-0 = {http://dx.doi.org/10.3389/fnbeh.2010.00027},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/20577637},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=20577637},
    doi = {10.3389/fnbeh.2010.00027},
    issn = {1662-5153},
    journal = {Frontiers in behavioral neuroscience},
    posted-at = {2010-08-12 12:37:29},
    priority = {2},
    title = {{Optogenetically Induced Olfactory Stimulation in Drosophila Larvae Reveals the Neuronal Basis of Odor-Aversion behavior.}},
    url = {http://dx.doi.org/10.3389/fnbeh.2010.00027},
    volume = {4},
    year = {2010}
}

@inproceedings{citeulike:4934205,
    abstract = {{The number of moves required to solve any state of Rubik's cube has been a matter of long-standing conjecture for over 25 years -- since Rubik's cube appeared. This number is sometimes called "God's number". An upper bound of 29 (in the face-turn metric) was produced in the early 1990's, followed by an upper bound of 27 in 2006.}},
    address = {New York, NY, USA},
    author = {Kunkle, Daniel and Cooperman, Gene},
    booktitle = {ISSAC '07: Proceedings of the 2007 international symposium on Symbolic and algebraic computation},
    citeulike-article-id = {4934205},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1277581},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1277548.1277581},
    doi = {10.1145/1277548.1277581},
    isbn = {978-1-59593-743-8},
    location = {Waterloo, Ontario, Canada},
    pages = {235--242},
    posted-at = {2010-08-09 19:15:27},
    priority = {2},
    publisher = {ACM},
    title = {{Twenty-six moves suffice for Rubik's cube}},
    url = {http://dx.doi.org/10.1145/1277548.1277581},
    year = {2007}
}

@article{citeulike:4483310,
    abstract = {{BACKGROUND:Olfactory Receptors (ORs) form the largest multigene family in vertebrates. Their evolution and their expansion in the vertebrate genomes was the subject of many studies. In this paper we apply a motif-based approach to this problem in order to uncover evolutionary characteristics.RESULTS:We extract deterministic motifs from ORs belonging to ten species using the MEX (Motif Extraction) algorithm, thus defining Common Peptides (CPs) characteristic to ORs. We identify species-specific CPs and show that their relative abundance is high only in fish and frog, suggesting relevance to water-soluble odorants. We estimate the origins of CPs according to the tree of life and track the gains and losses of CPs through evolution. We identify major CP gain in tetrapods and major losses in reptiles. Although the number of human ORs is less than half of the number of ORs in other mammals, the fraction of lost CPs is only 11\%.By examining the positions of CPs along the OR sequence, we find two regions that expanded only in tetrapods. Using CPs we are able to establish remote homology relations between ORs and non-OR GPCRs.Selecting CPs according to their evolutionary age, we bicluster ORs and CPs for each species. Clean biclustering emerges when using relatively novel CPs. Evolutionary age is used to track the history of CP acquisition in the collection of mammalian OR families within HORDE (Human Olfactory Receptor Data Explorer).CONCLUSION:The CP method provides a novel perspective that reveals interesting traits in the evolution of olfactory receptors. It is consistent with previous knowledge, and provides finer details. Using available phylogenetic trees, evolution can be rephrased in terms of CP origins.Supplementary information is also available at http://adios.tau.ac.il/ORPS}},
    author = {Gottlieb, Assaf and Olender, Tsviya and Lancet, Doron and Horn, David},
    citeulike-article-id = {4483310},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2148-9-91},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19416542},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19416542},
    day = {05},
    doi = {10.1186/1471-2148-9-91},
    issn = {1471-2148},
    journal = {BMC Evolutionary Biology},
    keywords = {irisa},
    month = may,
    number = {1},
    pages = {91+},
    posted-at = {2010-08-02 09:21:34},
    priority = {2},
    title = {{Common peptides shed light on evolution of Olfactory Receptors}},
    url = {http://dx.doi.org/10.1186/1471-2148-9-91},
    volume = {9},
    year = {2009}
}

@article{citeulike:964046,
    abstract = {{The main goal of the motif finding problem is to detect novel, over-represented unknown signals in a set of sequences (e.g. transcription factor binding sites in a genome). The most widely used algorithms for finding motifs obtain a generative probabilistic representation of these over-represented signals and try to discover profiles that maximize the information content score. Although these profiles form a very powerful representation of the signals, the major difficulty arises from the fact that the best motif corresponds to the global maximum of a non-convex continuous function. Popular algorithms like Expectation Maximization (EM) and Gibbs sampling tend to be very sensitive to the initial guesses and are known to converge to the nearest local maximum very quickly. In order to improve the quality of the results, EM is used with multiple random starts or any other powerful stochastic global methods that might yield promising initial guesses (like projection algorithms). Global methods do not necessarily give initial guesses in the convergence region of the best local maximum but rather suggest that a promising solution is in the neighborhood region. In this paper, we introduce a novel optimization framework that searches the neighborhood regions of the initial alignment in a systematic manner to explore the multiple local optimal solutions. This effective search is achieved by transforming the original optimization problem into its corresponding dynamical system and estimating the practical stability boundary of the local maximum. Our results show that the popularly used EM algorithm often converges to sub-optimal solutions which can be significantly improved by the proposed neighborhood profile search. Based on experiments using both synthetic and real datasets, our method demonstrates significant improvements in the information content scores of the probabilistic models. The proposed method also gives the flexibility in using different local solvers and global methods depending on their suitability for some specific datasets.}},
    author = {Reddy, Chandan K. and Weng, Yao-Chung C. and Chiang, Hsiao-Dong D.},
    citeulike-article-id = {964046},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1748-7188-1-23},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/17129371},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=17129371},
    day = {27},
    doi = {10.1186/1748-7188-1-23},
    issn = {1748-7188},
    journal = {Algorithms for molecular biology : AMB},
    month = nov,
    number = {1},
    pages = {23+},
    posted-at = {2010-07-03 14:34:43},
    priority = {2},
    title = {{Refining motifs by improving information content scores using neighborhood profile search.}},
    url = {http://dx.doi.org/10.1186/1748-7188-1-23},
    volume = {1},
    year = {2006}
}

@article{citeulike:2678511,
    abstract = {{Many of today's information systems are driven by explicit process models. Workflow management systems, but also ERP, CRM, SCM, and B2B, are configured on the basis of a workflow model specifying the order in which tasks need to be executed. Creating a workflow design is a complicated time-consuming process and typically there are discrepancies between the actual workflow processes and the processes as perceived by the management. To support the design of workflows, we propose the use of workflow mining. Starting point for workflow mining is a so-called  ” workflow log” containing information about the workflow process as it is actually being executed. In this paper, we introduce the concept of workflow mining and present a common format for workflow logs. Then we discuss the most challenging problems and present some of the workflow mining approaches available today.}},
    address = {Amsterdam, The Netherlands, The Netherlands},
    author = {Vanderaalst, W. and Vandongen, B. and Herbst, J. and Maruster, L. and Schimm, G. and Weijters, A.},
    citeulike-article-id = {2678511},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=961808.961812},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/S0169-023X(03)00066-1},
    citeulike-linkout-2 = {http://linkinghub.elsevier.com/retrieve/pii/S0169023X03000661},
    doi = {10.1016/S0169-023X(03)00066-1},
    issn = {0169023X},
    journal = {Data \& Knowledge Engineering},
    month = nov,
    number = {2},
    pages = {237--267},
    posted-at = {2010-07-03 12:06:38},
    priority = {2},
    publisher = {Elsevier Science Publishers B. V.},
    title = {{Workflow mining: A survey of issues and approaches}},
    url = {http://dx.doi.org/10.1016/S0169-023X(03)00066-1},
    volume = {47},
    year = {2003}
}

@article{citeulike:4122657,
    abstract = {The overall mean recognition probability (mean accuracy) of a pattern classifier is calculated and numerically plotted as a function of the pattern measurement complexity n and design data set size<tex>m</tex>. Utilized is the well-known probabilistic model of a two-class, discrete-measurement pattern environment (no Gaussian or statistical independence assumptions are made). The minimum-error recognition rule (Bayes) is used, with the unknown pattern environment probabilities estimated from the data relative frequencies. In calculating the mean accuracy over all such environments, only three parameters remain in the final equation:<tex>n, m</tex>, and the prior probability<tex>p\_{c}</tex>of either of the pattern classes. With a fixed design pattern sample, recognition accuracy can first increase as the number of measurements made on a pattern increases, but decay with measurement complexity higher than some optimum value. Graphs of the mean accuracy exhibit both an optimal and a maximum acceptable value of<tex>n</tex>for fixed<tex>m</tex>and<tex>p\_{c}</tex>. A four-place tabulation of the optimum<tex>n</tex>and maximum mean accuracy values is given for equally likely classes and<tex>m</tex>ranging from<tex>2</tex>to<tex>1000</tex>. The penalty exacted for the generality of the analysis is the use of the mean accuracy itself as a recognizer optimality criterion. Namely, one necessarily always has some particular recognition problem at hand whose Bayes accuracy will be higher or lower than the mean over all recognition problems having fixed<tex>n, m</tex>, and<tex>p\_{c}</tex>.},
    author = {Hughes, G.},
    booktitle = {Information Theory, IEEE Transactions on},
    citeulike-article-id = {4122657},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1054102},
    journal = {Information Theory, IEEE Transactions on},
    number = {1},
    pages = {55--63},
    posted-at = {2010-06-30 20:16:49},
    priority = {2},
    title = {{On the mean accuracy of statistical pattern recognizers}},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1054102},
    volume = {14},
    year = {1968}
}

@article{citeulike:7370527,
    abstract = {{Abstract\&nbsp;\&nbsp;Accurate thematic classification is one of the most commonly desired outputs from remote sensing images. Recent research efforts to improve the reliability and accuracy of image classification have led to the introduction of the Support Vector Classification (SVC) scheme. SVC is a new generation of supervised learning method based on the principle of statistical learning theory, which is designed to decrease uncertainty in the model structure and the fitness of data. We have presented a comparative analysis of SVC with the Maximum Likelihood Classification (MLC) method, which is the most popular conventional supervised classification technique. SVC is an optimization technique in which the classification accuracy heavily relies on identifying the optimal parameters. Using a case study, we verify a method to obtain these optimal parameters such that SVC can be applied efficiently. We use multispectral and hyperspectral images to develop thematic classes of known lithologic units in order to compare the classification accuracy of both the methods. We have varied the training to testing data proportions to assess the relative robustness and the optimal training sample requirement of both the methods to achieve comparable levels of accuracy. The results of our study illustrated that SVC improved the classification accuracy, was robust and did not suffer from dimensionality issues such as the Hughes Effect.}},
    author = {Oommen, Thomas and Misra, Debasmita and Twarakavi, Navin and Prakash, Anupma and Sahoo, Bhaskar and Bandopadhyay, Sukumar},
    citeulike-article-id = {7370527},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11004-008-9156-6},
    citeulike-linkout-1 = {http://www.springerlink.com/content/88j1306hp6386216},
    day = {1},
    doi = {10.1007/s11004-008-9156-6},
    issn = {1874-8961},
    journal = {Mathematical Geosciences},
    keywords = {dissertation, support\_vector\_machine},
    month = may,
    number = {4},
    pages = {409--424},
    posted-at = {2010-06-30 20:04:51},
    priority = {2},
    title = {{An Objective Analysis of Support Vector Machine Based Classification for Remote Sensing}},
    url = {http://dx.doi.org/10.1007/s11004-008-9156-6},
    volume = {40},
    year = {2008}
}

@proceedings{citeulike:1630245,
    abstract = {{In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection. Discords are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. We evaluate our work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with objective experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry, and we demonstrate the effectiveness of our discord discovery algorithm with more than one million experiments, on 82 different datasets from diverse domains.}},
    author = {Keogh, E. and Lin, J. and Fu, A.},
    booktitle = {Data Mining, Fifth IEEE International Conference on},
    citeulike-article-id = {1630245},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1565683},
    journal = {Data Mining, Fifth IEEE International Conference on},
    pages = {8 pp.+},
    posted-at = {2010-06-30 19:33:27},
    priority = {2},
    title = {{HOT SAX: efficiently finding the most unusual time series subsequence}},
    url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1565683},
    year = {2005}
}

@article{citeulike:692,
    abstract = {{BACKGROUND:In a previous paper, we introduced MUSCLE, a new program for creating multiple alignments of protein sequences, giving a brief summary of the algorithm and showing MUSCLE to achieve the highest scores reported to date on four alignment accuracy benchmarks. Here we present a more complete discussion of the algorithm, describing several previously unpublished techniques that improve biological accuracy and / or computational complexity. We introduce a new option, MUSCLE-fast, designed for high-throughput applications. We also describe a new protocol for evaluating objective functions that align two profiles.RESULTS:We compare the speed and accuracy of MUSCLE with CLUSTALW, Progressive POA and the MAFFT script FFTNS1, the fastest previously published program known to the author. Accuracy is measured using four benchmarks: BAliBASE, PREFAB, SABmark and SMART. We test three variants that offer highest accuracy (MUSCLE with default settings), highest speed (MUSCLE-fast), and a carefully chosen compromise between the two (MUSCLE-prog). We find MUSCLE-fast to be the fastest algorithm on all test sets, achieving average alignment accuracy similar to CLUSTALW in times that are typically two to three orders of magnitude less. MUSCLE-fast is able to align 1,000 sequences of average length 282 in 21 seconds on a current desktop computer.CONCLUSIONS:MUSCLE offers a range of options that provide improved speed and / or alignment accuracy compared with currently available programs. MUSCLE is freely available at http://www.drive5.com/muscle.}},
    address = {Department of Plant and Microbial Biology, 461 Koshland Hall, University of California, Berkeley, CA 94720-3102, USA. bob@drive5.com},
    author = {Edgar, Robert},
    citeulike-article-id = {692},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2105-5-113},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/15318951},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=15318951},
    day = {19},
    doi = {10.1186/1471-2105-5-113},
    issn = {1471-2105},
    journal = {BMC Bioinformatics},
    month = aug,
    number = {1},
    pages = {113+},
    posted-at = {2010-06-30 19:22:58},
    priority = {2},
    title = {{MUSCLE: a multiple sequence alignment method with reduced time and space complexity}},
    url = {http://dx.doi.org/10.1186/1471-2105-5-113},
    volume = {5},
    year = {2004}
}

@article{citeulike:1586554,
    abstract = {{Abstract\&nbsp;\&nbsp; Drosophila melanogaster has proven to be a useful model system to probe the mechanisms underlying the detection, discrimination, and perception of volatile odorants. The relatively small receptor repertoire of 62 odorant receptors makes the goal of understanding odor responses from the total receptor repertoire approachable in this system, and recent work has been directed toward this goal. In addition, new work not only sheds light but also raises more questions about the initial steps in odor perception in this system. Odorant receptor genes in Drosophila are predicted to encode seven transmembrane receptors, but surprising data suggest that these receptors may be inverted in the plasma membrane compared to classical G-protein coupled receptors. Finally, although some Drosophila odorant receptors are activated directly by odorant molecules, detection of a volatile pheromone, 11-cis vaccenyl acetate requires an extracellular adapter protein called LUSH for activation of pheromone sensitive neurons. Because pheromones are used by insects to trigger mating and other behaviors, these insights may herald new approaches to control behavior in pathogenic and agricultural pest insects.}},
    author = {Smith, Dean},
    citeulike-article-id = {1586554},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s00424-006-0190-2},
    citeulike-linkout-1 = {http://www.ingentaconnect.com/content/klu/424/2007/00000454/00000005/00000190},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/17205355},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=17205355},
    citeulike-linkout-4 = {http://www.springerlink.com/content/h626234424151873},
    day = {1},
    doi = {10.1007/s00424-006-0190-2},
    issn = {0031-6768},
    journal = {Pfl\"{u}gers Archiv European Journal of Physiology},
    month = aug,
    number = {5},
    pages = {749--758},
    posted-at = {2010-06-30 09:58:48},
    priority = {2},
    publisher = {Springer},
    title = {{Odor and pheromone detection in Drosophila melanogaster}},
    url = {http://dx.doi.org/10.1007/s00424-006-0190-2},
    volume = {454},
    year = {2007}
}

@incollection{citeulike:7369108,
    abstract = {{A methodology is presented to quantitatively model the expected relationships between investments in process improvements and improvements in business measures. Such a predictive model can be used as an auxiliary in process improvement planning in addition to established models like CMMI. Different from a generic model like CMMI, the proposed methodology allows for creating a fully customized model focusing on the context or product at hand. To manage the inherent parameter uncertainty of quantitative modelling of software processes a novel approach in this context is used by explicitly handling the parameter variations using interval arithmetic. The paper outlines the methodology and presents results from a study at Siemens.}},
    address = {Berlin, Heidelberg},
    author = {Birkh\"{o}lzer, Thomas and Dickmann, Christoph and Klein, Harald and Vaupel, J\"{u}rgen and Ast, Stefan and Meyer, Ludger},
    booktitle = {Product-Focused Software Process Improvement },
    chapter = {25},
    citeulike-article-id = {7369108},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-69566-0\_25},
    citeulike-linkout-1 = {http://www.springerlink.com/content/r83552w14vr26248},
    doi = {10.1007/978-3-540-69566-0\_25},
    editor = {Jedlitschka, Andreas and Salo, Outi},
    isbn = {978-3-540-69564-6},
    issn = {0302-9743},
    pages = {304--316},
    posted-at = {2010-06-30 09:55:08},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Customized Predictive Models for Process Improvement Projects}},
    url = {http://dx.doi.org/10.1007/978-3-540-69566-0\_25},
    volume = {5089},
    year = {2008}
}

@incollection{citeulike:7366077,
    abstract = {{Commercial software firms are increasingly using and contributing to open source software. Thus, they need to understand and work with open source software development processes. This paper investigates whether the practice of continuous integration of agile software development methods has had an impact on open source software projects. Using fine-granular data from more than 5000 active open source software projects we analyze the size of code contributions over a project's life-span. Code contribution size has stayed flat. We interpret this to mean that open source software development has not changed its code integration practices. In particular, within the limits of this study, we claim that the practice of continuous integration has not yet significantly influenced the behavior of open source software developers.}},
    address = {Boston, MA},
    author = {Deshpande, Amit and Riehle, Dirk},
    booktitle = {Open Source Development, Communities and Quality },
    chapter = {23},
    citeulike-article-id = {7366077},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-0-387-09684-1\_23},
    citeulike-linkout-1 = {http://www.springerlink.com/content/hj223l05x53l70v1},
    doi = {10.1007/978-0-387-09684-1\_23},
    editor = {Russo, Barbara and Damiani, Ernesto and Hissam, Scott and Lundell, Bj\"{o}rn and Succi, Giancarlo},
    isbn = {978-0-387-09683-4},
    issn = {1571-5736},
    pages = {273--280},
    posted-at = {2010-06-29 13:56:37},
    priority = {2},
    publisher = {Springer US},
    series = {IFIP – The International Federation for Information Processing},
    title = {{Continuous Integration in Open Source Software Development}},
    url = {http://dx.doi.org/10.1007/978-0-387-09684-1\_23},
    volume = {275},
    year = {2008}
}

@article{citeulike:7351135,
    author = {Gibbs, Wayt W.},
    citeulike-article-id = {7351135},
    journal = {Scientific American},
    month = sep,
    posted-at = {2010-06-23 11:35:18},
    priority = {2},
    title = {{Software's Chronic Crisis}},
    year = {1994}
}

@incollection{citeulike:7349861,
    abstract = {{This paper presents a value-based software process framework that has been derived from the 4+1 theory of value-based software engineering (VBSE). The value-based process framework integrates the four component theories – dependency, utility, decision, and control, to the central theory W, and orients itself as a 7-step process guide to practice value-based software engineering. We also illustrate applying the process framework to a supply chain organization through a case study analysis.}},
    address = {Berlin, Heidelberg},
    author = {Boehm, Barry and Jain, Apurva},
    booktitle = {Software Process Change },
    chapter = {1},
    citeulike-article-id = {7349861},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11754305\_1},
    citeulike-linkout-1 = {http://www.springerlink.com/content/hqn78653116517k6},
    doi = {10.1007/11754305\_1},
    editor = {Wang, Qing and Pfahl, Dietmar and Raffo, David M. and Wernick, Paul},
    isbn = {978-3-540-34199-4},
    pages = {1--10},
    posted-at = {2010-06-22 23:44:49},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {{A Value-Based Software Process Framework}},
    url = {http://dx.doi.org/10.1007/11754305\_1},
    volume = {3966},
    year = {2006}
}

@article{citeulike:7349857,
    abstract = {{As a recognized discipline, software engineering traces its roots back to the 1968 NATO conference where the term was first used extensively to highlight the need for an engineering approach to the development of software. In the 30 years since that first  ” software engineering” conference, significant attempts have been made to improve the overall effectiveness of the software development process, and thus reduce the frequency and severity of software project failures. A major part of this improvement effort has been the attempt to develop quantitative measures which can be used to more accurately describe and better understand and manage the software development life cycle. Thus, many software metrics and models have been introduced during this period. In this article, we briefly trace the history of the development of software metrics and models, and then summarize the current state of the field. For discussion purposes, this entire development period is then arbitrarily divided into an Introductory Period (1971–1985), Growth Period (1985–1997) and the Current Period (1997–?). The development of metrics during each of these periods is then related to the treatment of software metrics and models in software engineering curricula during that same period. Our conclusion is that software engineering curricula have indeed reflected the state of software engineering as the work in software metrics and models has progressed. Furthermore, software engineering curricula of the future should reflect the relatively mature state that software metrics have attained, by covering the basic concepts of metrics in appropriate core courses, and more advanced metrics topics in a specialized, elective metrics course.}},
    author = {Mills, Everald E.},
    citeulike-article-id = {7349857},
    citeulike-linkout-0 = {http://dx.doi.org/10.1023/A:1018909531948},
    citeulike-linkout-1 = {http://www.springerlink.com/content/l3398645k187285g},
    day = {1},
    doi = {10.1023/A:1018909531948},
    issn = {10227091},
    journal = {Annals of Software Engineering},
    month = mar,
    number = {1},
    pages = {181--200},
    posted-at = {2010-06-22 23:44:27},
    priority = {2},
    title = {{Metrics in the software engineering curriculum}},
    url = {http://dx.doi.org/10.1023/A:1018909531948},
    volume = {6},
    year = {1998}
}

@incollection{citeulike:7349055,
    abstract = {{The U.S. Department of Defense and other parts of the U.S. government use the Capability Maturity Model Integrated (CMMI) for process improvement to reduce the risk of poor performance by its major contractors. Acquisition officials have reported that many of its major programs suffer from cost, schedule, and technical performance problems even though those programs are being implemented by companies which rate high with respect to the CMMI. This paper explores possible reasons why companies with high CMMI ratings can still have significant performance problems and suggests possible remedies.}},
    address = {Berlin, Heidelberg},
    author = {Pyster, Arthur},
    booktitle = {Unifying the Software Process Spectrum },
    chapter = {8},
    citeulike-article-id = {7349055},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11608035\_8},
    citeulike-linkout-1 = {http://www.springerlink.com/content/p634738l5t05874t},
    doi = {10.1007/11608035\_8},
    editor = {Li, Mingshu and Boehm, Barry and Osterweil, Leon J.},
    isbn = {978-3-540-31112-6},
    pages = {75--82},
    posted-at = {2010-06-22 15:24:55},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {{What Beyond CMMI Is Needed to Help Assure Program and Project Success?}},
    url = {http://dx.doi.org/10.1007/11608035\_8},
    volume = {3840},
    year = {2006}
}

@incollection{citeulike:2050908,
    abstract = {{A process defines the way activities are organized, managed, measured, supported and improved to reach a goal. It has been shown, 15 years ago [1] that processes are software too; more precisely that their description can also be software. We hypothesize that a system can be characterized by its goal and by answering the questions: why, what and how.}},
    address = {Berlin, Heidelberg},
    author = {Estublier, Jacky},
    booktitle = {Unifying the Software Process Spectrum },
    chapter = {3},
    citeulike-article-id = {2050908},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11608035\_3},
    citeulike-linkout-1 = {http://www.springerlink.com/content/f8r4580p3016r025},
    doi = {10.1007/11608035\_3},
    editor = {Li, Mingshu and Boehm, Barry and Osterweil, Leon J.},
    isbn = {978-3-540-31112-6},
    journal = {Unifying the Software Process Spectrum},
    pages = {25--34},
    posted-at = {2010-06-22 15:20:36},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {{Software are Processes Too}},
    url = {http://dx.doi.org/10.1007/11608035\_3},
    volume = {3840},
    year = {2006}
}

@inproceedings{citeulike:7349026,
    abstract = {{Sound methods of analysis and comparison of software processes are crucial for such tasks as process understanding, process correctness verification, evolution management, process classification, process improvement, and choosing the appropriate process for a certain project. The purpose of our research is to lay the foundations for a systematic and rigorous comparison of processes by establishing fixed methods and conceptual frameworks that are able to assure that comparison efforts will yield predictable, reproducible results. The analysis framework presented here assumes that the comparison will be done relative to a fixed standard feature classification schema for the processes used, and with the use of a fixed formalism for modeling the processes. The aspect of the system described in this paper is focused on functional analysis of processes according to the predefined comparison topics, well formedness constraints, and instrumented agents. The paper describes our experience using our analysis system and its application to a logistics software process from the telecommunication domain. 1}},
    author = {Podorozhny, Rodion M. and Perry, Dewayne E. and Osterweil, Leon J.},
    booktitle = {International Software Process Workshop},
    citeulike-article-id = {7349026},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.74.4930},
    pages = {482--497},
    posted-at = {2010-06-22 15:17:50},
    priority = {2},
    title = {{Automatically Analyzing Software Processes: Experience Report}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.74.4930}
}

@book{citeulike:6169037,
    abstract = {{"This book presents international practices in the development and use of applied e-Learning and e-Teaching in the classroom in order to enhance student experience, add value to teaching practices, and illuminate best practices in the area of e-Assessment. This book provides insight into e-Learning and e-Teaching practices while exploring the roles of academic staff in adoption and application"--Provided by publisher.}},
    author = {McShea, Daniel W. and Brandon, Robert N.},
    citeulike-article-id = {6169037},
    citeulike-linkout-0 = {http://www.worldcat.org/oclc/55600801},
    isbn = {978},
    journal = {GIS Proc. ACM Int. Symp. Adv. Geogr. Inf. Syst. GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems},
    posted-at = {2010-06-22 15:17:00},
    priority = {2},
    publisher = {University of Chicago Press},
    series = {Springer series in synergetics, 18},
    title = {{Biology's first law : the tendency for diversity and complexity to increase in evolutionary systems}},
    url = {http://www.worldcat.org/oclc/55600801},
    year = {2010}
}

@article{citeulike:7239889,
    author = {Magn\'{u}sson, Kjartan and Sigurdsson, Sven and Babak, Petro and Gudmundsson, Stef\'{a}n and Dereksd\'{o}ttir, Eva H.},
    citeulike-article-id = {7239889},
    citeulike-linkout-0 = {http://dx.doi.org/10.3934/dcdsb.2004.4.695},
    doi = {10.3934/dcdsb.2004.4.695},
    issn = {1531-3492},
    journal = {Discrete and Continuous Dynamical Systems - Series B},
    keywords = {inna},
    month = may,
    number = {3},
    pages = {695--704},
    posted-at = {2010-06-03 16:14:00},
    priority = {2},
    title = {{A continuous density Kolmogorov type model for a migrating fish stock}},
    url = {http://dx.doi.org/10.3934/dcdsb.2004.4.695},
    volume = {4},
    year = {2004}
}

@article{citeulike:7239881,
    abstract = {{Uncertainty in estimates of survival of dispersing animals is a vexing difficulty in conservation biology. The current notion is that this uncertainty decreases the usefulness of spatially explicit population models in particular. We examined this problem by comparing dispersal models of three levels of complexity: (1) an event-based binomial model that considers only the occurrence of mortality or arrival, (2) a temporally explicit exponential model that employs mortality and arrival rates, and (3) a spatially explicit gridwalk model that simulates the movement of animals through an artificial landscape. Each model was fitted to the same set of field data. A first objective of the paper is to illustrate how the maximum-likelihood method can be used in all three cases to estimate the means and confidence limits for the relevant model parameters, given a particular set of data on dispersal survival. Using this framework we show that the structure of the uncertainty for all three models is strikingly similar. In fact, the results of our unified approach imply that spatially explicit dispersal models, which take advantage of information on landscape details, suffer less from uncertainly than do simpler models. Moreover, we show that the proposed strategy of model development safeguards one from error propagation in these more complex models. Finally, our approach shows that all models related to animal dispersal, ranging from simple to complex, can be related in a hierarchical fashion, so that the various approaches to modeling such dispersal can be viewed from a unified perspective.}},
    author = {Mooij, Wolf M. and DeAngelis, Donald L.},
    citeulike-article-id = {7239881},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/4134696},
    citeulike-linkout-1 = {http://www.jstor.org/stable/4134696},
    doi = {10.2307/4134696},
    issn = {10510761},
    journal = {Ecological Applications},
    keywords = {inna},
    number = {3},
    pages = {794--805},
    posted-at = {2010-06-03 16:12:20},
    priority = {2},
    publisher = {Ecological Society of America},
    title = {{Uncertainty in Spatially Explicit Animal Dispersal Models}},
    url = {http://dx.doi.org/10.2307/4134696},
    volume = {13},
    year = {2003}
}

@incollection{citeulike:7131605,
    abstract = {{We describe in this paper the experiments done to compare two algorithms that identify the family of regular languages in the limit, the algorithm of Trakhenbrot and Barzdin/Gold by one hand and the RPNI/Lang algorithm by the other. As a previous step, for a better comparison, we formulate the algorithm of Gold as a merging states in the prefix tree acceptor scheme.}},
    author = {Garc\'{\i}a, P. and Cano, A. and Ruiz, J.},
    booktitle = {Grammatical Inference: Algorithms and Applications },
    citeulike-article-id = {7131605},
    citeulike-linkout-0 = {http://www.springerlink.com/content/p49nx01ev9ux8pfy},
    keywords = {inference},
    pages = {257--258},
    posted-at = {2010-05-06 07:05:00},
    priority = {2},
    title = {{A Comparative Study of Two Algorithms for Automata Identification}},
    url = {http://www.springerlink.com/content/p49nx01ev9ux8pfy},
    year = {2000}
}

@incollection{citeulike:7131602,
    abstract = {{We propose 10 different open problems in the field of grammatical inference. In all cases, problems are theoretically oriented but correspond to practical questions. They cover the areas of polynomial learning models, learning from ordered alphabets, learning deterministic Pomdps, learning negotiation processes, learning from context-free background knowledge.}},
    address = {Berlin, Heidelberg},
    author = {de la Higuera, Colin},
    booktitle = {Grammatical Inference: Algorithms and Applications },
    chapter = {4},
    citeulike-article-id = {7131602},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11872436\_4},
    citeulike-linkout-1 = {http://www.springerlink.com/content/06301k441267gj32},
    doi = {10.1007/11872436\_4},
    editor = {Sakakibara, Yasubumi and Kobayashi, Satoshi and Sato, Kengo and Nishino, Tetsuro and Tomita, Etsuji},
    isbn = {978-3-540-45264-5},
    keywords = {inference},
    pages = {32--44},
    posted-at = {2010-05-06 07:04:05},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {{Ten Open Problems in Grammatical Inference}},
    url = {http://dx.doi.org/10.1007/11872436\_4},
    volume = {4201},
    year = {2006}
}

@incollection{citeulike:7130326,
    abstract = {{We present a method for modeling user navigation on a web site using grammatical inference of stochastic regular grammars. With this method we achieve better models than the previously used first order Markov chains, in terms of predictive accuracy and utility of recommendations. In order to obtain comparable results, we apply the same grammatical inference algorithms on Markov chains, modeled as probabilistic automata. The automata induced in this way perform better than the original Markov chains, as models for user navigation, but they are considerably inferior to the automata induced by the traditional grammatical inference methods. The evaluation of our method was based on two web usage data sets from two very dissimilar web sites. It consisted in producing, for each user, a personalized list of recommendations and then measuring its recall and expected utility.}},
    author = {Karampatziakis, Nikolaos and Paliouras, Georgios and Pierrakos, Dimitrios and Stamatopoulos, Panagiotis},
    booktitle = {Grammatical Inference: Algorithms and Applications },
    citeulike-article-id = {7130326},
    citeulike-linkout-0 = {http://www.springerlink.com/content/n8cbh619bv6415bh},
    keywords = {inference},
    pages = {187--198},
    posted-at = {2010-05-06 06:18:30},
    priority = {2},
    title = {{Navigation Pattern Discovery Using Grammatical Inference}},
    url = {http://www.springerlink.com/content/n8cbh619bv6415bh},
    year = {2004}
}

@incollection{citeulike:7024475,
    abstract = {{We study determinization of weighted finite-state automata (WFAs), which has important applications in automatic speech recognition (ASR). We provide the first polynomial-time algorithm to test for the twins property, which determines if a WFA admits a deterministic equivalent. We also provide a rigorous analysis of a determinization algorithm of Mohri, with tight bounds for acyclic WFAs. Given that WFAs can expand exponentially when determinized, we explore why those used in ASR tend to shrink. The folklore explanation is that ASR WFAs have an acyclic, multi-partite structure. We show, however, that there exist such WFAs that always incur exponential expansion when determinized. We then introduce a class of WFAs, also with this structure, whose expansion depends on the weights: some weightings cause them to shrink, while others, including random weightings, cause them to expand exponentially.We provide experimental evidence that ASR WFAs exhibit this weight dependence. That they shrink when determinized, therefore, is a result of favorable weightings in addition to special topology.}},
    author = {Buchsbaum, Adam L. and Giancarlo, Raffaele and Westbrook, Jeffery R.},
    booktitle = {Automata, Languages and Programming },
    citeulike-article-id = {7024475},
    citeulike-linkout-0 = {http://www.springerlink.com/content/yeclvf54qqlr8aaw},
    keywords = {irisa},
    pages = {482+},
    posted-at = {2010-04-16 09:34:15},
    priority = {2},
    title = {{On the Determinization of Weighted Finite Automata}},
    url = {http://www.springerlink.com/content/yeclvf54qqlr8aaw},
    year = {1998}
}

@article{citeulike:6622689,
    abstract = {{The mosquito Anopheles gambiae is the major vector of malaria in sub-Saharan Africa. It locates its human hosts primarily through olfaction, but little is known about the molecular basis of this process. Here we functionally characterize the Anopheles gambiae odorant receptor (AgOr) repertoire. We identify receptors that respond strongly to components of human odour and that may act in the process of human recognition. Some of these receptors are narrowly tuned, and some salient odorants elicit strong responses from only one or a few receptors, suggesting a central role for specific transmission channels in human host-seeking behaviour. This analysis of the Anopheles gambiae receptors permits a comparison with the corresponding Drosophila melanogaster odorant receptor repertoire. We find that odorants are differentially encoded by the two species in ways consistent with their ecological needs. Our analysis of the Anopheles gambiae repertoire identifies receptors that may be useful targets for controlling the transmission of malaria.}},
    author = {Carey, Allison F. and Wang, Guirong and Su, Chih-Ying and Zwiebel, Laurence J. and Carlson, John R.},
    citeulike-article-id = {6622689},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature08834},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature08834},
    day = {03},
    doi = {10.1038/nature08834},
    issn = {0028-0836},
    journal = {Nature},
    keywords = {irisa},
    month = feb,
    number = {7285},
    pages = {66--71},
    posted-at = {2010-03-08 13:50:08},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {{Odorant reception in the malaria mosquito Anopheles gambiae}},
    url = {http://dx.doi.org/10.1038/nature08834},
    volume = {464},
    year = {2010}
}

@article{citeulike:6776942,
    abstract = {{BACKGROUND:Insect odorant binding proteins (OBPs) and chemosensory proteins (CSPs) play an important role in chemical communication of insects. Gene discovery of these proteins is a time-consuming task. In recent years, expressed sequence tags (ESTs) of many insect species have accumulated, thus providing a useful resource for gene discovery.RESULTS:We have developed a computational pipeline to identify OBP and CSP genes from insect ESTs. In total, 752,841 insect ESTs were examined from 54 species covering eight Orders of Insecta. From these ESTs, 142 OBPs and 177 CSPs were identified, of which 117 OBPs and 129 CSPs are new. The complete open reading frames (ORFs) of 88 OBPs and 123 CSPs were obtained by electronic elongation. We randomly chose 26 OBPs from eight species of insects, and 21 CSPs from four species for RT-PCR validation. Twenty two OBPs and 16 CSPs were confirmed by RT-PCR, proving the efficiency and reliability of the algorithm. Together with all family members obtained from the NCBI (OBPs) or the UniProtKB (CSPs), 850 OBPs and 237 CSPs were analyzed for their structural characteristics and evolutionary relationship.CONCLUSIONS:A large number of new OBPs and CSPs were found, providing the basis for deeper understanding of these proteins. In addition, the conserved motif and evolutionary analysis provide some new insights into the evolution of insect OBPs and CSPs. Motif pattern fine-tune the functions of OBPs and CSPs, leading to the minor difference in binding sex pheromone or plant volatiles in different insect Orders.}},
    author = {Xu, Ya L. and He, Peng and Zhang, Lan and Fang, Shao Q. and Dong, Shuang L. and Zhang, Yong J. and Li, Fei},
    citeulike-article-id = {6776942},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2164-10-632},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/20034407},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=20034407},
    doi = {10.1186/1471-2164-10-632},
    issn = {1471-2164},
    journal = {BMC Genomics},
    keywords = {irisa},
    number = {1},
    pages = {632+},
    posted-at = {2010-03-08 13:49:13},
    priority = {2},
    title = {{Large-scale identification of odorant-binding proteins and chemosensory proteins from expressed sequence tags in insects}},
    url = {http://dx.doi.org/10.1186/1471-2164-10-632},
    volume = {10},
    year = {2009}
}

@article{citeulike:6776936,
    abstract = {{BACKGROUND:Dogs and rats have a highly developed capability to detect and identify odorant molecules, even at minute concentrations. Previous analyses have shown that the olfactory receptors (ORs) that specifically bind odorant molecules are encoded by the largest gene family sequenced in mammals so far.RESULTS:We identified five amino acid patterns characteristic of ORs in the recently sequenced boxer dog and brown Norway rat genomes. Using these patterns, we retrieved 1,094 dog genes and 1,493 rat genes from these shotgun sequences. The retrieved sequences constitute the olfactory receptor repertoires of these two animals. Subsets of 20.3\% (for the dog) and 19.5\% (for the rat) of these genes were annotated as pseudogenes as they had one or several mutations interrupting their open reading frames. We performed phylogenetic studies and organized these two repertoires into classes, families and subfamilies.CONCLUSION:We have established a complete or almost complete list of OR genes in the dog and the rat and have compared the sequences of these genes within and between the two species. Our results provide insight into the evolutionary development of these genes and the local amplifications that have led to the specific amplification of many subfamilies. We have also compared the human and rat ORs with the human and mouse OR repertoires.}},
    author = {Quignon, Pascale and Giraud, Mathieu and Rimbault, Maud and Lavigne, Patricia and Tacher, Sandrine and Morin, Emmanuelle and Retout, Elodie and Valin, Anne S. and Toh, Kerstin L. and Nicolas, Jacques and Galibert, Francis},
    citeulike-article-id = {6776936},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/gb-2005-6-10-r83},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/16207354},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=16207354},
    doi = {10.1186/gb-2005-6-10-r83},
    issn = {1465-6906},
    journal = {Genome Biology},
    keywords = {irisa},
    number = {10},
    pages = {R83+},
    posted-at = {2010-03-08 13:48:20},
    priority = {2},
    title = {{The dog and rat olfactory receptor repertoires}},
    url = {http://dx.doi.org/10.1186/gb-2005-6-10-r83},
    volume = {6},
    year = {2005}
}

@article{citeulike:6655701,
    abstract = {{During a circumnavigation of the Svalbard archipelago in May 2006, simultaneous marine environmental (meteorology, heat flux, ocean turbulence, irradiance) and biological (phytoplankton and zooplankton biomass/species) data were sampled at selected stations. The zooplankton data were supplemented by high-resolution, high-speed VPR sampling down to 100 m depth at most stations. We were able to sample different phases of the phytoplankton spring bloom in Arctic as well as in Atlantic waters, and the stations represented different situations with respect to irradiance, turbulence and water-column stability. Phytoplankton growth and depth distribution were physically controlled, while zooplankton distributions were affected by biological parameters and turbulence. Development of the zooplankton followed the phytoplankton bloom phase, which was progressing in a direction from west to east in the waters north of Svalbard, and southwards in the Barents Sea. Our results also showed that the zooplankton did not avoid  Phaeocystis pouchetii  colonies, which have earlier been described as toxic. Despite an early retreat of the ice this year there was no apparent mismatch between the phytoplankton bloom and the dominant mesozooplankton,  Calanus  spp.}},
    author = {Norrbin, Fredrika and Eilertsen, Hans C. and Degerlund, Maria},
    citeulike-article-id = {6655701},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.dsr2.2008.11.006},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0967064508003846},
    doi = {10.1016/j.dsr2.2008.11.006},
    issn = {09670645},
    journal = {Deep Sea Research Part II: Topical Studies in Oceanography},
    month = oct,
    number = {21-22},
    pages = {1945--1958},
    posted-at = {2010-02-11 21:58:44},
    priority = {2},
    title = {{Vertical distribution of primary producers and zooplankton grazers during different phases of the Arctic spring bloom}},
    url = {http://dx.doi.org/10.1016/j.dsr2.2008.11.006},
    volume = {56},
    year = {2009}
}

@article{citeulike:6655694,
    abstract = {{doi: 10.1515/BOT.2009.073 Abstract Polar algae have a striking ability to photosynthesize and grow under very low light and temperatures. In seaweeds, minimum light demands for photosynthetic saturation and compensation can be as low as 10 and 2 μmol photons m-2 s-1, respectively. For benthic microalgae, these values can be even lower because of the limited irradiance reaching deep sea floors. The extreme shade adaptation of these organisms sets their distributional limits at depths close to 40 m and enables them to tolerate long periods of extended darkness. In addition to their capability for efficient photosynthesis at extremely low light levels, polar algae possess metabolic adaptations to persist at low temperatures, which permit them to complete their life cycles at year-round temperatures close to 0°C. Seaweeds with the lowest temperature demands are the species endemic to the Antarctic while Arctic algae are comparatively less cold-adapted. These adaptive characteristics allow benthic marine algae to make high contributions to high latitude coastal primary productivity and energy fluxes, exceeding or equaling the production of primary producers in more temperate systems. The studies summarized here give important insights into the major physiological adaptations allowing marine benthic microalgae and seaweeds to colonize these extreme habitats.}},
    author = {G\'{o}mez, Iv\'{a}n and Wulff, Angela and Roleda, Michael Y. and Huovinen, Pirjo and Karsten, Ulf and Quartino, Mar\'{\i}a L. and Dunton, Ken and Wiencke, Christian},
    citeulike-article-id = {6655694},
    citeulike-linkout-0 = {http://www.reference-global.com/doi/abs/10.1515/BOT.2009.073},
    citeulike-linkout-1 = {http://dx.doi.org/10.1515/BOT.2009.073},
    day = {1},
    doi = {10.1515/BOT.2009.073},
    journal = {Botanica Marina},
    month = dec,
    number = {6},
    pages = {593--608},
    posted-at = {2010-02-11 21:55:09},
    priority = {2},
    title = {{Light and temperature demands of marine benthic microalgae and seaweeds in polar regions}},
    url = {http://dx.doi.org/10.1515/BOT.2009.073},
    volume = {52},
    year = {2009}
}

@article{citeulike:6655690,
    abstract = {{Pronounced seasonality is a characteristic feature of polar ecosystems, but seasonal studies in the high-Arctic pack-ice zone are still scarce because of logistical constraints. During six expeditions (1994–2003) to the Fram Strait area between Greenland and Svalbard in winter, spring, early summer, late summer and autumn, the sub-ice habitat and fauna below the pack ice (0–1 m depth) were analyzed for seasonal patterns. Both environmental variables such as ice cover, temperature, salinity and chlorophyll  a  (chl  a ), as well as species composition, abundance and biomass of the sub-ice fauna showed distinct seasonal dynamics. Most species of the sub-ice fauna were found in early summer, followed by autumn, spring and late summer; the lowest number occurred in winter. The sub-ice fauna was dominated by copepod nauplii during all seasons. Next numerous was the small pelagic copepod  Oithona similis,  followed by occassional swarms of  Pseudocalanus minutus  and  Calanus  spp. Abundances of the sympagic fauna in the sub-ice water layer were much lower, with ectinosomatid copepods being usually the most numerous sympagic group. In the course of the year, total abundances of the sub-ice fauna showed a steep increase from the earliest sampling dates towards the end of winter/beginning of spring reaching maximum numbers then, and a decrease to minimum numbers in early summer. A second peak occurred in late summer, followed by a decrease towards autumn. This significant trend was due to the abundances of copepod nauplii and  Oithona similis . Sympagic species were virtually absent during winter, and increased significantly in spring and early and late summer. A factor analysis revealed the variables ice cover and thickness, water temperature and salinity, as well as chl  a  as the major controlling factors for the seasonal patterns in different groups and species of the sub-ice fauna. Because of the special environmental conditions in the sub-ice habitat, and the unique species composition characterized by small taxa, young stages, and sympagic species, the seasonal dynamics of the Arctic sub-ice fauna differ substantially from those of the epipelagic zooplankton community in the Arctic Ocean.}},
    author = {Werner, Iris},
    citeulike-article-id = {6655690},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.dsr.2005.11.001},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0967063705002724},
    doi = {10.1016/j.dsr.2005.11.001},
    issn = {09670637},
    journal = {Deep Sea Research Part I: Oceanographic Research Papers},
    month = feb,
    number = {2},
    pages = {294--309},
    posted-at = {2010-02-11 21:49:22},
    priority = {2},
    title = {{Seasonal dynamics of sub-ice fauna below pack ice in the Arctic (Fram Strait)}},
    url = {http://dx.doi.org/10.1016/j.dsr.2005.11.001},
    volume = {53},
    year = {2006}
}

@article{citeulike:6655689,
    abstract = {{Alterations in sea ice and primary production are expected to have cascading influences on the food web in high Arctic marine ecosystems. This study spanned four years and examined the spring phytoplankton production bloom in Disko Bay, West Greenland (69°N, 53°W) (using chlorophyll  a  concentrations as a proxy) under contrasting sea ice conditions in 2001 and 2003 (heavy sea ice) and 2002 and 2004 (light sea ice). Satellite-based observations of chlorophyll  a , sea ice and sea surface temperature were used together with in situ depth profiles of chlorophyll  a  fluorescence collected at 24 sampling stations along the south coast of Disko Island (5–30 km offshore) in May 2003 and 2004. Chlorophyll  a  and sea surface temperatures were also obtained from the Moderate Resolution Imaging Spectroradiometer (MODIS: EOS-Terra and AQUA satellites) between March 2001 and July 2004. Daily SMMR/SSMI sea ice data were obtained in the same years. An empirical regional algorithm was developed to calibrate ratios of remotely sensed measurements of water leaving radiance with in situ chlorophyll  a  fluorescence. The optimal integration depth was 0–4 m, explaining between 70\% and 91\% of the variance. The spatial development of the phytoplankton bloom showed that the southwestern corner of the study area had the earliest and the largest spring phytoplankton bloom. The eastern part of Disko Bay, influenced by meltwater outflow from the glaciers, shows no signs of an early phytoplankton bloom and followed the general pattern of an accelerated bloom soon after the disappearance of sea ice. In all four years the coupling between phytoplankton and sea ice was bounded by average open water between 50\% and 80\%, likely due to the combined availability of light and stable open water. The daily incremental growth in both mean chlorophyll  a  density (chlorophyll  a  per volume water, μg l −1 ) and abundance (density of chlorophyll  a  extrapolated to ice free areas, tons) estimated by linear regression (chlorophyll  a  vs. day) between 1 April and 15 May was highest in 2002 and 2004 (light ice years) and lowest in 2001 and 2003 (heavy ice years). In years with late sea ice retreat the chlorophyll  a  attained only slightly lower densities than in years with early sea ice retreat. However, the abundance of chlorophyll  a  in light ice years was considerably larger than in heavy ice years, and there was an obvious effect of more open water for light-induced stimulation of primary production. This observation demonstrates the importance of estimating chlorophyll  a  abundance rather than density in sea ice covered areas. This study also presents the first regional calibration of MODIS chlorophyll  a  data for Arctic waters.}},
    author = {Heidejorgensen, M. and Laidre, K. and Logsdon, M. and Nielsen, T.},
    citeulike-article-id = {6655689},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.pocean.2007.01.006},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0079661107000110},
    doi = {10.1016/j.pocean.2007.01.006},
    issn = {00796611},
    journal = {Progress In Oceanography},
    month = apr,
    number = {1},
    pages = {79--95},
    posted-at = {2010-02-11 21:47:21},
    priority = {2},
    title = {{Springtime coupling between chlorophyll a, sea ice and sea surface temperature in Disko Bay, West Greenland}},
    url = {http://dx.doi.org/10.1016/j.pocean.2007.01.006},
    volume = {73},
    year = {2007}
}

@article{citeulike:6655688,
    abstract = {{A rise in global temperatures could potentially lead to less ice in the Arctic, including a reduction in the ice-covered period. The consequence of a changing ice cover on the food web structure and production in Disko Bay, Western Greenland, is analysed through application of a dynamical model for the planktonic food web. The model is successfully calibrated and tested for sensitivity, using a detailed data set for 1996–1997. Model scenarios are (1) extended ice cover and (2) no ice. These scenarios are compared to model runs with measured ice cover in two normal years. In the extended ice scenario, assuming unchanged copepod behaviour, copepods are starving or feeding in the ice/water interface from the time they ascend to the surface layer from over-wintering depths until the ice break-up in June. The total annual primary production reaches the same level as it does in the average year, but copepod ingestion and, as a consequence, vertical carbon export is reduced by app. 40\%. In the ice-free situation, an early diatom bloom is initiated by stratification of the water in March, before the copepods ascend. The diatom bloom is grazed upon by protozooplankton, which reach a high biomass before the copepods ascend in April. Annual primary production increases by 52\% while copepod ingestion and vertical loss of carbon is reduced by 57\%. This study illustrates how a change in the ice cover in Arctic areas can potentially create a mismatch between spring primary production and copepod grazers. The result may be a planktonic food web dominated by protozooplankton, resulting in lower export of organic material out of the photic zone despite increased primary productivity, or alternatively lead to changes in species composition or behaviour.}},
    author = {Hansen, A. and Nielsen, T. and Levinsen, H. and Madsen, S. and Thingstad, T. and Hansen, B.},
    citeulike-article-id = {6655688},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0967-0637(02)00133-4},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0967063702001334},
    doi = {10.1016/S0967-0637(02)00133-4},
    issn = {09670637},
    journal = {Deep Sea Research Part I: Oceanographic Research Papers},
    month = jan,
    number = {1},
    pages = {171--187},
    posted-at = {2010-02-11 21:45:36},
    priority = {2},
    title = {{Impact of changing ice cover on pelagic productivity and food web structure in Disko Bay, West Greenland: a dynamic model approach}},
    url = {http://dx.doi.org/10.1016/S0967-0637(02)00133-4},
    volume = {50},
    year = {2003}
}

@article{citeulike:6655687,
    abstract = {{The contribution from small and large cells to biomass and primary production was investigated during three cruises to the marginal ice zone in the northern Barents Sea in 2003, 2004 and 2005. Chlorophyll  a  biomass and primary production were size-fractionated at 10 μm. Particulate primary production was measured using  14 C and 24 h  in situ  incubations. Twelve stations were successfully sampled and the stations were grouped into three different stages of a phytoplankton bloom. No pre- or post-bloom situations were observed. The highest integrated chl  a  biomass and primary production were 588 mg chl  a  m −2  and 1475 mg C m −2  d −1  measured during peak bloom situations in May 2005. In the early and late bloom groups the chl  a  biomass and primary production were dominated by small cells, while large cells dominated in the peak bloom group. Most of the carbon was produced during the peak bloom dominated by large cells. When seen over the stations that were size-fractionated the small cells contributed with 46\% of the total carbon production (large+small cells). The importance of small cells in the carbon production is emphasized and small cells should not be neglected during phytoplankton blooms in marginal ice zones.}},
    author = {Hodal, H. and Kristiansen, S.},
    citeulike-article-id = {6655687},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.dsr2.2008.05.012},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0967064508001665},
    doi = {10.1016/j.dsr2.2008.05.012},
    issn = {09670645},
    journal = {Deep Sea Research Part II: Topical Studies in Oceanography},
    month = oct,
    number = {20-21},
    pages = {2176--2185},
    posted-at = {2010-02-11 21:42:14},
    priority = {2},
    title = {{The importance of small-celled phytoplankton in spring blooms at the marginal ice zone in the northern Barents Sea}},
    url = {http://dx.doi.org/10.1016/j.dsr2.2008.05.012},
    volume = {55},
    year = {2008}
}

@article{citeulike:6655683,
    abstract = {{The findings of a cruise to study the phytoplankton bloom dynamics associated with the marginal ice zone (MIZ) in the Bellingshausen Sea during Austral spring (November-December) 1992 are reported. Biomass and rate process measurements were carried out at stations located in the ice, ice edge and open water along the 85°W meridian in order to establish the productivity of the microalgae associated with sea-ice and in the water column. In addition, a series of transects along 85°W from sea-ice to open water conditions enabled an assessment of the development of phytoplankton populations. Low phytoplankton biomass and production were noted at ice-covered and ice-edge stations and in the open water close to the ice edge. Observations from the transects indicated no development of a classical ice edge bloom despite evidence that sea-ice had retreated more than 100 km during the study period. Survey data along the 85°W line revealed a region of high chlorophyll, centred on 67.5°S, which was initially observed during brash ice conditions. This feature, which remained geographically consistent, persisted for at least 25 days and was thought to be associated with a frontal region. Water column primary production ( 14 C) in this high chlorophyll region was ca 0.8 g C m −2  day − , more than 8 times higher than noted in the MIZ. Phytoplankton photosynthetic characteristics within this region indicated that cells were adapted to a low light regime. A critical depth of 80 m, estimated directly from oxygen flux measurements, was sufficient to permit the initiation and net growth of phytoplankton standing stocks in a mixed layer of  ca  70 m. A modelling approach using  14 C observations suggested that phytoplankton growth was less than the sum of the algal loss terms within this feature. An advective supply of cells therefore would be required to sustain the observed high and constant algal biomass. In addition, although this high chlorophyll feature was initially observed during brash-ice conditions, the available data suggest that it was initiated under open water conditions.}},
    author = {Boyd, P.},
    citeulike-article-id = {6655683},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0967-0645(95)00070-7},
    doi = {10.1016/0967-0645(95)00070-7},
    issn = {09670645},
    journal = {Deep Sea Research Part II:  Topical Studies in Oceanography},
    number = {4-5},
    pages = {1177--1200},
    posted-at = {2010-02-11 21:39:00},
    priority = {2},
    title = {{[duplicate] Water column and sea-ice primary production during Austral spring in the Bellingshausen Sea}},
    url = {http://dx.doi.org/10.1016/0967-0645(95)00070-7},
    volume = {42},
    year = {1995}
}

@article{citeulike:6655681,
    abstract = {{In shelf waters of the western Antarctic Peninsula (wAP), with abundant macro- and micronutrients, water-column stability has been suggested as the main factor controlling primary production; freshwater input from sea-ice melting stabilizes the upper water column by forming a shallow summer mixed layer. Retreating sea ice in the spring and summer thus defines the area of influence, the sea-ice zone (SIZ) and the marginal ice zone (MIZ). A 12-year time series (1995–2006) was analyzed to address two main questions: (1) what are the spatial and temporal patterns in primary production; and (2) to what extent and in what ways is primary production related to sea-ice dynamics. Data were collected on cruises performed during January of each year, at the height of the growth season, within the region bounded by 64°S and 64°W to the north and 68°S and 66°W to the south. Average daily integrated primary production varied by an order of magnitude, from  250 to  1100 mg C m −2  d −1 , with an average cruise primary production of 745 mg C m −2  d −1 . A strong onshore–offshore gradient was evident along the shelf with higher production observed inshore. Inter-annual regional production varied by a factor of 7: maximum rates were measured in 2006 (1788 mg C m −2  d −1 ) and minimum in 1999 (248 mg C m −2  d −1 ). The results support the hypothesis that primary production in the wAP shelf is related to sea-ice dynamics. To first order, shallower summer mixed-layer depths in the shelf correlated with late sea retreat and primary production. Principal component analysis showed that high primary production in January was associated with enhanced shelf production toward the coast and in the south, explaining 63\% of the variability in space and time. This first mode captured the inter-annual variability in regional production. Temporal variability in primary production (time series of anomalies defined for each location) showed spatial dependence: higher primary production correlated with shallow mixed-layer depths only at mid-shelf; in coastal and offshore waters, primary production correlated with deeper mixed layers. Thus, coastal primary production can show a non-linear relationship with summer mixed layers. Under conditions of large biomass (>20 mg chl  a  m −3 ) and shallow mixed-layer depth (e.g., 5 m) phytoplankton production becomes light limited. This limitation is reduced with a deepening of the summer mixed layer (e.g., 20 m). Dominance of diatoms and the ability to adapt and photosynthesize at higher light levels characterized the large phytoplankton blooms. No significant regional trend in primary production was detected within the 12-year series. We conclude that the regional average primary production on the wAP shelf is associated with shallow summer mixed layers in conjunction with late sea-ice retreat. An opposite relationship is observed for the highest production rates in coastal waters, associated with large biomass, where a deepening of the summer mixed layer relieves light limitation.}},
    author = {Vernet, M. and Martinson, D. and Iannuzzi, R. and Stammerjohn, S. and Kozlowski, W. and Sines, K. and Smith, R. and Garibotti, I.},
    citeulike-article-id = {6655681},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.dsr2.2008.05.021},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0967064508001586},
    doi = {10.1016/j.dsr2.2008.05.021},
    issn = {09670645},
    journal = {Deep Sea Research Part II: Topical Studies in Oceanography},
    month = sep,
    number = {18-19},
    pages = {2068--2085},
    posted-at = {2010-02-11 21:37:39},
    priority = {2},
    title = {{Primary production within the sea-ice zone west of the Antarctic Peninsula: I—Sea ice, summer mixed layer, and irradiance}},
    url = {http://dx.doi.org/10.1016/j.dsr2.2008.05.021},
    volume = {55},
    year = {2008}
}

@article{citeulike:6655679,
    abstract = {{The findings of a cruise to study the phytoplankton bloom dynamics associated with the marginal ice zone (MIZ) in the Bellingshausen Sea during Austral spring (November-December) 1992 are reported. Biomass and rate process measurements were carried out at stations located in the ice, ice edge and open water along the 85°W meridian in order to establish the productivity of the microalgae associated with sea-ice and in the water column. In addition, a series of transects along 85°W from sea-ice to open water conditions enabled an assessment of the development of phytoplankton populations. Low phytoplankton biomass and production were noted at ice-covered and ice-edge stations and in the open water close to the ice edge. Observations from the transects indicated no development of a classical ice edge bloom despite evidence that sea-ice had retreated more than 100 km during the study period. Survey data along the 85°W line revealed a region of high chlorophyll, centred on 67.5°S, which was initially observed during brash ice conditions. This feature, which remained geographically consistent, persisted for at least 25 days and was thought to be associated with a frontal region. Water column primary production ( 14 C) in this high chlorophyll region was ca 0.8 g C m −2  day − , more than 8 times higher than noted in the MIZ. Phytoplankton photosynthetic characteristics within this region indicated that cells were adapted to a low light regime. A critical depth of 80 m, estimated directly from oxygen flux measurements, was sufficient to permit the initiation and net growth of phytoplankton standing stocks in a mixed layer of  ca  70 m. A modelling approach using  14 C observations suggested that phytoplankton growth was less than the sum of the algal loss terms within this feature. An advective supply of cells therefore would be required to sustain the observed high and constant algal biomass. In addition, although this high chlorophyll feature was initially observed during brash-ice conditions, the available data suggest that it was initiated under open water conditions.}},
    author = {Boyd, P.},
    citeulike-article-id = {6655679},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0967-0645(95)00070-7},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/0967-0645(95)00070-7},
    doi = {10.1016/0967-0645(95)00070-7},
    issn = {09670645},
    journal = {Deep Sea Research Part II:  Topical Studies in Oceanography},
    number = {4-5},
    pages = {1177--1200},
    posted-at = {2010-02-11 21:35:41},
    priority = {2},
    title = {{Water column and sea-ice primary production during Austral spring in the Bellingshausen Sea}},
    url = {http://dx.doi.org/10.1016/0967-0645(95)00070-7},
    volume = {42},
    year = {1995}
}

@article{citeulike:6655677,
    author = {Malone, T.},
    citeulike-article-id = {6655677},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0198-0149(87)90127-0},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/0198014987901270},
    doi = {10.1016/0198-0149(87)90127-0},
    issn = {01980149},
    journal = {Deep Sea Research Part A. Oceanographic Research Papers},
    month = jan,
    number = {1},
    pages = {139},
    posted-at = {2010-02-11 21:33:47},
    priority = {2},
    title = {{Primary production of the ocean water column as a function of surface light intensity}},
    url = {http://dx.doi.org/10.1016/0198-0149(87)90127-0},
    volume = {34},
    year = {1987}
}

@inproceedings{citeulike:6544724,
    abstract = {{Libre (free, open source) software is one of the paradigmatic cases where heavy use of telematic tools and userdriven software development are key points. This paper proposes a methodology for measuring and analyzing remotely big libre software projects using publicly-available data from their version control repositories. By means of a tool called CVSAnalY that has been implemented following this methodology, measurements and analyses can be made in an automatic and non-intrusive way, providing real-time and historical data about the project and its contributors.}},
    author = {Robles, Gregorio and Koch, Stefan and Gonz\'{a}lez-Barahona, Jes\'{u}s M. and Carlos, Juan},
    booktitle = {In Proceedings of the 2nd ICSE Workshop on Remote Analysis and Measurement of Software Systems (RAMSS},
    citeulike-article-id = {6544724},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.58.6959},
    keywords = {thesis-phd},
    pages = {51--55},
    posted-at = {2010-01-15 18:23:15},
    priority = {2},
    title = {{Remote Analysis and Measurement of Libre Software Systems By Means of the CVSAnalY tool}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.58.6959},
    year = {2004}
}

@proceedings{citeulike:6544685,
    abstract = {{In order to predict the number of changes in the following months for the project Eclipse, we have applied a statistical (non-explanatory) model based on time series analysis. We have obtained the monthly number of changes in the CVS repository of Eclipse, using the CVSAnalY tool. The input to our model was the filtered series of the number of changes per month, and the output was the number of changes per month for the next three months. Then we aggregated the results of the three months to obtain the total number of changes in the given period in the challenge.}},
    author = {Herraiz, I. and Gonzalez-Barahona, J. M. and Robles, G.},
    citeulike-article-id = {6544685},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/MSR.2007.10},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4228669},
    day = {26},
    doi = {10.1109/MSR.2007.10},
    journal = {Mining Software Repositories, 2007. ICSE Workshops MSR '07. Fourth International Workshop on},
    keywords = {thesis-phd},
    month = may,
    pages = {32},
    posted-at = {2010-01-15 17:25:22},
    priority = {2},
    title = {{Forecasting the Number of Changes in Eclipse Using Time Series Analysis}},
    url = {http://dx.doi.org/10.1109/MSR.2007.10},
    year = {2007}
}

@proceedings{citeulike:6350422,
    abstract = {{We present the results of a study in which author entropy was used to characterize author contributions per file. Our analysis reveals three patterns: banding in the data, uneven distribution of data across bands, and file size dependent distributions within bands. Our results suggest that when two authors contribute to a file, large files are more likely to have a dominant author than smaller files.}},
    author = {Casebolt, J. R. and Krein, J. L. and MacLean, A. C. and Knutson, C. D. and Delorey, D. P.},
    booktitle = {Mining Software Repositories, 2009. MSR '09. 6th IEEE International Working Conference on},
    citeulike-article-id = {6350422},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/MSR.2009.5069484},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5069484},
    day = {17},
    doi = {10.1109/MSR.2009.5069484},
    keywords = {msr},
    month = may,
    pages = {91--94},
    posted-at = {2009-12-10 18:18:02},
    priority = {2},
    title = {{Author entropy vs. file size in the gnome suite of applications}},
    url = {http://dx.doi.org/10.1109/MSR.2009.5069484},
    year = {2009}
}

@article{citeulike:3837636,
    abstract = {{Our variant ascertainment algorithm, VAAL, uses massively parallel DNA sequence data to identify differences between bacterial genomes with high sensitivity and specificity. VAAL detected 98\% of differences (including large insertion-deletions) between pairs of strains from three species while calling no false positives. VAAL also pinpointed a single mutation between Vibrio cholerae genomes, identifying an antibiotic's site of action by identifying sequence differences between drug-sensitive strains and drug-resistant derivatives.}},
    author = {Nusbaum, Chad and Ohsumi, Toshiro K. and Gomez, James and Aquadro, John and Victor, Thomas C. and Warren, Robert M. and Hung, Deborah T. and Birren, Bruce W. and Lander, Eric S. and Jaffe, David B.},
    citeulike-article-id = {3837636},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nmeth.1286},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nmeth.1286},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/19079253},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=19079253},
    day = {14},
    doi = {10.1038/nmeth.1286},
    issn = {1548-7091},
    journal = {Nature Methods},
    keywords = {short\_reads},
    month = dec,
    number = {1},
    pages = {67--69},
    posted-at = {2009-11-23 12:49:54},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {{Sensitive, specific polymorphism discovery in bacteria using massively parallel sequencing}},
    url = {http://dx.doi.org/10.1038/nmeth.1286},
    volume = {6},
    year = {2008}
}

@article{citeulike:3158518,
    abstract = {{New sequencing technologies promise a new era in the use of DNA sequence. However, some of these technologies produce very short reads, typically of a few tens of base pairs, and to use these reads effectively requires new algorithms and software. In particular, there is a major issue in efficiently aligning short reads to a reference genome and handling ambiguity or lack of accuracy in this alignment. Here we introduce the concept of mapping quality, a measure of the confidence that a read actually comes from the position it is aligned to by the mapping algorithm. We describe the software MAQ that can build assemblies by mapping shotgun short reads to a reference genome, using quality scores to derive genotype calls of the consensus sequence of a diploid genome, e.g., from a human sample. MAQ makes full use of mate-pair information and estimates the error probability of each read alignment. Error probabilities are also derived for the final genotype calls, using a Bayesian statistical model that incorporates the mapping qualities, error probabilities from the raw sequence quality scores, sampling of the two haplotypes, and an empirical model for correlated errors at a site. Both read mapping and genotype calling are evaluated on simulated data and real data. MAQ is accurate, efficient, versatile, and user-friendly. It is freely available at http://maq.sourceforge.net.}},
    address = {Sanger Institute;},
    author = {Li, Heng and Ruan, Jue and Durbin, Richard},
    citeulike-article-id = {3158518},
    citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.078212.108},
    citeulike-linkout-1 = {http://genome.cshlp.org/content/18/11/1851.abstract},
    citeulike-linkout-2 = {http://genome.cshlp.org/content/18/11/1851.full.pdf},
    citeulike-linkout-3 = {http://genome.cshlp.org/cgi/content/abstract/18/11/1851},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/18714091},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=18714091},
    day = {1},
    doi = {10.1101/gr.078212.108},
    issn = {1088-9051},
    journal = {Genome Research},
    keywords = {short\_reads},
    month = nov,
    number = {11},
    pages = {1851--1858},
    posted-at = {2009-11-23 12:48:46},
    priority = {2},
    title = {{Mapping short DNA sequencing reads and calling variants using mapping quality scores}},
    url = {http://dx.doi.org/10.1101/gr.078212.108},
    volume = {18},
    year = {2008}
}

@article{citeulike:5801584,
    abstract = {{Genome resequencing with short reads generally relies on alignments against a single reference. GenomeMapper supports simultaneous mapping of short reads against multiple genomes by integrating related genomes (e.g., individuals of the same species) into a single graph structure. It constitutes the first approach for handling multiple references and introduces representations for alignments against complex structures. Demonstrated benefits include access to polymorphisms that cannot be identified by alignments against the reference alone. Download GenomeMapper at http://1001genomes.org webcite.}},
    author = {Schneeberger, Korbinian and Hagmann, Jorg and Ossowski, Stephan and Warthmann, Norman and Gesing, Sandra and Kohlbacher, Oliver and Weigel, Detlef},
    citeulike-article-id = {5801584},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/gb-2009-10-9-r98},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19761611},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19761611},
    day = {17},
    doi = {10.1186/gb-2009-10-9-r98},
    issn = {1465-6906},
    journal = {Genome Biology},
    keywords = {short\_reads},
    month = sep,
    number = {9},
    pages = {R98+},
    posted-at = {2009-11-23 12:46:43},
    priority = {2},
    title = {{Simultaneous alignment of short reads against multiple genomes}},
    url = {http://dx.doi.org/10.1186/gb-2009-10-9-r98},
    volume = {10},
    year = {2009}
}

@article{citeulike:3658666,
    abstract = {{Whole-genome hybridization studies have suggested that the nuclear genomes of accessions (natural strains) of Arabidopsis thaliana can differ by several percent of their sequence. To examine this variation, and as a first step in the 1001 Genomes Project for this species, we produced 15- to 25-fold coverage in Illumina sequencing-by-synthesis (SBS) reads for the reference accession, Col-0, and two divergent strains, Bur-0 and Tsu-1. We aligned reads to the reference genome sequence to assess data quality metrics and to detect polymorphisms. Alignments revealed 823,325 unique SNPs and 79,961 unique 1-3 bp indels in the divergent accessions at a specificity of more than 99\%, and over 2,000 potential errors in the reference genome sequence. We also identified more than 3.4 Mb of the Bur-0 and Tsu-1 genomes as being either extremely dissimilar, deleted, or duplicated relative to the reference genome. To obtain sequences for these regions, we incorporated the Velvet assembler into a targeted de novo assembly method. This approach yielded 10,921 high confidence contigs that were anchored to flanking sequences and harbored indels as large as 641 bp. Our methods are broadly applicable for polymorphism discovery in moderate to large genomes even at highly diverged loci, and we established by subsampling the Illumina SBS coverage depth required to inform a broad range of functional and evolutionary studies. Our pipeline for aligning reads and predicting SNPs and indels, SHORE, is available for download at http://1001genomes.org.}},
    author = {Ossowski, Stephan and Schneeberger, Korbinian and Clark, Richard M. and Lanz, Christa and Warthmann, Norman and Weigel, Detlef},
    citeulike-article-id = {3658666},
    citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.080200.108},
    citeulike-linkout-1 = {http://genome.cshlp.org/content/18/12/2024.abstract},
    citeulike-linkout-2 = {http://genome.cshlp.org/content/18/12/2024.full.pdf},
    citeulike-linkout-3 = {http://genome.cshlp.org/cgi/content/abstract/18/12/2024},
    citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/18818371},
    citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=18818371},
    day = {1},
    doi = {10.1101/gr.080200.108},
    issn = {1088-9051},
    journal = {Genome Research},
    keywords = {short\_reads},
    month = jan,
    number = {12},
    pages = {2024--2033},
    posted-at = {2009-11-23 12:45:32},
    priority = {2},
    title = {{Sequencing of natural strains of Arabidopsis thaliana with short reads}},
    url = {http://dx.doi.org/10.1101/gr.080200.108},
    volume = {18},
    year = {2008}
}

@article{citeulike:2289016,
    abstract = {{Massively parallel sequencing instruments enable rapid and inexpensive DNA sequence data production. Because these instruments are new, their data require characterization with respect to accuracy and utility. To address this, we sequenced a Caernohabditis elegans N2 Bristol strain isolate using the Solexa Sequence Analyzer, and compared the reads to the reference genome to characterize the data and to evaluate coverage and representation. Massively parallel sequencing facilitates strain-to-reference comparison for genome-wide sequence variant discovery. Owing to the short-read-length sequences produced, we developed a revised approach to determine the regions of the genome to which short reads could be uniquely mapped. We then aligned Solexa reads from C. elegans strain CB4858 to the reference, and screened for single-nucleotide polymorphisms (SNPs) and small indels. This study demonstrates the utility of massively parallel short read sequencing for whole genome resequencing and for accurate discovery of genome-wide polymorphisms.}},
    address = {[1] Washington University School of Medicine, Department of Genetics and Genome Sequencing Center, 4444 Forest Park Blvd., St. Louis, Missouri 63108, USA. [2] These authors contributed equally to this work.},
    author = {Hillier, LaDeana W. and Marth, Gabor T. and Quinlan, Aaron R. and Dooling, David and Fewell, Ginger and Barnett, Derek and Fox, Paul and Glasscock, Jarret I. and Hickenbotham, Matthew and Huang, Weichun and Magrini, Vincent J. and Richt, Ryan J. and Sander, Sacha N. and Stewart, Donald A. and Stromberg, Michael and Tsung, Eric F. and Wylie, Todd and Schedl, Tim and Wilson, Richard K. and Mardis, Elaine R.},
    citeulike-article-id = {2289016},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nmeth.1179},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nmeth.1179},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18204455},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18204455},
    citeulike-linkout-4 = {http://www.wormbase.org/db/misc/paper?name=WBPaper00031443},
    day = {20},
    doi = {10.1038/nmeth.1179},
    issn = {1548-7105},
    journal = {Nature Methods},
    keywords = {short\_reads},
    month = jan,
    number = {2},
    pages = {183--188},
    posted-at = {2009-11-23 12:43:51},
    priority = {2},
    publisher = {Nature Publishing Group},
    title = {{Whole-genome sequencing and variant discovery in C. elegans}},
    url = {http://dx.doi.org/10.1038/nmeth.1179},
    volume = {5},
    year = {2008}
}

@incollection{citeulike:5973585,
    abstract = {{The problem of discovering frequent subgraphs of graph data can be solved by constructing a candidate set of subgraphs first, and then, identifying within this candidate set those subgraphs that meet the frequent subgraph requirement. In Apriori-based graph mining, to determine candidate subgraphs from a huge number of generated adjacency matrices is usually the dominating factor for the overall graph mining performance since it requires to perform many graph isomorphism tests. To address this issue, we develop an effective algorithm for the candidate set generation. It is a hash-based algorithm and was confirmed effective through experiments on both real-world and synthetic graph data.}},
    author = {Nguyen, Phu C. and Washio, Takashi and Ohara, Kouzou and Motoda, Hiroshi},
    citeulike-article-id = {5973585},
    citeulike-linkout-0 = {http://www.springerlink.com/content/5qq5ctje4akhef2y},
    journal = {Knowledge Discovery in Databases: PKDD 2004},
    keywords = {algorithm, apriori\_algorithm},
    pages = {349--361},
    posted-at = {2009-10-20 11:49:59},
    priority = {2},
    title = {{Using a Hash-Based Method for Apriori-Based Graph Mining}},
    url = {http://www.springerlink.com/content/5qq5ctje4akhef2y},
    year = {2004}
}

@proceedings{citeulike:5972696,
    abstract = {Searching for the longest common subsequence (LCS) of biosequences is one of the most important problems in bioinformatics. A fast algorithm for LCS problem FAST\_LCS is presented. The algorithm first seeks the successors of the initial identical character pairs according to a successor table to obtain all the identical pairs and their levels. By tracing back from the identical character pair at the highest level, strong pruning rules are developed. For two sequences X and Y with length n and m, respectively, the memory required for FAST\_LCS is max{4*(n+1)+4*(m+1), L}, where L is the number of identical character pairs. The time complexity of parallel computing is O(|LCS(X,Y)|), where |LCS(X,Y)| is the length of the LCS of X, Y. Experimental result on the gene sequences of tigr database using MPP parallel computer Shenteng 1800 shows that our algorithm can find the exact solutions significantly more efficiently than other LCS algorithms},
    author = {Liu, Wei},
    citeulike-article-id = {5972696},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/IMSCCS.2006.6},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4673521},
    day = {17},
    doi = {10.1109/IMSCCS.2006.6},
    journal = {Computer and Computational Sciences, 2006. IMSCCS '06. First International Multi-Symposiums on},
    keywords = {algorithm, lcs},
    month = nov,
    pages = {27--34},
    posted-at = {2009-10-19 23:04:25},
    priority = {2},
    title = {{A Fast Parallel Longest Common Subsequence Algorithm Based on Pruning Rules}},
    url = {http://dx.doi.org/10.1109/IMSCCS.2006.6},
    volume = {1},
    year = {2008}
}

@proceedings{citeulike:5972687,
    abstract = {{Apriori is one of the most important algorithms used in rule association mining. In this paper, we first discuss the limitations of the Apriori algorithm and then propose an enhancement for improving its efficiency. The improved algorithm is based on the combination of forward scan and reverse scan of a given database. If certain conditions are satisfied, the improved algorithm can greatly reduce the scanning times required for the discovery of candidate itemsets. Theoretical proof and analysis are given for the rationality of our algorithm. A simulation instance is given in order to show the advantages of this algorithm compared with Apriori.}},
    author = {Sun, Dongme and Teng, Shaohua and Zhang, Wei and Zhu, Haibin},
    citeulike-article-id = {5972687},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/COGINF.2007.4341914},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4341914},
    day = {08},
    doi = {10.1109/COGINF.2007.4341914},
    journal = {Cognitive Informatics, 6th IEEE International Conference on},
    keywords = {algorithm, apriori\_algorithm},
    month = oct,
    pages = {385--390},
    posted-at = {2009-10-19 23:00:58},
    priority = {2},
    title = {{An Algorithm to Improve the Effectiveness of Apriori}},
    url = {http://dx.doi.org/10.1109/COGINF.2007.4341914},
    year = {2007}
}

@article{citeulike:5971661,
    abstract = {{People evidence significant inaccuracies when predicting their response to many emotional life events. One unanswered question is whether such affective forecasting errors are due to participants' poor estimation of their initial emotional reactions (an  initial intensity bias ), poor estimation of the rate at which these emotional reactions diminish over time (a  decay bias ), or both. The present research used intensive longitudinal procedures to explore this question in the wake of an upsetting life event: the dissolution of a romantic relationship. Results revealed that the affective forecasting error is entirely accounted for by an initial intensity bias, with no contribution by a decay bias. In addition, several moderators of the affective forecasting error emerged: participants who were more in love with their partners, who thought it was unlikely they would soon enter a new relationship, and who played less of a role in initiating the breakup made especially inaccurate forecasts.}},
    author = {Eastwick, Paul W. and Finkel, Eli J. and Krishnamurti, Tamar and Loewenstein, George},
    citeulike-article-id = {5971661},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jesp.2007.07.001},
    citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0022103107000960},
    doi = {10.1016/j.jesp.2007.07.001},
    issn = {00221031},
    journal = {Journal of Experimental Social Psychology},
    keywords = {divorce, psychology},
    month = may,
    number = {3},
    pages = {800--807},
    posted-at = {2009-10-19 18:07:41},
    priority = {2},
    title = {{Mispredicting distress following romantic breakup: Revealing the time course of the affective forecasting error☆}},
    url = {http://dx.doi.org/10.1016/j.jesp.2007.07.001},
    volume = {44},
    year = {2008}
}

@incollection{citeulike:5956826,
    abstract = {{This paper presents an association rule mining system that is capable of handling set-valued attributes. Our previous research has exposed us to a variety of real-world biological datasets that contain attributes whose values are sets of elements, instead of just individual elements. However, very few data mining tools accept datasets that contain these set-valued attributes, and none of them allow the mining of association rules directly from this type of data. We introduce in this paper two algorithms for mining (classification) association rules directly from set-valued data and compare their performance. We have implemented a system based on one of these algorithms and have applied it to a number of biological datasets. We describe here our system and highlight its merits by means of comparing the results achieved with it and the failed attempts to mine association rules from those datasets using standard tools. Our system makes the creation of input files containing set-valued data much easier, and makes the mining of association rules directly from these data possible.}},
    author = {Shoemaker, Christopher and Ruiz, Carolina},
    citeulike-article-id = {5956826},
    citeulike-linkout-0 = {http://www.springerlink.com/content/nt6mb8x3yekhxa8t},
    journal = {Intelligent Data Engineering and Automated Learning},
    keywords = {algorithm, mining\_system},
    pages = {669--676},
    posted-at = {2009-10-17 19:41:14},
    priority = {2},
    title = {{Association Rule Mining Algorithms for Set-Valued Data}},
    url = {http://www.springerlink.com/content/nt6mb8x3yekhxa8t},
    year = {2003}
}

@article{citeulike:2939267,
    abstract = {{Note: OCR errors may be found in this Reference List extracted from the full text article.  ACM has opted to expose the complete List rather than only correct and linked references.}},
    address = {New York, NY, USA},
    author = {Tichy, Walter F.},
    citeulike-article-id = {2939267},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=357404},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/357401.357404},
    doi = {10.1145/357401.357404},
    issn = {0734-2071},
    journal = {ACM Trans. Comput. Syst.},
    keywords = {algorithm},
    month = nov,
    number = {4},
    pages = {309--321},
    posted-at = {2009-10-02 17:07:59},
    priority = {2},
    publisher = {ACM},
    title = {{The string-to-string correction problem with block moves}},
    url = {http://dx.doi.org/10.1145/357401.357404},
    volume = {2},
    year = {1984}
}

@article{citeulike:878244,
    abstract = {{The  string-to-string correction problem  is to determine the distance between two strings as measured by the minimum cost sequence of \&ldquo;edit operations\&rdquo; needed to change the one string into the other. The edit operations investigated allow changing one symbol of a string into another single symbol, deleting one symbol from a string, or inserting a single symbol into a string. An algorithm is presented which solves this problem in time proportional to the product of the lengths of the two strings. Possible applications are to the problems of automatic spelling correction and determining the longest subsequence of characters common to two strings.}},
    address = {New York, NY, USA},
    author = {Wagner, Robert A. and Fischer, Michael J.},
    citeulike-article-id = {878244},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=321811},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/321796.321811},
    doi = {10.1145/321796.321811},
    issn = {0004-5411},
    journal = {J. ACM},
    keywords = {algorithm},
    month = jan,
    number = {1},
    pages = {168--173},
    posted-at = {2009-10-02 17:07:06},
    priority = {2},
    publisher = {ACM},
    title = {{The String-to-String Correction Problem}},
    url = {http://dx.doi.org/10.1145/321796.321811},
    volume = {21},
    year = {1974}
}

@incollection{citeulike:5868601,
    abstract = {{The longest common subsequence(LCS) problem is one of the classical and well-studied problems in computer science. The computation of the LCS is a frequent task in DNA sequence analysis, and has applications to genetics and molecular biology. In this paper we define new variants, introducing the notion of gap-constraints in LCS problem and present efficient algorithms to solve them.}},
    author = {Rahman, M. and Iliopoulos, Costas},
    citeulike-article-id = {5868601},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/11940128\_41},
    citeulike-linkout-1 = {http://www.springerlink.com/content/t2p026348775823r},
    doi = {10.1007/11940128\_41},
    journal = {Algorithms and Computation},
    keywords = {algorithm},
    pages = {399--408},
    posted-at = {2009-10-01 16:29:08},
    priority = {2},
    title = {{Algorithms for Computing Variants of the Longest Common Subsequence Problem}},
    url = {http://dx.doi.org/10.1007/11940128\_41},
    year = {2006}
}

@inproceedings{citeulike:3025832,
    abstract = {{Efficient and accurate similarity searching for a large amount of time series data set is an important but non-trivial problem. Many dimensionality reduction techniques have been proposed for effective representation of time series data in order to realize such similarity searching, including Singular Value Decomposition (SVD), the Discrete Fourier transform (DFT), the Adaptive Piecewise Constant Approximation (APCA), and the recently proposed Symbolic Aggregate Approximation (SAX).}},
    address = {Washington, DC, USA},
    author = {Lkhagva, Battuguldur and Suzuki, Yu and Kawagoe, Kyoji},
    booktitle = {ICDEW '06: Proceedings of the 22nd International Conference on Data Engineering Workshops},
    citeulike-article-id = {3025832},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1130158},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/ICDEW.2006.99},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/ICDEW.2006.99},
    doi = {10.1109/ICDEW.2006.99},
    isbn = {0-7695-2571-7},
    journal = {icdew},
    keywords = {dissertation, litreview, sax},
    pages = {115+},
    posted-at = {2009-08-29 16:29:55},
    priority = {2},
    publisher = {IEEE Computer Society},
    title = {{New Time Series Data Representation ESAX for Financial Applications}},
    url = {http://dx.doi.org/10.1109/ICDEW.2006.99},
    volume = {0},
    year = {2006}
}

@book{citeulike:5410331,
    abstract = {{"It premieres the most adept researchers in the field who have bravely and
soundly followed mixed methodology approaches."

-NACADA (National ACademic ADvising Association)


In recent years, researchers have begun to combine quantitative and
qualitative approaches within single study research designs. As such, the
literature on mixed methods research has grown at a rapid pace. While more
methodological books addressing mixed methods are becoming available, the
foundational writings of this field are still scattered across diverse
disciplines and their wide range of publications outlets, leaving students and
researchers at a disadvantage to find the exemplary or model studies to help
them understand how to conduct their own mixed methods research.


In light of the dispersed nature of the mixed methods literature, **The Mixed
Methods Reader **editors have organized a collection of key methodological
mixed methods discussions and exemplar mixed methods research studies in one
easy-to-access location. This integrative collection draws from the
international literature appearing across diverse research disciplines over
the past thirty years. **The Mixed Methods Reader **is divided into two parts:
Part I – Methodological Selections and Part II – Exemplar Research Studies.
Part I includes a collection of 14 foundational writings from the mixed
methods research literature. These readings convey the overall development and
evolution of mixed methods research and address essential topics for
researchers new to the field of mixed methods research. These topics include
its foundations; design types; implementation issues such as sampling, data
analysis, and validity; rhetorical devices for reporting mixed methods
studies; and critiques about the current thinking in the field. Part II
includes 9 exemplar mixed methods research studies drawn from a range of
disciplines and international scholars. The studies were intentionally
selected to illustrate four major types of mixed methods designs. As with the
methodological chapters, the editors organize the exemplar research studies so
that the reader can see a natural progression of the different approaches to
conducting mixed methods research.


**The Mixed Methods Reader**, edited by two leading researchers in mixed
methods research, offers students and researchers a rich balance of
foundational works and exemplary studies across a range of disciplines. This
reader is an invaluable primary or supplementary resource for courses that
address mixed methods research.


**Key Features**

  * Each of the 14 foundational readings offers a brief introduction by the
editors, discussing the reading's overall importance to mixed methods research
and explaining what aspect of the research process is addressed.

  * The foundational readings are organized around the research process to
facilitate its use as a text or supplement for research courses emphasizing
mixed methods approaches. They cover research design types and purposes, data
collection, data analysis, reporting of mixed methods studies, and future
directions.

  * Each of the 9 exemplary studies include a brief commentary from the
editors, highlighting the noteworthy features of the article. These exemplary
studies range in discipline and setting yet focus intently on the research
process and the various ways of conducting mixed methods studies.

  * Visual diagrams accompany each exemplary study: These visual diagrams will
convey the overall structure and approach used in each of the studies.

  * Discussion questions accompanying each selection further call attention to
the key points and help a student or individual researcher to tie together the
core concepts presented in the commentaries and articles.}},
    citeulike-article-id = {5410331},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1412951453},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/1412951453},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/1412951453},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/1412951453},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/1412951453/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/1412951453},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/1412951453},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN1412951453},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=1412951453\&index=books\&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/1412951453},
    day = {10},
    howpublished = {Paperback},
    isbn = {1412951453},
    keywords = {proposal},
    month = dec,
    posted-at = {2009-08-11 01:10:27},
    priority = {2},
    publisher = {Sage Publications, Inc},
    title = {{The Mixed Methods Reader}},
    url = {http://www.worldcat.org/isbn/1412951453},
    year = {2007}
}

@book{citeulike:447180,
	abstract = {Once again, editors Norman K. Denzin and Yvonna S Lincoln have put together a
volume that represents the state of the art for the theory and practice of
qualitative inquiry. Built on the foundation of the landmark first edition,
published in 1994, the second edition is both the bridge and the roadmap to
the territory that lies ahead for researchers across the disciplines.

The Second Edition is a significant revision; in fact, it is virtually a new
work. It features six new chapter topics, including, among others, auto-
ethnography, critical race theory, applied ethnography, queer theory, and
testimonies. Another fifteen chapters are written by new contributors. And
every chapter in the book has been thoroughly revised and updated.

At the beginning of the twenty-first century, it is necessary to re-engage the
promise of qualitative research as a generative form of inquiry. The Second
Edition of the Handbook reveals how the discourses of qualitative research can
be used to imagine and create a free and democratic society. Ground-breaking,
thought-provoking, comprehensive and featuring the contributions of a virtual
"Who's Who" in the human sciences, Handbook of Qualitative Research, Second
Edition is absolutely an essential text for the library of any scholar
interested in the art and science of research.},
	citeulike-article-id = {447180},
	citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0761915125},
	citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0761915125},
	citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0761915125},
	citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0761915125},
	citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0761915125/citeulike00-21},
	citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0761915125},
	citeulike-linkout-6 = {http://www.worldcat.org/isbn/0761915125},
	citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0761915125},
	citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0761915125&index=books&linkCode=qs},
	citeulike-linkout-9 = {http://www.librarything.com/isbn/0761915125},
	edition = {2nd},
	howpublished = {Hardcover},
	isbn = {0761915125},
	keywords = {proposal},
	month = {March},
	posted-at = {2009-08-11 01:08:30},
	priority = {2},
	publisher = {Sage Publications, Inc},
	title = {Handbook of Qualitative Research},
	url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0761915125},
	year = {2000}
}

	

@incollection{GubaLincoln-CompetingParadigms,
	author = {Guba, Egon G. and Lincoln, Yvonna S.},
	booktitle = {The Landscape of Qualitative Research},
	citeulike-article-id = {5410307},
	citeulike-linkout-0 = {http://www.fosonline.org/MCI/DB/view.cfm?ENID=294},
	comment = {Beschreiben Paradigmen qualitativer sozialforschung: Positivismus, Postpositivismus, Kritische Theorie und Konstruktivismus. Eventuell relevant, f\"{u}r einen Methodenartikel},
	editor = {Denzin, Norman K. and Lincoln, Yvonna S.},
	keywords = {proposal},
	pages = {195--220},
	posted-at = {2009-08-11 00:31:17},
	priority = {0},
	publisher = {Sage},
	title = {Competing paradigms in qualitative research},
	url = {http://www.fosonline.org/MCI/DB/view.cfm?ENID=294},
	year = {1998}
}



@article{citeulike:2132242,
	abstract = {In recent years evaluators of educational and social programs have expanded their methodological repertoire with designs that include the use of both qualitative and quantitative methods. Such practice, however, needs to be grounded in a theory that can meaningfully guide the design and implementation of mixed-method evaluations. In this study, a mixed-method conceptual framework was developed from the theoretical literature and then refined through an analysis of 57 empirical mixed-method evaluations. Five purposes for mixed-method evaluations are identified in this conceptual framework: triangulation, complementarity, development, initiation, and expansion. For each of the five purposes, a recommended design is also presented in terms of seven relevant design characteristics. These design elements encompass issues about methods, the phenomena under investigation, paradigmatic framework, and criteria for implementation. In the empirical review, common misuse of the term triangulation was apparent in evaluations that stated such a purpose but did not employ an appropriate design. In addition, relatively few evaluations in this review integrated the different method types at the level of data analysis. Strategies for integrated data analysis are among the issues identified as priorities for further mixed-method work.},
	author = {Greene, Jennifer C. and Caracelli, Valerie J. and Graham, Wendy F.},
	citeulike-article-id = {2132242},
	citeulike-linkout-0 = {http://dx.doi.org/10.2307/1163620},
	citeulike-linkout-1 = {http://www.jstor.org/stable/1163620},
	doi = {10.2307/1163620},
	issn = {01623737},
	journal = {Educational Evaluation and Policy Analysis},
	keywords = {proposal},
	number = {3},
	pages = {255--274},
	posted-at = {2009-08-11 00:18:11},
	priority = {2},
	publisher = {American Educational Research Association},
	title = {Toward a Conceptual Framework for Mixed-Method Evaluation Designs},
	url = {http://dx.doi.org/10.2307/1163620},
	volume = {11},
	year = {1989}
}



@article{citeulike:5410299,
	abstract = {Four integrative data analysis strategies for mixed-method evaluation designs are derived from and illustrated by empirical practice: data transformation, typology development, extreme case analysis, and data consolidation/merging. The appropriateness of these strategies for different kinds of mixed-method intents is then discussed. Where appropriate, such integrative strategies are encouraged as ways to realize the full potential of mixed-methodological approaches.},
	author = {Caracelli, Valerie J. and Greene, Jennifer C.},
	citeulike-article-id = {5410299},
	citeulike-linkout-0 = {http://dx.doi.org/10.2307/1164421},
	citeulike-linkout-1 = {http://www.jstor.org/stable/1164421},
	doi = {10.2307/1164421},
	issn = {01623737},
	journal = {Educational Evaluation and Policy Analysis},
	keywords = {proposal},
	number = {2},
	pages = {195--207},
	posted-at = {2009-08-11 00:17:52},
	priority = {2},
	publisher = {American Educational Research Association},
	title = {Data Analysis Strategies for Mixed-Method Evaluation Designs},
	url = {http://dx.doi.org/10.2307/1164421},
	volume = {15},
	year = {1993}
}



@article{citeulike:5410262,
	abstract = {Health care research includes many studies that combine quantitative and qualitative methods. In this paper, we revisit the quantitative-qualitative debate and review the arguments for and against using mixed-methods. In addition, we discuss the implications stemming from our view, that the paradigms upon which the methods are based have a different view of reality and therefore a different view of the phenomenon under study. Because the two paradigms do not study the same phenomena, quantitative and qualitative methods cannot be combined for cross-validation or triangulation purposes. However, they can be combined for complementary purposes. Future standards for mixed-methods research should clearly reflect this recommendation.},
	author = {Sale, Joanna E. M. and Lohfeld, Lynne H. and Brazil, Kevin},
	citeulike-article-id = {5410262},
	citeulike-linkout-0 = {http://dx.doi.org/10.1023/A:1014301607592},
	citeulike-linkout-1 = {http://www.springerlink.com/content/reptjmhej4la023r},
	doi = {10.1023/A:1014301607592},
	journal = {Quality and Quantity},
	keywords = {proposal},
	month = {February},
	number = {1},
	pages = {43--53},
	posted-at = {2009-08-10 23:57:15},
	priority = {2},
	title = {Revisiting the Quantitative-Qualitative Debate: Implications for Mixed-Methods Research},
	url = {http://dx.doi.org/10.1023/A:1014301607592},
	volume = {36},
	year = {2002}
}


@book{citeulike:209817,
	abstract = {\_ \_

"Creswell's **Research Design** is an accessible and useful book that
stimulates students through walk through experiences, use of exercises, and
production of actual writing samples. It is a book that models the types of
issues that best suit different approaches and allows students to understand
when to use mixed methods. Furthermore, its focus on theory and paradigms is
done in a way that helps students decode their meaning."

--MARTHA MONTERO-SIEBURTH, \_University of Massachusetts, Boston \_

"One of the most formidable challenges of research design is stating your
purpose. Creswell's approach takes the guesswork out of the process."

--STEVE GUERRIERO, \_Organization \& Management, Antioch New England Graduate
School \_

The **Second Edition **of the bestselling **Research Design: Qualitative,
Quantitative, and Mixed Methods Approaches **offers a unique comparison of
three key approaches to inquiry. This comparison begins with preliminary
consideration of knowledge claims for all three approaches, a review of the
literature, and reflections about the importance of writing and ethics in
scholarly inquiry. The book also addresses the key elements of the process of
research: writing an introduction; stating a purpose for the study;
identifying research questions and hypotheses; using theory; defining,
delimiting and stating the significance of the study; and advancing methods
and procedures for data collection and analysis.

**

Key Features:**

  * Provides a clear presentation of how to implement a mixed methods design
in your proposal or plan as well as show how to implement qualitative and
quantitative approaches

  * Presents the ethical issues that may arise in quantitative, qualitative
and mixed methods studies

  * Offers extensive writing tips to help get your research plan started in
the right direction

  * Contains the latest developments in qualitative inquiry-including
advocacy, participatory, and emancipatory approaches

This book is ideal for readers who seek assistance in designing a full
research study or planning a proposal for a scholarly journal article,
dissertation or thesis. The book is an invaluable reference on the basics of
research design as well as an effective text for graduate courses in Research
Methods, Research Design, and related topics. The book serves a broad audience
of social and human scientists in fields of marketing, management, criminal
justice, psychology, sociology, K-12 education, higher and post-secondary
education, nursing, health sciences, urban studies, and family research.

\^{A} 

(20080208)},
	author = {Creswell, John W.},
	citeulike-article-id = {209817},
	citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0761924426},
	citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0761924426},
	citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0761924426},
	citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0761924426},
	citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0761924426/citeulike00-21},
	citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0761924426},
	citeulike-linkout-6 = {http://www.worldcat.org/isbn/0761924426},
	citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0761924426},
	citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0761924426&index=books&linkCode=qs},
	citeulike-linkout-9 = {http://www.librarything.com/isbn/0761924426},
	edition = {2nd},
	howpublished = {Paperback},
	isbn = {0761924426},
	keywords = {proposal},
	month = {July},
	posted-at = {2009-08-10 02:25:17},
	priority = {2},
	publisher = {Sage Publications, Inc},
	title = {Research Design: Qualitative, Quantitative, and Mixed Methods Approaches (2nd Edition)},
	url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0761924426},
	year = {2002}
}

	
@phdthesis{csdl2-06-05,
	abstract = {Software development is slow, expensive and error prone, often resulting in products with a large number of defects which cause serious problems in usability, reliability, and performance. To combat this problem, software measurement provides a systematic and empirically-guided approach to control and improve software development processes and final products. However, due to the high cost associated with ``metrics collection'' and difficulties in ``metrics decision-making,'' measurement is not widely adopted by software organizations. This dissertation proposes a novel metrics-based program called ``software project telemetry'' to address the problems. It uses software sensors to collect metrics automatically and unobtrusively. It employs a domain-specific language to represent telemetry trends in software product and process metrics. Project management and process improvement decisions are made by detecting changes in telemetry trends and comparing trends between different periods of the same project. Software project telemetry avoids many problems inherent in traditional metrics models, such as the need to accumulate a historical project database and ensure that the historical data remain comparable to current and future projects. The claim of this dissertation is that software project telemetry provides an effective approach to (1) automated metrics collection and analysis, and (2) in-process, empirically-guided software development process problem detection and diagnosis. Two empirical studies were carried out to evaluate the claim: one in software engineering classes, and the other in the Collaborative Software Development Lab. The results suggested that software project telemetry had acceptably-low metrics collection and analysis overhead, and that it provided decision-making value at least in the exploratory context of the two studies.},
	author = {Zhang, Qin},
	citeulike-article-id = {5402133},
	citeulike-linkout-0 = {http://csdl.ics.hawaii.edu/techreports/06-05/06-05.pdf},
	keywords = {file-import-09-08-10, hackystat, thesis-phd},
	month = {December},
	posted-at = {2009-08-10 00:05:48},
	priority = {2},
	school = {University of Hawaii, Department of Information and Computer Sciences},
	title = {Improving Software Development Process and Product Management with Software Project Telemetry},
	type = {{Ph.D.} Thesis},
	url = {http://csdl.ics.hawaii.edu/techreports/06-05/06-05.pdf},
	year = {2006}
}

	

@inproceedings{citeulike:5398684,
	abstract = {this paper we propose DynaMine, a tool that analyzes source code check-ins to find highly correlated method calls as well as common bug fixes in order to automatically discover application-specific coding patterns. Potential patterns discovered through mining are passed to a dynamic analysis tool for validation; finally, the results of dynamic analysis are presented to the user},
	author = {Livshits, Benjamin and Zimmermann, Thomas},
	booktitle = {In ESEC/FSE},
	citeulike-article-id = {5398684},
	citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.9759},
	keywords = {proposal},
	pages = {296--305},
	posted-at = {2009-08-08 19:57:04},
	priority = {2},
	title = {DynaMine: Finding Common Error Patterns by Mining Software Revision Histories},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.9759},
	year = {2005}
}



@inproceedings{citeulike:3929070,
	abstract = {Modern source-control systems, such as Subversion, preserve change-sets of files as atomic commits. However, the specific ordering information in which files were changed is typically not found in these source-code repositories. In this paper, a set of heuristics for grouping change-sets (i.e., log-entries) found in source-code repositories is presented. Given such groups of change-sets, sequences of files that frequently change together are uncovered. This approach not only gives the (unordered) sets of files but supplements them with (partial temporal) ordering information. The technique is demonstrated on a subset of KDE source-code repository. The results show that the approach is able to find sequences of changed-files.},
	address = {New York, NY, USA},
	author = {Kagdi, Huzefa and Yusuf, Shehnaaz and Maletic, Jonathan I.},
	booktitle = {MSR '06: Proceedings of the 2006 international workshop on Mining software repositories},
	citeulike-article-id = {3929070},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1137983.1137996},
	citeulike-linkout-1 = {http://dx.doi.org/10.1145/1137983.1137996},
	doi = {10.1145/1137983.1137996},
	isbn = {1-59593-397-2},
	location = {Shanghai, China},
	pages = {47--53},
	posted-at = {2009-08-08 17:46:58},
	priority = {2},
	publisher = {ACM},
	title = {Mining sequences of changed-files from version histories},
	url = {http://dx.doi.org/10.1145/1137983.1137996},
	year = {2006}
}


@misc{citeulike:5397994,
	abstract = {During the evolution of a large software system there are requirements to extend  the system since the demands of the customer and the environment grow or  change constantly. Such large systems reach often a high level of complexity. Any  additional extension would take many changes and adaptations in the system. At  that point it is necessary to examine the system and its components concerning  the structural behaviour with respect to the need for restructuring. This master  \&\#039;s thesis evaluates the software evolution of a Telecommunication Switching  System. All investigations and results are based on release histories of different  decomposition levels and modules stored in a database. The major goal was to  identify \&\#034;logical coupling\&\#034; among modules and to determine whether or not this  coupling represents real module dependencies. The author developed a methodology  named \&\#034;CAESAR.\&\#034; It consists of two main processes: 1.) The Change  Sequence Analysis (CSA) represents all changes of a...},
	author = {Univ and Gall, Harald and Hajek, Karin},
	citeulike-article-id = {5397994},
	citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.5101},
	posted-at = {2009-08-08 16:39:49},
	priority = {2},
	title = {Detection of Logical Coupling Based on Product Release History},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.5101},
	year = {1998}
}


@inproceedings{citeulike:4406375,
	abstract = {Files, classes, or methods have frequently been investigated in recent research on co-change. In this paper, we present a first study at the level of lines. To identify line changes across several versions, we define the annotation graph which captures how lines evolve over time. The annotation graph provides more fine-grained software evolution information such as life cycles of each line and related changes: "Whenever a developer changed line 1 of version.txt she also changed line 25 of Library.java."},
	address = {New York, NY, USA},
	author = {Zimmermann, Thomas and Kim, Sunghun and Zeller, Andreas and Whitehead, E. James},
	booktitle = {MSR '06: Proceedings of the 2006 international workshop on Mining software repositories},
	citeulike-article-id = {4406375},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1137983.1138001},
	citeulike-linkout-1 = {http://dx.doi.org/10.1145/1137983.1138001},
	doi = {10.1145/1137983.1138001},
	isbn = {1-59593-397-2},
	location = {Shanghai, China},
	pages = {72--75},
	posted-at = {2009-08-06 02:39:47},
	priority = {2},
	publisher = {ACM},
	title = {Mining version archives for co-changed lines},
	url = {http://dx.doi.org/10.1145/1137983.1138001},
	year = {2006}
}



@article{citeulike:4534888,
	abstract = {A comprehensive literature survey on approaches for mining software repositories (MSR) in the context of software evolution is presented. In particular, this survey deals with those investigations that examine multiple versions of software artifacts or other temporal information. A taxonomy is derived from the analysis of this literature and presents the work via four dimensions: the type of software repositories mined (what), the purpose (why), the adopted/invented methodology used (how), and the evaluation method (quality). The taxonomy is demonstrated to be expressive (i.e., capable of representing a wide spectrum of MSR investigations) and effective (i.e., facilitates similarities and comparisons of MSR investigations). Lastly, a number of open research issues in MSR that require further investigation are identified.},
	address = {New York, NY, USA},
	author = {Kagdi, Huzefa and Collard, Michael L. and Maletic, Jonathan I.},
	citeulike-article-id = {4534888},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1345056.1345057},
	citeulike-linkout-1 = {http://dx.doi.org/10.1002/smr.344},
	doi = {10.1002/smr.344},
	issn = {1532-060X},
	journal = {J. Softw. Maint. Evol.},
	keywords = {proposal},
	number = {2},
	pages = {77--131},
	posted-at = {2009-08-06 02:39:18},
	priority = {2},
	publisher = {John Wiley \&amp; Sons, Inc.},
	title = {A survey and taxonomy of approaches for mining software repositories in the context of software evolution},
	url = {http://dx.doi.org/10.1002/smr.344},
	volume = {19},
	year = {2007}
}



@inproceedings{citeulike:5213050,
	abstract = {The thesis proposes a software-change prediction approach that is based on mining fine-grained evolutionary couplings from source code repositories. Here, fine-grain refers to identifying couplings between source code entities such as methods, control structures, or even comments. This differs from current source code mining techniques that typically only identify couplings between files or fairly high-level entities. Furthermore, the model combines the mined evolutionary couplings with the estimated changes identified by traditional impact analysis techniques (e.g., static analysis of call and program-dependency graphs). The research hypothesis is that software-change prediction using the proposed synergistic approach results in an overall improved expressiveness (i.e., granularity and context given to a developer) and effectiveness (i.e., accuracy of the prediction)},
	address = {New York, NY, USA},
	author = {Kagdi, Huzefa},
	booktitle = {ASE '07: Proceedings of the twenty-second IEEE/ACM international conference on Automated software engineering},
	citeulike-article-id = {5213050},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1321742},
	citeulike-linkout-1 = {http://dx.doi.org/10.1145/1321631.1321742},
	doi = {10.1145/1321631.1321742},
	isbn = {978-1-59593-882-4},
	location = {Atlanta, Georgia, USA},
	pages = {559--562},
	posted-at = {2009-08-06 02:34:18},
	priority = {2},
	publisher = {ACM},
	title = {Improving change prediction with fine-grained source code mining},
	url = {http://dx.doi.org/10.1145/1321631.1321742},
	year = {2007}
}



@article{citeulike:983796,
	abstract = {Software developers are often faced with modification tasks that involve source which is spread across a code base. Some dependencies between source code, such as those between source code written in different languages, are difficult to determine using existing static and dynamic analyses. To augment existing analyses and to help developers identify relevant source code during a modification task, we have developed an approach that applies data mining techniques to determine change patterns - sets of files that were changed together frequently in the past - from the change history of the code base. Our hypothesis is that the change patterns can be used to recommend potentially relevant source code to a developer performing a modification task. We show that this approach can reveal valuable dependencies by applying the approach to the Eclipse and Mozilla open source projects and by evaluating the predictability and interestingness of the recommendations produced for actual modification tasks on these systems.},
	address = {Piscataway, NJ, USA},
	author = {Ying, A. T. T. and Murphy, G. C. and Ng, R. and Chu-Carroll, M. C.},
	booktitle = {Software Engineering, IEEE Transactions on},
	citeulike-article-id = {983796},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1018388},
	citeulike-linkout-1 = {http://dx.doi.org/10.1109/TSE.2004.52},
	citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1324645},
	doi = {10.1109/TSE.2004.52},
	issn = {0098-5589},
	journal = {Software Engineering, IEEE Transactions on},
	keywords = {proposal},
	month = {September},
	number = {9},
	pages = {574--586},
	posted-at = {2009-08-06 01:57:50},
	priority = {2},
	publisher = {IEEE Press},
	title = {Predicting source code changes by mining change history},
	url = {http://dx.doi.org/10.1109/TSE.2004.52},
	volume = {30},
	year = {2004}
}



@inproceedings{citeulike:5375867,
	abstract = {Understanding function signature change properties and evolution patterns is important for researchers concerned with alleviating signature change impacts, understanding software evolution, and predicting future evolution patterns. We provide detailed signature change properties by analyzing seven software project histories to reveal multiple properties of signature changes, including their kind, frequency, correlation with other changes, number of parameter changes, and evolution patterns of signature change kinds. We show that signature changes can be used as measurement aid for software evolution analysis.},
	address = {Washington, DC, USA},
	author = {Kim, Sunghun and Whitehead, E. James and Jennifer Bevan},
	booktitle = {ICSM '06: Proceedings of the 22nd IEEE International Conference on Software Maintenance},
	citeulike-article-id = {5375867},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1172973},
	citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICSM.2006.47},
	doi = {10.1109/ICSM.2006.47},
	isbn = {0-7695-2354-4},
	keywords = {proposal},
	pages = {4--13},
	posted-at = {2009-08-06 01:45:46},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Properties of Signature Change Patterns},
	url = {http://dx.doi.org/10.1109/ICSM.2006.47},
	year = {2006}
}



@inproceedings{citeulike:5375823,
	abstract = {Understanding software change patterns during evolution is important for researchers concerned with alleviating change impacts. It can provide insight to understand the software evolution, predict future changes, and develop new refactoring algorithms. However, most of the current research focus on the procedural programs like C, or object-oriented programs like Java; seldom effort has been made for aspect-oriented software. In this paper, we propose an approach for mining change patterns in AspectJ software evolution. Our approach first decomposes the software changes into a set of atomic change representations, then employs the apriori data mining algorithm to generate the most frequent itemsets. The patterns we found reveal multiple properties of software changes, including their kind, frequency, and correlation with other changes. In our empirical evaluation on several non-trivial AspectJ benchmarks, we demonstrate that those change patterns can be used as measurement aid and fault predication for AspectJ software evolution analysis.},
	author = {Qian, Yin and Zhang, Sai and Qi, Zhengwei},
	booktitle = {Computer Science and Software Engineering, 2008 International Conference on},
	citeulike-article-id = {5375823},
	citeulike-linkout-0 = {http://dx.doi.org/10.1109/CSSE.2008.802},
	citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4722012},
	doi = {10.1109/CSSE.2008.802},
	journal = {Computer Science and Software Engineering, 2008 International Conference on},
	keywords = {proposal},
	pages = {108--111},
	posted-at = {2009-08-06 01:38:01},
	priority = {2},
	title = {Mining Change Patterns in AspectJ Software Evolution},
	url = {http://dx.doi.org/10.1109/CSSE.2008.802},
	volume = {2},
	year = {2008}
}


@incollection{citeulike:5361927,
	abstract = {The workshop addresses practitioners and/or researchers who are interested in empirical software engineering, software process improvement, and quality management.Practitioners are being addressed specifically, since this workshop is also intended to find out what kind of information practitioners need, which kind of support they expect from research regarding the aggregation of information, and how they select software engineering technology.},
	author = {Ciolkowski, Marcus and Jedlitschka, Andreas},
	citeulike-article-id = {5361927},
	citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-73460-4\_34},
	citeulike-linkout-1 = {http://www.springerlink.com/content/p027315160r04l51},
	doi = {10.1007/978-3-540-73460-4\_34},
	journal = {Product-Focused Software Process Improvement},
	keywords = {methodology, proposal, research},
	pages = {402--404},
	posted-at = {2009-08-04 21:33:37},
	priority = {2},
	title = {Experience on Applying Quantitative and Qualitative Empiricism to Software Engineering},
	url = {http://dx.doi.org/10.1007/978-3-540-73460-4\_34},
	year = {2007}
}



@article{citeulike:5361919,
	abstract = {In this paper, we argue that the gap between  empirical software engineering and software  engineering practice might be lessened if more attention  were paid to two important aspects of evidence. The  first is that evidence from case or field studies of actual  software engineering practice is essential in order to  understand and inform that practice. The second is that  the nature of evidence should fit the purpose to which  the evidence is going to be put. One type of evidence is  not per se better than another. For example, the  evidence required to persuade a manager to change an  aspect of practice might be totally different in nature  from that required to deepen the academic community's  understanding of such practice.},
	address = {Los Alamitos, CA, USA},
	author = {Segal, Judith},
	citeulike-article-id = {5361919},
	citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/STEP.2003.33},
	citeulike-linkout-1 = {http://dx.doi.org/10.1109/STEP.2003.33},
	doi = {10.1109/STEP.2003.33},
	isbn = {0-7695-2218-1},
	journal = {Software Technology and Engineering Practice, International Workshop on},
	keywords = {methodology, proposal, research},
	pages = {40--47},
	posted-at = {2009-08-04 21:32:44},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {The Nature of Evidence in Empirical Software Engineering},
	url = {http://dx.doi.org/10.1109/STEP.2003.33},
	volume = {0},
	year = {2003}
}



@inproceedings{citeulike:5361802,
	abstract = {In this paper, we argue that the gap between empirical software engineering and software engineering practice might be lessened if more attention were paid to two important aspects of evidence. The first is that evidence from case or field studies of actual software engineering practice is essential in order to understand and inform that practice. The second is that the nature of evidence should fit the purpose to which the evidence is going to be put. One type of evidence is not per se better than another. For example, the evidence required to persuade a manager to change an aspect of practice might be totally different in nature from that required to deepen the academic community's understanding of such practice.},
	address = {Washington, DC, USA},
	author = {Segal, Judith},
	booktitle = {STEP '03: Proceedings of the Eleventh Annual International Workshop on Software Technology and Engineering Practice},
	citeulike-article-id = {5361802},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1034388},
	isbn = {0-7695-2218-1},
	keywords = {methodology, proposal, research},
	pages = {40--47},
	posted-at = {2009-08-04 21:31:06},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {The Nature of Evidence in Empirical Software Engineering},
	url = {http://portal.acm.org/citation.cfm?id=1034388},
	year = {2003}
}



@article{citeulike:5361791,
	author = {Sim, Susan E. and Singer, Janice and Storey, Margaret-Anne},
	citeulike-article-id = {5361791},
	citeulike-linkout-0 = {http://dx.doi.org/10.1023/A:1009809824225},
	citeulike-linkout-1 = {http://www.springerlink.com/content/m22746122r2t13h8},
	doi = {10.1023/A:1009809824225},
	journal = {Empirical Software Engineering},
	keywords = {methodology, proposal, research},
	month = {March},
	number = {1},
	pages = {85--93},
	posted-at = {2009-08-04 21:11:35},
	priority = {2},
	title = {Beg, Borrow, or Steal: Using Multidisciplinary Approaches in Empirical Software Engineering Research},
	url = {http://dx.doi.org/10.1023/A:1009809824225},
	volume = {6},
	year = {2001}
}



@article{citeulike:1396399,
	author = {Tichy, Walter F.},
	citeulike-article-id = {1396399},
	citeulike-linkout-0 = {http://dx.doi.org/10.1023/A:1009844119158},
	citeulike-linkout-1 = {http://www.springerlink.com/content/rr70j282h2k01960},
	doi = {10.1023/A:1009844119158},
	journal = {Empirical Software Engineering},
	keywords = {methodology, proposal, research},
	month = {December},
	number = {4},
	pages = {309--312},
	posted-at = {2009-08-04 21:10:13},
	priority = {2},
	title = {Hints for Reviewing Empirical Work in Software Engineering},
	url = {http://dx.doi.org/10.1023/A:1009844119158},
	volume = {5},
	year = {2000}
}



@inproceedings{citeulike:4712996,
	abstract = {This paper reports on the research published between the years 1997 and 2003 inclusive in the journal of Empirical Software Engineering, drawing on the taxonomy developed by Glass et al. in [3]. We found that the research was somewhat narrow in topic with about half the papers focusing on measurement/metrics, review and inspection; that researchers were almost as interested in formulating as in evaluating; that hypothesis testing and laboratory experiments dominated evaluations; that research was not very likely to focus on people and extremely unlikely to refer to other disciplines. We discuss our findings in the context of making empirical software engineering more relevant to practitioners.},
	address = {New York, NY, USA},
	author = {Segal, Judith and Grinyer, Antony and Sharp, Helen},
	booktitle = {REBSE '05: Proceedings of the 2005 workshop on Realising evidence-based software engineering},
	citeulike-article-id = {4712996},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1083174.1083176},
	citeulike-linkout-1 = {http://dx.doi.org/10.1145/1083174.1083176},
	doi = {10.1145/1083174.1083176},
	isbn = {1-59593-121-X},
	keywords = {methodology, proposal, research},
	location = {St. Louis, Missouri},
	pages = {1--4},
	posted-at = {2009-08-04 21:09:09},
	priority = {2},
	publisher = {ACM},
	title = {The type of evidence produced by empirical software engineers},
	url = {http://dx.doi.org/10.1145/1083174.1083176},
	year = {2005}
}



@article{citeulike:1421943,
	abstract = {While empirical studies in software engineering are beginning to gain recognition in the research community, this subarea is also entering a new level of maturity by beginning to address the human aspects of software development. This added focus has added a new layer of complexity to an already challenging area of research. Along with new research questions, new research methods are needed to study nontechnical aspects of software engineering. In many other disciplines, qualitative research methods have been developed and are commonly used to handle the complexity of issues involving human behavior. This paper presents several qualitative methods for data collection and analysis and describes them in terms of how they might be incorporated into empirical studies of software engineering, in particular how they might be combined with quantitative methods. To illustrate this use of qualitative methods, examples from real software engineering studies are used throughout.},
	address = {Piscataway, NJ, USA},
	author = {Seaman, Carolyn B.},
	citeulike-article-id = {1421943},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=322687},
	citeulike-linkout-1 = {http://dx.doi.org/10.1109/32.799955},
	doi = {10.1109/32.799955},
	issn = {0098-5589},
	journal = {IEEE Trans. Softw. Eng.},
	keywords = {methodology, proposal, research},
	month = {July},
	number = {4},
	pages = {557--572},
	posted-at = {2009-08-04 21:08:12},
	priority = {2},
	publisher = {IEEE Press},
	title = {Qualitative Methods in Empirical Studies of Software Engineering},
	url = {http://dx.doi.org/10.1109/32.799955},
	volume = {25},
	year = {1999}
}



@article{citeulike:4712961,
	abstract = {Over the past decade we have performed a sustained series of qualitative studies of software development practice, focusing on social factors. Using an ethnographically-informed approach, we have addressed four areas of software practice: software quality management systems, the emergence of object technology, professional end user development and agile development. Several issues have arisen from this experience, including the nature of research questions that such studies can address, the advantages and challenges associated with being a member of the community under study, and how to maintain rigour in data collection. In this paper, we will draw on our studies to illustrate our approach and to discuss these and other issues.},
	address = {Newton, MA, USA},
	author = {Robinson, H. and Segal, J. and Sharp, H.},
	citeulike-article-id = {4712961},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1240332.1240476},
	citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.infsof.2007.02.007},
	citeulike-linkout-2 = {http://linkinghub.elsevier.com/retrieve/pii/S0950584907000110},
	doi = {10.1016/j.infsof.2007.02.007},
	issn = {09505849},
	journal = {Information and Software Technology},
	keywords = {methodology, proposal, research},
	month = {June},
	number = {6},
	pages = {540--551},
	posted-at = {2009-08-04 21:06:30},
	priority = {2},
	publisher = {Butterworth-Heinemann},
	title = {Ethnographically-informed empirical studies of software practice},
	url = {http://dx.doi.org/10.1016/j.infsof.2007.02.007},
	volume = {49},
	year = {2007}
}


@techreport{citeulike:5333719,
	author = {Barnes, N.},
	citeulike-article-id = {5333719},
	citeulike-linkout-0 = {http://www.ravenbrook.com/project/p4dti/master/design/ bugzilla-schema/},
	institution = {Ravenbrook Limited},
	keywords = {proposal},
	month = {July},
	posted-at = {2009-08-02 23:37:02},
	priority = {2},
	title = {Bugzilla database schema.},
	url = {http://www.ravenbrook.com/project/p4dti/master/design/ bugzilla-schema/},
	year = {2004}
}


@book{citeulike:1230319,
	abstract = {**Learn how to employ JADE to build multi-agent systems!**

JADE (Java Agent DEvelopment framework) is a middleware for the development of
applications, both in the mobile and fixed environment, based on the Peer-to-
Peer intelligent autonomous agent approach. JADE enables developers to
implement and deploy multi-agent systems, including agents running on wireless
networks and limited-resource devices.

\_Developing Multi-Agent Systems with JADE\_ is a practical guide to using JADE.
The text will give an introduction to agent technologies and the JADE
Platform, before proceeding to give a comprehensive guide to programming with
JADE. Basic features such as creating agents, agent tasks, agent
communication, agent discovery and GUIs are covered, as well as more advanced
features including ontologies and content languages, complex behaviours,
interaction protocols, agent mobility, and the in-process interface. Issues
such as JADE internals, running JADE agents on mobile devices, deploying a
fault tolerant JADE platform, and main add-ons are also covered in depth.

\_Developing Multi-Agent Systems with JADE\_:

  * Comprehensive guide to using JADE to build multi-agent systems and agent
orientated programming.

  * Describes and explains ontologies and content language, interaction
protocols and complex behaviour.

  * Includes material on persistence, security and a semantics framework.

  * Contains numerous examples, problems, and illustrations to enhance
learning.

  * Presents a case study demonstrating the use of JADE in practice.

  * Offers an accompanying website with additional learning resources such as
sample code, exercises and PPT-slides.

This invaluable resource will provide multi-agent systems practitioners,
programmers working in the software industry with an interest on multi-agent
systems as well as final year undergraduate and postgraduate students in CS
and advanced networking and telecoms courses with a comprehensive guide to
using JADE to employ multi agent systems.

With contributions from experts in JADE and multi agent technology.},
	author = {Bellifemine, Fabio L. and Caire, Giovanni and Greenwood, Dominic},
	citeulike-article-id = {1230319},
	citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0470057475},
	citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0470057475},
	citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0470057475},
	citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0470057475},
	citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0470057475/citeulike00-21},
	citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0470057475},
	citeulike-linkout-6 = {http://www.worldcat.org/isbn/0470057475},
	citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0470057475},
	citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0470057475&index=books&linkCode=qs},
	citeulike-linkout-9 = {http://www.librarything.com/isbn/0470057475},
	howpublished = {Hardcover},
	isbn = {0470057475},
	keywords = {proposal},
	month = {April},
	posted-at = {2009-07-20 00:06:03},
	priority = {2},
	publisher = {Wiley},
	title = {Developing Multi-Agent Systems with JADE (Wiley Series in Agent Technology)},
	url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0470057475},
	year = {2007}
}

	

@phdthesis{citeulike:2703162,
	abstract = {A recent focus of interest in software engineering research is on low-level software processes, which define how software developers or development teams should carry on development activities in short phases that last from several minutes to a few hours. Anecdotal evidence exists for the positive impact on quality and productivity of certain low-level software processes such as test-driven development and continuous integration. However, empirical research on low-level software processes often yields conflicting results. A significant threat to the validity of the empirical studies on low-level software processes is that they lack the ability to rigorously assess process conformance. That is to say, the degree to which developers follow the low-level software processes can not be evaluated. In order to improve the quality of empirical research on low-level software processes, I developed a technique called Software Development Stream Analysis (SDSA) that can infer development behaviors using automatically collected in-process software metrics. The collection of development activities is supported by Hackystat, a framework for automated software process and product metrics collection and analysis. SDSA abstracts the collected software metrics into a software development stream, a time-series data structure containing time-stamped development events. It then partitions the development stream into episodes, and then uses a rule-based system to infer low-level development behaviors exhibited in episodes. With the capabilities provided by Hackystat and SDSA, I developed the Zorro software system to study a specific low-level software process called Test-Driven Development (TDD). Experience reports have shown that TDD can greatly improve software quality with increased developer productivity, but empirical research findings on TDD are often mixed. An inability to rigorously assess process conformance is a possible explanation. Zorro can rigorously assess process conformance to a specific operational definition for TDD, and thus enable more controlled, comparable empirical studies. My research has demonstrated that Zorro can recognize the low-level software development behaviors that characterize TDD. Both the pilot and classroom case studies support this conclusion. The industrial case study shows that the automated data collection and development behavior inference has the potential to be useful for researchers.},
	author = {Kou, Hongbing},
	citeulike-article-id = {2703162},
	citeulike-linkout-0 = {http://csdl.ics.hawaii.edu/techreports/07-04/07-04.pdf},
	keywords = {proposal},
	month = {December},
	posted-at = {2009-07-19 23:23:13},
	priority = {2},
	school = {University of Hawaii, Department of Information and Computer Sciences},
	title = {Automated Inference of Software Development Behaviors: Design, Implementation and Validation of Zorro for Test-Driven Development},
	type = {{Ph.D.} Thesis},
	url = {http://csdl.ics.hawaii.edu/techreports/07-04/07-04.pdf},
	year = {2007}
}

	

@book{citeulike:709476,
	abstract = {Our ability to generate and collect data has been increasing rapidly. Not only are all of our business, scientific, and government transactions now computerized, but the widespread use of digital cameras, publication tools, and bar codes also generate data. On the collection side, scanned text and image platforms, satellite remote sensing systems, and the World Wide Web have flooded us with a tremendous amount of data. This explosive growth has generated an even more urgent need for new techniques and automated tools that can help us transform this data into useful information and knowledge.<br><br>Like the first edition, voted the most popular data mining book by KD Nuggets readers, this book explores concepts and techniques for the discovery of patterns hidden in large data sets, focusing on issues relating to their feasibility, usefulness, effectiveness, and scalability. However, since the publication of the first edition, great progress has been made in the development of new data mining methods, systems, and applications. This new edition substantially enhances the first edition, and new chapters have been added to address recent developments on mining complex types of data including stream data, sequence data, graph structured data, social network data, and multi-relational data.<br><br>Whether you are a seasoned professional or a new student of data mining, this book has much to offer you:<br>* A comprehensive, practical look at the concepts and techniques you need to know to get the most out of real business data.<br>* Updates that incorporate input from readers, changes in the field, and more material on statistics and machine learning.<br>* Dozens of algorithms and implementation examples, all in easily understood pseudo-code and suitable for use in real-world, large-scale data mining projects.<br>* Complete classroom support for instructors at www.mkp.com/datamining2e companion site.},
	author = {Han, Jiawei and Kamber, Micheline},
	citeulike-article-id = {709476},
	citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/1558609016},
	citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/1558609016},
	citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/1558609016},
	citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/1558609016},
	citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/1558609016/citeulike00-21},
	citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/1558609016},
	citeulike-linkout-6 = {http://www.worldcat.org/isbn/1558609016},
	citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN1558609016},
	citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=1558609016&index=books&linkCode=qs},
	citeulike-linkout-9 = {http://www.librarything.com/isbn/1558609016},
	howpublished = {Hardcover},
	isbn = {1558609016},
	keywords = {proposal},
	month = {January},
	posted-at = {2009-07-18 17:25:55},
	priority = {2},
	publisher = {Morgan Kaufmann},
	title = {Data Mining,  Second Edition, Second Edition : Concepts and Techniques (The Morgan Kaufmann Series in Data Management Systems) (The Morgan Kaufmann Series in Data Management Systems)},
	url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/1558609016},
	year = {2006}
}

	

@manual{citer,
	address = {Vienna, Austria},
	author = {{R Development Core Team}},
	citeulike-article-id = {5173022},
	citeulike-linkout-0 = {http://www.R-project.org},
	comment = {{ISBN} 3-900051-07-0},
	keywords = {file-import-09-07-16},
	organization = {R Foundation for Statistical Computing},
	posted-at = {2009-07-16 01:49:45},
	priority = {2},
	title = {R: A language and environment for statistical computing},
	url = {http://www.R-project.org},
	year = {2005}
}



@article{citeulike:5164952,
	abstract = {In the past, we proposed an incremental mining algorithm for maintenance of sequential patterns based on the concept of pre-large sequences as new records were inserted. In this paper, we attempt to apply the concept of pre-large sequences to maintain sequential  patterns as records are deleted. Pre-large sequences are defined by a lower support threshold and an upper support threshold. They act as buffers to avoid the movements of sequential patterns directly from large to small and vice-versa. Our proposed algorithm does not  require rescanning original databases until the accumulative amount of deleted customer sequences exceeds a safety bound, which depends on database size. As databases grow larger, the numbers of deleted customer sequences allowed before database rescanning  is required also grow. The proposed approach is thus efficient for a large database.},
	address = {Los Alamitos, CA, USA},
	author = {Wang, Ching Y. and Hong, Tzung P. and Tseng, Shian S.},
	citeulike-article-id = {5164952},
	citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/ICDM.2001.989562},
	citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICDM.2001.989562},
	doi = {10.1109/ICDM.2001.989562},
	isbn = {0-7695-1119-8},
	journal = {Data Mining, IEEE International Conference on},
	keywords = {proposal},
	pages = {536+},
	posted-at = {2009-07-15 21:44:03},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Maintenance of Sequential Patterns for Record Deletion},
	url = {http://dx.doi.org/10.1109/ICDM.2001.989562},
	volume = {0},
	year = {2001}
}



@misc{citeulike:5164923,
	abstract = {: The problem of mining sequential patterns was recently introduced in [AS95]. We are given a database of sequences, where each sequence is a list of transactions ordered by transaction-time, and each transaction is a set of items. The problem is to discover all sequential patterns with a user-specified minimum support, where the support of a pattern is the number of data-sequences that contain the pattern. An example of a sequential pattern is \&\#034;5\% of customers bought `Foundation\&\#039; and `Ringworld\&\#039; in one transaction, followed by `Second Foundation\&\#039; in a later transaction\&\#034;. We generalize the problem as follows. First, we add time constraints that specify a minimum and/or maximum time period between adjacent elements in a pattern. Second, we relax the restriction that the items in an element of a sequential pattern must come from the same transaction, instead allowing the items to be present in a set of transactions whose transaction-times are within a user-specified time window. Third, g...},
	author = {Srikant, Ramakrishnan and Srikant, Ramakrishnan and Agrawal, Rakesh and Agrawal, Rakesh},
	citeulike-article-id = {5164923},
	citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.7320},
	keywords = {proposal},
	pages = {3--17},
	posted-at = {2009-07-15 21:38:31},
	priority = {2},
	title = {Mining Sequential Patterns: Generalizations And Performance Improvements},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.7320},
	year = {1996}
}



@article{citeulike:769773,
	abstract = {The set of frequent closed itemsets uniquely determines the exact frequency of all itemsets, yet it can be orders of magnitude smaller than the set of all frequent itemsets. In this paper, we present CHARM, an efficient algorithm for mining all frequent closed itemsets. It enumerates closed sets using a dual itemset-tidset search tree, using an efficient hybrid search that skips many levels. It also uses a technique called diffsets to reduce the memory footprint of intermediate computations. Finally, it uses a fast hash-based approach to remove any "nonclosed" sets found during computation. We also present CHARM-L, an algorithm that outputs the closed itemset lattice, which is very useful for rule generation and visualization. An extensive experimental evaluation on a number of real and synthetic databases shows that CHARM is a state-of-the-art algorithm that outperforms previous methods. Further, CHARM-L explicitly generates the frequent closed itemset lattice.},
	address = {Los Alamitos, CA, USA},
	author = {Zaki, Mohammed J. and Hsiao, Ching J.},
	citeulike-article-id = {769773},
	citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/TKDE.2005.60},
	citeulike-linkout-1 = {http://dx.doi.org/10.1109/TKDE.2005.60},
	citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1401887},
	doi = {10.1109/TKDE.2005.60},
	issn = {1041-4347},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	keywords = {proposal},
	number = {4},
	pages = {462--478},
	posted-at = {2009-07-15 17:54:52},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Efficient Algorithms for Mining Closed Itemsets and Their Lattice Structure},
	url = {http://dx.doi.org/10.1109/TKDE.2005.60},
	volume = {17},
	year = {2005}
}


@article{citeulike:5159924,
	abstract = {This paper presents a method for the discovery of temporal patterns in multivariate time series and their conversion into a linguistic knowledge representation applied to sleep-related breathing disorders. The main idea lies in introducing several abstraction levels that allow a step-wise identification of temporal patterns. Self-organizing neural networks are used to discover elementary patterns in the time series. Machine learning (ML) algorithms use the results of the neural networks to automatically generate a rule-based description. At the next levels, temporal grammatical rules are inferred. This method covers one of the main  ” bottlenecks” in the design of knowledge-based systems, namely, the knowledge acquisition problem. An evaluation of the rules lead to an overall sensitivity of 0.762, and a specificity of 0.758.},
	author = {Guimar\~{a}es, G.},
	citeulike-article-id = {5159924},
	citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0933-3657(01)00089-6},
	citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0933-3657(01)00089-6},
	doi = {10.1016/S0933-3657(01)00089-6},
	issn = {09333657},
	journal = {Artificial Intelligence in Medicine},
	keywords = {proposal},
	month = {November},
	number = {3},
	pages = {211--237},
	posted-at = {2009-07-15 16:50:49},
	priority = {2},
	title = {A method for automated temporal knowledge acquisition applied to sleep-related breathing disorders},
	url = {http://dx.doi.org/10.1016/S0933-3657(01)00089-6},
	volume = {23},
	year = {2001}
}

	

@phdthesis{citeulike:5159625,
	address = {Germany},
	author = {H\"{o}ppner, F.},
	citeulike-article-id = {5159625},
	institution = {Technical University Braunschweig},
	keywords = {proposal, thesis},
	posted-at = {2009-07-15 16:01:45},
	priority = {2},
	school = {Technical University Braunschweig},
	title = {Knowledge Discovery from SequentialData.},
	year = {2003}
}



@misc{citeulike:5159615,
	abstract = {. Recently, association rule mining has been generalized to the  discovery of episodes in event sequences. In this paper, we additionally  take durations into account and thus present a generalization to time  intervals. We discover frequent temporal patterns in a single series of  such labeled intervals, which we call a state sequence. A temporal pattern  is dened as a set of states together with their interval relationships  described in terms of Allen\&\#039;s interval logic, for instance \A before B,  A overlaps C, C overlaps B\&\#034; or equivalently \state A ends before state  B starts, the gap is covered by state C\&\#034;. As an example we consider  the problem of deriving local weather forecasting rules that allow us to  conclude from the qualitative behaviour of the air-pressure curve to the  wind-strength. Here, the states have been extracted automatically from  (multivariate) time series and characterize the trend of the time series  locally within the assigned time interval.  1 },
	author = {H\"{o}ppner, Frank},
	citeulike-article-id = {5159615},
	citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.701},
	keywords = {proposal},
	posted-at = {2009-07-15 15:58:33},
	priority = {2},
	title = {Discovery of Temporal Patterns - Learning Rules about the Qualitative Behaviour of Time Series},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.701},
	year = {2001}
}



@inproceedings{citeulike:5159362,
	abstract = {this paper, we consider interval-based events where the duration of events is expressed in terms of endpoint values, and these are used to form temporal constraint in the discovery process. We introduce the notion of temporal representation which is capable of expressing the relationships between interval-based events. We develop new methods for finding such interesting patterns.},
	author = {Kam, Po-Shan and Fu, Ada W.},
	booktitle = {Proceedings of the 2nd International Conference on Data Warehousing and Knowledge Discovery (DaWaK'00},
	citeulike-article-id = {5159362},
	citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.7200},
	keywords = {proposal},
	pages = {317--326},
	posted-at = {2009-07-15 15:24:48},
	priority = {2},
	title = {Discovering Temporal Patterns for Interval-based Events},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.7200},
	year = {2000}
}



@article{citeulike:3013168,
	abstract = {Large-scale clinical databases provide a detailed perspective on patient phenotype in disease and the characteristics of health care processes. Important information is often contained in the relationships between the values and timestamps of sequences of clinical data. The analysis of clinical time sequence data across entire patient populations may reveal data patterns that enable a more precise understanding of disease presentation, progression, and response to therapy, and thus could be of great value for clinical and translational research. Recent work suggests that the combination of temporal data mining methods with techniques from artificial intelligence research on knowledge-based temporal abstraction may enable the mining of clinically relevant temporal features from these previously problematic general clinical data.},
	address = {Division of Clinical Informatics, Department of Public Health Sciences, University of Virginia, Suite 3181 West Complex, 1335 Hospital Drive, Charlottesville, VA 22908-0717, USA. arp4m@virginia.edu},
	author = {Post, A.},
	citeulike-article-id = {3013168},
	citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cll.2007.10.005},
	citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S027227120700114X},
	citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18194720},
	citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18194720},
	doi = {10.1016/j.cll.2007.10.005},
	issn = {02722712},
	journal = {Clinics in Laboratory Medicine},
	keywords = {proposal},
	month = {March},
	number = {1},
	pages = {83--100},
	posted-at = {2009-07-15 02:58:08},
	priority = {2},
	title = {Temporal Data Mining},
	url = {http://dx.doi.org/10.1016/j.cll.2007.10.005},
	volume = {28},
	year = {2008}
}



@incollection{citeulike:5153756,
	abstract = {Fluents are logical descriptions of situations that persist, and composite fluents are statistically significant temporal relationships between fluents.T his paper presents an algorithm for learning composite fluents incrementally from categorical time series data.Th e algorithm is tested with a large dataset of mobile robot episodes.I t is given no knowledge of the episodic structure of the dataset (i.e., it learns without supervision) yet it discovers fluents that correspond well with episodes.},
	author = {Cohen, Paul},
	citeulike-article-id = {5153756},
	citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-44816-0\_27},
	citeulike-linkout-1 = {http://www.springerlink.com/content/p888cm6xygv80r9k},
	doi = {10.1007/3-540-44816-0\_27},
	journal = {Advances in Intelligent Data Analysis},
	keywords = {proposal},
	pages = {268--277},
	posted-at = {2009-07-15 02:49:06},
	priority = {2},
	title = {Fluent Learning: Elucidating the Structure of Episodes},
	url = {http://dx.doi.org/10.1007/3-540-44816-0\_27},
	year = {2001}
}



@incollection{citeulike:5153722,
	abstract = {In many daily transactions, the time when an event takes place is known and stored in databases. Examples range from sales records, stock exchange, patient records, to scientific databases in geophysics and astronomy. Such databases incorporate the concept of time which describes when an event starts and ends as historical records [9]. The temporal nature of data provides us with a better understanding of the trend or pattern over time. In market-basket data, we can have a pattern like  ” 75\% of customers buy peanuts when butter starts to be in big sales and before bread is sold out”. We observe that there may be some correlations among peanuts, butter and bread so that we can have better planning for marketing strategy. Knowledge discovery in temporal databases thus catches the attention of researchers [8, 4].},
	author = {Kam, Po-Shan and Fu, Ada},
	citeulike-article-id = {5153722},
	citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-44466-1\_32},
	citeulike-linkout-1 = {http://www.springerlink.com/content/b5eg19hu445vx0q7},
	doi = {10.1007/3-540-44466-1\_32},
	journal = {Data Warehousing and Knowledge Discovery},
	keywords = {proposal},
	pages = {317--326},
	posted-at = {2009-07-15 02:47:33},
	priority = {2},
	title = {Discovering Temporal Patterns for Interval-based Events},
	url = {http://dx.doi.org/10.1007/3-540-44466-1\_32},
	year = {2000}
}



@inproceedings{citeulike:2804633,
	abstract = {. Data mining can be used to extensively automate the data analysis process. Techniques for mining interval time series, however, have not been considered. Such time series are common in many applications. In this paper, we investigate mining techniques for such time series. Specifically, we propose a technique to discover temporal containment relationships. An item A is said to contain an item B if an event of type B occurs during the time span of an event of type A, and this is a...},
	author = {Villafane, Roy and Hua, Kien A. and Tran, Duc and Maulik, Basab},
	booktitle = {Data Warehousing and Knowledge Discovery},
	citeulike-article-id = {2804633},
	citeulike-linkout-0 = {http://citeseer.ist.psu.edu/villafane99mining.html},
	citeulike-linkout-1 = {http://citeseer.lcs.mit.edu/villafane99mining.html},
	citeulike-linkout-2 = {http://citeseer.ifi.unizh.ch/villafane99mining.html},
	citeulike-linkout-3 = {http://citeseer.comp.nus.edu.sg/villafane99mining.html},
	keywords = {proposal},
	pages = {318--330},
	posted-at = {2009-07-15 02:11:00},
	priority = {2},
	title = {Mining Interval Time Series},
	url = {http://citeseer.ist.psu.edu/villafane99mining.html},
	year = {1999}
}

	

@misc{citeulike:5128872,
	abstract = {In this paper, we introduce a knowledge-based meta-model which serves as a unified resource model for integrating characteristics of major types of objects appearing in software development models (SDMs). The URM consists of resource classes and a web of relations that link different types of resources found in different kinds of models of software development. The URM includes specialized models for software systems, documents, agents, tools, and development processes. The URM has served as the basis for integrating and interoperating a number of process-centered CASE environments. The major benefit of the URM is twofold: First, it forms a higher level of abstraction supporting SDM formulation that subsumes many typical models of software development objects. Hence, it enables a higher level of reusability for existing support mechanisms of these models. Second, it provides a basis to support complex reasoning mechanisms that address issues across different types of software objects. ...},
	author = {Mi, Peiwei and Scacchi, Walt},
	citeulike-article-id = {5128872},
	citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.7533},
	keywords = {proposal},
	pages = {313--330},
	posted-at = {2009-07-12 22:05:44},
	priority = {2},
	title = {A Meta-Model for Formulating Knowledge-Based Models of Software Development},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.7533},
	volume = {17},
	year = {1994}
}

	

@article{citeulike:5128170,
	abstract = {This paper presents a novel method to derive a Petri net from any specification model that can be mapped into a state-based representation with arcs labeled with symbols from an alphabet of events (a Transition System, TS). The method is based on the theory of regions for Elementary Transition Systems (ETS). Previous work has shown that, for any ETS, there exists a Petri Net with minimum transition count (one transition for each label) with a reachability graph isomorphic to the original Transition System. Our method extends and implements that theory by using the following three mechanisms that provide a framework for synthesis of safe Petri nets from arbitrary TSs. First, the requirement of isomorphism is relaxed to bisimulation of TSs, thus extending the class of synthesizable TSs to a new class called Excitation-Closed Transition Systems (ECTS). Second, for the first time, we propose a method of PN synthesis for an arbitrary TS based on mapping a TS event into a set of transition labels in a PN. Third, the notion of irredundant region set is exploited, to minimize the number of places in the net without affecting its behavior. The synthesis method can derive different classes of place-irredundant Petri Nets (e.g., pure, free choice, unique choice) from the same TS, depending on the constraints imposed on the synthesis algorithm. This method has been implemented and applied in different frameworks. The results obtained from the experiments have demonstrated the wide applicability of the method},
	author = {Cortadella, J. and Kishinevsky, M. and Lavagno, L. and Yakovlev, A.},
	booktitle = {Computers, IEEE Transactions on},
	citeulike-article-id = {5128170},
	citeulike-linkout-0 = {http://dx.doi.org/10.1109/12.707587},
	citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=707587},
	doi = {10.1109/12.707587},
	journal = {Computers, IEEE Transactions on},
	keywords = {proposal},
	number = {8},
	pages = {859--882},
	posted-at = {2009-07-12 19:27:47},
	priority = {2},
	title = {Deriving Petri nets from finite transition systems},
	url = {http://dx.doi.org/10.1109/12.707587},
	volume = {47},
	year = {1998}
}

	

@misc{citeulike:5128143,
	abstract = {Understanding the dynamic behavior of a workflow is crucial for being able to modify, maintain, and improve it. A particularly difficult aspect of some behavior is concurrency. Automated techniques which seek to mine workflow data logs to discover information about the workflows must be able to handle the concurrency that manifests itself in the workflow executions. This paper presents techniques to discover patterns of concurrent behavior from traces of workflow events. The techniques are based on a probabilistic analysis of the event traces. Using metrics for the number, frequency, and regularity of event occurrences, a determination is made of the likely concurrent behavior being manifested by the system. Discovering this behavior can help a workflow designer better understand and improve the work processes they are managing.},
	author = {Cook, Jonathan E. and Du, Zhidian and Liu, Chongbing and Wolf, Alexander L. and Er},
	citeulike-article-id = {5128143},
	citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.4990},
	keywords = {proposal},
	posted-at = {2009-07-12 18:35:49},
	priority = {2},
	title = {Discovering Models of Behavior for Concurrent Workflows},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.4990},
	year = {2004}
}

	

@incollection{citeulike:5128110,
	abstract = {The topic of process mining has attracted the attention of both researchers and tool vendors in the Business Process Management (BPM) space. The goal of process mining is to discover process models from event logs, i.e., events logged by some information system are used to extract information about activities and their causal relations. Several algorithms have been proposed for process mining. Many of these algorithms cannot deal with concurrency. Other typical problems are the presence of duplicate activities, hidden activities, non-free-choice constructs, etc. In addition, real-life logs contain noise (e.g., exceptions or incorrectly logged events) and are typically incomplete (i.e., the event logs contain only a fragment of all possible behaviors). To tackle these problems we propose a completely new approach based on genetic algorithms. As can be expected, a genetic approach is able to deal with noise and incompleteness. However, it is not easy to represent processes properly in a genetic setting. In this paper, we show a genetic process mining approach using the so-called causal matrix as a representation for individuals. We elaborate on the relation between Petri nets and this representation and show that genetic algorithms can be used to discover Petri net models from event logs. Keywords: Process Mining, Petri Nets, Genetic Algorithms, Process Discovery, Business Process Intelligence, Business Activity Monitoring.},
	author = {van der Aalst, W. M. P. and de Medeiros, Alves K. A. and Weijters, A. J. M. M.},
	citeulike-article-id = {5128110},
	citeulike-linkout-0 = {http://dx.doi.org/10.1007/11494744_5},
	citeulike-linkout-1 = {http://www.springerlink.com/content/kue571vhwbm6x05n},
	doi = {10.1007/11494744_5},
	journal = {Applications and Theory of Petri Nets 2005},
	keywords = {proposal},
	pages = {48--69},
	posted-at = {2009-07-12 17:40:46},
	priority = {2},
	title = {Genetic Process Mining},
	url = {http://dx.doi.org/10.1007/11494744_5},
	year = {2005}
}
	

@article{citeulike:5128101,
	abstract = {Contemporary workflow management systems are driven by explicit process models, i.e., a completely specified workflow design is required in order to enact a given workflow process. Creating a workflow design is a complicated time-consuming process and typically, there are discrepancies between the actual workflow processes and the processes as perceived by the management. Therefore, we propose a technique for rediscovering workflow models. This technique uses workflow logs to discover the workflow process as it is actually being executed. The workflow log contains information about events taking place. We assume that these events are totally ordered and each event refers to one task being executed for a single case. This information can easily be extracted from transactional information systems (e.g., Enterprise Resource Planning systems such as SAP and Baan). The rediscovering technique proposed in this paper can deal with noise and can also be used to validate workflow processes by uncovering and measuring the discrepancies between prescriptive models and actual process executions.},
	address = {Amsterdam, The Netherlands, The Netherlands},
	author = {Weijters, A. J. M. M. and van der Aalst, W. M. P.},
	citeulike-article-id = {5128101},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1273325},
	issn = {1069-2509},
	journal = {Integr. Comput.-Aided Eng.},
	keywords = {proposal},
	number = {2},
	pages = {151--162},
	posted-at = {2009-07-12 17:36:56},
	priority = {2},
	publisher = {IOS Press},
	title = {Rediscovering workflow models from event-based data using little thumb},
	url = {http://portal.acm.org/citation.cfm?id=1273325},
	volume = {10},
	year = {2003}
}
	


@incollection{citeulike:5044991,
	abstract = {Modern enterprises increasingly use the workflow paradigm to prescribe how business processes should be performed. Processes are typically modeled as annotated activity graphs. We present an approach for a system that constructs process models from logs of past, unstructured executions of the given process. The graph so produced conforms to the dependencies and past executions present in the log. By providing models that capture the previous executions of the process, this technique allows easier introduction of a workflow system and evaluation and evolution of existing process models. We also present results from applying the algorithm to synthetic data sets as well as process logs obtained from an IBM Flowmark installation.},
	author = {Agrawal, Rakesh and Gunopulos, Dimitrios and Leymann, Frank},
	citeulike-article-id = {5044991},
	citeulike-linkout-0 = {http://dx.doi.org/10.1007/BFb0101003},
	citeulike-linkout-1 = {http://www.springerlink.com/content/0836165x01666l40},
	doi = {10.1007/BFb0101003},
	journal = {Advances in Database Technology — EDBT'98},
	keywords = {white-paper},
	pages = {467--483},
	posted-at = {2009-07-03 12:55:20},
	priority = {2},
	title = {Mining process models from workflow logs},
	url = {http://dx.doi.org/10.1007/BFb0101003},
	year = {1998}
}

	

@article{citeulike:3718014,
	abstract = {Abstract  Process mining includes the automated discovery of processes from event logs. Based on observed events (e.g., activities being executed or messages being exchanged) a process model is constructed. One of the essential problems in process mining is that one cannot assume to have seen all possible behavior. At best, one has seen a representative subset. Therefore, classical synthesis techniques are not suitable as they aim at finding a model that is able to exactly reproduce the log. Existing process mining techniques try to avoid such  ” overfitting” by generalizing the model to allow for more behavior. This generalization is often driven by the representation language and very crude assumptions about completeness. As a result, parts of the model are  ” overfitting” (allow only for what has actually been observed) while other parts may be  ” underfitting” (allow for much more behavior without strong support for it). None of the existing techniques enables the user to control the balance between  ” overfitting” and  ” underfitting”. To address this, we propose a two-step approach. First, using a configurable approach, a transition system is constructed. Then, using the  ” theory of regions”, the model is synthesized. The approach has been implemented in the context of ProM and overcomes many of the limitations of traditional approaches.},
	author = {van der Aalst, W. and Rubin, V. and Verbeek, H. and van Dongen, B. and Kindler, E. and G\"{u}nther, C.},
	citeulike-article-id = {3718014},
	citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10270-008-0106-z},
	citeulike-linkout-1 = {http://www.springerlink.com/content/u43v780550278h4l},
	doi = {10.1007/s10270-008-0106-z},
	journal = {Software and Systems Modeling},
	keywords = {proposal},
	posted-at = {2009-07-11 23:17:06},
	priority = {2},
	title = {Process mining: a two-step approach to balance between underfitting and overfitting},
	url = {http://dx.doi.org/10.1007/s10270-008-0106-z},
	year = {2009}
}


@phdthesis{citeulike:5120757,
	address = {Boulder, CO, USA},
	author = {Cook, Jonathan E.},
	citeulike-article-id = {5120757},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=924798},
	isbn = {0-591-25740-8},
	keywords = {proposal},
	posted-at = {2009-07-11 22:03:30},
	priority = {2},
	publisher = {University of Colorado at Boulder},
	title = {Process discovery and validation through event-data analysis},
	url = {http://portal.acm.org/citation.cfm?id=924798},
	year = {1996}
}

	

@article{citeulike:5120603,
	author = {Biermann, A. W. and Feldman, J.},
	citeulike-article-id = {5120603},
	journal = {IEEE Trans. Computers},
	keywords = {proposal},
	pages = {592--597},
	posted-at = {2009-07-11 21:35:17},
	priority = {2},
	title = {On the Synthesis of Finite-State Machines from Samples of Their Behavior},
	year = {1972}
}

	

@article{citeulike:328044,
	abstract = {Many software process methods and tools presuppose the existence of a formal model of a process. Unfortunately, developing a formal model for an on-going, complex process can be difficult, costly, and error prone. This presents a practical barrier to the adoption of process technologies, which would be lowered by automated assistance in creating formal models. To this end, we have developed a data analysis technique that we term  process discovery.  Under this technique, data describing process events are first captured from an on-going process and then used to generate a formal model of the behavior of that process. In this article we describe a Markov method that we developed specifically for process discovery, as well as describe two additional methods that we   adopted from other domains and augmented for our purposes. The three methods range from the purely algorithmic to the purely statistical. We compare the methods and discuss their application in an industrial case study.},
	address = {New York, NY, USA},
	author = {Cook, Jonathan E. and Wolf, Alexander L.},
	citeulike-article-id = {328044},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=287001},
	citeulike-linkout-1 = {http://dx.doi.org/10.1145/287000.287001},
	doi = {10.1145/287000.287001},
	issn = {1049-331X},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	keywords = {white-paper},
	month = {July},
	number = {3},
	pages = {215--249},
	posted-at = {2009-07-03 13:04:14},
	priority = {2},
	publisher = {ACM},
	title = {Discovering models of software processes from event-based data},
	url = {http://dx.doi.org/10.1145/287000.287001},
	volume = {7},
	year = {1998}
}

	

@inproceedings{citeulike:5112229,
	abstract = {Software is a ubiquitous component of our daily life. We often depend on the correct working of software systems. Due to the difficulty and complexity of software systems, bugs and anomalies are prevalent. Bugs have caused billions of dollars loss, in addition to privacy and security threats. In this work, we address software reliability issues by proposing a novel method to classify software behaviors based on past history or runs. With the technique, it is possible to generalize past known errors and mistakes to capture failures and anomalies. Our technique first mines a set of discriminative features capturing repetitive series of events from program execution traces. It then performs feature selection to select the best features for classification. These features are then used to train a classifier to detect failures. Experiments and case studies on traces of several benchmark software systems and a real-life concurrency bug from MySQL server show the utility of the technique in capturing failures and anomalies. On average, our pattern-based classification technique outperforms the baseline approach by 24.68\% in accuracy.},
	address = {New York, NY, USA},
	author = {Lo, David and Cheng, Hong and Han, Jiawei and Khoo, Siau C. and Sun, Chengnian},
	booktitle = {KDD '09: Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
	citeulike-article-id = {5112229},
	citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1557019.1557083},
	citeulike-linkout-1 = {http://dx.doi.org/10.1145/1557019.1557083},
	doi = {10.1145/1557019.1557083},
	isbn = {978-1-60558-495-9},
	keywords = {proposal},
	location = {Paris, France},
	pages = {557--566},
	posted-at = {2009-07-11 00:34:50},
	priority = {2},
	publisher = {ACM},
	title = {Classification of software behaviors for failure detection: a discriminative pattern mining approach},
	url = {http://dx.doi.org/10.1145/1557019.1557083},
	year = {2009}
}

	
@techreport{citeulike:5090131,
	address = {Pittsburgh, PA 15213},
	author = {Pomeroy-Huff, Marsha and Mullaney, Julia and Cannon, Robert and Seburn, Mark},
	citeulike-article-id = {5090131},
	editor = {Humphrey, Watts S.},
	institution = {Software Engineering Institute},
	keywords = {proposal},
	organization = {Carnegie Mellon University},
	posted-at = {2009-07-07 22:57:28},
	priority = {2},
	title = {The Personal Software Process (PSP)
Body of Knowledge, Version 1.0},
	year = {2008}
}

	
@misc{Sayyad:2005,
	author = {Shirabad, J. Sayyad and Menzies, T. J.},
	citeulike-article-id = {5070504},
	howpublished = {School of Information Technology and Engineering, University of Ottawa, Canada},
	keywords = {proposal, white-paper},
	posted-at = {2009-07-06 03:15:39},
	priority = {2},
	title = {{The {PROMISE} Repository of Software Engineering Databases.}},
	url = {http://promise.site.uottawa.ca/SERepository},
	year = {2005}
}

	

@inproceedings{citeulike:5043676,
	abstract = {Software repositories such as source control systems, defect tracking systems, and archived communications between project personnel are used to help manage the progress of software projects. Software practitioners and researchers more and more recognize the potential benefit of mining this information to support the maintenance of software systems, improve software design/reuse, and empirically validate novel ideas and techniques. Research is now proceeding to uncover the ways in which mining these repositories can help to understand software development, to support predictions about software development, and to plan various evolutionary aspects of software projects.},
	author = {Gall, Harald and Lanza, Michele and Zimmermann, Thomas},
	booktitle = {Software Engineering - Companion, 2007. ICSE 2007 Companion. 29th International Conference on},
	citeulike-article-id = {5043676},
	doi = {10.1109/ICSECOMPANION.2007.8},
	journal = {Software Engineering - Companion, 2007. ICSE 2007 Companion. 29th International Conference on},
	keywords = {white-paper},
	pages = {107--108},
	posted-at = {2009-07-03 02:09:42},
	priority = {2},
	title = {4th International Workshop on Mining Software Repositories ({MSR} 2007)},
	url = {http://dx.doi.org/10.1109/ICSECOMPANION.2007.8},
	year = {2007}
}

	

@incollection{citeulike:5043673,
	abstract = {Under the umbrella of buzzwords such as  ” Business Activity Monitoring” (BAM) and  ” Business Process Intelligence” (BPI) both academic (e.g., EMiT, Little Thumb, InWoLvE, Process Miner, and MinSoN) and commercial tools (e.g., ARIS PPM, HP BPI, and ILOG JViews) have been developed. The goal of these tools is to extract knowledge from event logs (e.g., transaction logs in an ERP system or audit trails in a WFM system), i.e., to do process mining. Unfortunately, tools use different formats for reading/storing log files and present their results in different ways. This makes it difficult to use different tools on the same data set and to compare the mining results. Furthermore, some of these tools implement concepts that can be very useful in the other tools but it is often difficult to combine tools. As a result, researchers working on new process mining techniques are forced to build a mining infrastructure from scratch or test their techniques in an isolated way, disconnected from any practical applications. To overcome these kind of problems, we have developed the ProM framework, i.e., an  ” pluggable” environment for process mining. The framework is flexible with respect to the input and output format, and is also open enough to allow for the easy reuse of code during the implementation of new process mining ideas. This paper introduces the ProM framework and gives an overview of the plug-ins that have been developed.},
	author = {van Dongen, B. F. and de Medeiros, A. K. A. and Verbeek, H. M. W. and Weijters, A. J. M. M. and van der Aalst, W. M. P.},
	citeulike-article-id = {5043673},
	doi = {10.1007/11494744\_25},
	journal = {Applications and Theory of Petri Nets 2005},
	keywords = {white-paper},
	pages = {444--454},
	posted-at = {2009-07-03 01:44:31},
	priority = {2},
	title = {The {ProM} Framework: A New Era in Process Mining Tool Support},
	url = {http://dx.doi.org/10.1007/11494744\_25},
	year = {2005}
}



@incollection{citeulike:1885717,
	abstract = {Software development processes are often not explicitly modelled and sometimes even chaotic. In order to keep track of the involved documents and files, engineers use Software Configuration Management (SCM) systems. Along the way, those systems collect and store information on the software process itself. Thus, SCM information can be used for constructing explicit process models, which is called software process mining. In this paper we show that (1) a Process Mining Framework can be used for obtaining software process models as well as for analysing and optimising them; (2) an algorithmic approach, which arose from our research on software processes, is integrated in the framework.},
	author = {Rubin, Vladimir and G\"{u}nther, Christian and van der Aalst, Wil and Kindler, Ekkart and van Dongen, Boudewijn and Sch\"{a}fer, Wilhelm},
	citeulike-article-id = {1885717},
	doi = {10.1007/978-3-540-72426-1\_15},
	journal = {Software Process Dynamics and Agility},
	keywords = {white-paper},
	pages = {169--181},
	posted-at = {2009-07-03 01:42:24},
	priority = {2},
	title = {Process Mining Framework for Software Processes},
	url = {http://dx.doi.org/10.1007/978-3-540-72426-1\_15},
	year = {2007}
}



@article{citeulike:5043672,
	abstract = {The paper discusses the problems that a software development organization must address in order to assess and improve its software processes. In particular, the authors are involved in a project aiming at assessing and improving the current practice and the quality manual of the Business Unit Telecommunications for Defense (BUTD) of a large telecommunications company. The paper reports on the usage of formal process modeling languages to detect inconsistencies, ambiguities, incompleteness, and opportunities for improvement of both the software process and its documentation},
	author = {Bandinelli, S. and Fuggetta, A. and Lavazza, L. and Loi, M. and Picco, G. P.},
	booktitle = {Software Engineering, IEEE Transactions on},
	citeulike-article-id = {5043672},
	doi = {10.1109/32.387473},
	journal = {Software Engineering, IEEE Transactions on},
	keywords = {white-paper},
	number = {5},
	pages = {440--454},
	posted-at = {2009-07-03 01:38:26},
	priority = {2},
	title = {Modeling and improving an industrial software process},
	url = {http://dx.doi.org/10.1109/32.387473},
	volume = {21},
	year = {1995}
}



@incollection{citeulike:5043670,
	abstract = {Capturing a process as it is being executed in a descriptive process model is a key activity in process improvement. Performing descriptive process modeling in industry environments is hindered by factors such as dispersed process knowledge or inconsistent understanding of the process among different project members. A systematic approach can alleviate some of the problems. This paper sketches fundamental difficulties in gaining process knowledge and describes a systematic approach to process elicitation. The approach employs techniques from other domains like social sciences that have been tailored to the process elicitation context and places them in a decision framework that gives guidance on selecting appropriate techniques in specific modeling situations. Initial experience with the approach is reported.},
	author = {Becker-Kornstaedt, Ulrike},
	citeulike-article-id = {5043670},
	doi = {10.1007/3-540-44813-6\_27},
	journal = {Product Focused Software Process Improvement},
	keywords = {white-paper},
	pages = {312--325},
	posted-at = {2009-07-03 01:36:12},
	priority = {2},
	title = {Towards Systematic Knowledge Elicitation for Descriptive Software Process Modeling},
	url = {http://dx.doi.org/10.1007/3-540-44813-6\_27},
	year = {2001}
}



@incollection{citeulike:5043664,
	abstract = {This paper describes a reference model for open source software (OSS) processes and its application towards discovering such processes from OSS project artifacts. This reference model is the means to map evidence of an enacted process to a classification of agents, resources, tools, and activities that characterize the process.},
	author = {Jensen, Chris and Scacchi, Walt},
	citeulike-article-id = {5043664},
	doi = {10.1007/978-0-387-72486-7\_26},
	journal = {Open Source Development, Adoption and Innovation},
	keywords = {white-paper},
	pages = {265--270},
	posted-at = {2009-07-03 01:18:35},
	priority = {2},
	title = {Guiding the Discovery of Open Source Software Processes with a Reference Model},
	url = {http://dx.doi.org/10.1007/978-0-387-72486-7\_26},
	year = {2007}
}



@misc{citeulike:5043104,
	abstract = {Contents 1 Motivation and Basic Ideas 7  1.1 Software Market Sizes, Software Crisis ....... 8  1.2 Where are we in Software Process Improvement (SPI)? . . . ....................... 10  1.3 Six Approaches to SPI ................. 11  1.4 Some reflections on SPI................ 12 2 Total Quality Management (TQM) 13 3 Capability Maturity Model (CMM) 16  3.1 CMM survey ...................... 16  3.2 Extended CMM levels ................. 17  3.3 CMM, level details . .................. 18  3.4 CMM Process Assessments . ............. 27  3.5 Software Engineering Process Groups, SEPGs . . . 28  3.6 The Personal Software Process, PSP ........ 30  3.7 Further work around CMM at SEI . . . ........ 32 4 Quality Improvement Paradigm (QIP) 33  4.1 QIP survey ....................... 33  4.2 Typical goals of process improvement ........ 35  4.3 NASA Software Engineering Laboratory, NASA--SEL 37  4.4 Software Experience Factory, consolidated NASA-SEL 38 5 SPICE, ISO-standardization 40 6 European BOOTS},
	author = {Conradi, Reidar},
	citeulike-article-id = {5043104},
	keywords = {white-paper},
	posted-at = {2009-07-02 18:41:32},
	priority = {2},
	title = {{SPI} frameworks: {TQM}, {CMM}, {SPICE}, {ISO} 9001, {QIP} Experiences and trends - Norwegian {SPIQ} project},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.3010}
}


@article{citeulike:5043101,
	abstract = {Mining knowledge about ordering from sequence data is an important problem with many applications, such as bioinformatics, Web mining, network management, and intrusion detection. For example, if many customers follow a partial order in their purchases of a series of products, the partial order can be used to predict other related customers' future purchases and develop marketing campaigns. Moreover, some biological sequences (e.g., microarray data) can be clustered based on the partial orders shared by the sequences. Given a set of items, a total order of a subset of items can be represented as a string. A string database is a multiset of strings. In this paper, we identify a novel problem of mining frequent closed partial orders from strings. Frequent closed partial orders capture the nonredundant and interesting ordering information from string databases. Importantly, mining frequent closed partial orders can discover meaningful knowledge that cannot be disclosed by previous data mining techniques. However, the problem of mining frequent closed partial orders is challenging. To tackle the problem, we develop Frecpo (for frequent closed partial order), a practically efficient algorithm for mining the complete set of frequent closed partial orders from large string databases. Several interesting pruning techniques are devised to speed up the search. We report an extensive performance study on both real data sets and synthetic data sets to illustrate the effectiveness and the efficiency of our approach},
	author = {Pei, J. and Wang, H. and Liu, J. and Wang, K. and Wang, Jianyong and Yu, P. S.},
	booktitle = {Knowledge and Data Engineering, IEEE Transactions on},
	citeulike-article-id = {5043101},
	doi = {10.1109/TKDE.2006.172},
	journal = {Knowledge and Data Engineering, IEEE Transactions on},
	keywords = {white-paper},
	number = {11},
	pages = {1467--1481},
	posted-at = {2009-07-02 18:36:57},
	priority = {2},
	title = {Discovering Frequent Closed Partial Orders from Strings},
	url = {http://dx.doi.org/10.1109/TKDE.2006.172},
	volume = {18},
	year = {2006}
}



@misc{citeulike:5043099,
	abstract = {Sequences of events describing the behavior and actions of users or systems can be collected in several domains. An episode is a collection of events that occur relatively close to each other in a given partial order. We consider the problem of discovering frequently occurring episodes in a sequence. Once such episodes are known, one can produce rules for describing or predicting the behavior of the sequence. We give efficient algorithms for the discovery of all frequent episodes from a given class of episodes, and present detailed experimental results. The methods are in use in telecommunication alarm management.},
	author = {Mannila, Heikki and Toivonen, Hannu and Verkamo, A. Inkeri},
	citeulike-article-id = {5043099},
	keywords = {white-paper},
	posted-at = {2009-07-02 18:34:20},
	priority = {2},
	title = {Discovery of Frequent Episodes in Event Sequences},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.7.3051},
	year = {1997}
}



@incollection{citeulike:5043097,
	abstract = {Sequential pattern mining is an important data mining problem with broad applications. However, it is also a challenging problem since the mining may have to generate or examine a combinatorially explosive number of intermediate subsequences. Recent studies have developed two major classes of sequential pattern mining methods: (1) a candidate generation-and-test approach, represented by (i)GSP [30], a horizontal format-based sequential pattern mining method, and (ii) SPADE [36], a vertical format-based method; and (2) a sequential pattern growth method, represented by PrefixSpan [26] and its further extensions, such as CloSpan for mining closed sequential patterns [35].},
	author = {Han, J. and Pei, J. and Yan, X.},
	citeulike-article-id = {5043097},
	doi = {10.1007/11362197\_8},
	journal = {Foundations and Advances in Data Mining},
	keywords = {white-paper},
	pages = {183--220},
	posted-at = {2009-07-02 18:32:10},
	priority = {2},
	title = {Sequential Pattern Mining by Pattern-Growth: Principles and Extensions*},
	url = {http://dx.doi.org/10.1007/11362197\_8},
	year = {2005}
}



@inproceedings{citeulike:5043094,
	abstract = {Abstract. The Unification-based Temporal Grammar is a temporal extension of static unification-based grammars. It defines a hierarchical temporal rule language to express complex patterns present in multivariate time series. The Temporal Data Mining Method is the accompanying framework to discover temporal knowledge based on this rule language. A semiotic hierarchy of temporal patterns, which are not a priori given, is build in a bottom up manner from static logical descriptions of multivariate time instants. We demonstrate the methods using music data, extracting typical parts of songs. 1},
	author = {M\"{o}rchen, Fabian and Ultsch, Alfred},
	booktitle = {Proceedings of the 27th Annual German Conference in Artificial Intelligence (KI'04},
	citeulike-article-id = {5043094},
	keywords = {white-paper},
	pages = {127--140},
	posted-at = {2009-07-02 18:24:06},
	priority = {2},
	title = {Mining hierarchical temporal patterns in multivariate time series},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.88.603},
	year = {2004}
}



@misc{citeulike:5043086,
	abstract = {Rule mining is the practice of discovering interesting and unexpected rules from large data sets. Depending on the exact problem formulation, this may be a very complicated problem. Existing methods typically make strong simplifying assumptions about the form of the rules, and limit the measure of rule quality to simple properties, such as confidence. Because confidence in itself is not a good indicator of how interesting a rule is to the user, the mined rules are typically sorted according to some secondary interestingness measure. In this paper we present a rule mining method that is based on genetic programming. Because we use specialized pattern matching hardware to evaluate each rule, our method supports a very wide range of rule formats, and can use any reasonable fitness measure. We develop a fitness measure that is well-suited for our method, and give empirical results of applying the method to synthetic and real-world data sets.},
	author = {S{\ae}trom, P\r{a}l and Hetland, Magnus L.},
	citeulike-article-id = {5043086},
	keywords = {white-paper},
	posted-at = {2009-07-02 18:16:42},
	priority = {2},
	title = {Unsupervised Temporal Rule Mining with Genetic Programming and Specialized Hardware},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.3417},
	year = {2003}
}



@article{citeulike:5042856,
	abstract = {Most of the software in regular use in businesses and organisations all over the world cannot be completely specified. It cannot be implemented, once and for all. Both the original implementation and the inevitable subsequent evolution (maintenance) are a continual learning experience driven, inter alia, by feedback from the results of the behaviour under execution of the software, as perceived by various stakeholders, by advances and growth in the user organisations and by adaptation to changes in the external world, both independent and as a result of installation and use of the software. Real world, termed type-E, software is essentially evolutionary in nature. The study of the processes of evolution of such software is of considerable interest, as is that of the domains that co-evolve with the software. After briefly discussing the meaning of the term evolution in the context of software, its technology, the software process and related domains, this paper describes some of the facets of the evolution phenomenon and implications to the evolution process as identified during many years of active interest in the topic.},
	author = {Lehman, Meir M. and Ramil, Juan F.},
	citeulike-article-id = {5042856},
	doi = {10.1023/A:1020557525901},
	journal = {Annals of Software Engineering},
	keywords = {white-paper},
	month = {December},
	number = {1},
	pages = {275--309},
	posted-at = {2009-07-02 15:36:19},
	priority = {2},
	title = {Software Evolution and Software Evolution Processes},
	url = {http://dx.doi.org/10.1023/A:1020557525901},
	volume = {14},
	year = {2002}
}



@inproceedings{citeulike:5029482,
	abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article.  ACM has opted to expose the complete List rather than only correct and linked references.},
	address = {New York, NY, USA},
	author = {Humphrey, Watts S.},
	booktitle = {ESP '97: Papers presented at the seventh workshop on Empirical studies of programmers},
	citeulike-article-id = {5029482},
	doi = {10.1145/266399.266418},
	isbn = {0-89791-992-0},
	keywords = {white-paper},
	location = {Alexandria, Virginia, United States},
	pages = {224--232},
	posted-at = {2009-07-01 05:18:32},
	priority = {2},
	publisher = {ACM},
	title = {What do we know about programming?},
	url = {http://dx.doi.org/10.1145/266399.266418},
	year = {1997}
}



@techreport{citeulike:5012661,
	address = {Finland},
	author = {Vilo, J.},
	citeulike-article-id = {5012661},
	institution = {University of Helsinki},
	keywords = {proposal},
	posted-at = {2009-06-29 14:40:15},
	priority = {2},
	school = {Department of Computer Science},
	title = {Discovering frequent patterns from strings.},
	year = {1998}
}

	

@inproceedings{citeulike:775528,
	abstract = {We are given a large database of customer transactions, where each transaction consists of customer-id, transaction time, and the items bought in the transaction. We introduce the problem of mining sequential patterns over such databases. We present three algorithms to solve this problem, and empirically evaluate their performance using synthetic data. Two of the proposed algorithms, AprioriSome and AprioriAll, have comparable performance, albeit AprioriSome performs a little better when the minimum number of customers that must support a sequential pattern is low. Scale-up experiments show that both AprioriSome and AprioriAll scale linearly with the number of customer transactions. They also have excellent scale-up properties with respect to the number of transactions per customer and the number of items in a transaction},
	author = {Agrawal, R. and Srikant, R.},
	citeulike-article-id = {775528},
	doi = {10.1109/ICDE.1995.380415},
	journal = {Data Engineering, 1995. Proceedings of the Eleventh International Conference on},
	pages = {3--14},
	posted-at = {2009-06-29 13:48:02},
	priority = {2},
	title = {Mining sequential patterns},
	url = {http://dx.doi.org/10.1109/ICDE.1995.380415},
	year = {1995}
}

	

@article{citeulike:707616,
	abstract = {An on-line algorithm is presented for constructing the suffix tree for a given string in time linear in the length of the string. The new algorithm has the desirable property of processing the string symbol by symbol from left to right. It has always the suffix tree for the scanned part of the string ready. The method is developed as a linear-time version of a very simple algorithm for (quadratic size) suffix tries. Regardless of its quadratic worst-case this latter algorithm can be a good...},
	author = {Ukkonen, Esko},
	citeulike-article-id = {707616},
	journal = {Algorithmica},
	keywords = {proposal},
	number = {3},
	pages = {249--260},
	posted-at = {2009-06-29 12:35:04},
	priority = {2},
	title = {On-Line Construction of Suffix Trees},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.751},
	volume = {14},
	year = {1995}
}


	
@inproceedings{citeulike:3978085,
	abstract = {Time series motifs are approximately repeated patterns foundwithin the data. Such motifs have utility for many data mining algorithms, including rule-discovery,novelty-detection, summarization and clustering. Since the formalization of the problem and the introduction of efficient linear time algorithms, motif discovery has been successfully applied tomany domains, including medicine, motion capture, robotics and meteorology.},
	address = {New York, NY, USA},
	author = {Yankov, Dragomir and Keogh, Eamonn and Medina, Jose and Chiu, Bill and Zordan, Victor},
	booktitle = {KDD '07: Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining},
	citeulike-article-id = {3978085},
	doi = {10.1145/1281192.1281282},
	isbn = {978-1-59593-609-7},
	keywords = {proposal},
	location = {San Jose, California, USA},
	pages = {844--853},
	posted-at = {2009-06-29 02:13:44},
	priority = {2},
	publisher = {ACM},
	title = {Detecting time series motifs under uniform scaling},
	url = {http://dx.doi.org/10.1145/1281192.1281282},
	year = {2007}
}



@inproceedings{citeulike:3025877,
	address = {New York, NY, USA},
	author = {Keogh, Eamonn and Lonardi, Stefano and Chiu, Bill '.},
	booktitle = {KDD '02: Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining},
	citeulike-article-id = {3025877},
	doi = {10.1145/775047.775128},
	isbn = {158113567X},
	keywords = {proposal},
	location = {Edmonton, Alberta, Canada},
	pages = {550--556},
	posted-at = {2009-06-28 23:06:23},
	priority = {2},
	publisher = {ACM},
	title = {Finding surprising patterns in a time series database in linear time and space},
	url = {http://dx.doi.org/10.1145/775047.775128},
	year = {2002}
}



@incollection{citeulike:5003404,
	abstract = {We consider the problem of finding frequent subsequences in sequential data. We examine three algorithms using a trie with K levels. The O(K 2 n) breadth-first (BF) algorithm inserts a pattern into the trie at level k only if level k-1 has been completed. The O(Kn) depth-first (DF) algorithm inserts a pattern and all its prefixes into the trie before examining another pattern. A threshold is used to store only frequent subsequences. Since DF cannot apply the threshold until the trie is complete, it makes poor use of memory. The heuristic depth-first (HDF) algorithm, a variant of DF, uses the threshold in the same manner as BF. HDF gains efficiency but loses a predictable amount of accuracy.},
	author = {Jiang, Linhui and Hamilton, Howard},
	citeulike-article-id = {5003404},
	doi = {10.1007/3-540-44886-1\_38},
	journal = {Advances in Artificial Intelligence},
	keywords = {proposal},
	pages = {992},
	posted-at = {2009-06-28 23:01:07},
	priority = {2},
	title = {Methods for Mining Frequent Sequential Patterns},
	url = {http://dx.doi.org/10.1007/3-540-44886-1\_38},
	year = {2003}
}



@incollection{citeulike:5003338,
	abstract = {In the last years, the completion of the human genome sequencing showed up a wide range of new challenging issues involving raw data analysis. In particular, the discovery of information implicitly encoded in biological sequences is assuming a prominent role in identifying genetic diseases and in deciphering biological mechanisms. This information is usually represented by patterns frequently occurring in the sequences. Because of biological observations, a specific class of patterns is becoming particularly interesting: frequent structured patterns. In this respect, it is biologically meaningful to look at both  ” exact” and  ” approximate” repetitions of the patterns within the available sequences. This paper gives a contribution in this setting by providing some algorithms which allow to discover frequent structured patterns, either in  ” exact” or  ” approximate” form, present in a collection of input biological sequences.},
	author = {Palopoli, Luigi and Terracina, Giorgio},
	citeulike-article-id = {5003338},
	doi = {10.1007/3-540-36182-0\_6},
	journal = {Discovery Science},
	keywords = {proposal},
	pages = {283--296},
	posted-at = {2009-06-28 22:52:07},
	priority = {2},
	title = {Discovering Frequent Structured Patterns from String Databases: An Application to Biological Sequences},
	url = {http://dx.doi.org/10.1007/3-540-36182-0\_6},
	year = {2008}
}


@book{citeulike:465665,
	abstract = {{This introductory text offers a clear exposition of the algorithmic principles driving advances in bioinformatics. Accessible to students in both biology and computer science, it strikes a unique balance between rigorous mathematics and practical techniques, emphasizing the ideas underlying algorithms rather than offering a collection of apparently unrelated problems.<br /> <br /> The book introduces biological and algorithmic ideas together, linking issues in computer science to biology and thus capturing the interest of students in both subjects. It demonstrates that relatively few design techniques can be used to solve a large number of practical problems in biology, and presents this material intuitively.<br /> <br /> <i>An Introduction to Bioinformatics Algorithms</i> is one of the first books on bioinformatics that can be used by students at an undergraduate level. It includes a dual table of contents, organized by algorithmic idea and biological idea; discussions of biologically relevant problems, including a detailed problem formulation and one or more solutions for each; and brief biographical sketches of leading figures in the field. These interesting vignettes offer students a glimpse of the inspirations and motivations for real work in bioinformatics, making the concepts presented in the text more concrete and the techniques more approachable.<br /> <br /> PowerPoint presentations, practical bioinformatics problems, sample code, diagrams, demonstrations, and other materials can be found at the Author's website.}},
	author = {Jones, Neil C. and Pevzner, Pavel A.},
	citeulike-article-id = {465665},
	howpublished = {Hardcover},
	isbn = {0262101068},
	month = {August},
	posted-at = {2009-06-28 22:34:44},
	priority = {2},
	publisher = {{The MIT Press}},
	title = {An Introduction to Bioinformatics Algorithms (Computational Molecular Biology)},
	url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0262101068},
	year = {2004}
}


@incollection{citeulike:3978065,
	abstract = {The Unification-Based Temporal Grammar is a temporal extension of static unification-based grammars. It defines a hierarchical temporal rule language to express complex patterns present in multivariate time series. The Temporal Data Mining Method is the accompanying framework to discover temporal knowledge based on this rule language. A semiotic hierarchy of temporal patterns, which are not a priori given, is built in a bottom up manner from static logical descriptions of multivariate time instants. We demonstrate the methods using music data, extracting typical parts of songs.},
	address = {Berlin / Heidelberg, Germany},
	author = {M\"{o}rchen, Fabian and Ultsch, Alfred},
	booktitle = {KI 2004: Advances in Artificial Intelligence},
	citeulike-article-id = {3978065},
	doi = {10.1007/b100351},
	editor = {Biundo, Susanne and Fr\"{u}hwirth, Thom and Palm, G\"{u}nther},
	isbn = {978-3-540-23166-0},
	issn = {0302-9743 (Print) 1611-3349 (Online)},
	journal = {KI 2004: Advances in Artificial Intelligence},
	keywords = {proposal},
	pages = {127--140},
	posted-at = {2009-06-28 17:36:05},
	priority = {2},
	publisher = {Springer},
	series = {Lecture Notes in Artificial Intelligence},
	title = {Mining Hierarchical Temporal Patterns in Multivariate Time Series},
	url = {http://dx.doi.org/10.1007/b100351},
	volume = {3238},
	year = {2004}
}


@article{citeulike:3978076,
	abstract = {Abstract\&nbsp;\&nbsp;We present a new method for the understandable description of local temporal relationships in multivariate data, called Time Series Knowledge Mining (TSKM). We define the Time Series Knowledge Representation (TSKR) as a new language for expressing temporal knowledge in time interval data. The patterns have a hierarchical structure, with levels corresponding to the temporal concepts duration, coincidence, and partial order. The patterns are very compact, but offer details for each element on demand. In comparison with related approaches, the TSKR is shown to have advantages in robustness, expressivity, and comprehensibility. The search for coincidence and partial order in interval data can be formulated as instances of the well known frequent itemset problem. Efficient algorithms for the discovery of the patterns are adapted accordingly. A novel form of search space pruning effectively reduces the size of the mining result to ease interpretation and speed up the algorithms. Human interaction is used during the mining to analyze and validate partial results as early as possible and guide further processing steps. The efficacy of the methods is demonstrated using two real life data sets. In an application to sports medicine the results were recognized as valid and useful by an expert of the field.},
	author = {M\"{o}rchen, Fabian and Ultsch, Alfred},
	citeulike-article-id = {3978076},
	doi = {10.1007/s10618-007-0070-1},
	journal = {Data Mining and Knowledge Discovery},
	keywords = {proposal},
	month = {October},
	number = {2},
	pages = {181--215},
	posted-at = {2009-06-28 17:34:38},
	priority = {2},
	title = {Efficient mining of understandable patterns from multivariate interval time series},
	url = {http://dx.doi.org/10.1007/s10618-007-0070-1},
	volume = {15},
	year = {2007}
}



@inproceedings{citeulike:5000906,
	author = {Vilain, M.},
	booktitle = {2nd National (US) Conference on Artificial Intelligence},
	citeulike-article-id = {5000906},
	keywords = {proposal},
	location = {Pittsburgh, Pa.},
	pages = {197--201},
	posted-at = {2009-06-28 17:13:46},
	priority = {2},
	publisher = {AAAI Press},
	title = {A system for reasoning about time.},
	year = {1982}
}



@article{citeulike:5000870,
	abstract = {The temporal interval relationships formalized by Allen, and later extended to accommodate semiintervals by Freksa, have been widely utilized in both data modeling and artificial intelligence research to facilitate reasoning between the relative temporal ordering of events. In practice, however, some modifications to the relationships are necessary when linear temporal sequences are provided, when event times are aggregated, or when data is supplied to a granularity which is larger than required. This paper discusses these modifications and outlines a solution to this problem which accommodates any available knowledge of interval midpoints.},
	author = {Roddick, J. F. and Mooney, C. H.},
	booktitle = {Knowledge and Data Engineering, IEEE Transactions on},
	citeulike-article-id = {5000870},
	doi = {10.1109/TKDE.2005.12},
	journal = {Knowledge and Data Engineering, IEEE Transactions on},
	keywords = {proposal},
	number = {1},
	pages = {133--135},
	posted-at = {2009-06-28 17:08:08},
	priority = {2},
	title = {Linear temporal sequences and their interpretation using midpoint relationships},
	url = {http://dx.doi.org/10.1109/TKDE.2005.12},
	volume = {17},
	year = {2005}
}



@inproceedings{citeulike:5000685,
	address = {London, UK},
	author = {Rainsford, Chris P. and Roddick, John F.},
	booktitle = {PKDD '99: Proceedings of the Third European Conference on Principles of Data Mining and Knowledge Discovery},
	citeulike-article-id = {5000685},
	isbn = {3-540-66490-4},
	pages = {504--509},
	posted-at = {2009-06-28 16:37:29},
	priority = {2},
	publisher = {Springer-Verlag},
	title = {Adding Temporal Semantics to Association Rules},
	url = {http://portal.acm.org/citation.cfm?id=669526},
	year = {1999}
}



@incollection{citeulike:4994404,
	abstract = {The class hierarchy is an important aspect of object-oriented software development. Design and maintenance of such a hierarchy is a difficult task that is often accomplished without any clear guidance or tool support. Formal concept analysis provides a natural theoretical framework for this problem because it can guarantee maximal factorization while preserving specialization relationships. The framework can be useful for several software development scenarios within the class hierarchy life-cycle such as design from scratch using a set of class specifications, or a set of object examples, refactoring/reengineering from existing object code or from the observation of the actual use of the classes in applications and hierarchy evolution by incrementally adding new classes. The framework can take into account different levels of specification details and suggests a number of well-defined alternative designs. These alternatives can be viewed as normal forms for class hierarchies where each normal form addresses particular design goals. An overview of work in the area is presented by highlighting the formal concept analysis notions that are involved. One particularly difficult problem arises when taking associations between classes into account. Basic scaling has to be extended because the scales used for building the concept lattice are dependent on it. An approach is needed to treat this circularity in a well-defined manner. Possible solutions are discussed.},
	author = {Godin, Robert   and Valtchev, Petko  },
	citeulike-article-id = {4994404},
	doi = {10.1007/11528784\_16},
	journal = {Formal Concept Analysis},
	keywords = {proposal},
	pages = {304--323},
	posted-at = {2009-06-28 04:38:03},
	priority = {2},
	title = {Formal Concept Analysis-Based Class Hierarchy Design in Object-Oriented Software Development},
	url = {http://dx.doi.org/10.1007/11528784\_16},
	year = {2005}
}



@book{citeulike:257416,
	author = {Hesse, Wolfgang   and Tilley, Thomas  },
	citeulike-article-id = {257416},
	doi = {10.1007/11528784\_15},
	journal = {Lecture Notes in Computer Science},
	keywords = {proposal},
	month = {July},
	pages = {288--303},
	posted-at = {2009-06-28 04:35:44},
	priority = {2},
	title = {Formal Concept Analysis Used for Software Analysis and Modelling},
	url = {http://dx.doi.org/10.1007/11528784\_15},
	volume = {3626},
	year = {2005}
}



@incollection{citeulike:1378634,
	abstract = {Formal Concept Analysis (FCA) has typically been applied in the field of software engineering to support software maintenance and object-oriented class identification tasks. This paper presents a broader overview by describing and classifying academic papers that report the application of FCA to software engineering. The papers are classified using a framework based on the activities defined in the ISO12207 Software Engineering standard. Two alternate classification schemes based on the programming language under analysis and target application size are also discussed. In addition, the authors work to support agile methods and formal specification via FCA is introduced.},
	author = {Tilley, Thomas   and Cole, Richard   and Becker, Peter   and Eklund, Peter  },
	citeulike-article-id = {1378634},
	doi = {10.1007/11528784\_13},
	journal = {Formal Concept Analysis},
	keywords = {proposal},
	pages = {250--271},
	posted-at = {2009-06-28 04:34:12},
	priority = {2},
	title = {A Survey of Formal Concept Analysis Support for Software Engineering Activities},
	url = {http://dx.doi.org/10.1007/11528784\_13},
	year = {2005}
}



@article{citeulike:272197,
	abstract = {We propose the time interval multimedia event (TIME) framework as a robust approach for classification of semantic events in multimodal video documents. The representation used in TIME extends the Allen temporal interval relations and allows for proper inclusion of context and synchronization of the heterogeneous information sources involved in multimodal video analysis. To demonstrate the viability of our approach, it was evaluated on the domains of soccer and news broadcasts. For automatic classification of semantic events, we compare three different machine learning techniques, i.c. C4.5 decision tree, maximum entropy, and support vector machine. The results show that semantic video indexing results significantly benefit from using the TIME framework.},
	author = {Snoek, C. G. M.  and Worring, M. },
	citeulike-article-id = {272197},
	doi = {10.1109/TMM.2005.850966},
	journal = {Multimedia, IEEE Transactions on},
	keywords = {proposal},
	number = {4},
	pages = {638--647},
	posted-at = {2009-06-28 04:04:05},
	priority = {2},
	title = {Multimedia Event-Based Video Indexing Using Time Intervals},
	url = {http://dx.doi.org/10.1109/TMM.2005.850966},
	volume = {7},
	year = {2005}
}


@misc{citeulike:4072008,
	author = {Alspaugh, Thomas  A. },
	citeulike-article-id = {4072008},
	howpublished = {webpage},
	institution = {Department of Informatics, Bren School of Information and Computer Sciences},
	location = {Irvine},
	organization = {University of California},
	posted-at = {2009-06-28 03:09:03},
	priority = {2},
	title = {Allen's interval algebra},
	url = {http://www.ics.uci.edu/\~{}alspaugh/foundations/allen.html}
}



@article{citeulike:4991400,
	abstract = {Without Abstract},
	author = {Chittaro, Luca   and Montanari, Angelo  },
	citeulike-article-id = {4991400},
	doi = {10.1023/A:1018933906603},
	journal = {Annals of Mathematics and Artificial Intelligence},
	keywords = {proposal},
	month = {February},
	number = {1},
	pages = {1--4},
	posted-at = {2009-06-27 20:12:54},
	priority = {2},
	title = {Editorial: Temporal representation and reasoning},
	url = {http://dx.doi.org/10.1023/A:1018933906603},
	volume = {22},
	year = {1998}
}



@article{citeulike:4991332,
	address = {Essex, UK},
	author = {Freksa, Christian  },
	citeulike-article-id = {4991332},
	doi = {10.1016/0004-3702(92)90090-K},
	issn = {0004-3702},
	journal = {Artif. Intell.},
	keywords = {proposal},
	number = {1-2},
	pages = {199--227},
	posted-at = {2009-06-27 19:59:03},
	priority = {2},
	publisher = {Elsevier Science Publishers Ltd.},
	title = {Temporal reasoning based on semi-intervals},
	url = {http://dx.doi.org/10.1016/0004-3702(92)90090-K},
	volume = {54},
	year = {1992}
}



@article{citeulike:191348,
	address = {New York, NY, USA},
	author = {Allen, James  F. },
	citeulike-article-id = {191348},
	doi = {10.1145/182.358434},
	issn = {0001-0782},
	journal = {Commun. ACM},
	keywords = {proposal},
	month = {November},
	number = {11},
	pages = {832--843},
	posted-at = {2009-06-27 19:36:52},
	priority = {2},
	publisher = {ACM Press},
	title = {Maintaining knowledge about temporal intervals},
	url = {http://dx.doi.org/10.1145/182.358434},
	volume = {26},
	year = {1983}
}



@misc{citeulike:1277366,
	abstract = {this paper, we surveyed the list of existing association rule mining techniques.
This investigation is prepared to our new project titled mining historical changes
to web delta},
	author = {Zhao, Qiankun   and Bhowmick, Sourav  S. },
	citeulike-article-id = {1277366},
	keywords = {proposal},
	posted-at = {2009-06-24 15:29:52},
	priority = {2},
	title = {Sequential Pattern Matching: A Survey},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.8692}
}



@article{citeulike:1748833,
	address = {New York, NY, USA},
	author = {M\"orchen, Fabian  },
	citeulike-article-id = {1748833},
	doi = {10.1145/1294301.1294302},
	issn = {1931-0145},
	journal = {SIGKDD Explor. Newsl.},
	keywords = {proposal},
	month = {June},
	number = {1},
	pages = {41--55},
	posted-at = {2009-06-22 19:01:45},
	priority = {2},
	publisher = {ACM Press},
	title = {Unsupervised pattern mining from symbolic temporal data},
	url = {http://dx.doi.org/10.1145/1294301.1294302},
	volume = {9},
	year = {2007}
}



@article{citeulike:819708,
	address = {Piscataway, NJ, USA},
	author = {Yang, Jiong   and Wang, Wei   and Yu, Philip  S. },
	citeulike-article-id = {819708},
	doi = {10.1109/TKDE.2003.1198394},
	issn = {1041-4347},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	keywords = {proposal},
	month = {March},
	number = {3},
	pages = {613--628},
	posted-at = {2009-06-21 17:30:08},
	priority = {2},
	publisher = {IEEE Educational Activities Department},
	title = {Mining Asynchronous Periodic Patterns in Time Series Data},
	url = {http://dx.doi.org/10.1109/TKDE.2003.1198394},
	volume = {15},
	year = {2003}
}



@book{citeulike:143101,
	abstract = {{"People sometimes ask me what they should read to find out about artificial intelligence. Herbert Simon's book The Sciences of the Artificial is always on the list I give them. Every page issues a challenge to conventional thinking, and the layman who digests it well will certainly understand what the field of artificial intelligence hopes to accomplish. I recommend it in the same spirit that I recommend Freud to people who ask about psychoanalysis, or Piaget to those who ask about child psychology: If you want to learn about a subject, start by reading its founding fathers." -- George A. Miller, <i>Complex Information Processing</i>  <P>Continuing his exploration of the organization of complexity and the science of design, this new edition of Herbert Simon's classic work on artificial intelligence adds a chapter that sorts out the current themes and tools -- chaos, adaptive systems, genetic algorithms -- for analyzing complexity and complex systems. There are updates throughout the book as well. These take into account important advances in cognitive psychology and the science of design while confirming and extending the book's basic thesis: that a physical symbol system has the necessary and sufficient means for intelligent action. The chapter "Economic Reality" has also been revised to reflect a change in emphasis in Simon's thinking about the respective roles of organizations and markets in economic systems.}},
	author = {Simon, Herbert  A. },
	citeulike-article-id = {143101},
	howpublished = {Paperback},
	isbn = {0262691914},
	keywords = {proposal},
	month = {October},
	posted-at = {2009-06-20 02:10:19},
	priority = {2},
	publisher = {{The MIT Press}},
	title = {The Sciences of the Artificial - 3rd Edition},
	url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0262691914},
	year = {1996}
}



@book{citeulike:606469,
	abstract = {{Richard Dawkins is not a shy man. Edward Larson's research shows that most scientists today are not formally religious, but Dawkins is an in-your-face atheist in the witty British style:<p> <blockquote>I want to persuade the reader, not just that the Darwinian world-view happens to be true, but that it is the only known theory that could, in principle, solve the mystery of our existence.</blockquote><p> The title of this 1986 work, Dawkins's second book, refers to the Rev.  William Paley's 1802 work, <I>Natural Theology</I>, which argued that just as finding a watch would lead you to conclude that a watchmaker must exist, the complexity of living organisms proves that a Creator exists. Not so, says Dawkins: "All appearances to the contrary, the only watchmaker in nature is the blind forces of physics, albeit deployed in a very special way... it is the <I>blind</I> watchmaker."<p> Dawkins is a hard-core scientist: he doesn't just tell you what is so, he shows you how to find out for yourself. For this book, he wrote <I>Biomorph</I>, one of the first artificial life programs. You can check Dawkins's results on your own Mac or PC.} {<B>"The best general account of evolution I have read in recent years."\&\#151;E. O. Wilson. With a new introduction.</B><BR><BR>Twenty years after its original publication, <I>The Blind Watchmaker</I>, framed with a new introduction by the author, is as prescient and timely a book as ever. The watchmaker belongs to the eighteenth-century theologian William Paley, who argued that just as a watch is too complicated and functional to have sprung into existence by accident, so too must all living things, with their far greater complexity, be purposefully designed. Charles Darwin's brilliant discovery challenged the creationist arguments; but only Richard Dawkins could have written this elegant riposte. Natural selection\&\#151;the unconscious, automatic, blind, yet essentially nonrandom process Darwin discovered\&\#151;is the blind watchmaker in nature.}},
	author = {Dawkins, Richard  },
	citeulike-article-id = {606469},
	howpublished = {Paperback},
	isbn = {0393315703},
	keywords = {proposal},
	month = {September},
	posted-at = {2009-06-20 02:07:35},
	priority = {2},
	publisher = {{W. W. Norton}},
	title = {The Blind Watchmaker: Why the Evidence of Evolution Reveals a Universe Without Design},
	url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0393315703},
	year = {1996}
}



@article{citeulike:4913213,
	author = {Fischer, Gerhard  },
	citeulike-article-id = {4913213},
	doi = {10.1023/A:1022972113929},
	journal = {Automated Software Engineering},
	keywords = {proposal},
	month = {April},
	number = {2},
	pages = {233--237},
	posted-at = {2009-06-20 01:34:55},
	priority = {2},
	title = {Desert Island: Software Engineering—A Human Activity},
	url = {http://dx.doi.org/10.1023/A:1022972113929},
	volume = {10},
	year = {2003}
}



@inproceedings{citeulike:2826276,
	abstract = {Efficient and accurate similarity searching on a large time series data set is an important but non- trivial problem. In this work, we propose a new approach to improve the quality of similarity search on time series data by combining symbolic aggregate approximation (SAX) and piecewise linear approximation. The approach consists of three steps: transforming real valued time series sequences to symbolic strings via SAX, pattern matching on the symbolic strings and a post-processing via Piecewise Linear Approximation.},
	author = {Nguyen and Anh, Duong  T. },
	booktitle = {Information Technology Convergence, 2007. ISITC 2007. International Symposium on},
	citeulike-article-id = {2826276},
	doi = {10.1109/ISITC.2007.24},
	journal = {Information Technology Convergence, 2007. ISITC 2007. International Symposium on},
	keywords = {sax, search, similarity},
	pages = {58--62},
	posted-at = {2009-05-27 18:26:19},
	priority = {2},
	title = {Combining SAX and Piecewise Linear Approximation to Improve Similarity Search on Financial Time Series},
	url = {http://dx.doi.org/10.1109/ISITC.2007.24},
	year = {2007}
}



@article{citeulike:4518026,
	abstract = {Abstract\&nbsp;\&nbsp;Process mining aims at extracting information from event logs to capture the business process as it is being executed. Process mining is particularly useful in situations where events are recorded but there is no system enforcing people to work in a particular way. Consider for example a hospital where the diagnosis and treatment activities are recorded in the hospital information system, but where health-care professionals determine the  ” careflow.” Many process mining approaches have been proposed in recent years. However, in spite of many researchers' persistent efforts, there are still several challenging problems to be solved. In this paper, we focus on mining non-free-choice constructs, i.e., situations where there is a mixture of choice and synchronization. Although most real-life processes exhibit non-free-choice behavior, existing algorithms are unable to adequately deal with such constructs. Using a Petri-net-based representation, we will show that there are two kinds of causal dependencies between tasks, i.e., explicit and implicit ones. We propose an algorithm that is able to deal with both kinds of dependencies. The algorithm has been implemented in the ProM framework and experimental results shows that the algorithm indeed significantly improves existing process mining techniques.},
	author = {Wen, Lijie   and van der Aalst, Wil   and Wang, Jianmin   and Sun, Jiaguang  },
	citeulike-article-id = {4518026},
	doi = {10.1007/s10618-007-0065-y},
	journal = {Data Mining and Knowledge Discovery},
	keywords = {mining, process},
	month = {October},
	number = {2},
	pages = {145--180},
	posted-at = {2009-05-14 13:33:00},
	priority = {2},
	title = {Mining process models with non-free-choice constructs},
	url = {http://dx.doi.org/10.1007/s10618-007-0065-y},
	volume = {15},
	year = {2007}
}


@article{citeulike:4501572,
	abstract = {The last decade has witnessed a tremendous growths of interests in applications that deal with querying and mining of time series data. Numerous representation methods for dimensionality reduction and similarity measures geared towards time series have been introduced. Each individual work introducing a particular method has made specific claims and, aside from the occasional theoretical justifications, provided quantitative experimental observations. However, for the most part, the comparative aspects of these experiments were too narrowly focused on demonstrating the benefits of the proposed methods over some of the previously introduced ones. In order to provide a comprehensive validation, we conducted an extensive set of time series experiments re-implementing 8 different representation methods and 9 similarity measures and their variants, and testing their effectiveness on 38 time series data sets from a wide variety of application domains. In this paper, we give an overview of these different techniques and present our comparative experimental findings regarding their effectiveness. Our experiments have provided both a unified validation of some of the existing achievements, and in some cases, suggested that certain claims in the literature may be unduly optimistic.},
	author = {Ding, Hui   and Trajcevski, Goce   and Scheuermann, Peter   and Wang, Xiaoyue   and Keogh, Eamonn  },
	citeulike-article-id = {4501572},
	doi = {10.1145/1454159.1454226},
	journal = {Proc. VLDB Endow.},
	number = {2},
	pages = {1542--1552},
	posted-at = {2009-05-10 22:19:43},
	priority = {2},
	publisher = {VLDB Endowment},
	title = {Querying and mining of time series data: experimental comparison of representations and distance measures},
	url = {http://dx.doi.org/10.1145/1454159.1454226},
	volume = {1},
	year = {2008}
}



@inproceedings{citeulike:4446167,
	abstract = {The last decade has seen a huge interest in classification of time series. Most of this work assumes that the data resides in main memory and is processed offline. However, recent advances in sensor technologies require resource-efficient algorithms that can be implemented directly on the sensors as real-time algorithms. We show how a recently introduced framework for time series classification, time series bitmaps, can be implemented as efficient classifiers which can be updated in constant time and space in the face of very high data arrival rates. We describe results from a case study of an important entomological problem, and further demonstrate the generality of our ideas with an example from robotics.},
	address = {Washington, DC, USA},
	author = {Kasetty, Shashwati   and Stafford, Candice   and Walker, Gregory  P.  and Wang, Xiaoyue   and Keogh, Eamonn  },
	booktitle = {ICTAI '08: Proceedings of the 2008 20th IEEE International Conference on Tools with Artificial Intelligence},
	citeulike-article-id = {4446167},
	doi = {10.1109/ICTAI.2008.143},
	isbn = {978-0-7695-3440-4},
	keywords = {litreview, sax, similarity},
	pages = {149--156},
	posted-at = {2009-04-30 19:36:30},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Real-Time Classification of Streaming Sensor Data},
	url = {http://dx.doi.org/10.1109/ICTAI.2008.143},
	year = {2008}
}



@inproceedings{citeulike:3175770,
	author = {Wei, Li   and Keogh, Eamonn  J.  and Xi, Xiaopeng  },
	booktitle = {ICDM},
	citeulike-article-id = {3175770},
	doi = {10.1109/ICDM.2006.138},
	keywords = {litreview, sax, search, similarity},
	pages = {711--720},
	posted-at = {2009-04-30 19:33:04},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {SAXually Explicit Images: Finding Unusual Shapes},
	url = {http://dx.doi.org/10.1109/ICDM.2006.138},
	year = {2006}
}



@book{citeulike:4434481,
	abstract = {Using high-quality, real-world case studies and examples, this introduction to
mathematical statistics shows how to use statistical methods and when to use
them. This book can be used as a brief introduction to design of experiments.
This successful, calculus-based book of probability and statistics, was one of
the first to make real-world applications an integral part of motivating
discussion. The number of problem sets has increased in all sections. Some
sections include almost 50\% new problems, while the most popular case studies
remain. For anyone needing to develop proficiency with Mathematical
Statistics.},
	author = {Larsen, Richard  J.  and Marx, Morris  L. },
	citeulike-article-id = {4434481},
	edition = {3rd},
	howpublished = {Hardcover},
	isbn = {0139223037},
	keywords = {litreview, similarity},
	month = {January},
	posted-at = {2009-04-29 14:54:10},
	priority = {2},
	publisher = {Prentice Hall},
	title = {An Introduction to Mathematical Statistics and Its Applications (3rd Edition)},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0139223037},
	year = {2000}
}



@inproceedings{citeulike:227029,
	address = {Washington, DC, USA},
	author = {Keogh, Eamonn   and Lin, Jessica   and Truppel, Wagner  },
	booktitle = {ICDM '03: Proceedings of the Third IEEE International Conference on Data Mining},
	citeulike-article-id = {227029},
	isbn = {0769519784},
	keywords = {litreview, sax},
	posted-at = {2009-04-28 14:29:55},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Clustering of Time Series Subsequences is Meaningless: Implications for Previous and Future Research},
	url = {http://portal.acm.org/citation.cfm?id=952156},
	year = {2003}
}



@article{citeulike:4412621,
	abstract = {We develop an event detection framework that has two significant  advantages over past work. First, we introduce an  extended set of time-wise and object-wise statistical features  including not only the trajectory coordinates but also  the histograms and HMM based representations of object's  speed, orientation, location, size, and aspect ratio. These  features enable detection of events that cannot be detected  with the existing trajectory features reported so far. Second,  we introduce a spectral clustering algorithm that can automatically  estimate the optimal number of clusters. First,  we construct feature-wise affinity matrices from the pair-wise  similarity scores of objects using the extended set of  features. To determine the usual events, we apply eigen-vector  decomposition and obtain object clusters. We show  that the number of eigenvectors used in the decomposition is  proportional to the optimal number of clusters. Unlike the  conventional approaches that try to fit predefined models to  events, we analyze the conformity of objects using affinity  matrices to find the unusual events. We improve the feature  selection process by incorporating feature variances.  We prove that the clustering stage is not adversely affected  by high dimensionality of data space. Our simulations with  synthetic and real data reveal that the proposed detection  methods accurately detect usual and unusual events.},
	address = {Los Alamitos, CA, USA},
	author = {Porikli, Fatih   and Haga, Tetsuji  },
	citeulike-article-id = {4412621},
	doi = {10.1109/CVPR.2004.335},
	issn = {1063-6919},
	journal = {Computer Vision and Pattern Recognition Workshop},
	keywords = {litreview, similarity},
	pages = {114+},
	posted-at = {2009-04-27 22:01:38},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Event Detection by Eigenvector Decomposition Using Object and Frame Features},
	url = {http://dx.doi.org/10.1109/CVPR.2004.335},
	volume = {7},
	year = {2004}
}



@inproceedings{citeulike:4412617,
	abstract = {Consider the problem of monitoring tens of thousands of time series data streams in an online fashion and making decisions based on them. In addition to single stream statistics such as average and standard deviation, we also want to find high correlations among all pairs of streams. A stock market trader might use such a tool to spot arbitrage opportunities. This paper proposes efficient methods for solving this problem based on Discrete Fourier Transforms and a three level time interval hierarchy. Extensive experiments on synthetic data and real world financial trading data show that our algorithm beats the direct computation approach by several orders of magnitude. It also improves on previous Fourier Transform approaches by allowing the efficient computation of time-delayed correlation over any size sliding window and any time delay. Correlation also lends itself to an efficient grid-based data structure. The result is the first algorithm that we know of to compute correlations over thousands of data streams in real time. The algorithm is incremental, has fixed response time, and can monitor the pairwise correlations of 10,000 streams on a single PC. The algorithm is embarrassingly parallelizable.},
	author = {Zhu, Yunyue   and Shasha, Dennis  },
	booktitle = {VLDB '02: Proceedings of the 28th international conference on Very Large Data Bases},
	citeulike-article-id = {4412617},
	keywords = {litreview, similarity},
	location = {Hong Kong, China},
	pages = {358--369},
	posted-at = {2009-04-27 21:58:48},
	priority = {2},
	publisher = {VLDB Endowment},
	title = {StatStream: statistical monitoring of thousands of data streams in real time},
	url = {http://portal.acm.org/citation.cfm?id=1287401},
	year = {2002}
}



@techreport{citeulike:4041809,
	abstract = {Hackystat is an open source framework for automated collection and analysis of software engineering process and product data. Hackystat has been in development since 2001, and has gone through eight major architectural revisions during that time. In 2007, we performed the latest architectural revision, whose primary goal was to reimplement Hackystat as a service-oriented architecture (SOA). This version has now been in public release for a year, and this paper reports on our experiences: the motivations that led us to reimplement the system as a SOA, the costs and benefits of that conversion, and our lessons learned.},
	address = {Los Angeles, California},
	author = {Johnson, Philip  M.  and Zhang, Shaoxuan   and Senin, Pavel  },
	booktitle = {Submitted to the 2009 {IEEE} Service Cup Conference},
	citeulike-article-id = {4041809},
	institution = {Department of Information and Computer Sciences, University of Hawaii, Honolulu, Hawaii 96822},
	keywords = {publication},
	month = {February},
	number = {{CSDL}-09-07},
	posted-at = {2009-04-27 13:00:38},
	priority = {2},
	title = {Experiences with Hackystat as a service-oriented architecture},
	url = {http://csdl.ics.hawaii.edu/techreports/09-07/09-07.pdf},
	year = {2009}
}



@book{citeulike:167581,
	author = {Duda, Richard  O.  and Hart, Peter  E.  and Stork, David  G. },
	citeulike-article-id = {167581},
	howpublished = {Hardcover},
	isbn = {0471056693},
	keywords = {litreview},
	month = {November},
	posted-at = {2009-04-26 20:58:15},
	priority = {2},
	publisher = {Wiley-Interscience},
	title = {Pattern Classification (2nd Edition)},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0471056693},
	year = {2000}
}



@inproceedings{citeulike:4408223,
	abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article.  ACM has opted to expose the complete List rather than only correct and linked references.},
	address = {New York, NY, USA},
	author = {Hellerstein, Joseph  M.  and Koutsoupias, Elias   and Papadimitriou, Christos  H. },
	booktitle = {PODS '97: Proceedings of the sixteenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems},
	citeulike-article-id = {4408223},
	doi = {10.1145/263661.263688},
	isbn = {0-89791-910-6},
	keywords = {litreview, sax, search, similarity},
	location = {Tucson, Arizona, United States},
	pages = {249--256},
	posted-at = {2009-04-26 19:53:17},
	priority = {2},
	publisher = {ACM},
	title = {On the analysis of indexing schemes},
	url = {http://dx.doi.org/10.1145/263661.263688},
	year = {1997}
}



@misc{citeulike:4406444,
	abstract = {We introduce an extended representation of time series that allows fast, accurate classification and clustering in addition to the ability to explore time series data in a relevance feedback framework. The representation consists of piecewise linear segments to represent shape and a weight vector that contains the relative importance of each individual linear segment. In the classification context, the weights are learned automatically as part of the training cycle. In the relevance feedback context, the weights are determined by an interactive and iterative process in which users rate various choices presented to them. Our representation allows a user to define a variety of similarity measures that can be tailored to specific domains. We demonstrate our approach on space telemetry, medical and synthetic data. 1.0 Introduction Time series account for much of the data stored in business, medical, engineering and social science databases. Much of the utility of collecting this data com...},
	author = {Keogh, Eamonn  J.  and Pazzani, Michael  J. },
	citeulike-article-id = {4406444},
	keywords = {litreview, paa, similarity},
	posted-at = {2009-04-26 16:51:34},
	priority = {2},
	title = {An Enhanced Representation of Time Series Which Allows Fast and Accurate Classification, Clustering and Relevance Feedback},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.9288},
	year = {1998}
}



@book{citeulike:499150,
	abstract = {{Wavelets are a mathematical development that may revolutionize the world of information storage and retrieval according to many experts. They are a fairly simple mathematical tool now being applied to the compression of data--such as fingerprints, weather satellite photographs, and medical x-rays--that were previously thought to be impossible to condense without losing crucial details.  <P>This monograph contains 10 lectures presented by Dr. Daubechies as the principal speaker at the 1990 CBMS-NSF Conference on Wavelets and Applications. The author has worked on several aspects of the wavelet transform and has developed a collection of wavelets that are remarkably efficient.  <P>The opening chapter provides an overview of the main problems presented in the book. Following chapters discuss the theoretical and practical aspects of wavelet theory, including wavelet transforms, orthonormal bases of wavelets, and characterization of functional spaces by means of wavelets. The last chapter presents several topics under active research, as multidimensional wavelets, wavelet packet bases, and a construction of wavelets tailored to decompose functions defined in a finite interval. Because of their interdisciplinary origins, wavelets appeal to scientists and engineers of many different backgrounds.}},
	author = {Daubechies, Ingrid  },
	citeulike-article-id = {499150},
	howpublished = {Paperback},
	isbn = {0898712742},
	keywords = {litreview, wavelet},
	month = {December},
	posted-at = {2009-04-26 13:49:40},
	priority = {2},
	publisher = {{Soc for Industrial \& Applied Math}},
	title = {Ten Lectures on Wavelets (C B M S - N S F Regional Conference Series in Applied Mathematics)},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0898712742},
	year = {1992}
}



@article{citeulike:4384535,
	abstract = {Time series stored as feature vectors can be indexed by multi-dimensional index trees like R-Tree for fast retrieval. Due to the dimensionality curse problem, transformations are applied to time series to reduce the number of dimensions of the feature vectors. Different transformations like Discrete Fourier Transform (DFT), Discrete Wavelet Transform (DWT), Karhunen-Loeve (K-L) transform or Singular Value Decomposition (SVD) can be applied. While the use of DFT and K-L transform or SVD have been studied in the literature, to our knowledge, there is no in-depth study on the application of DWT. In this paper, we propose to use Haar Wavelet Transform for time series indexing. The major contributions are: (1) we show that Euclidean distance is preserved in the Haar transformed domain and no false dismissal will occur in range query, (2) we show that Haar transform can outperform DFT through experiments, (3) a new similarity model is suggested to accommodate vertical shift of time series, and (4) a two-phase method is proposed for efficient n-nearest neighbor query in time series databases.},
	address = {Los Alamitos, CA, USA},
	author = {Chan, Kin  P.  and Fu, Wai  C. },
	citeulike-article-id = {4384535},
	doi = {10.1109/ICDE.1999.754915},
	issn = {1063-6382},
	journal = {Data Engineering, International Conference on},
	keywords = {litreview, similarity, wavelet},
	pages = {126+},
	posted-at = {2009-04-23 11:27:16},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Efficient Time Series Matching by Wavelets},
	url = {http://dx.doi.org/10.1109/ICDE.1999.754915},
	volume = {0},
	year = {1999}
}



@incollection{citeulike:4384496,
	abstract = {The existing multi-dimensional index structures are not adequate for indexing higher-dimensional data sets. Although conceptually they can be extended to higher dimensionalities, they usually require time and space that grow exponentially with the dimensionality. In this paper, we analyze the existing index structures and derive some requirements of an index structure for content-based image retrieval. We also propose a new structure, called CIR(Content-based Image Retrieval)-tree, for indexing large amounts of point data in high dimensional space that satisfies the requirements. In order to justify the performance of the proposed structure, we compare the proposed structure with the existing index structures in the various environments. We show through experiments that our proposed structure outperforms the existing structures in terms of retrieval time and storage overhead.},
	author = {Yoo, Jae   and Shin, Myung   and Lee, Seok   and Choi, Kil   and Cho, Ki   and Hur, Dae  },
	citeulike-article-id = {4384496},
	doi = {10.1007/3-540-48962-2\_10},
	journal = {Advanced Multimedia Content Processing},
	keywords = {litreview, search, similarity, tree},
	pages = {131--144},
	posted-at = {2009-04-23 11:07:15},
	priority = {2},
	title = {An Efficient Index Structure for High Dimensional Image Data},
	url = {http://dx.doi.org/10.1007/3-540-48962-2\_10},
	year = {1999}
}



@inproceedings{citeulike:2843857,
	address = {San Francisco, CA, USA},
	author = {Berchtold, Stefan   and Keim, Daniel  A.  and Kriegel, Hans-Peter  },
	booktitle = {VLDB '96: Proceedings of the 22th International Conference on Very Large Data Bases},
	citeulike-article-id = {2843857},
	isbn = {1558603824},
	keywords = {litreview, similarity, tree},
	pages = {28--39},
	posted-at = {2009-04-23 11:06:15},
	priority = {2},
	publisher = {Morgan Kaufmann Publishers Inc.},
	title = {The {X}-tree: An Index Structure for High-Dimensional Data},
	url = {http://portal.acm.org/citation.cfm?id=645922.673502},
	year = {1996}
}



@inproceedings{citeulike:4384489,
	abstract = {Feature-based similarity searching is emerging as an important search paradigm in database systems. The technique used is to map the data items as points into a high-dimensional feature space which is indexed using a multidimensional data structure. Similarity searching then corresponds to a range search over the data structure. Although several data structures have been proposed for feature indexing, none of them is known to scale beyond 10-15 dimensional spaces. This paper introduces the hybrid tree-a multidimensional data structure for indexing high-dimensional feature spaces. Unlike other multidimensional data structures, the hybrid tree cannot be classified as either a pure data partitioning (DP) index structure (such as the R-tree, SS-tree or SR-tree) or a pure space partitioning (SP) one (such as the KDB-tree or hB-tree); rather it combines the positive aspects of the two types of index structures into a single data structure to achieve a search performance which is more scalable to high dimensionalities than either of the above techniques. Furthermore, unlike many data structures (e.g. distance-based index structures like the SS-tree and SR-tree), the hybrid tree can support queries based on arbitrary distance functions. Our experiments on \&ldquo;real\&rdquo; high-dimensional large-size feature databases demonstrate that the hybrid tree scales well to high dimensionality and large database sizes. It significantly outperforms both purely DP-based and SP-based index mechanisms as well as linear scans at all dimensionalities for large-sized databases},
	author = {Chakrabarti, K.  and Mehrotra, S. },
	booktitle = {Data Engineering, 1999. Proceedings., 15th International Conference on},
	citeulike-article-id = {4384489},
	doi = {10.1109/ICDE.1999.754960},
	journal = {Data Engineering, 1999. Proceedings., 15th International Conference on},
	keywords = {litreview, search, similarity, tree},
	pages = {440--447},
	posted-at = {2009-04-23 11:03:52},
	priority = {2},
	title = {The hybrid tree: an index structure for high dimensional feature spaces},
	url = {http://dx.doi.org/10.1109/ICDE.1999.754960},
	year = {1999}
}



@inproceedings{citeulike:4373408,
	abstract = {Abstract: The problem of finding patterns of interest in time series databases (query by content) is an important one, with applications in virtually every field of science. A variety of approaches have been suggested. These approaches are robust to noise, offset translation, and amplitude scaling to varying degrees. However, they are all extremely sensitive to scaling in the time axis (longitudinal scaling). We present a method for similarity search that is robust to scaling in the time axis, in addition to noise, offset translation, and amplitude scaling. The method has been tested on medical, financial, space telemetry and artificial data. Furthermore the method is exceptionally fast, with the predicted 2 to 4 orders of magnitude speedup actually observed. The method uses a piecewise linear representation of the original data. We also introduce a new algorithm which both decides the optimal number of linear segments to use, and produces the actual linear representation.},
	address = {Washington, DC, USA},
	author = {Keogh, E. },
	booktitle = {ICTAI '97: Proceedings of the 9th International Conference on Tools with Artificial Intelligence},
	citeulike-article-id = {4373408},
	keywords = {litreview, similarity},
	pages = {578+},
	posted-at = {2009-04-22 04:51:15},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Fast similarity search in the presence of longitudinal scaling in time series databases},
	url = {http://portal.acm.org/citation.cfm?id=880107},
	year = {1997}
}



@inproceedings{citeulike:4373332,
	abstract = {We examine the problem of finding similar tumor  shapes. Starting from a natural similarity  function (the so-called `max morphological  distance\&\#039;), we show how to lower-bound it and  how to search for nearest neighbors in large  collections of tumor-like shapes.  Specifically, we use state-of-the-art concepts  from morphology, namely the `pattern spectrum  \&\#039; of a shape, to map each shape to a point  in n-dimensional space. Following [16, 30], we  organize the n-d points in an R-tree. We show  that the L1 (= max) norm in the n-d space  lower-bounds the actual distance. This guarantees  no false dismissals for range queries. In  addition, we present a nearest neighbor algorithm  that also guarantees no false dismissals.  Finally, we implemented the method and  tested it against a testbed of realistic tumor  shapes, using an established tumor-growth  model of Murray Eden[13]. The experiments  Permission to copy without fee all or part of this material is granted provided that the copies ...},
	author = {Korn, Flip   and Sidiropoulos, Nikolaos   and Faloutsos, Christos   and Siegel, Eliot   and Protopapas, Zenon  },
	booktitle = {In Proceedings of the Int. Conf. on Very Large Data Bases},
	citeulike-article-id = {4373332},
	keywords = {litreview, similarity},
	pages = {215--226},
	posted-at = {2009-04-22 02:57:59},
	priority = {2},
	title = {Fast Nearest Neighbor Search in Medical Image Databases},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.9993},
	year = {1996}
}



@article{citeulike:4373331,
	author = {Heck, A. },
	citeulike-article-id = {4373331},
	doi = {10.1023/A:1005078508777},
	journal = {Space Science Reviews},
	editor = {D. Maoz, A. Sternberg, E. M. Leibowitz},
	month = {August},
	number = {3},
	pages = {549},
	posted-at = {2009-04-22 02:54:00},
	priority = {2},
	title = {{A}stronomical {T}ime {S}eries, {P}roceedings of {T}he {F}lorence and {G}eorge {W}ise {O}bservatory 25th {A}nniversary {S}ymposium},
	url = {http://dx.doi.org/10.1023/A:1005078508777},
	volume = {85},
	year = {1998}
}



@article{citeulike:4367455,
	author = {Kruskal, Joseph  B. },
	citeulike-article-id = {4367455},
	journal = {SIAM Review},
	keywords = {litreview, similarity},
	number = {2},
	pages = {201--237},
	posted-at = {2009-04-20 04:17:44},
	priority = {2},
	publisher = {SIAM},
	title = {An Overview of Sequence Comparison: Time Warps, String Edits, and Macromolecules},
	url = {http://scitation.aip.org/getabs/servlet/GetabsServlet?prog=normal\&id=SIREAD000025000002000201000001\&idtype=cvips\&gifs=yes},
	volume = {25},
	year = {1983}
}



@article{citeulike:3980022,
	abstract = {The Dynamic Time Warping (DTW) is a popular similarity measure between time
series. The DTW fails to satisfy the triangle inequality and its computation
requires quadratic time. Hence, to find closest neighbors quickly, we use
bounding techniques. We can avoid most DTW computations with an inexpensive
lower bound (LB Keogh). We compare LB Keogh with a tighter lower bound (LB
Improved). We find that LB Improved-based search is faster. As an example, our
approach is 2-3 times faster over random-walk and shape time series.},
	author = {Lemire, Daniel  },
	citeulike-article-id = {3980022},
	eprint = {0811.3301},
	keywords = {dtw, litreview, similarity},
	month = {Nov},
	posted-at = {2009-04-20 03:46:18},
	priority = {2},
	title = {Faster Retrieval with a Two-Pass Dynamic-Time-Warping Lower Bound},
	url = {http://arxiv.org/abs/0811.3301},
	year = {2008}
}



@book{citeulike:180287,
	author = {Cormen, Thomas  H.  and Leiserson, Charles  E.  and Rivest, Ronald  L.  and Stein, Clifford  },
	citeulike-article-id = {180287},
	howpublished = {Hardcover},
	isbn = {0262032937},
	keywords = {litreview},
	month = {September},
	posted-at = {2009-04-20 00:51:56},
	priority = {2},
	publisher = {{The MIT Press}},
	title = {Introduction to Algorithms, Second Edition},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262032937},
	year = {2001}
}



@inproceedings{citeulike:343069,
	address = {New York, NY, USA},
	author = {Beckmann, Norbert   and Kriegel, Hans-Peter   and Schneider, Ralf   and Seeger, Bernhard  },
	booktitle = {SIGMOD '90: Proceedings of the 1990 ACM SIGMOD international conference on Management of data},
	citeulike-article-id = {343069},
	doi = {10.1145/93597.98741},
	issn = {0163-5808},
	keywords = {lcs, litreview},
	month = {June},
	number = {2},
	pages = {322--331},
	posted-at = {2009-04-20 00:31:55},
	priority = {2},
	publisher = {ACM Press},
	title = {The {R}*-tree: an efficient and robust access method for points and rectangles},
	url = {http://dx.doi.org/10.1145/93597.98741},
	volume = {19},
	year = {1990}
}



@inproceedings{citeulike:4367061,
	abstract = {We propose an inter-sequence matching method for exact and similarity matching of image sequences. Our method transforms the image sequence matching problem into matching sequences of real numbers. The method does not require sequences to be of the same length. It uses a modified version of the Longest Common Subsequence (LCS) method for actually matching two sequences. We also propose a feature-based indexing mechanism to filter out those sequences which are matching candidates with a given query sequence from a large data set. Like all other feature-based indexing methods, our method maps each sequence into a point in K dimensional space, where K is the number of extracted features for the sequence. It operates in two phases, hypothesizing and verification. Lengths and moments (mean and variance) of sequences are used as features. Experimental results indicate that the features and proposed method for query processing do well as a filter.},
	address = {Washington, DC, USA},
	author = {Yazdani, Nasser   and \"{O}zsoyoglu, Meral  Z. },
	booktitle = {SSDBM '96: Proceedings of the Eighth International Conference on Scientific and Statistical Database Management},
	citeulike-article-id = {4367061},
	doi = {10.1109/SSDM.1996.505915},
	isbn = {0-8186-7264-1},
	keywords = {lcs, litreview},
	pages = {53--62},
	posted-at = {2009-04-20 00:24:26},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Sequence Matching of Images},
	url = {http://dx.doi.org/10.1109/SSDM.1996.505915},
	year = {1996}
}



@incollection{citeulike:4367057,
	abstract = {The purpose of subsequence matching is to find a query sequence from a long data sequence. Due to the abundance of applications, many solutions have been proposed. Virtually all previous solutions use the Euclidean measure as the basis for measuring distance between sequences. Recent studies, however, suggest that the Euclidean distance often fails to produce proper results due to the irregularity in the data, which is not so uncommon in our problem domain. Addressing this problem, some non-Euclidean measures, such as Dynamic Time Warping (DTW) and Longest Common Subsequence (LCS), have been proposed. However, most of the previous work in this direction focused on the whole sequence matching problem where query and data sequences are the same length. In this paper, we propose a novel subsequence matching framework using a non-Euclidean measure, in particular, LCS, and a new index query scheme. The proposed framework is based on the Dual Match framework where data sequences are divided into a series of disjoint equi-length subsequences and then indexed in an R-tree. We introduced similarity bound for index matching with LCS. The proposed query matching scheme reduces significant numbers of false positives in the match result. Furthermore, we developed an algorithm to skip expensive LCS computations through observing the warping paths. We validated our framework through extensive experiments using 48 different time series datasets. The results of the experiments suggest that our approach significantly improves the subsequence matching performance in various metrics.},
	author = {Han, Tae   and Ko, Seung-Kyu   and Kang, Jaewoo  },
	citeulike-article-id = {4367057},
	doi = {10.1007/978-3-540-73499-4\_44},
	journal = {Machine Learning and Data Mining in Pattern Recognition},
	keywords = {lcs, litreview},
	pages = {585--600},
	posted-at = {2009-04-20 00:20:00},
	priority = {2},
	title = {Efficient Subsequence Matching Using the Longest Common Subsequence with a Dual Match Index},
	url = {http://dx.doi.org/10.1007/978-3-540-73499-4\_44},
	year = {2007}
}



@inproceedings{citeulike:4344279,
	abstract = {Jagadish et al. (see Proc. ACM SIGACT-SIGMOD-SIGART PODS, p.36-45, 1995) developed a general framework for posing queries based on similarity. The framework enables a formal definition of the notion of similarity for an application domain of choice, and then its use in queries to perform similarity-based search. We adapt this framework to the specialized domain of real-valued sequences. (Although some of the ideas we present are applicable to other types of data as well). In particular we focus on whole-match queries. By whole-match query we mean the case where the user has to specify the whole sequence. Similarity-based search can be computationally very expensive. The computation cost depends heavily on the length of sequences being compared. To make such similarity testing feasible on large data sets, we propose the use of a signature based technique. In a nutshell, our approach is to \&ldquo;shrink\&rdquo; the data sequences into signatures, and search the signatures instead of the real sequences, with further comparison being required only when a possible match is indicated. Being shorter, signatures can usually be compared much faster than the original sequences. In addition, signatures are usually easier to index. For such a signature-based technique to be effective one has to assure that (1) the signature comparison is fast, and (2) the signature comparison gives few false alarms, and no false dismissals. We obtain measures of goodness for our technique. The technique is illustrated with a couple of very different examples},
	author = {Faloutsos, C.  and Jagadish, H. V.  and Mendelzon, A. O.  and Milo, T. },
	booktitle = {Compression and Complexity of Sequences 1997. Proceedings},
	citeulike-article-id = {4344279},
	doi = {10.1109/SEQUEN.1997.666899},
	journal = {Compression and Complexity of Sequences 1997. Proceedings},
	keywords = {litreview, similarity},
	pages = {2--20},
	posted-at = {2009-04-17 16:18:29},
	priority = {2},
	title = {A signature technique for similarity-based queries},
	url = {http://dx.doi.org/10.1109/SEQUEN.1997.666899},
	year = {1997}
}



@inproceedings{citeulike:3168542,
	address = {New York, NY, USA},
	author = {Rafiei, Davood   and Mendelzon, Alberto  },
	booktitle = {SIGMOD '97: Proceedings of the 1997 ACM SIGMOD international conference on Management of data},
	citeulike-article-id = {3168542},
	doi = {10.1145/253260.253264},
	isbn = {0897919114},
	keywords = {litreview},
	location = {Tucson, Arizona, United States},
	pages = {13--25},
	posted-at = {2009-04-17 16:13:48},
	priority = {2},
	publisher = {ACM},
	title = {Similarity-based queries for time series data},
	url = {http://dx.doi.org/10.1145/253260.253264},
	year = {1997}
}



@article{citeulike:4343933,
	abstract = {Recently some fast methods ( LAESA  and  TLAESA ) have been proposed to find nearest neighbours in metric spaces. The average number of distances computed by these algorithms does not depend on the number of prototypes and they show linear space complexity. These results where obtained through vast experimentation using only artificial data. In this paper, we corroborate this behaviour when applied to handwritten character recognition tasks. Moreover, we compare  LAESA  and  TLAESA  with some classical algorithms also working in metric spaces.},
	author = {Mic\'{o}, L. },
	citeulike-article-id = {4343933},
	doi = {10.1016/S0167-8655(98)00007-5},
	issn = {01678655},
	journal = {Pattern Recognition Letters},
	keywords = {litreview},
	month = {March},
	number = {3-4},
	pages = {351--356},
	posted-at = {2009-04-17 14:31:47},
	priority = {2},
	title = {Comparison of fast nearest neighbour classifiers for handwritten character recognition},
	url = {http://dx.doi.org/10.1016/S0167-8655(98)00007-5},
	volume = {19},
	year = {1998}
}



@article{citeulike:4343286,
	address = {Amsterdam, The Netherlands, The Netherlands},
	author = {Vidal, Enrique   and Casacuberta, Francisco  },
	citeulike-article-id = {4343286},
	doi = {10.1016/0167-6393(88)90022-2},
	issn = {0167-6393},
	journal = {Speech Commun.},
	keywords = {litreview},
	number = {1},
	pages = {67--79},
	posted-at = {2009-04-17 14:31:35},
	priority = {2},
	publisher = {Elsevier Science Publishers B. V.},
	title = {On the verification of triangle inequality by dynamic time-warping dissimilarity measures},
	url = {http://dx.doi.org/10.1016/0167-6393(88)90022-2},
	volume = {7},
	year = {1988}
}



@incollection{citeulike:4342003,
	abstract = {Time series are comprehensively appeared and developed in many applications. Similarity search under time warping has attracted much interest between the time series in the large databases. DTW (Dynamic Time Warping) is a robust distance measure and is superior to Euclidean distance. Nevertheless, it is more unfortunate that DTW has a quadratic time and the false dismissals are come forth since DTW distance does not satisfy the triangular inequality. In this paper, we propose an efficient range query algorithm based on a new similarity search method under time warping. When our range query applies for this method, it can remove the significant non-qualify time series as early as possible. Hence, it speeds up the calculation time and reduces the number of scanning the time series. Guaranteeing no false dismissals the lower bounding function is advised that consistently underestimate the DTW distance and satisfy the triangular inequality. Through the experimental results, our range query algorithm outperforms the existing others.},
	author = {Li, Chuyu   and Jin, Long   and Seo, Sungbo   and Ryu, Keun  },
	citeulike-article-id = {4342003},
	doi = {10.1007/11596448\_106},
	journal = {Computational Intelligence and Security},
	keywords = {litreview},
	pages = {721--728},
	posted-at = {2009-04-17 10:28:40},
	priority = {2},
	title = {An Efficient Range Query Under the Time Warping Distance},
	url = {http://dx.doi.org/10.1007/11596448\_106},
	year = {2005}
}



@incollection{citeulike:4326324,
	abstract = {In retail industry, it is very important to understand seasonal sales pattern, because this knowledge can assist decision makers in managing inventory and formulating marketing strategies. Self-Organizing Map (SOM) is suitable for extracting and illustrating essential structures because SOM has unsupervised learning and topology preserving properties, and prominent visualization techniques. In this experiment, we propose a method for seasonal pattern analysis using Self-Organizing Map. Performance test with real-world data from stationery stores in Indonesia shows that the method is effective for seasonal pattern analysis. The results are used to formulate several marketing and inventory management strategies. Keywords: Visualization, Clustering, Temporal Data, Self-Organizing Maps.},
	author = {Denny and Lee, Vincent  C. },
	citeulike-article-id = {4326324},
	journal = {Advances in Knowledge Discovery and Data Mining},
	keywords = {litreview},
	pages = {424--430},
	posted-at = {2009-04-16 13:56:51},
	priority = {2},
	title = {An Alternative Methodology for Mining Seasonal Pattern Using Self-Organizing Map},
	url = {http://www.springerlink.com/content/k3q3tpd3acaf2c0b
},
	year = {2004}
}



@article{citeulike:3000416,
	abstract = {Abstract.\&nbsp;\&nbsp; The problem of similarity search in large time series databases has attracted much attention recently. It is a non-trivial problem because of the inherent high dimensionality of the data. The most promising solutions involve first performing dimensionality reduction on the data, and then indexing the reduced data with a spatial access method. Three major dimensionality reduction techniques have been proposed: Singular Value Decomposition (SVD), the Discrete Fourier transform (DFT), and more recently the Discrete Wavelet Transform (DWT). In this work we introduce a new dimensionality reduction technique which we call Piecewise Aggregate Approximation (PAA). We theoretically and empirically compare it to the other techniques and demonstrate its superiority. In addition to being competitive with or faster than the other methods, our approach has numerous other advantages. It is simple to understand and to implement, it allows more flexible distance measures, including weighted Euclidean queries, and the index can be built in linear time.},
	author = {Keogh, Eamonn   and Chakrabarti, Kaushik   and Pazzani, Michael   and Mehrotra, Sharad  },
	citeulike-article-id = {3000416},
	doi = {10.1007/PL00011669},
	journal = {Knowledge and Information Systems},
	keywords = {litreview, sax},
	number = {3},
	pages = {263--286},
	posted-at = {2009-04-15 03:52:46},
	priority = {2},
	title = {Dimensionality Reduction for Fast Similarity Search in Large Time Series Databases},
	url = {http://dx.doi.org/10.1007/PL00011669},
	volume = {3},
	year = {2001}
}



@article{citeulike:2821475,
	abstract = {Abstract\&nbsp;\&nbsp;Many high level representations of time series have been proposed for data mining, including Fourier transforms, wavelets, eigenwaves, piecewise polynomial models, etc. Many researchers have also considered symbolic representations of time series, noting that such representations would potentiality allow researchers to avail of the wealth of data structures and algorithms from the text processing and bioinformatics communities. While many symbolic representations of time series have been introduced over the past decades, they all suffer from two fatal flaws. First, the dimensionality of the symbolic representation is the same as the original data, and virtually all data mining algorithms scale poorly with dimensionality. Second, although distance measures can be defined on the symbolic approaches, these distance measures have little correlation with distance measures defined on the original time series. In this work we formulate a new symbolic representation of time series. Our representation is unique in that it allows dimensionality/numerosity reduction, and it also allows distance measures to be defined on the symbolic approach that lower bound corresponding distance measures defined on the original series. As we shall demonstrate, this latter feature is particularly exciting because it allows one to run certain data mining algorithms on the efficiently manipulated symbolic representation, while producing identical results to the algorithms that operate on the original data. In particular, we will demonstrate the utility of our representation on various data mining tasks of clustering, classification, query by content, anomaly detection, motif discovery, and visualization.},
	author = {Lin, Jessica   and Keogh, Eamonn   and Wei, Li   and Lonardi, Stefano  },
	citeulike-article-id = {2821475},
	doi = {10.1007/s10618-007-0064-z},
	journal = {Data Mining and Knowledge Discovery},
	keywords = {litreview, sax},
	month = {October},
	number = {2},
	pages = {107--144},
	posted-at = {2009-04-15 03:51:17},
	priority = {2},
	title = {Experiencing {SAX}: a novel symbolic representation of time series},
	url = {http://dx.doi.org/10.1007/s10618-007-0064-z},
	volume = {15},
	year = {2007}
}



@inproceedings{citeulike:4303331,
	abstract = {Ad hoc querying is difficult on very large datasets, since it is usually not possible to have the entire dataset on disk. While compression can be used to decrease the size of the dataset, compressed data is notoriously difficult to index or access.   In this paper we consider a very large dataset comprising multiple distinct time sequences. Each point in the sequence is a numerical value. We show how to compress such a dataset into a format that supports ad hoc querying, provided that a small error can be tolerated when the data is uncompressed. Experiments on large, real world datasets ( AT\&amp;T  customer calling patterns) show that the proposed method achieves an average of less than 5\% error in any data value after compressing to a mere 2.5\% of the original space ( i.e. , a 40:1 compression ratio), with these numbers not very sensitive to dataset size. Experiments on aggregate queries achieved a 0.5\% reconstruction error with a space requirement under 2\%.},
	address = {New York, NY, USA},
	author = {Korn, Flip   and Jagadish, H. V.  and Faloutsos, Christos  },
	booktitle = {SIGMOD '97: Proceedings of the 1997 ACM SIGMOD international conference on Management of data},
	citeulike-article-id = {4303331},
	doi = {10.1145/253260.253332},
	isbn = {0-89791-911-4},
	keywords = {litreview},
	location = {Tucson, Arizona, United States},
	pages = {289--300},
	posted-at = {2009-04-12 22:00:21},
	priority = {2},
	publisher = {ACM},
	title = {Efficiently supporting ad hoc queries in large datasets of time sequences},
	url = {http://dx.doi.org/10.1145/253260.253332},
	year = {1997}
}



@inproceedings{citeulike:4295248,
	abstract = {Key words numerical time sequence, subsequence matching, indexing structure, a sequence of linear segments 1},
	author = {Morinaka, Y.  and Yoshikawa, M.  and Amagasa, T.  and Uemura, S. },
	citeulike-article-id = {4295248},
	journal = {PAKDD},
	keywords = {litreview, similarity},
	posted-at = {2009-04-09 19:11:07},
	priority = {2},
	title = {The {L}-index: An Indexing Structure for Efficient Subsequence Matching in TimeSequence Databases},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.4751},
	year = {2001}
}



@inproceedings{citeulike:4165220,
	abstract = {Similarity-based search over time-series databases has been a hot research topic for a long history, which is widely used in many applications, including multimedia retrieval, data mining, web search and retrieval, and so on. However, due to high dimensionality (i.e. length) of the time series, the similarity search over directly indexed time series usually encounters a serious problem, known as the "dimensionality curse". Thus, many dimensionality reduction techniques are proposed to break such curse by reducing the dimensionality of time series. Among all the proposed methods, only  Piecewise Linear Approximation  (PLA) does not have indexing mechanisms to support similarity queries, which prevents it from efficiently searching over very large time-series databases. Our initial studies on the effectiveness of different reduction methods, however, show that PLA performs no worse than others. Motivated by this, in this paper, we re-investigate PLA for approximating and indexing time series. Specifically, we propose a novel distance function in the reduced PLA-space, and prove that this function indeed results in a lower bound of the Euclidean distance between the original time series, which can lead to no  false dismissals  during the similarity search. As a second step, we develop an effective approach to index these lower bounds to improve the search efficiency. Our extensive experiments over a wide spectrum of real and synthetic data sets have demonstrated the efficiency and effectiveness of PLA together with the newly proposed lower bound distance, in terms of both  pruning power  and  wall clock time , compared with two state-of-the-art reduction methods,  Adaptive Piecewise Constant Approximation  (APCA) and  Chebyshev Polynomials  (CP).},
	author = {Chen, Qiuxia   and Chen, Lei   and Lian, Xiang   and Liu, Yunhao   and Yu, Jeffrey  X. },
	booktitle = {VLDB '07: Proceedings of the 33rd international conference on Very large data bases},
	citeulike-article-id = {4165220},
	isbn = {978-1-59593-649-3},
	keywords = {litreview, pla},
	location = {Vienna, Austria},
	pages = {435--446},
	posted-at = {2009-04-09 19:10:15},
	priority = {2},
	publisher = {VLDB Endowment},
	title = {Indexable {PLA} for efficient similarity search},
	url = {http://portal.acm.org/citation.cfm?id=1325851.1325903},
	year = {2007}
}



@inproceedings{citeulike:2753031,
	address = {New York, NY, USA},
	author = {Cai, Yuhan   and Ng, Raymond  },
	booktitle = {SIGMOD '04: Proceedings of the 2004 ACM SIGMOD international conference on Management of data},
	citeulike-article-id = {2753031},
	doi = {10.1145/1007568.1007636},
	isbn = {1581138598},
	keywords = {chebyshev, litreview},
	pages = {599--610},
	posted-at = {2009-04-09 19:08:19},
	priority = {2},
	publisher = {ACM},
	title = {Indexing spatio-temporal trajectories with Chebyshev polynomials},
	url = {http://dx.doi.org/10.1145/1007568.1007636},
	year = {2004}
}



@inproceedings{citeulike:3734066,
	abstract = {Considers the use of wavelet transformations as a dimensionality reduction technique to permit efficient similarity searching over high-dimensional time-series data. While numerous transformations have been proposed and studied, the only wavelet that has been shown to be effective for this application is the Haar wavelet. In this work, we observe that a large class of wavelet transformations (not only orthonormal wavelets but also bi-orthonormal wavelets) can be used to support similarity searching. This class includes the most popular and most effective wavelets being used in image compression. We present a detailed performance study of the effects of using different wavelets on the performance of similarity searching for time-series data. We include several wavelets that outperform both the Haar wavelet and the best-known non-wavelet transformations for this application. To ensure our results are usable by an application engineer, we also show how to configure an indexing strategy for the best-performing transformations. Finally, we identify classes of data that can be indexed efficiently using these wavelet transformations},
	author = {Popivanov, I.  and Miller, R. J. },
	booktitle = {Data Engineering, 2002. Proceedings. 18th International Conference on},
	citeulike-article-id = {3734066},
	doi = {10.1109/ICDE.2002.994711},
	journal = {Data Engineering, 2002. Proceedings. 18th International Conference on},
	keywords = {dwt, litreview},
	pages = {212--221},
	posted-at = {2009-04-09 19:07:19},
	priority = {2},
	title = {Similarity search over time-series data using wavelets},
	url = {http://dx.doi.org/10.1109/ICDE.2002.994711},
	year = {2002}
}



@misc{citeulike:4295242,
	abstract = {Time series data are of growing importance in many newdatabase applications, such as data warehousing and data mining [3, 8, 2, 12]. A time series (or time sequence) is a sequence ofreal numbers, each number representing a value at a time point. Typical examples include stock prices or currency exchange rates,biomedical measurements, weather data, etc... collected over time. Therefore, time series databases supporting fast retrieval oftime series data and similarity queries are desired.},
	citeulike-article-id = {4295242},
	keywords = {dwt, litreview},
	posted-at = {2009-04-09 19:05:40},
	priority = {2},
	title = {Efficient Time Series Matching by Wavelets},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.113.8628}
}



@incollection{citeulike:3973409,
	abstract = {We propose an indexing method for time sequences for processing similarity queries. We use the Discrete Fourier Transform (DFT) to map time sequences to the frequency domain, the crucial observation being that, for most sequences of practical interest, only the first few frequencies are strong. Another important observation is Parseval's theorem, which specifies that the Fourier transform preserves the Euclidean distance in the time or frequency domain. Having thus mapped sequences to a lower-dimensionality space by using only the first few Fourier coefficients, we use R * -trees to index the sequences and efficiently answer similarity queries. We provide experimental results which show that our method is superior to search based on sequential scanning. Our experiments show that a few coefficients (1–3) are adequate to provide good performance. The performance gain of our method increases with the number and length of sequences.},
	author = {Agrawal, Rakesh   and Faloutsos, Christos   and Swami, Arun  },
	citeulike-article-id = {3973409},
	doi = {10.1007/3-540-57301-1\_5},
	journal = {Foundations of Data Organization and Algorithms},
	keywords = {litreview},
	pages = {69--84},
	posted-at = {2009-04-09 19:04:28},
	priority = {2},
	title = {Efficient similarity search in sequence databases},
	url = {http://dx.doi.org/10.1007/3-540-57301-1\_5},
	year = {1993}
}



@inproceedings{citeulike:3978002,
	abstract = {The problem of efficiently locating previously known patterns in a time series database (i.e., query by content) has received much attention and may now largely be regarded as a solved problem. However, from a knowledge discovery viewpoint, a more interesting problem is the enumeration of previously unknown, frequently occurring patterns. We call such patterns “motifs,” because of their close analogy to their discrete counterparts in computation biology. An efficient motif discovery algorithm for time series would be useful as a tool for summarizing and visualizing massive time series databases. In addition, it could be used as a subroutine in various other data mining tasks, including the discovery of association rules, clustering and classification. In this work we carefully motivate, then introduce, a non-trivial definition of time series motifs. We propose an efficient algorithm to discover them, and we demonstrate the utility and efficiency of our approach on several real world datasets.},
	author = {Lin, Jessica   and Keogh, Eamonn  J.  and Lonardi, Stefano   and Patel, Pranav  },
	booktitle = {2nd Workshop on Temporal Data Mining, at the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	citeulike-article-id = {3978002},
	keywords = {dtw, similarity, thesis},
	location = {Edmonton, Alberta, Canada},
	month = {July},
	posted-at = {2009-03-05 11:22:44},
	priority = {2},
	title = {Finding Motifs in Time Series},
	year = {2002}
}



@inproceedings{citeulike:2946589,
	address = {San Francisco, CA, USA},
	author = {Yi, Byoung-Kee   and Faloutsos, Christos  },
	booktitle = {VLDB '00: Proceedings of the 26th International Conference on Very Large Data Bases},
	citeulike-article-id = {2946589},
	isbn = {1558607153},
	keywords = {dtw, litreview, paa, similarity, thesis},
	pages = {385--394},
	posted-at = {2009-02-26 13:26:35},
	priority = {2},
	publisher = {Morgan Kaufmann Publishers Inc.},
	title = {Fast Time Sequence Indexing for Arbitrary {L}p Norms},
	url = {http://portal.acm.org/citation.cfm?id=645926.671689},
	year = {2000}
}



@article{citeulike:1736140,
	address = {New York, NY, USA},
	author = {Chakrabarti, Kaushik   and Keogh, Eamonn   and Mehrotra, Sharad   and Pazzani, Michael  },
	citeulike-article-id = {1736140},
	doi = {10.1145/568518.568520},
	issn = {0362-5915},
	journal = {ACM Trans. Database Syst.},
	keywords = {dtw, gemini, litreview, paa, similarity, thesis},
	month = {June},
	number = {2},
	pages = {188--228},
	posted-at = {2009-02-26 13:25:29},
	priority = {2},
	publisher = {ACM Press},
	title = {Locally adaptive dimensionality reduction for indexing large time series databases},
	url = {http://dx.doi.org/10.1145/568518.568520},
	volume = {27},
	year = {2002}
}



@inproceedings{citeulike:532335,
	address = {New York, NY, USA},
	author = {Lin, Jessica   and Keogh, Eamonn   and Lonardi, Stefano   and Chiu, Bill  },
	booktitle = {DMKD '03: Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery},
	citeulike-article-id = {532335},
	doi = {10.1145/882082.882086},
	keywords = {dtw, litreview, similarity, thesis},
	pages = {2--11},
	posted-at = {2009-02-26 12:51:56},
	priority = {2},
	publisher = {ACM Press},
	title = {A symbolic representation of time series, with implications for streaming algorithms},
	url = {http://dx.doi.org/10.1145/882082.882086},
	year = {2003}
}



@incollection{citeulike:4107287,
	abstract = {In this digital age, great interest has been shifted toward multimedia data manipulations. This includes videos, images, and audios, where typical manipulations require fairly large storage and are computationally intensive. Recent research has demonstrated the utilities of time series representation in various data mining tasks, allowing considerable reduction in time and space complexity. Specifically, the utilities of Uniform Scaling (US) and Dynamic Time Warping (DTW) have been shown to be necessary in several human-related domains, where uniform stretching or shrinking, as well as some local variation are typical. Classic examples include a query-by-humming system and motion capture data. However, all the past work has neglected the importance of data normalization before distance calculations, and therefore does not guarantee accurate retrievals. In this work, we discuss this concern and present a technique that accurately and efficiently searches under the US with DTW for normalized time series data, where no-false-dismissals are guaranteed.},
	author = {Euachongprasit, Waiyawuth   and Ratanamahatana, Chotirat  },
	citeulike-article-id = {4107287},
	doi = {10.1007/978-3-540-68125-0\_11},
	journal = {Advances in Knowledge Discovery and Data Mining},
	pages = {100--111},
	posted-at = {2009-02-26 12:45:40},
	priority = {2},
	title = {Accurate and Efficient Retrieval of Multimedia Time Series Data Under Uniform Scaling and Time Warping},
	url = {http://dx.doi.org/10.1007/978-3-540-68125-0\_11},
	year = {2008}
}



@inproceedings{citeulike:4043115,
	abstract = {Dynamic Time Warping (DTW) is a pattern matching approach that can be used for limited vocabulary speech recognition, which is based on a temporal alignment of the input signal with the template models. The main drawback of this method is its high computational cost when the length of the signals increases. This paper presents a modified ver- sion of the DTW, based on the Discrete Wavelet Transform (DWT), that reduces its original complexity. Many wavelet families with different support-sizes are experimented and the corresponding results are reported.},
	author = {Junior, Sylvio  B.  and Guido, Rodrigo  C.  and Chen, Shi-Huang   and Vieira, Lucimar  S.  and Sanchez, Fabricio  L. },
	booktitle = {Multimedia Workshops, 2007. ISMW '07. Ninth IEEE International Symposium on},
	citeulike-article-id = {4043115},
	doi = {10.1109/ISM.Workshops.2007.51},
	journal = {Multimedia Workshops, 2007. ISMW '07. Ninth IEEE International Symposium on},
	keywords = {dtw, litreview, thesis},
	pages = {256--263},
	posted-at = {2009-02-13 11:04:31},
	priority = {2},
	title = {Improved Dynamic Time Warping Based on the Discrete Wavelet Transform},
	url = {http://dx.doi.org/10.1109/ISM.Workshops.2007.51},
	year = {2007}
}



@inproceedings{citeulike:4036334,
	abstract = {A variety of techniques currently exist for measuring the similarity between time series datasets. Of these techniques, the methods whose matching criteria is bounded by a specified \&\#949; threshold value, such as the LCSS and the EDR techniques, have been shown to be robust in the presence of noise, time shifts, and data scaling. Our work proposes a new algorithm, called the Fast Time Series Evaluation (FTSE) method, which can be used to evaluate such threshold value techniques, including LCSS and EDR. Using FTSE, we show that these techniques can be evaluated faster than using either traditional dynamic programming or even warp-restricting methods such as the Sakoe-Chiba band and the Itakura Parallelogram.},
	address = {New York, NY, USA},
	author = {Morse, Michael  D.  and Patel, Jignesh  M. },
	booktitle = {SIGMOD '07: Proceedings of the 2007 ACM SIGMOD international conference on Management of data},
	citeulike-article-id = {4036334},
	doi = {10.1145/1247480.1247544},
	isbn = {978-1-59593-686-8},
	keywords = {dtw, lcs, litreview, thesis},
	location = {Beijing, China},
	pages = {569--580},
	posted-at = {2009-02-11 18:02:03},
	priority = {2},
	publisher = {ACM},
	title = {An efficient and accurate method for evaluating time series similarity},
	url = {http://dx.doi.org/10.1145/1247480.1247544},
	year = {2007}
}



@article{citeulike:4031866,
	abstract = {We address the handling of time series search based on two important distance definitions: Euclidean distance and time warping distance. The conventional method reduces the dimensionality by means of a discrete Fourier transform. We apply the Haar wavelet transform technique and propose the use of a proper normalization so that the method can guarantee no false dismissal for Euclidean distance. We found that this method has competitive performance from our experiments. Euclidean distance measurement cannot handle the time shifts of patterns. It fails to match the same rise and fall patterns of sequences with different scales. A distance measure that handles this problem is the time warping distance. However, the complexity of computing the time warping distance function is high. Also, as time warping distance is not a metric, most indexing techniques would not guarantee any false dismissal. We propose efficient strategies to mitigate the problems of time warping. We suggest a Haar wavelet-based approximation function for time warping distance, called Low Resolution Time Warping, which results in less computation by trading off a small amount of accuracy. We apply our approximation function to similarity search in time series databases, and show by experiment that it is highly effective in suppressing the number of false alarms in similarity search.},
	author = {Chan, F. K. P.  and Fu, A. W. C.  and Yu, C. },
	booktitle = {Knowledge and Data Engineering, IEEE Transactions on},
	citeulike-article-id = {4031866},
	doi = {10.1109/TKDE.2003.1198399},
	journal = {Knowledge and Data Engineering, IEEE Transactions on},
	keywords = {dtw, litreview, similarity, thesis, wavelet},
	number = {3},
	pages = {686--705},
	posted-at = {2009-02-10 21:43:38},
	priority = {2},
	title = {Haar wavelets for efficient similarity search of time-series: with and without time warping},
	url = {http://dx.doi.org/10.1109/TKDE.2003.1198399},
	volume = {15},
	year = {2003}
}



@inproceedings{citeulike:4031865,
	abstract = {Mining time series data is an important approach for the analysis in many application areas as diverse as biology, environmental research, medicine, or stock chart analysis. As nearly all data mining tasks on this kind of data depend on a distance function between two time series, a huge number of such functions has been developed during the last decades. The introduction of threshold-based distance functions presented a new concept of time series similarity and these functions were applied to data mining techniques on a wide spectrum of time series data. In this demonstration, we present the Java toolkit T-Time which is able to perform several data mining tasks for a complete range of threshold values in an interactive way. The results are visually presented in a very concise way so that the user can easily identify important threshold values. Combined with domain-specific knowledge, these pivotal values can yield novel insights beyond the means of the underlying data mining techniques the analysis is based on.},
	author = {Assfalg, J.  and Kriegel, H. P.  and Kroger, P.  and Kunath, P.  and Pryakhin, A.  and Renz, M. },
	booktitle = {Data Engineering, 2008. ICDE 2008. IEEE 24th International Conference on},
	citeulike-article-id = {4031865},
	doi = {10.1109/ICDE.2008.4497636},
	journal = {Data Engineering, 2008. ICDE 2008. IEEE 24th International Conference on},
	keywords = {dtw, litreview, similarity, thesis},
	pages = {1620--1623},
	posted-at = {2009-02-10 21:41:29},
	priority = {2},
	title = {T-Time: Threshold-Based Data Mining on Time Series},
	url = {http://dx.doi.org/10.1109/ICDE.2008.4497636},
	year = {2008}
}



@article{citeulike:3357064,
	author = {Rinzivillo, Salvatore   and Pedreschi, Dino   and Nanni, Mirco   and Giannotti, Fosca   and Andrienko, Natalia   and Andrienko, Gennady  },
	citeulike-article-id = {3357064},
	doi = {10.1057/palgrave.ivs.9500183},
	issn = {1473-8716},
	journal = {Information Visualization},
	keywords = {litreview, publication, similarity, thesis},
	number = {3-4},
	pages = {225--239},
	posted-at = {2009-02-10 21:31:06},
	priority = {2},
	publisher = {Palgrave Macmillan},
	title = {Visually driven analysis of movement data by progressive clustering},
	url = {http://dx.doi.org/10.1057/palgrave.ivs.9500183},
	volume = {7},
	year = {2008}
}



@article{citeulike:2427286,
	address = {New York, NY, USA},
	author = {Schreck, Tobias   and Teku\vsov\'a, Tatiana   and Kohlhammer, J\"orn   and Fellner, Dieter  },
	citeulike-article-id = {2427286},
	doi = {10.1145/1345448.1345454},
	issn = {1931-0145},
	journal = {SIGKDD Explor. Newsl.},
	keywords = {dtw, litreview, similarity, thesis},
	month = {December},
	number = {2},
	pages = {30--37},
	posted-at = {2009-02-10 21:26:54},
	priority = {2},
	publisher = {ACM},
	title = {Trajectory-based visual analysis of large financial time series data},
	url = {http://dx.doi.org/10.1145/1345448.1345454},
	volume = {9},
	year = {2007}
}



@inproceedings{citeulike:4025073,
	abstract = {Time series data poses a significant variation to the traditional segmentation techniques of data mining because the observation is derived from multiple instances of the same underlying record. Additionally, the standard segmentation methods employed in traditional clustering require instances to be classified exactly by attaching an event to a specific cluster at the exclusion of other clusters. This paper is an investigation into the predictive power of the clustering technique on stock market data and its ability to provide stock predictions that can be utilised in strategies that outperform the underlying market. This uses a brute force approach to the prediction of stock prices based on the formation of a cluster around the query sequence. The prediction is then applied in a model designed to capitalise on the derived prediction. The predictive accuracy of minimum distance clusters produced promising results with a prediction error incorporated into the forecast strategy.},
	address = {Darlinghurst, Australia, Australia},
	author = {Nayak, Richi   and Braak, Paul  T. },
	booktitle = {AIDM '07: Proceedings of the 2nd international workshop on Integrating artificial intelligence and data mining},
	citeulike-article-id = {4025073},
	isbn = {978-1-920682-65-1},
	keywords = {litreview, similarity, thesis},
	location = {Gold Coast, Australia},
	pages = {95--103},
	posted-at = {2009-02-09 09:56:43},
	priority = {2},
	publisher = {Australian Computer Society, Inc.},
	title = {Temporal pattern matching for the prediction of stock prices},
	url = {http://portal.acm.org/citation.cfm?id=1386993.1387003},
	year = {2007}
}



@article{citeulike:973785,
	address = {New York, NY, USA},
	author = {Li, Tao   and Li, Qi   and Zhu, Shenghuo   and Ogihara, Mitsunori  },
	citeulike-article-id = {973785},
	doi = {10.1145/772862.772870},
	issn = {1931-0145},
	journal = {SIGKDD Explor. Newsl.},
	keywords = {litreview, thesis, wavelet},
	month = {December},
	number = {2},
	pages = {49--68},
	posted-at = {2009-02-09 09:54:19},
	priority = {2},
	publisher = {ACM Press},
	title = {A survey on wavelet applications in data mining},
	url = {http://dx.doi.org/10.1145/772862.772870},
	volume = {4},
	year = {2002}
}



@article{citeulike:2693625,
	address = {New York, NY, USA},
	author = {Maier, David  },
	citeulike-article-id = {2693625},
	doi = {10.1145/322063.322075},
	issn = {0004-5411},
	journal = {J. ACM},
	keywords = {lcs, litreview, thesis},
	month = {April},
	number = {2},
	pages = {322--336},
	posted-at = {2009-02-09 09:33:53},
	priority = {2},
	publisher = {ACM},
	title = {The Complexity of Some Problems on Subsequences and Supersequences},
	url = {http://dx.doi.org/10.1145/322063.322075},
	volume = {25},
	year = {1978}
}



@inproceedings{citeulike:4024793,
	abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article.  ACM has opted to expose the complete List rather than only correct and linked references.},
	address = {New York, NY, USA},
	author = {Hadlock, F. },
	booktitle = {IEA/AIE '88: Proceedings of the 1st international conference on Industrial and engineering applications of artificial intelligence and expert systems},
	citeulike-article-id = {4024793},
	doi = {10.1145/55674.55676},
	isbn = {0-89791-271-3},
	keywords = {lcs, litreview, thesis},
	location = {Tullahoma, Tennessee, United States},
	pages = {645--653},
	posted-at = {2009-02-09 09:31:17},
	priority = {2},
	publisher = {ACM},
	title = {An efficient algorithm for pattern detection and classification},
	url = {http://dx.doi.org/10.1145/55674.55676},
	year = {1988}
}



@inproceedings{citeulike:2659746,
	abstract = {The aim of this paper is to give a comprehensive comparison of well-known longest common subsequence algorithms (for two input strings) and study their behaviour in various application environments. The performance of the methods depends heavily on the properties of the problem instance as well as the supporting data structures used in the implementation. We want to make also a clear distinction between methods that determine the actual lcs and those calculating only its length, since the execution time and more importantly, the space demand depends crucially on the type of the task. To our knowledge, this is the first time this kind of survey has been done. Due to the page limits, the paper gives only a coarse overview of the performance of the algorithms; more detailed studies are reported elsewhere},
	author = {Bergroth, L.  and Hakonen, H.  and Raita, T. },
	booktitle = {String Processing and Information Retrieval, 2000. SPIRE 2000. Proceedings. Seventh International Symposium on},
	citeulike-article-id = {2659746},
	doi = {10.1109/SPIRE.2000.878178},
	journal = {String Processing and Information Retrieval, 2000. SPIRE 2000. Proceedings. Seventh International Symposium on},
	keywords = {lcs, litreview, thesis},
	pages = {39--48},
	posted-at = {2009-02-09 09:26:20},
	priority = {2},
	title = {A survey of longest common subsequence algorithms},
	url = {http://dx.doi.org/10.1109/SPIRE.2000.878178},
	year = {2000}
}



@inproceedings{citeulike:4022060,
	abstract = {Monitoring predefined patterns in streaming time series is useful to applications such as trend-related analysis, sensor networks and video surveillance. Most current studies on such monitoring employ Euclidean distance to calculate the similarities between given query patterns and subsequences of streaming time series. Euclidean distance has been shown to be ineffective in measuring distances of time series in which shifting and scaling usually exist. Consequently, warping distances such as dynamic time warping (DTW), longest common subsequence (LCSS), have been proposed to handle warps in temporal dimension. However, they are inadequate in handling shifting and scaling in amplitude dimension. Moreover, they have been designed mainly for full sequence matching, whereas in online monitoring applications, we typically have no knowledge on the positions and lengths of possible matching subsequences. In this paper, we first discuss the weaknesses of existing warping distances on detecting patterns from streaming time series. We then propose a novel warping distance, which we name Spatial Assembling Distance (SpADe), that is able to handle shifting and scaling in both temporal and amplitude dimensions. We further propose an efficient approach for continuous pattern detection using SpADe, that is fundamental for subsequence matching on streaming data. Finally, our experimental results show that SpADe is effective and efficient for continuous pattern detection in streaming time series.},
	author = {Chen, Yueguo   and Nascimento, M. A.  and Ooi, Beng  C.  and Tung, A. K. H. },
	booktitle = {Data Engineering, 2007. ICDE 2007. IEEE 23rd International Conference on},
	citeulike-article-id = {4022060},
	doi = {10.1109/ICDE.2007.367924},
	journal = {Data Engineering, 2007. ICDE 2007. IEEE 23rd International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {786--795},
	posted-at = {2009-02-07 17:10:12},
	priority = {2},
	title = {SpADe: On Shape-based Pattern Detection in Streaming Time Series},
	url = {http://dx.doi.org/10.1109/ICDE.2007.367924},
	year = {2007}
}



@inproceedings{citeulike:4022058,
	abstract = {Matching video segments in order to detect their similarity is a necessary task in retrieval and summarization applications. In order to determine nearly identical content, such as repeated takes of the same scene, very precise matching of sequences of features extracted from the video segments needs to be performed. In this paper we compare the performance of three distance measures for the task of clustering multiple takes of the same scene: dynamic time warping (DTW) and two variants of longest common subsequence (LCSS). We also evaluate the influence of the quality of the input segmentation on the performance of the algorithms.},
	author = {Bailer, W. },
	booktitle = {Database and Expert Systems Application, 2008. DEXA '08. 19th International Conference on},
	citeulike-article-id = {4022058},
	doi = {10.1109/DEXA.2008.26},
	journal = {Database and Expert Systems Application, 2008. DEXA '08. 19th International Conference on},
	pages = {595--599},
	posted-at = {2009-02-07 17:06:10},
	priority = {2},
	title = {A Comparison of Distance Measures for Clustering Video Sequences},
	url = {http://dx.doi.org/10.1109/DEXA.2008.26},
	year = {2008}
}



@article{citeulike:4021682,
	abstract = {In a way similar to the string-to-string correction problem, we address discrete time series similarity in light of a time-series-to-time-series-correction problem for which the similarity between two time series is measured as the minimum cost sequence of edit operations needed to transform one time series into another. To define the edit operations, we use the paradigm of a graphical editing process and end up with a dynamic programming algorithm that we call time warp edit distance (TWED). TWED is slightly different in form from dynamic time warping (DTW), longest common subsequence (LCSS), or edit distance with real penalty (ERP) algorithms. In particular, it highlights a parameter that controls a kind of stiffness of the elastic measure along the time axis. We show that the similarity provided by TWED is a potentially useful metric in time series retrieval applications since it could benefit from the triangular inequality property to speed up the retrieval process while tuning the parameters of the elastic measure. In that context, a lower bound is derived to link the matching of time series into down sampled representation spaces to the matching into the original space. The empiric quality of the TWED distance is evaluated on a simple classification task. Compared to edit distance, DTW, LCSS, and ERP, TWED has proved to be quite effective on the considered experimental task.},
	author = {Marteau, P. F. },
	booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	citeulike-article-id = {4021682},
	doi = {10.1109/TPAMI.2008.76},
	journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	number = {2},
	pages = {306--318},
	posted-at = {2009-02-07 14:07:24},
	priority = {2},
	title = {Time Warp Edit Distance with Stiffness Adjustment for Time Series Matching},
	url = {http://dx.doi.org/10.1109/TPAMI.2008.76},
	volume = {31},
	year = {2009}
}



@book{citeulike:1454223,
	abstract = {{A timeless classic in how complex information should be presented graphically.  The Strunk \& White  of visual design. Should occupy a place of honor--within arm's reach--of everyone  attempting to understand or depict numerical data graphically.  The design of the book is an exemplar of the principles it espouses:  elegant typography and layout, and seamless integration of lucid text and perfectly chosen graphical examples. Very Highly Recommended.}},
	author = {Tufte, Edward  R. },
	citeulike-article-id = {1454223},
	howpublished = {Hardcover},
	isbn = {096139210X},
	keywords = {dtw, litreview, thesis},
	posted-at = {2009-02-06 14:23:45},
	priority = {2},
	publisher = {{Graphics Press}},
	title = {The Visual Display of Quantitative Information},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/096139210X}
}



@inproceedings{citeulike:4015923,
	abstract = {Visualisations play an important part in the development of ideas. They make ingredients and relations explicit, guide thinking processes of the designer or scientist, and support communications, often across the boundaries of disciplines. In the fields of cognitive psychology and human-machine interaction, block diagrams have been a dominant means for representing cognitive systems. However, we believe that this form of representation may constrain how we think about cognition in undesirable ways. This form of representation biases viewers to see cognition as a sequential, step-by-step process, under emphasizing the dynamical properties of closed-loop, adaptive processes. Block diagrams emphasize activity and internal mental operations (awareness) and occlude the ecological or work domain (situational) constraints},
	author = {Stappers, P. J.  and Flach, J. M. },
	booktitle = {Systems, Man and Cybernetics, 2004 IEEE International Conference on},
	citeulike-article-id = {4015923},
	doi = {10.1109/ICSMC.2004.1398404},
	journal = {Systems, Man and Cybernetics, 2004 IEEE International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {821--826 vol.1},
	posted-at = {2009-02-06 14:04:52},
	priority = {2},
	title = {Visualizing cognitive systems: getting past block diagrams},
	url = {http://dx.doi.org/10.1109/ICSMC.2004.1398404},
	volume = {1},
	year = {2004}
}



@article{citeulike:3994742,
	author = {Tinbergen, J. },
	citeulike-article-id = {3994742},
	journal = {Zeitschrift f\"{u}r National- \"{o}konomie 1},
	pages = {669--679},
	posted-at = {2009-02-02 11:58:41},
	priority = {2},
	title = {Bestimmung und Deutung von Angebotskurven. Ein Beispiel.},
	year = {1930}
}



@misc{citeulike:3994561,
	author = {Hanau, A. },
	citeulike-article-id = {3994561},
	institution = {Vierteljahrshefte zur Konjunkturforschung 7},
	keywords = {dtw, litreview, thesis},
	posted-at = {2009-02-02 11:40:50},
	priority = {2},
	publisher = {Vierteljahrshefte zur Konjunkturforschung 7},
	title = {Die Prognose der Schweinepreise},
	year = {1928}
}



@misc{citeulike:3994263,
	author = {Koopmans, T. C. },
	citeulike-article-id = {3994263},
	institution = {Netherlands Economic Institute},
	keywords = {dtw, litreview, thesis},
	location = {Haarlem},
	posted-at = {2009-02-02 11:33:05},
	priority = {2},
	publisher = {Netherlands Economic Institute},
	title = {Linear Regression Analysis of Economic Time Series},
	year = {1937}
}



@inproceedings{citeulike:1237593,
	author = {Fu, Ada  W.  and Keogh, Eamonn   and Leo and Ratanamahatana, Chotirat  A. },
	booktitle = {VLDB '05: Proceedings of the 31st international conference on Very large data bases},
	citeulike-article-id = {1237593},
	isbn = {1595931546},
	pages = {649--660},
	posted-at = {2009-02-01 20:27:56},
	priority = {2},
	publisher = {VLDB Endowment},
	title = {Scaling and time warping in time series querying},
	url = {http://portal.acm.org/citation.cfm?id=1083592.1083668},
	year = {2005}
}



@article{citeulike:1082000,
	abstract = {Senior Member-Walid G. Aref and Senior Member-Ahmed K. Elmagarmid},
	address = {Piscataway, NJ, USA},
	author = {Elfeky, Mohamed  G. },
	citeulike-article-id = {1082000},
	doi = {10.1109/TKDE.2005.114},
	issn = {1041-4347},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	month = {July},
	number = {7},
	pages = {875--887},
	posted-at = {2009-02-01 20:11:27},
	priority = {2},
	publisher = {IEEE Educational Activities Department},
	title = {Periodicity Detection in Time Series Databases},
	url = {http://dx.doi.org/10.1109/TKDE.2005.114},
	volume = {17},
	year = {2005}
}



@inproceedings{citeulike:825581,
	address = {New York, NY, USA},
	author = {Faloutsos, Christos   and Ranganathan, M.  and Manolopoulos, Yannis  },
	booktitle = {SIGMOD '94: Proceedings of the 1994 ACM SIGMOD international conference on Management of data},
	citeulike-article-id = {825581},
	doi = {10.1145/191839.191925},
	issn = {0163-5808},
	keywords = {dtw, litreview, thesis},
	pages = {419--429},
	posted-at = {2009-02-01 20:11:02},
	priority = {2},
	publisher = {ACM Press},
	title = {Fast subsequence matching in time-series databases},
	url = {http://dx.doi.org/10.1145/191839.191925},
	year = {1994}
}



@article{citeulike:3991527,
	author = {Young, P.  and Shellswell, S. },
	booktitle = {Automatic Control, IEEE Transactions on},
	citeulike-article-id = {3991527},
	journal = {Automatic Control, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {2},
	pages = {281--283},
	posted-at = {2009-02-01 16:52:35},
	priority = {2},
	title = {Time series analysis, forecasting and control},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1099963},
	volume = {17},
	year = {1972}
}



@book{citeulike:3449765,
	abstract = {Time Series Analysis With Applications in R, Second Edition, presents an
accessible approach to understanding time series models and their
applications. Although the emphasis is on time domain ARIMA models and their
analysis, the new edition devotes two chapters to the frequency domain and
three to time series regression models, models for heteroscedasticity, and
threshold models. All of the ideas and methods are illustrated with both real
and simulated data sets.

A unique feature of this edition is its integration with the R computing
environment. The tables and graphical displays are accompanied by the R
commands used to produce them. An extensive R package, TSA, which contains
many new or revised R functions and all of the data used in the book,
accompanies the written text. Script files of R commands for each chapter are
available for download. There is also an extensive appendix in the book that
leads the reader through the use of R commands and the new R package to carry
out the analyses.},
	author = {Cryer, Jonathan  D.  and Chan, Kung-Sik  },
	citeulike-article-id = {3449765},
	edition = {2nd},
	howpublished = {Hardcover},
	isbn = {0387759581},
	keywords = {dtw, litreview, thesis},
	month = {October},
	posted-at = {2009-02-01 12:18:27},
	priority = {2},
	publisher = {Springer},
	title = {Time Series Analysis: With Applications in R (Springer Texts in Statistics)},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387759581},
	year = {2008}
}



@book{citeulike:2206845,
	abstract = {{<B>Time Series: Theory and Methods</B> is a systematic account of linear time series models and their application to the modelling and prediction of data collected sequentially in time. The aim is to provide specific techniques for handling data and at the same time to provide a thorough understanding of the mathematical basis for techniques. Both time and frequency domain methods are discussed, but the book is written in such a way that either approach could be emphasized. The book intended to be a text for graduate students in statistics, mathematics, engineering, and the natural or social sciences. It contains substantial chapters on multivariate series and state-space models (including applications of the Kalman recursions to missing-value problems) and shorter accounts of special topics including long-range dependence, infinite variance processes and non-linear models. Most of the programs used in the book are available on diskettes for the IBM-PC. These diskettes, with the accompanying manual, <I>ITSM: The Interactive Time Series</I> <I>Modelling </I> <I>Package</I> <I> for the</I> <I>PC</I>, also by Brockwell and Davis, can be purchased from Springer-Verlag.}},
	author = {Brockwell, Peter  J.  and Davis, Richard  A. },
	citeulike-article-id = {2206845},
	howpublished = {Hardcover},
	isbn = {0387974296},
	keywords = {dtw, litreview, thesis},
	month = {September},
	posted-at = {2009-02-01 11:02:02},
	priority = {2},
	publisher = {Springer},
	title = {Time Series: Theory and Methods (Springer Series in Statistics)},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387974296},
	year = {1998}
}



@book{citeulike:3991239,
	abstract = {This book presents modern developments in time series econometrics that are
applied to macroeconomic and financial time series. It attempts to bridge the
gap between methods and realistic applications. This book contains the most
important approaches to analyse time series which may be stationary or
nonstationary. Modelling and forecasting univariate time series is the
starting point. For multiple stationary time series Granger causality tests
and vector autoregressive models are presented. For real applied work the
modelling of nonstationary uni- or multivariate time series is most important.
Therefore, unit root and cointegration analysis as well as vector error
correction models play a central part. Modelling volatilities of financial
time series with autoregressive conditional heteroskedastic models is also
treated.},
	author = {Kirchg\"{a}ssner, Gebhard   and Wolters, J\"{u}rgen  },
	citeulike-article-id = {3991239},
	edition = {1},
	howpublished = {Hardcover},
	isbn = {354073290X},
	keywords = {dtw, litreview, thesis},
	month = {October},
	posted-at = {2009-02-01 10:47:08},
	priority = {2},
	publisher = {Springer},
	title = {Introduction to Modern Time Series Analysis},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/354073290X},
	year = {2007}
}



@book{citeulike:3991222,
	abstract = {This monograph of carefully collected articles reviews recent developments in
theoretical and applied statistical science, highlights current noteworthy
results and illustrates their applications; and points out possible new
directions to pursue. With its enlightening account of statistical discoveries
and its numerous figures and tables, Probability and Statistical Models with
Applications is a must read for probabilists and theoretical and applied
statisticians.},
	citeulike-article-id = {3991222},
	edition = {1},
	howpublished = {Hardcover},
	isbn = {1584881240},
	keywords = {dtw, litreview, thesis},
	month = {September},
	posted-at = {2009-02-01 10:12:49},
	priority = {2},
	publisher = {Chapman \& Hall/CRC},
	title = {Probability and Statistical Models with Applications},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1584881240},
	year = {2000}
}



@book{citeulike:3989988,
	abstract = {The Wiley Classics Library consists of selected books that have become
recognized classics in their respective fields. With these new unabridged and
inexpensive editions, Wiley hopes to extend the life of these important works
by making them available to future generations of mathematicians and
scientists. Currently available in the Series: T. W. Anderson Statistical
Analysis of Time Series T. S. Arthanari \& Yadolah Dodge Mathematical
Programming in Statistics Emil Artin Geometric Algebra Norman T. J. Bailey The
Elements of Stochastic Processes with Applications to the Natural Sciences
George E. P. Box \& George C. Tiao Bayesian Inference in Statistical Analysis
R. W. Carter Simple Groups of Lie Type William G. Cochran \& Gertrude M. Cox
Experimental Designs, Second Edition Richard Courant Differential and Integral
Calculus, Volume I Richard Courant Differential and Integral Calculus, Volume
II Richard Courant \& D. Hilbert Methods of Mathematical Physics, Volume I
Richard Courant \& D. Hilbert Methods of Mathematical Physics, Volume II D. R.
Cox Planning of Experiments Harold M. S. Coxeter Introduction to Modern
Geometry, Second Edition Charles W. Curtis \& Irving Reiner Representation
Theory of Finite Groups and Associative Algebras Charles W. Curtis \& Irving
Reiner Methods of Representation Theory with Applications to Finite Groups and
Orders, Volume I Charles W. Curtis \& Irving Reiner Methods of Representation
Theory with Applications to Finite Groups and Orders, Volume II Bruno de
Finetti Theory of Probability, Volume 1 Bruno de Finetti Theory of
Probability, Volume 2 W. Edwards Deming Sample Design in Business Research
Amos de Shalit \& Herman Feshbach Theoretical Nuclear Physics, Volume 1
—Nuclear Structure J. L. Doob Stochastic Processes Nelson Dunford \& Jacob T.
Schwartz Linear Operators, Part One, General Theory Nelson Dunford \& Jacob T.
Schwartz Linear Operators, Part Two, Spectral Theory—Self Adjoint Operators in
Hilbert Space Nelson Dunford \& Jacob T. Schwartz Linear Operators, Part Three,
Spectral Operators Herman Fsehbach Theoretical Nuclear Physics: Nuclear
Reactions Bernard Friedman Lectures on Applications-Oriented Mathematics
Gerald d. Hahn \& Samuel S. Shapiro Statistical Models in Engineering Morris H.
Hansen, William N. Hurwitz \& William G. Madow Sample Survey Methods and
Theory, Volume I—Methods and Applications Morris H. Hansen, William N. Hurwitz
\& William G. Madow Sample Survey Methods and Theory, Volume II—Theory Peter
Henrici Applied and Computational Complex Analysis, Volume 1—Power
Series—lntegration—Conformal Mapping—Location of Zeros Peter Henrici Applied
and Computational Complex Analysis, Volume 2—Special Functions—Integral
Transforms—Asymptotics—Continued Fractions Peter Henrici Applied and
Computational Complex Analysis, Volume 3—Discrete Fourier Analysis—Cauchy
Integrals—Construction of Conformal Maps—Univalent Functions Peter Hilton \&
Yel-Chiang Wu A Course in Modern Algebra Harry Hochetadt Integral Equations
Erwin O. Kreyezig Introductory Functional Analysis with Applications William
H. Louisell Quantum Statistical Properties of Radiation All Hasan Nayfeh
Introduction to Perturbation Techniques Emanuel Parzen Modern Probability
Theory and Its Applications P.M. Prenter Splines and Variational Methods
Walter Rudin Fourier Analysis on Groups C. L. Siegel Topics in Complex
Function Theory, Volume I—Elliptic Functions and Uniformization Theory C. L.
Siegel Topics in Complex Function Theory, Volume II—Automorphic and Abelian
integrals C. L Siegel Topics in Complex Function Theory, Volume III—Abelian
Functions \& Modular Functions of Several Variables J. J. Stoker Differential
Geometry J. J. Stoker Water Waves: The Mathematical Theory with Applications
J. J. Stoker Nonlinear Vibrations in Mechanical and Electrical Systems},
	author = {Anderson, T. W. },
	citeulike-article-id = {3989988},
	edition = {First},
	howpublished = {Paperback},
	isbn = {0471047457},
	keywords = {dtw, litreview, thesis},
	month = {June},
	posted-at = {2009-02-01 10:02:38},
	priority = {2},
	publisher = {Wiley-Interscience},
	title = {The Statistical Analysis of Time Series},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0471047457},
	year = {1994}
}



@article{citeulike:2090933,
	abstract = {Time series data, due to their numerical and continuous nature, are difficult to process, analyze, and mine. However, these tasks become easier when the data can be transformed into meaningful symbols. Most recent works on time series only address how to identify a given pattern from a time series and do not consider the problem of identifying a suitable set of time points for segmenting the time series in accordance with a given set of pattern templates (e.g., a set of technical patterns for stock analysis). However, the use of fixed-length segmentation is an oversimplified approach to this problem; hence, a dynamic approach (with high controllability) is preferable so that the time series can be segmented flexibly and effectively according to the needs of the users and the applications. In view of the fact that this segmentation problem is an optimization problem and evolutionary computation is an appropriate tool to solve it, we propose an evolutionary time series segmentation algorithm. This approach allows a sizeable set of pattern templates to be generated for mining or query. In addition, defining similarity between time series (or time series segments) is of fundamental importance in fitness computation. By identifying the perceptually important points directly from the time domain, time series segments and templates of different lengths can be compared and intuitive pattern matching can be carried out in an effective and efficient manner. Encouraging experimental results are reported from tests that segment both artificial time series generated from the combinations of pattern templates and the time series of selected Hong Kong stocks.},
	author = {Chung, Fu-Lai   and Fu, Tak-Chung   and Ng, V.  and Luk, R. W. P. },
	booktitle = {Evolutionary Computation, IEEE Transactions on},
	citeulike-article-id = {2090933},
	doi = {10.1109/TEVC.2004.832863},
	journal = {Evolutionary Computation, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {5},
	pages = {471--489},
	posted-at = {2009-01-27 14:11:56},
	priority = {2},
	title = {An evolutionary approach to pattern-based time series segmentation},
	url = {http://dx.doi.org/10.1109/TEVC.2004.832863},
	volume = {8},
	year = {2004}
}



@inproceedings{citeulike:3513035,
	abstract = {Recognition of hand-drawn shapes is an important and widely studied problem. By adopting a generative probabilistic framework we are able to formulate a robust and flexible approach to shape recognition which allows for a wide range of shapes and which can recognize new shapes from a single exemplar. It also provides meaningful probabilistic measures of model score which can be used as part of a larger probabilistic framework for interpreting a page of ink. We also show how Bayesian model comparison allows the trade-off between data fit and model complexity to be optimized automatically.},
	address = {Washington, DC, USA},
	author = {Krishnapuram, Balaji   and Bishop, Christopher  M.  and Szummer, Martin  },
	booktitle = {IWFHR '04: Proceedings of the Ninth International Workshop on Frontiers in Handwriting Recognition},
	citeulike-article-id = {3513035},
	doi = {10.1109/IWFHR.2004.46},
	isbn = {0-7695-2187-8},
	keywords = {dtw, litreview, thesis},
	pages = {20--25},
	posted-at = {2009-01-26 13:43:27},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {{G}enerative {M}odels and {B}ayesian {M}odel Comparison for Shape Recognition},
	url = {http://dx.doi.org/10.1109/IWFHR.2004.46},
	year = {2004}
}



@book{citeulike:3822011,
	abstract = {This collection of twenty-three original papers represents the first effort to
bring together the work of constraint programming researchers scattered across
multiple disciplines and across the world. The collection contributes to the
understanding of the common principles of this emerging general paradigm, the
investigation of its theoretical foundations as well as applications to real-
world computing problems. It is organized around themes of concurrency and
reactive systems, languages and environments, algorithms, computer graphics,
and artificial intelligence. Constraint programming aims at supporting a wide
range of complex applications which are often modeled naturally in terms of
constraints. Early work, in the 1960s and 1970s, made use of constraints in
computer graphics, user interfaces, and artificial intelligence. Such work
introduced a declarative component in otherwise-procedural systems to reduce
the development effort. The mid-1980s have witnessed the emergence of general-
purpose programming languages based on constraints, such as constraint logic
programming and concurrent constraint programming, with significant
applications in academia and industry. Today, an increasing number of
researchers from all over the map of computing are looking at different
aspects of this new computational paradigm.},
	citeulike-article-id = {3822011},
	howpublished = {Hardcover},
	isbn = {0262193612},
	keywords = {dtw, litreview, thesis},
	month = {May},
	posted-at = {2008-12-23 13:02:48},
	priority = {2},
	publisher = {The MIT Press},
	title = {Principles and Practice of Constraint Programming},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262193612},
	year = {1995}
}



@inproceedings{citeulike:3821484,
	abstract = {A Query by Humming system allows the user to find a song by humming part of the tune. No musical training is needed. Previous query by humming systems have not provided satisfactory results for various reasons. Some systems have low retrieval precision because they rely on melodic contour information from the hum tune, which in turn relies on the error-prone note segmentation process. Some systems yield better precision when matching the melody directly from audio, but they are slow because of their extensive use of Dynamic Time Warping (DTW). Our approach improves both the retrieval precision and speed compared to previous approaches. We treat music as a time series and exploit and improve well-developed techniques from time series databases to index the music for fast similarity queries. We improve on existing DTW indexes technique by introducing the concept of  envelope transforms , which gives a general guideline for extending existing dimensionality reduction methods to DTW indexes. The net result is high scalability. We confirm our claims through extensive experiments.},
	address = {New York, NY, USA},
	author = {Zhu, Yunyue   and Shasha, Dennis  },
	booktitle = {SIGMOD '03: Proceedings of the 2003 ACM SIGMOD international conference on Management of data},
	citeulike-article-id = {3821484},
	doi = {10.1145/872757.872780},
	isbn = {1-58113-634-X},
	keywords = {dtw, litreview, thesis},
	location = {San Diego, California},
	pages = {181--192},
	posted-at = {2008-12-23 05:35:52},
	priority = {2},
	publisher = {ACM},
	title = {Warping indexes with envelope transforms for query by humming},
	url = {http://dx.doi.org/10.1145/872757.872780},
	year = {2003}
}



@article{citeulike:3056920,
	address = {New York, NY, USA},
	author = {Hjaltason, Gisli  R.  and Samet, Hanan  },
	citeulike-article-id = {3056920},
	doi = {10.1145/958942.958948},
	issn = {0362-5915},
	journal = {ACM Trans. Database Syst.},
	keywords = {dtw, litreview, thesis},
	month = {December},
	number = {4},
	pages = {517--580},
	posted-at = {2008-12-22 22:38:00},
	priority = {2},
	publisher = {ACM},
	title = {Index-driven similarity search in metric spaces (Survey Article)},
	url = {http://dx.doi.org/10.1145/958942.958948},
	volume = {28},
	year = {2003}
}



@inproceedings{citeulike:3816328,
	abstract = {The problem of finding patterns of interest in time series databases (query by content) is an important one, with applications in virtually every field of science. A variety of approaches have been suggested. These approaches are robust to noise, offset translation, and amplitude scaling to varying degrees. However, they are all extremely sensitive to scaling in the time axis (longitudinal scaling). We present a method for similarity search that is robust to scaling in the time axis, in addition to noise, offset translation, and amplitude scaling. The method has been tested on medical, financial, space telemetry and artificial data. Furthermore the method is exceptionally fast, with the predicted 2 to 4 orders of magnitude speedup actually observed. The method uses a piecewise linear representation of the original data. We also introduce a new algorithm which both decides the optimal number of linear segments to use, and produces the actual linear representation},
	author = {Keogh, E. },
	booktitle = {Tools with Artificial Intelligence, 1997. Proceedings., Ninth IEEE International Conference on},
	citeulike-article-id = {3816328},
	doi = {10.1109/TAI.1997.632306},
	journal = {Tools with Artificial Intelligence, 1997. Proceedings., Ninth IEEE International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {578--584},
	posted-at = {2008-12-22 01:04:00},
	priority = {2},
	title = {Fast similarity search in the presence of longitudinal scaling in time series databases},
	url = {http://dx.doi.org/10.1109/TAI.1997.632306},
	year = {1997}
}



@inproceedings{citeulike:3816327,
	abstract = {We introduce a new model of similarity of time sequences that captures the intuitive notion that two sequences should be considered similar if they have enough non-overlapping time-ordered pairs of subsequences thar are similar. The model allows the amplitude of one of the two sequences to be scaled by any suitable amount and its offset adjusted appropriately. Two subsequences are considered similar if one can be enclosed within an envelope of a specified width drawn around the other. The model also allows non-matching gaps in the matching subsequences. The matching subsequences need not be aligned along the time axis. Given this model of similarity, we present fast search techniques for discovering all similar sequences in a set of sequences. These techniques can also be used to find all (sub)sequences similar to a given sequence. We applied this matching system to the U.S. mutual funds data and discovered interesting matches.},
	author = {Agrawal, Rakesh   and Lin, King-Ip   and Sawhney, Harpreet  S.  and Shim, Kyuseok  },
	booktitle = {In VLDB},
	citeulike-article-id = {3816327},
	keywords = {dtw, litreview, thesis},
	pages = {490--501},
	posted-at = {2008-12-22 01:02:20},
	priority = {2},
	title = {Fast Similarity Search in the Presence of Noise, Scaling, and Translation in Time-Series Databases},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.4179},
	year = {1995}
}



@article{citeulike:3816322,
	abstract = {Motivation: Increasingly, biological processes are being studied   through time series of RNA expression data collected for large   numbers of genes. Because common processes may unfold at varying   rates in different experiments or individuals, methods are needed that will allow corresponding expression states in different time series to be mapped to one another.  Results: We present implementations of time warping algorithms   applicable to RNA and protein expression data and demonstrate their application to published yeast RNA expression time series. Programs executing two warping algorithms are described, a simple warping algorithm and an interpolative algorithm, along with programs that generate graphics that visually present alignment information. We show time warping to be superior to simple clustering at mapping corresponding time states. We document the impact of statistical measurement noise and sample size on the quality of time alignments,  and present issues related to statistical assessment of alignment   quality through alignment scores. We also discuss directions for algorithm improvement including development of multiple time series alignments and possible applications to causality searches and non-temporal processes ( concentration warping').  Availability: Academic implementations of alignment programs   genewarp and genewarpi and the graphics generation programs grphwarp and grphwarpi are available as Win32 system DOS box executables on our web site along with documentation on their use. The publicly available data on which they were demonstrated may be found at http://genome-www.stanford.edu/cellcycle/.   Postscript files generated by grphwarp and grphwarpi may be directly printed or viewed using GhostView software available at http://www.cs.wisc.edu/\~{}ghost/.  Contact: church@arep.med.harvard.edu  Supplementary information: http://arep.med.harvard.edu/timewarp/supplement.htm. 10.1093/bioinformatics/17.6.495},
	author = {Aach, John   and Church, George  M. },
	citeulike-article-id = {3816322},
	doi = {10.1093/bioinformatics/17.6.495},
	journal = {Bioinformatics},
	keywords = {dtw, litreview, thesis},
	month = {June},
	number = {6},
	pages = {495--508},
	posted-at = {2008-12-22 00:51:21},
	priority = {2},
	title = {Aligning gene expression time series with time warping algorithms},
	url = {http://dx.doi.org/10.1093/bioinformatics/17.6.495},
	volume = {17},
	year = {2001}
}



@incollection{citeulike:3816243,
	abstract = {Widespread interest in discovering features and trends in time- series has generated a need for tools that support interactive exploration.This paper introduces timeboxes: a powerful direct-manipulation metaphor for the specification of queries over time series datasets. Our TimeSearcher implementation of timeboxes supports interactive formulation and modification of queries, thus speeding the process of exploring time series data sets and guiding data mining.},
	author = {Hochheiser, Harry   and Shneiderman, Ben  },
	citeulike-article-id = {3816243},
	doi = {10.1007/3-540-45650-3\_38},
	journal = {Discovery Science},
	keywords = {dtw, litreview, thesis},
	pages = {441--446},
	posted-at = {2008-12-21 23:13:53},
	priority = {2},
	title = {Interactive Exploration of Time Series Data},
	url = {http://dx.doi.org/10.1007/3-540-45650-3\_38},
	year = {2001}
}



@book{citeulike:1109201,
	address = {Menlo Park, CA, USA},
	author = {Fayyad, Usama  M.  and Piatetsky-Shapiro, Gregory   and Smyth, Padhraic   and Uthurusamy, Ramasamy  },
	citeulike-article-id = {1109201},
	editor = {Fayyad, Usama  M.  and Piatetsky-Shapiro, Gregory   and Smyth, Padhraic   and Uthurusamy, Ramasamy  },
	isbn = {0262560976},
	keywords = {dtw, litreview, thesis},
	posted-at = {2008-12-21 23:12:28},
	priority = {2},
	publisher = {American Association for Artificial Intelligence},
	title = {Advances in knowledge discovery and data mining},
	url = {http://portal.acm.org/citation.cfm?id=257938},
	year = {1996}
}



@inproceedings{citeulike:3816224,
	abstract = {Sequential data is easily understood through a simple line graph, yet systems to search such data typically rely on complex interfaces or query languages. This paper presents QuerySketch, a financial database application in which graphs are used for query input as well as output. QuerySketch allows users to sketch a graph freehand, then view stocks whose price histories match the sketch. Using the same graphical format for both input and output results in an interface that is powerful, flexible, yet easy to use.},
	address = {New York, NY, USA},
	author = {Wattenberg, Martin  },
	booktitle = {CHI '01: CHI '01 extended abstracts on Human factors in computing systems},
	citeulike-article-id = {3816224},
	doi = {10.1145/634067.634292},
	isbn = {1-58113-340-5},
	keywords = {dtw, litreview},
	location = {Seattle, Washington},
	pages = {381--382},
	posted-at = {2008-12-21 22:53:35},
	priority = {2},
	publisher = {ACM},
	title = {Sketching a graph to query a time-series database},
	url = {http://dx.doi.org/10.1145/634067.634292},
	year = {2001}
}



@inproceedings{citeulike:3816213,
	abstract = {Query-by-Example is a query language for use by non-programmers querying a relational data base. In an earlier paper, the features of this language were introduced; however, it was assumed that the data base was already defined and available to the user.},
	address = {New York, NY, USA},
	author = {Zloof, Mosh\'e  M. },
	booktitle = {VLDB '75: Proceedings of the 1st International Conference on Very Large Data Bases},
	citeulike-article-id = {3816213},
	doi = {10.1145/1282480.1282482},
	keywords = {dtw, litreview, thesis},
	location = {Framingham, Massachusetts},
	pages = {1--24},
	posted-at = {2008-12-21 22:48:45},
	priority = {2},
	publisher = {ACM},
	title = {Query-by-example: the invocation and definition of tables and forms},
	url = {http://dx.doi.org/10.1145/1282480.1282482},
	year = {1975}
}



@incollection{citeulike:3815893,
	abstract = {Conceptually, the techniques of linguistic pattern recognition are largely independent of the medium, but overall performance is influenced by the preprocessing to such an extent that until a few years ago the pattern recognition step was generally viewed as a small appendix to the main body of signal processing knowledge. To this day, it remains impossible to build a serious system without paying close attention to preprocessing, and deep algorithmic work on the recognizer will often yield smaller gains than seemingly more superficial changes to the front end. In Section 9.1, we introduce a speech coding method, linear prediction, that has played an important role in practical application since the 1970s.We extend the discussion of quantization started in Section 8.1 from scalars to vectors and discuss the Fourier transform-based (homomorphic) techniques that currently dominate the field.},
	citeulike-article-id = {3815893},
	doi = {10.1007/978-1-84628-986-6\_9},
	journal = {Mathematical Linguistics},
	keywords = {dtw, litreview, thesis},
	pages = {219--246},
	posted-at = {2008-12-21 17:43:45},
	priority = {2},
	title = {Speech and handwriting},
	url = {http://dx.doi.org/10.1007/978-1-84628-986-6\_9},
	year = {2008}
}



@incollection{citeulike:3815889,
	abstract = {Efficient retrieval of time series data has gained recent attention from the research community. In particular, finding meaningful distance measurements for various applications is one of the most important issues in the field, since no single distance measurement works for all applications. In this paper, we propose a different distance measurement for time series applications based on Constraint Continuous Editing Distance (CCED) that adjusts the potential energy of each sequence for optimal similarity. Furthermore, we also propose a lower bounding distance for CCED for efficient indexing and fast retrieval, even though CCED does not satisfy triangle inequality.},
	author = {Chhieng, Van   and Wong, Raymond  },
	citeulike-article-id = {3815889},
	doi = {10.1007/978-3-540-71703-4\_51},
	journal = {Advances in Databases: Concepts, Systems and Applications},
	keywords = {dtw, litreview, thesis},
	pages = {598--610},
	posted-at = {2008-12-21 17:38:37},
	priority = {2},
	title = {Adaptive Distance Measurement for Time Series Databases},
	url = {http://dx.doi.org/10.1007/978-3-540-71703-4\_51},
	year = {2008}
}



@article{citeulike:3815887,
	abstract = {Abstract\&nbsp;\&nbsp;In this paper, we define time series query filtering, the problem of monitoring the streaming time series for a set of predefined patterns. This problem is of great practical importance given the massive volume of streaming time series available through sensors, medical patient records, financial indices and space telemetry. Since the data may arrive at a high rate and the number of predefined patterns can be relatively large, it may be impossible for the comparison algorithm to keep up. We propose a novel technique that exploits the commonality among the predefined patterns to allow monitoring at higher bandwidths, while maintaining a guarantee of no false dismissals. Our approach is based on the widely used envelope-based lower-bounding technique. As we will demonstrate on extensive experiments in diverse domains, our approach achieves tremendous improvements in performance in the offline case, and significant improvements in the fastest possible arrival rate of the data stream that can be processed with guaranteed no false dismissals. As a further demonstration of the utility of our approach, we demonstrate that it can make semisupervised learning of time series classifiers tractable.},
	author = {Wei, Li   and Keogh, Eamonn   and Van Herle, Helga   and Mafra-Neto, Agenor   and Abbott, Russell  },
	citeulike-article-id = {3815887},
	doi = {10.1007/s10115-006-0033-7},
	journal = {Knowledge and Information Systems},
	keywords = {dtw, litreview, thesis},
	month = {April},
	number = {3},
	pages = {313--344},
	posted-at = {2008-12-21 17:37:36},
	priority = {2},
	title = {Efficient query filtering for streaming time series with applications to semisupervised learning of time series classifiers},
	url = {http://dx.doi.org/10.1007/s10115-006-0033-7},
	volume = {11},
	year = {2007}
}



@incollection{citeulike:3815884,
	abstract = {It is well known that Dynamic Time Warping (DTW) is superior to Euclidean distance as a similarity measure in time series analyses. Use of DTW with the recently introduced warping window constraints and lower bounding measures has significantly increased the accuracy of time series classification while reducing the computational expense required. The warping window technique learns arbitrary constraints on the warping path while performing time series alignment. This work utilizes genetic algorithms to find the optimal warping window constraints which provide a better classification accuracy. Performance of the proposed methodology has been investigated on two problems from diverse domains with favorable results.},
	author = {Kumar, Pankaj   and Gupta, Ankur   and Jayaraman, Valadi  K.  and Kulkarni, Bhaskard  },
	citeulike-article-id = {3815884},
	doi = {10.1007/978-3-540-72960-0\_12},
	journal = {Advances in Metaheuristics for Hard Optimization},
	keywords = {dtw, litreview, thesis},
	pages = {251--261},
	posted-at = {2008-12-21 17:35:01},
	priority = {2},
	title = {Aligning Time Series with Genetically Tuned Dynamic Time Warping Algorithm},
	url = {http://dx.doi.org/10.1007/978-3-540-72960-0\_12},
	year = {2008}
}



@article{citeulike:785210,
	author = {Keogh, Eamonn   and Ratanamahatana, Chotirat  A. },
	citeulike-article-id = {785210},
	doi = {10.1007/s10115-004-0154-9},
	journal = {Knowledge and Information Systems},
	keywords = {dtw, litreview, thesis},
	month = {March},
	number = {3},
	pages = {358--386},
	posted-at = {2008-12-21 17:31:59},
	priority = {2},
	title = {Exact indexing of dynamic time warping},
	url = {http://dx.doi.org/10.1007/s10115-004-0154-9},
	volume = {7},
	year = {2005}
}



@incollection{citeulike:3815880,
	abstract = {Constraints are a natural mechanism for the specification of similarity queries on time-series data. However, to realize the expressive power of constraint programming in this context, one must provide the matching implementation technology for efficient indexing of very large data sets. In this paper, we formalize the intuitive notions of exact and approximate similarity between time-series patterns and data. Our definition of similarity extends the distance metric used in [2, 7] with invariance under a group of transformations. Our main observation is that the resulting, more expressive, set of constraint queries can be supported by a new indexing technique, which preserves all the desirable properties of the indexing scheme proposed in [2, 7].},
	author = {Goldin, Dina   and Kanellakis, Paris  },
	citeulike-article-id = {3815880},
	doi = {10.1007/3-540-60299-2\_9},
	journal = {Principles and Practice of Constraint Programming — CP '95},
	keywords = {dtw, litreview, thesis},
	pages = {137--153},
	posted-at = {2008-12-21 17:28:50},
	priority = {2},
	title = {On similarity queries for time-series data: Constraint specification and implementation},
	url = {http://dx.doi.org/10.1007/3-540-60299-2\_9},
	year = {1995}
}



@incollection{citeulike:3815871,
	citeulike-article-id = {3815871},
	doi = {10.1007/978-3-540-37014-7\_2},
	journal = {Dynamic Programming},
	keywords = {litreview},
	pages = {45--100},
	posted-at = {2008-12-21 17:15:50},
	priority = {2},
	title = {Applications of Dynamic Programming},
	url = {http://dx.doi.org/10.1007/978-3-540-37014-7\_2},
	year = {2007}
}



@inproceedings{citeulike:3815864,
	abstract = {We investigate techniques for similarity analysis of spatio-temporal trajectories for mobile objects. Such data may contain a large number of outliers, which degrade the performance of Euclidean and time warping distance. Therefore, we propose the use of non-metric distance functions based on the longest common subsequence (LCSS), in conjunction with a sigmoidal matching function. Finally, we compare these new methods to various L<sub>p</sub> norms and also to time warping distance (for real and synthetic data) and present experimental results that validate the accuracy and efficiency of our approach, especially in the presence of noise.},
	author = {Vlachos, M.  and Gunopulos, D.  and Kollios, G. },
	booktitle = {Database and Expert Systems Applications, 2002. Proceedings. 13th International Workshop on},
	citeulike-article-id = {3815864},
	journal = {Database and Expert Systems Applications, 2002. Proceedings. 13th International Workshop on},
	keywords = {dtw, litreview, thesis},
	pages = {721--726},
	posted-at = {2008-12-21 17:09:37},
	priority = {2},
	title = {Robust similarity measures for mobile object trajectories},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1045983},
	year = {2002}
}



@incollection{citeulike:2902692,
	abstract = {Similarity of objects is one of the crucial concepts in several applications, including data mining. For complex objects, similarity is nontrivial to define. In this paper we present an intuitive model for measuring the similarity between two time series. The model takes into account outliers, different scaling functions, and variable sampling rates. Using methods from computational geometry, we show that this notion of similarity can be computed in polynomial time. Using statistical approximation techniques, the algorithms can be speeded up considerably. We give preliminary experimental results that show the naturalness of the notion.},
	author = {Das, Gautam   and Gunopulos, Dimitrios   and Mannila, Heikki  },
	citeulike-article-id = {2902692},
	doi = {10.1007/3-540-63223-9\_109},
	journal = {Principles of Data Mining and Knowledge Discovery},
	keywords = {dtw, litreview, thesis},
	pages = {88--100},
	posted-at = {2008-12-21 17:07:58},
	priority = {2},
	title = {Finding similar time series},
	url = {http://dx.doi.org/10.1007/3-540-63223-9\_109},
	year = {1997}
}



@inproceedings{citeulike:2902876,
	address = {New York, NY, USA},
	author = {Gunopulos, Dimitrios   and Das, Gautam  },
	booktitle = {KDD '00: Tutorial notes of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining},
	citeulike-article-id = {2902876},
	doi = {10.1145/349093.349108},
	isbn = {1581133057},
	keywords = {dtw, litreview, thesis},
	pages = {243--307},
	posted-at = {2008-12-21 17:06:02},
	priority = {2},
	publisher = {ACM},
	title = {Time series similarity measures (tutorial PM-2)},
	url = {http://dx.doi.org/10.1145/349093.349108},
	year = {2000}
}



@inproceedings{citeulike:3815082,
	author = {Chu, Selina   and Keogh, Eamonn   and Hart, David   and Pazzani, Michael  },
	citeulike-article-id = {3815082},
	journal = {Proceedings of the Second SIAM Intl. Conf. on Data Mining},
	keywords = {litreview, thesis},
	posted-at = {2008-12-21 04:29:45},
	priority = {2},
	title = {Iterative Deepening Dynamic Time
Warping for Time Series},
	url = {http://www.siam.org/meetings/sdm02/proceedings/sdm02-12.pdf},
	year = {2002}
}



@inproceedings{citeulike:3815076,
	abstract = {After the generation of multimedia data turned digital, an explosion of interest in their data storage, retrieval, and processing has drastically increased. This includes videos, images, and audios, where we now have higher expectations in exploiting these data at hands. Typical manipulations are in some forms of video/image/audio processing, including automatic speech recognition, which require fairly large amount of storage and are computationally intensive. In our recent work, we have demonstrated the utility of time series representation in the task of clustering multimedia data using k-medoids method, which allows considerable amount of reduction in computational effort and storage space. However, k- means is a much more generic clustering method when Euclidean distance is used. In this work, we will demonstrate that unfortunately, k-means clustering will sometimes fail to give correct results, an unaware fact that may be overlooked by many researchers. This is especially the case when Dynamic Time Warping (DTW) is used as the distance measure in averaging the shape of time series. We also will demonstrate that the current averaging algorithm may not produce the real average of the time series, thus generates incorrect k-means clustering results, and then show potential causes why DTW averaging methods may not achieve meaningful clustering results. Lastly, we conclude with a suggestion of a method to potentially find the shape-based time series average that satisfies the required properties.},
	author = {Niennattrakul, V.  and Ratanamahatana, C. A. },
	booktitle = {Multimedia and Ubiquitous Engineering, 2007. MUE '07. International Conference on},
	citeulike-article-id = {3815076},
	doi = {10.1109/MUE.2007.165},
	journal = {Multimedia and Ubiquitous Engineering, 2007. MUE '07. International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {733--738},
	posted-at = {2008-12-21 04:17:26},
	priority = {2},
	title = {On Clustering Multimedia Time Series Data Using {K}-Means and {D}ynamic {T}ime {W}arping},
	url = {http://dx.doi.org/10.1109/MUE.2007.165},
	year = {2007}
}



@inproceedings{citeulike:3815040,
	abstract = {Fast similarity searching in large time sequence databases has typically used Euclidean distance as a dissimilarity metric. However, for several applications, including matching of voice, audio and medical signals (e.g., electrocardiograms), one is required to permit local accelerations and decelerations in the rate of sequences, leading to a popular, field tested dissimilarity metric called the \&ldquo;time warping\&rdquo; distance. From the indexing viewpoint, this metric presents two major challenges: (a) it does not lead to any natural indexable \&ldquo;features\&rdquo;, and (b) comparing two sequences requires time quadratic in the sequence length. To address each problem, we propose to use: (a) a modification of the so called \&ldquo;FastMap\&rdquo;, to map sequences into points, with little compromise of \&ldquo;recall\&rdquo; (typically zero); and (b) a fast linear test, to help us discard quickly many of the false alarms that FastMap will typically introduce. Using both ideas in cascade, our proposed method achieved up to an order of magnitude speed-up over sequential scanning on both real and synthetic datasets},
	author = {Yi, Byoung-Kee   and Jagadish, H. V.  and Faloutsos, C. },
	booktitle = {Data Engineering, 1998. Proceedings., 14th International Conference on},
	citeulike-article-id = {3815040},
	doi = {10.1109/ICDE.1998.655778},
	journal = {Data Engineering, 1998. Proceedings., 14th International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {201--208},
	posted-at = {2008-12-21 02:21:14},
	priority = {2},
	title = {Efficient retrieval of similar time sequences under time warping},
	url = {http://dx.doi.org/10.1109/ICDE.1998.655778},
	year = {1998}
}



@inproceedings{citeulike:3789964,
	abstract = {Abstract: Considerable effort has been put towards developing intelligent and natural interfaces between users and computer systems. This is done by means of a variety of modes of information (visual, audio, pen, etc.) either used individually or in combination. In this work, we focus on the visual sensory information to recognize human activity in form of hand-arm movements from a small, predefined vocabulary. We accomplish this task by means of a matching technique by determining the distance between the unknown input and a set of previously defined templates. A dynamic time warping (DTW) algorithm is used to perform the time alignment and normalization by computing a temporal transformation allowing the two signals to be matched. The system is trained with finite video sequences of single gesture performances whose start and end point are accurately known. Preliminary experiments are accomplished off-line and result in a recognition accuracy of up to 92\%.},
	address = {Washington, DC, USA},
	author = {Corradini, Andrea  },
	booktitle = {RATFG-RTS '01: Proceedings of the IEEE ICCV Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems (RATFG-RTS'01)},
	citeulike-article-id = {3789964},
	keywords = {dtw, litreview, thesis},
	posted-at = {2008-12-15 17:14:19},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Dynamic Time Warping for Off-Line Recognition of a Small Gesture Vocabulary},
	url = {http://portal.acm.org/citation.cfm?id=882476.883586},
	year = {2001}
}



@inproceedings{citeulike:3789957,
	abstract = {In this paper an approach to classify hand shapes into different classes according to the similarity measures between features is proposed. We show how to use an Exploratory Data Analysis to extract novel, single feature of hand from images. Based on the obtained curve-like shape of the feature, hands are classified into one of 21 possible classes of Croatian sign language using Dynamic Time Warping and Longest Common Subsequence as similarity measures. Performance of the system was evaluated with 1260 images. Results show that high classification accuracy can be obtained from a single feature recognition and a small number of training sample.},
	author = {Kuzmanic, A.  and Zanchi, V. },
	booktitle = {EUROCON, 2007. The International Conference on "Computer as a Tool"},
	citeulike-article-id = {3789957},
	doi = {10.1109/EURCON.2007.4400350},
	journal = {EUROCON, 2007. The International Conference on "Computer as a Tool"},
	keywords = {dtw, litreview, thesis},
	pages = {264--269},
	posted-at = {2008-12-15 17:10:27},
	priority = {2},
	title = {Hand shape classification using {DTW} and {LCSS} as similarity measures for vision-based gesture recognition system},
	url = {http://dx.doi.org/10.1109/EURCON.2007.4400350},
	year = {2007}
}



@article{citeulike:2584345,
	abstract = {This survey describes the state of the art of online handwriting recognition during a period of renewed activity in the field. It is based on an extensive review of the literature, including journal articles, conference proceedings, and patents. Online versus offline recognition, digitizer technology, and handwriting properties and recognition problems are discussed. Shape recognition algorithms, preprocessing and postprocessing techniques, experimental systems, and commercial products are examined},
	author = {Tappert, C. C.  and Suen, C. Y.  and Wakahara, T. },
	booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	citeulike-article-id = {2584345},
	doi = {10.1109/34.57669},
	journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {8},
	pages = {787--808},
	posted-at = {2008-12-15 17:04:49},
	priority = {2},
	title = {The state of the art in online handwriting recognition},
	url = {http://dx.doi.org/10.1109/34.57669},
	volume = {12},
	year = {1990}
}



@article{citeulike:3789944,
	abstract = {This paper compares the current state of the art in online Japanese character recognition with techniques in western handwriting recognition. It discusses important developments in preprocessing, classification, and postprocessing for Japanese character recognition in recent years and relates them to the developments in western handwriting recognition. Comparing eastern and western handwriting recognition techniques allows learning from very different approaches and understanding the underlying common foundations of handwriting recognition. This is very important when it comes to developing compact modules for integrated systems supporting many writing systems capable of recognizing multilanguage documents.},
	author = {Jaeger, S.  and Liu, C. L.  and Nakagawa, M. },
	citeulike-article-id = {3789944},
	doi = {10.1007/s10032-003-0107-y},
	journal = {International Journal on Document Analysis and Recognition},
	keywords = {dtw, litreview, thesis},
	month = {October},
	number = {2},
	pages = {75--88},
	posted-at = {2008-12-15 16:59:51},
	priority = {2},
	title = {The state of the art in Japanese online handwriting recognition compared to techniques in western handwriting recognition},
	url = {http://dx.doi.org/10.1007/s10032-003-0107-y},
	volume = {6},
	year = {2003}
}



@article{citeulike:125682,
	author = {Yutao, Shou   and Nikos, Mamoulis   and David, Cheung  },
	citeulike-article-id = {125682},
	doi = {10.1007/s10994-005-5828-3},
	issn = {0885-6125},
	journal = {Machine Learning},
	keywords = {dtw, litreview, thesis},
	month = {February},
	number = {2-3},
	pages = {231--267},
	posted-at = {2008-12-15 16:45:58},
	priority = {2},
	publisher = {Kluwer Academic Publishers},
	title = {Fast and Exact Warping of Time Series Using Adaptive Segmental Approximations},
	url = {http://dx.doi.org/10.1007/s10994-005-5828-3},
	volume = {58},
	year = {2005}
}



@incollection{citeulike:3789897,
	abstract = {As the world has shifted towards manipulation of information and its technology, we have been increasingly overwhelmed by the amount of available multimedia data while having higher expectations to fully exploit these data at hands. One of the attempts is to develop content-based multimedia information retrieval systems, which greatly facilitate us to intuitively search by its contents; a classic example is a Query-by-Humming system. Nevertheless, typical content-based search for multimedia data usually requires a large amount of storages and is computationally intensive. Recently, time series representation has been successfully applied to a wide variety of research, including multimedia retrieval due to the great reduction in time and space complexity. Besides, an enhancement, Uniform Scaling, has been proposed and applied prior to distance calculation, as well as it has been demonstrated that Uniform Scaling can outperform Euclidean distance. These previous work on Uniform Scaling, nonetheless, overlook the importance and effects of normalisation, which make their frameworks impractical for real world data. Therefore, in this paper, we justify this importance of normalisation in multimedia data and propose an efficient solution for searching multimedia time series data under Uniform Scaling and normalisation.},
	author = {Euachongprasit, Waiyawuth   and Ratanamahatana, Chotirat  },
	citeulike-article-id = {3789897},
	doi = {10.1007/978-3-540-78646-7\_49},
	journal = {Advances in Information Retrieval},
	keywords = {dtw, litreview, thesis},
	pages = {506--513},
	posted-at = {2008-12-15 16:16:06},
	priority = {2},
	title = {Efficient Multimedia Time Series Data Retrieval Under Uniform Scaling and Normalisation},
	url = {http://dx.doi.org/10.1007/978-3-540-78646-7\_49},
	year = {2008}
}



@incollection{citeulike:3789894,
	abstract = {Relatively few query tools exist for data exploration and pattern identification in time series data sets. In previous work we introduced Timeboxes. Timeboxes are rectangular, direct-manipulation queries for studying time-series datasets. We demonstrated how Timeboxes can be used to support interactive exploration via dynamic queries, along with overviews of query results and drag-and-drop support for query-by-example. In this paper, we extend our work by introducing Variable Time Timeboxes (VTT). VTTs are a natural generalization of Timeboxes, which permit the specification of queries that allow a degree of uncertainty in the time axis. We carefully motivate the need for these more expressive queries, and demonstrate the utility of our approach on several data sets.},
	author = {Keogh, Eamonn   and Hochheiser, Harry   and Shneiderman, Ben  },
	citeulike-article-id = {3789894},
	doi = {10.1007/3-540-36109-X\_19},
	journal = {Flexible Query Answering Systems},
	keywords = {dtw, litreview, thesis},
	pages = {240--250},
	posted-at = {2008-12-15 16:14:09},
	priority = {2},
	title = {An Augmented Visual Query Mechanism for Finding Patterns in Time Series Data},
	url = {http://dx.doi.org/10.1007/3-540-36109-X\_19},
	year = {2002}
}



@misc{citeulike:3788829,
	author = {Dimitrios, Gunopulos  },
	citeulike-article-id = {3788829},
	keywords = {litreview, thesis},
	posted-at = {2008-12-15 06:48:48},
	priority = {2},
	title = {Time Series Similarity Measures},
	url = {http://mrw.interscience.wiley.com/emrw/9780470011812/eob/article/b2a12074/current/abstract}
}



@article{citeulike:3788783,
	abstract = {Abstract--In this paper, we give a comprehensive description of our writer-independent online handwriting recognition system frog on hand. The focus of this work concerns the presentation of the classification/training approach, which we call cluster generative statistical dynamic time warping (CSDTW). CSDTW is a general, scalable, HMM-based method for variable-sized, sequential data that holistically combines cluster analysis and statistical sequence modeling. It can handle general classification problems that rely on this sequential type of data, e.g., speech recognition, genome processing, robotics, etc. Contrary to previous attempts, clustering and statistical sequence modeling are embedded in a single feature space and use a closely related distance measure. We show character recognition experiments of frog on hand using CSDTW on the UNIPEN online handwriting database. The recognition accuracy is significantly higher than reported results of other handwriting recognition systems. Finally, we describe the real-time implementation of frog on hand on a Linux Compaq iPAQ embedded device.},
	address = {Washington, DC, USA},
	author = {Bahlmann, Claus   and Burkhardt, Hans  },
	citeulike-article-id = {3788783},
	doi = {10.1109/TPAMI.2004.1262308},
	issn = {0162-8828},
	journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
	keywords = {dtw, litreview, thesis},
	number = {3},
	pages = {299--310},
	posted-at = {2008-12-15 06:30:08},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {The Writer Independent Online Handwriting Recognition System frog on hand and Cluster Generative Statistical Dynamic Time Warping},
	url = {http://dx.doi.org/10.1109/TPAMI.2004.1262308},
	volume = {26},
	year = {2004}
}



@article{citeulike:3744226,
	abstract = {Poor handwriting is a diagnostic criterion for developmental coordination disorder. Typical of poor handwriting is its low overall quality and the high variability of the spatial characteristics of the letters, usually assessed with a subjective handwriting scale. Recently, Dynamic Time Warping (DTW), a technique originally developed for speech recognition, was introduced for pattern recognition in handwriting. The present study evaluates its application to analyze poor handwriting. Forty children attending Dutch mainstream primary schools were recruited and based on their scores on the Concise Evaluation Scale for Children's Handwriting (Dutch abbreviation: BHK), 20 good and 20 poor writers (of whom 13 were scheduled for handwriting intervention) were identified. The groups were matched for age (7-9 years), school grade (grades 2 and 3) and handedness. The children subsequently wrote sequences of the letter "a" on a graphics tablet in three conditions (normal, fast, and accurate). Classical kinematics were obtained and for each individual letter DTW was used to calculate the distance from the mean shape. The DTW data revealed much higher variability in the letter forms of the poor writers that was independent of the kinematic results of larger trajectories, faster movements, and higher pen pressure. The current results suggest that DTW is a valid and objective technique for letter-form analysis in handwriting and may hence be useful to evaluate the rehabilitation treatments of children suffering from poor handwriting. In education research it may be exploited to explore how children (should) learn to write.},
	author = {Di Brina, C.  and Niels, R.  and Overvelde, A.  and Levi, G.  and Hulstijn, W. },
	citeulike-article-id = {3744226},
	doi = {10.1016/j.humov.2008.02.012},
	issn = {0167-9457},
	journal = {Human movement science},
	keywords = {dtw, litreview, thesis},
	month = {April},
	number = {2},
	pages = {242--255},
	posted-at = {2008-12-04 02:15:21},
	priority = {2},
	title = {Dynamic time warping: a new method in the study of poor handwriting.},
	url = {http://dx.doi.org/10.1016/j.humov.2008.02.012},
	volume = {27},
	year = {2008}
}



@article{citeulike:3736775,
	abstract = {We present an efficient and robust multiscale DTW (Ms-
DTW) approach to music synchronization for time-aligning
CD recordings of different interpretations of the same piece.
The general strategy is to recursively project an alignment
path computed at a coarse resolution level to the next higher
level and then to refine the projected path. As main contributions,
we address several crucial issues including the design
and specification of robust and scalable audio features, suitable
local cost measures,MsDTWlevels, constraint regions,
as well as sampling rate adaptation and structural enhancement
strategies. Extensive experiments on Western classical
music show that our MsDTW-based algorithm yields the
same alignment result as the classical DTW-based strategy
while significantly reducing the running time and memory
requirements. Even for pieces of a duration of 10 to 15 minutes,
the alignment (based on previously extracted feature
sequences) can be computed in less than a second.},
	author = {Muller, M.  and Mattes, H.  and Kurth, F. },
	booktitle = {in Proc. ISMIR},
	citeulike-article-id = {3736775},
	keywords = {dtw, litreview, thesis},
	location = {Victoria, Canada},
	pages = {192--197},
	posted-at = {2008-12-02 19:47:57},
	priority = {2},
	title = {An efficient multiscale approach to
audio synchronization},
	url = {http://www.google.com/url?sa=t\&\#38;source=web\&\#38;ct=res\&\#38;cd=2\&\#38;url=http\%3A\%2F\%2Farnetminer.org\%2Fviewpub.do\%3Fpid\%3D2106739\%26mode\%3Dpub\&\#38;ei=5I81SYviKZmWsAOrmoSHBg\&\#38;usg=AFQjCNGOl-fUcp4Q2PJKISmoUrdy16Fm3g\&\#38;sig2=MB2z\_J\_cyQ766tYPoeXoKg},
	year = {2006}
}



@article{citeulike:3736765,
	abstract = {Dynamic Time Warping (DTW) has a quadratic time and space complexity that limits its use to small time series. In this paper we introduce FastDTW, an approximation of DTW that has a linear time and space complexity. FastDTW uses a multilevel approach that recursively projects a solution from a coarser resolution and refines the projected solution. We prove the linear time and space complexity of FastDTW both theoretically and empirically. We also analyze the accuracy of FastDTW by comparing it to two other types of existing approximate DTW algorithms: constraints (such as Sakoe-Chiba Bands) and abstraction. Our results show a large improvement in accuracy over existing methods.},
	address = {Amsterdam, The Netherlands, The Netherlands},
	author = {Salvador, Stan   and Chan, Philip  },
	citeulike-article-id = {3736765},
	issn = {1088-467X},
	journal = {Intell. Data Anal.},
	keywords = {dtw, litreview, thesis},
	number = {5},
	pages = {561--580},
	posted-at = {2008-12-02 19:42:38},
	priority = {2},
	publisher = {IOS Press},
	title = {Toward accurate dynamic time warping in linear time and space},
	url = {http://portal.acm.org/citation.cfm?id=1367993},
	volume = {11},
	year = {2007}
}



@inproceedings{citeulike:3733947,
	abstract = {In this paper, we discuss an on-line signature verification system based on dynamic time-warping (DTW). The DTW-algorithm originates from the field of speech recognition, and has been applied successfully in the signature verification area more than once. However, until now, few adaptations have been made in order to take the specific characteristics of signature verification into account. According to us, one of the most important differences is the availability of a rather large number of reference patterns, making it possible to determine which parts of a reference signature are important and which are not. By disconnecting the DTW-stage and the feature extraction process we are able to deal efficiently with this extra amount of information. We demonstrate the benefits of our approach by building and evaluating a complete system},
	author = {Martens, R.  and Claesen, L. },
	booktitle = {Pattern Recognition, 1996., Proceedings of the 13th International Conference on},
	citeulike-article-id = {3733947},
	doi = {10.1109/ICPR.1996.546791},
	journal = {Pattern Recognition, 1996., Proceedings of the 13th International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {38--42 vol.3},
	posted-at = {2008-12-02 03:27:24},
	priority = {2},
	title = {On-line signature verification by dynamic time-warping},
	url = {http://dx.doi.org/10.1109/ICPR.1996.546791},
	volume = {3},
	year = {1996}
}



@inproceedings{citeulike:3733945,
	abstract = {We focus on the use of the dynamic time warping (DTW) technique in the signature verification area. The DTW algorithm originates from the field of speech recognition, where it is a highly appreciated component of speaker specific isolated word recognisers. A few years ago the DTW algorithm was successfully introduced in the area of online signature verification. The characteristics of speech recognition and signature verification are however rather different. Starting from these dissimilarities, our objective is to extract an alternative DTW approach that is better suited to the signature verification problem},
	author = {Martens, R.  and Claesen, L. },
	booktitle = {Document Analysis and Recognition, 1997., Proceedings of the Fourth International Conference on},
	citeulike-article-id = {3733945},
	doi = {10.1109/ICDAR.1997.620587},
	journal = {Document Analysis and Recognition, 1997., Proceedings of the Fourth International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {653--656 vol.2},
	posted-at = {2008-12-02 03:26:10},
	priority = {2},
	title = {Dynamic programming optimisation for on-line signature verification},
	url = {http://dx.doi.org/10.1109/ICDAR.1997.620587},
	volume = {2},
	year = {1997}
}



@article{citeulike:1807913,
	abstract = {Despite their known weaknesses, hidden Markov models (HMMs) have been the dominant technique for acoustic modeling in speech recognition for over two decades. Still, the advances in the HMM framework have not solved its key problems: it discards information about time dependencies and is prone to overgeneralization. In this paper, we attempt to overcome these problems by relying on straightforward template matching. The basis for the recognizer is the well-known DTW algorithm. However, classical DTW continuous speech recognition results in an explosion of the search space. The traditional top-down search is therefore complemented with a data-driven selection of candidates for DTW alignment. We also extend the DTW framework with a flexible subword unit mechanism and a class sensitive distance measure-two components suggested by state-of-the-art HMM systems. The added flexibility of the unit selection in the template-based framework leads to new approaches to speaker and environment adaptation. The template matching system reaches a performance somewhat worse than the best published HMM results for the Resource Management benchmark, but thanks to complementarity of errors between the HMM and DTW systems, the combination of both leads to a decrease in word error rate with 17\% compared to the HMM results},
	author = {De Wachter, M.  and Matton, M.  and Demuynck, K.  and Wambacq, P.  and Cools, R.  and Van Compernolle, D. },
	booktitle = {Audio, Speech and Language Processing, IEEE Transactions on [see also Speech and Audio Processing, IEEE Transactions on]},
	citeulike-article-id = {1807913},
	doi = {10.1109/TASL.2007.894524},
	journal = {Audio, Speech and Language Processing, IEEE Transactions on [see also Speech and Audio Processing, IEEE Transactions on]},
	keywords = {dtw, litreview, thesis},
	number = {4},
	pages = {1377--1390},
	posted-at = {2008-12-02 03:20:17},
	priority = {2},
	title = {Template-Based Continuous Speech Recognition},
	url = {http://dx.doi.org/10.1109/TASL.2007.894524},
	volume = {15},
	year = {2007}
}



@inproceedings{citeulike:1033529,
	abstract = {For many performance analysis problems, the ability to reason across traces is invaluable. However, due to non-determinism in the OS and virtual machines, even two identical runs of an application yield slightly different traces. For example, it is unlikely that two identical runs of an application will suffer context switches at exactly the same points. These sorts of variations across traces make it difficult to reason across traces. This paper describes and evaluates an algorithm, dynamic time warping (DTW) that can be used to align traces, thus enabling us to reason across traces. While DTW comes from prior work our use of DTW is novel. Also we describe and evaluate an enhancement to DTW that significantly improves the quality of its alignments. Our results show that for applications whose performance varies significantly over time, DTW does a great job at aligning the traces. For applications whose performance stays largely constant for significant periods of time, the original DTW does not perform well; however, our enhanced DTW performs much better.},
	author = {Mytkowicz, T.  and Diwan, A.  and Hauswirth, M.  and Sweeney, P. F. },
	citeulike-article-id = {1033529},
	doi = {10.1109/IPDPS.2006.1639592},
	journal = {Parallel and Distributed Processing Symposium, 2006. IPDPS 2006. 20th International},
	keywords = {dtw, litreview, thesis},
	pages = {8 pp.+},
	posted-at = {2008-12-02 03:17:17},
	priority = {2},
	title = {Aligning traces for performance evaluation},
	url = {http://dx.doi.org/10.1109/IPDPS.2006.1639592},
	year = {2006}
}



@incollection{citeulike:3733930,
	abstract = {In this paper, we report the results of recognition of online handwritten Tamil characters. We experimented with two different approaches. One is subspace based method wherein the interactions between the features in the feature spate are assumed to be linear. In the second approach, we investigated an elastic matching technique using dynamic programming principles. We compare the methods to find their suitability for an on-line form-filling application in writer dependent, independent and adaptive scenarios. The comparison is in terms of average recognition accuracy and the number of training samples required to obtain an acceptable performance. While the first criterion evaluates effective recognition capability of a scheme, the second one is important for studying the effectiveness of a scheme in real time applications. We also perform error analysis to determine the advisability of combining the classifiers.},
	author = {Joshi, Niranjan   and Sita, G.  and Ramakrishnan, A. G.  and Madhvanath, Sriganesh  },
	citeulike-article-id = {3733930},
	journal = {Neural Information Processing},
	keywords = {dtw, litreview, thesis},
	pages = {806--813},
	posted-at = {2008-12-02 03:12:44},
	priority = {2},
	title = {Tamil Handwriting Recognition Using Subspace and DTW Based Classifiers},
	url = {http://www.springerlink.com/content/v8xlqt222kvw63kj
},
	year = {2004}
}



@article{citeulike:3733907,
	abstract = {One of the most challenging areas in the field of automatic control is the design of automatic control devices that 'learn' to improve their performamce based upon experience, i.e., that can adapt themselves to circumstances as they find them. The military and commercial implications of such devices are impressive, and interest in the two main areas of research in the field of control, the USA and the USSR, runs high. Unfortunately, though, both theory and construction of adaptive controllers are in their infancy, and some time may pass before they are commonplace. Nonetheless, development at this time of adequate theories of processes of this nature is essential.  The purpose of our paper is to show how the functional equation technique of a new mathematical discipline, dynamic programming, can be used in the formulation and solution of a variety of optimization problems concerning the design of adaptive devices. Although, occasionally, a solution in closed form can be obtained, in general, numerical solution via the use of high-speed digital computers is contemplated.  We discuss here the closely allied problems of formulating adaptive control processes in precise mathematical terms and of presenting feasible computational algoritbms for determining numerical solutioms.  To illustrate the general concepts, consider a system which is governed by the inhomogeneous Van der Pol equation<tex>ddot{x} + mu(x^{2} - 1) dot{x} + x = r(t), 0 leq t leq T</tex>, where<tex>r(t)</tex>is a random function whose statistical properties are only partially known to a feedback control device which seeks to keep the system near the unstable equilibrium state<tex>x = 0, dot{x} = 0</tex>. It proposes to do this by selecting the value of \&\#956; as a function of the state of the system at time<tex>t</tex>, and the time<tex>t</tex>itself. By observing the random process<tex>r(t)</tex>, the controller may, with the passage of time, infer more and more concerning the statistical properties of the function<tex>r(t)</tex>and thus may be expected to improve the quality of its control decisions. In this way the controller adapts itself to circumstances as it finds them. The process is thus an interesting example of adaptive control, and, conceivably, with some immediate ap- plications.  Lastly, some areas of this general domain requiring additional research are indicated.},
	author = {Bellman, R.  and Kalaba, R. },
	booktitle = {Automatic Control, IRE Transactions on},
	citeulike-article-id = {3733907},
	journal = {Automatic Control, IRE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {2},
	pages = {1--9},
	posted-at = {2008-12-02 02:50:59},
	priority = {2},
	title = {On adaptive control processes},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1104847},
	volume = {4},
	year = {1959}
}



@article{citeulike:3733894,
	abstract = {Comprehensive two-dimensional gas chromatography (GC \&\#xd7; GC) is now recognized as the preferred technique for the detailed analysis and characterization of complex mixtures of volatile compounds. However, for comparison purposes, taking into account all the information contained in the chromatogram is far from trivial. In this paper, it is shown that the combination of peak alignment by dynamic time warping and multivariate analysis facilitated the comparison of complex chromatograms of tobacco extracts. The comparison is shown to be efficient enough to provide a clear discrimination among three types of tobacco. A tentative interpretation of loadings is presented in order to give access to the compounds which differ from one sample to another. Once located, mass spectrometry was used to identify markers of tobacco type.},
	author = {Vial, J.  and Nocairi, H.  and Sassiat, P.  and Mallipatu, S.  and Cognon, G.  and Thiebaut, D.  and Teillet, B.  and Rutledge, D. },
	citeulike-article-id = {3733894},
	doi = {10.1016/j.chroma.2008.09.027},
	issn = {00219673},
	journal = {Journal of Chromatography A},
	keywords = {dtw, litreview, thesis},
	month = {September},
	posted-at = {2008-12-02 02:32:00},
	priority = {2},
	title = {Combination of dynamic time warping and multivariate analysis for the comparison of comprehensive two-dimensional gas chromatogramsApplication to plant extracts},
	url = {http://dx.doi.org/10.1016/j.chroma.2008.09.027},
	year = {2008}
}



@incollection{citeulike:3733893,
	abstract = {The problem of similarity search in time series database has attracted a lot of interest in the data mining field. DTW(Dynamic Time Warping) is a robust distance measure function for time series, which can handle time shifting and scaling. The main defect of DTW lies in its relatively high computational complexity of similarity search. In this paper, we develop a simple but efficient approximation technique for DTW to speed up the search process. Our method is based on a variation of the traditional histograms of the time series. This method can work with a time linear with the size of the database. In our experiment, we proved that the proposed technique is efficient and produces few false dismissals in most applications.},
	author = {Gu, Jie   and Jin, Xiaomin  },
	citeulike-article-id = {3733893},
	doi = {10.1007/11875581\_101},
	journal = {Intelligent Data Engineering and Automated Learning – IDEAL 2006},
	keywords = {dtw, litreview, thesis},
	pages = {841--848},
	posted-at = {2008-12-02 02:31:17},
	priority = {2},
	title = {A Simple Approximation for Dynamic Time Warping Search in Large Time Series Database},
	url = {http://dx.doi.org/10.1007/11875581\_101},
	year = {2006}
}



@inproceedings{citeulike:3731715,
	abstract = {Finding similar patterns in a time sequence is a well-studied problem. Most of the current techniques work well for queries of a prespecified length, but not for variable length queries. We propose a new indexing technique that works well for variable length queries. The central idea is to store index structures at different resolutions for a given dataset. The resolutions are based on wavelets. For a given query, a number of subqueries at different resolutions are generated. The ranges of the subqueries are progressively refined based on results from previous subqueries. Our experiments show that the total cost for our method is 4 to 20 times less than the current techniques including linear scan. Because of the need to store information at multiple resolution levels, the storage requirement of our method could potentially be large. In the second part of the paper we show how the index information can be compressed with minimal information loss. According to our experimental results, even after compressing the size of the index to one fifth, the total cost of our method is 3 to 15 times less than the current techniques},
	author = {Kahveci, T.  and Singh, A. },
	booktitle = {Data Engineering, 2001. Proceedings. 17th International Conference on},
	citeulike-article-id = {3731715},
	doi = {10.1109/ICDE.2001.914838},
	journal = {Data Engineering, 2001. Proceedings. 17th International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {273--282},
	posted-at = {2008-12-01 06:05:35},
	priority = {2},
	title = {Variable length queries for time series data},
	url = {http://dx.doi.org/10.1109/ICDE.2001.914838},
	year = {2001}
}



@inproceedings{citeulike:3731713,
	abstract = {We investigate the problem of searching similar multiattribute time sequences. Such sequences arise naturally in a number of medical, financial, video, weather forecast, and stock market databases where more than one attribute is of interest at a time instant. We first solve the simple case in which the distance is defined as the Euclidean distance. Later we extend it to shift and scale invariance. We formulate a new symmetric scale and shift invariant notion of distance for such sequences. We also propose a new index structure that transforms the data sequences and clusters them according to their shiftings and scalings. This clustering improves the efficiency considerably. According to our experiments with real and synthetic datasets, the index structure's performance is 5 to 45 times better than competing techniques, the exact speedup based on other optimizations such as caching and replication.},
	author = {Kahveci, T.  and Singh, A.  and Gurel, A. },
	booktitle = {Scientific and Statistical Database Management, 2002. Proceedings. 14th International Conference on},
	citeulike-article-id = {3731713},
	doi = {10.1109/SSDM.2002.1029718},
	journal = {Scientific and Statistical Database Management, 2002. Proceedings. 14th International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {175--184},
	posted-at = {2008-12-01 06:04:10},
	priority = {2},
	title = {Similarity searching for multi-attribute sequences},
	url = {http://dx.doi.org/10.1109/SSDM.2002.1029718},
	year = {2002}
}



@inproceedings{citeulike:3731711,
	abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article.  ACM has opted to expose the complete List rather than only correct and linked references.},
	address = {New York, NY, USA},
	author = {Kelvin and Wong, Man  H. },
	booktitle = {PODS '99: Proceedings of the eighteenth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems},
	citeulike-article-id = {3731711},
	doi = {10.1145/303976.304000},
	isbn = {1-58113-062-7},
	keywords = {dtw, litreview, thesis},
	location = {Philadelphia, Pennsylvania, United States},
	pages = {237--248},
	posted-at = {2008-12-01 06:02:47},
	priority = {2},
	publisher = {ACM},
	title = {Fast time-series searching with scaling and shifting},
	url = {http://dx.doi.org/10.1145/303976.304000},
	year = {1999}
}



@article{citeulike:3731706,
	abstract = {We consider the problem of finding similar patterns in a time sequence. Typical applications of this problem involve large databases consisting of long time sequences of different lengths. Current time sequence search techniques work well for queries of a prespecified length, but not for arbitrary length queries. We propose a novel indexing technique that works well for arbitrary length queries. The proposed technique stores index structures at different resolutions for a given data set. We prove that this index structure is superior to existing index structures that use a single resolution. We propose a range query and nearest neighbor query technique on this index structure and prove the optimality of our index structure for these search techniques. The experimental results show that our method is 4 to 20 times faster than the current techniques, including sequential scan, for range queries and 3 times faster than sequential scan and other techniques for nearest neighbor queries. Because of the need to store information at multiple resolution levels, the storage requirement of our method could potentially be large. In the second part, we show how the index information can be compressed with minimal information loss. According to our experimental results, even after compressing the size of the index to one fifth, the total cost of our method is 3 to 15 times less than the current techniques.},
	author = {Kahveci, T.  and Singh, A. K. },
	booktitle = {Knowledge and Data Engineering, IEEE Transactions on},
	citeulike-article-id = {3731706},
	doi = {10.1109/TKDE.2004.1269667},
	journal = {Knowledge and Data Engineering, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {4},
	pages = {418--433},
	posted-at = {2008-12-01 05:59:02},
	priority = {2},
	title = {Optimizing similarity search for arbitrary length time series queries},
	url = {http://dx.doi.org/10.1109/TKDE.2004.1269667},
	volume = {16},
	year = {2004}
}



@inproceedings{citeulike:2264785,
	abstract = {We investigate techniques for analysis and retrieval of object trajectories in two or three dimensional space. Such data usually contain a large amount of noise, that has made previously used metrics fail. Therefore, we formalize non-metric similarity functions based on the longest common subsequence (LCSS), which are very robust to noise and furthermore provide an intuitive notion of similarity between trajectories by giving more weight to similar portions of the sequences. Stretching of sequences in time is allowed, as well as global translation of the sequences in space. Efficient approximate algorithms that compute these similarity measures are also provided. We compare these new methods to the widely used Euclidean and time warping distance functions (for real and synthetic data) and show the superiority of our approach, especially in the strong presence of noise. We prove a weaker version of the triangle inequality and employ it in an indexing structure to answer nearest neighbor queries. Finally, we present experimental results that validate the accuracy and efficiency of our approach},
	author = {Vlachos, M.  and Kollios, G.  and Gunopulos, D. },
	booktitle = {Data Engineering, 2002. Proceedings. 18th International Conference on},
	citeulike-article-id = {2264785},
	doi = {10.1109/ICDE.2002.994784},
	journal = {Data Engineering, 2002. Proceedings. 18th International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {673--684},
	posted-at = {2008-12-01 05:57:25},
	priority = {2},
	title = {Discovering similar multidimensional trajectories},
	url = {http://dx.doi.org/10.1109/ICDE.2002.994784},
	year = {2002}
}



@article{citeulike:603020,
	abstract = {The technique of dynamic programming for the time registration of a reference and a test pattern has found widespread use in the area of isolated word recognition. Recently, a number of variations on the basic time warping algorithm have been proposed by Sakoe and Chiba, and Rabiner, Rosenberg, and Levinson. These algorithms all assume that the test input is the time pattern of a feature vector from an isolated word whose endpoints are known (at least approximately). The major differences in the methods are the global path constraints (i.e., the region of possible warping paths), the local continuity constraints on the path, and the distance weighting and normalization used to give the overall minimum distance. The purpose of this investigation is to study the effects of such variations on the performance of different dynamic time warping algorithms for a realistic speech database. The performance measures that were used include: speed of operation, memory requirements, and recognition accuracy. The results show that both axis orientation and relative length of the reference and the test patterns are important factors in recognition accuracy. Our results suggest a new approach to dynamic time warping for isolated words in which both the reference and test patterns are linearly warped to a fixed length, and then a simplified dynamic time warping algorithm is used to handle the nonlinear component of the time alignment. Results with this new algorithm show performance comparable to or better than that of all other dynamic time warping algorithms that were studied.},
	author = {Myers, C.  and Rabiner, L.  and Rosenberg, A. },
	citeulike-article-id = {603020},
	journal = {Acoustics, Speech, and Signal Processing [see also IEEE Transactions on Signal Processing], IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {6},
	pages = {623--635},
	posted-at = {2008-12-01 03:52:05},
	priority = {2},
	title = {Performance tradeoffs in dynamic time warping algorithms for isolated word recognition},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1163491},
	volume = {28},
	year = {1980}
}



@inproceedings{citeulike:964832,
	address = {Washington, DC, USA},
	author = {Zhang, Zhang   and Huang, Kaiqi   and Tan, Tieniu  },
	booktitle = {ICPR '06: Proceedings of the 18th International Conference on Pattern Recognition (ICPR'06)},
	citeulike-article-id = {964832},
	doi = {10.1109/ICPR.2006.392},
	keywords = {dtw, litreview, thesis},
	pages = {1135--1138},
	posted-at = {2008-12-01 03:51:45},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Comparison of Similarity Measures for Trajectory Clustering in Outdoor Surveillance Scenes},
	url = {http://dx.doi.org/10.1109/ICPR.2006.392},
	year = {2006}
}



@article{citeulike:3568196,
	abstract = {To recognize speech, handwriting or sign language, many hybrid approaches have been proposed that combine Dynamic Time Warping (DTW) or Hidden Markov Models (HMM) with discriminative classifiers. However, all methods rely directly on the likelihood models of DTW/HMM. We hypothesize that time warping and classification should be separated because of conflicting likelihood modelling demands. To overcome these restrictions, we propose to use Statistical DTW (SDTW) only for time warping, while classifying the warped features with a different method. Two novel statistical classifiers are proposed (CDFD and Q-DFFM), both using a selection of discriminative features (DF), and are shown to outperform HMM and SDTW. However, we have found that combining likelihoods of multiple models in a second classification stage degrades performance of the proposed classifiers, while improving performance with HMM and SDTW. A proof-of-concept experiment, combining DFFM mappings of multiple SDTW models with SDTW likelihoods, shows that also for model-combining, hybrid classification can provide significant improvement over SDTW. Although recognition is mainly based on 3D hand motion features, these results can be expected to generalize to recognition with more detailed measurements such as hand/body pose and facial expression.},
	author = {Lichtenauer, J. F.  and Hendriks, E. A.  and Reinders, M. J. },
	booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	citeulike-article-id = {3568196},
	doi = {10.1109/TPAMI.2008.123},
	journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {11},
	pages = {2040--2046},
	posted-at = {2008-12-01 03:49:25},
	priority = {2},
	title = {Sign Language Recognition by Combining Statistical DTW and Independent Classification},
	url = {http://dx.doi.org/10.1109/TPAMI.2008.123},
	volume = {30},
	year = {2008}
}



@article{citeulike:2737624,
	abstract = {Continuously monitoring through time the correlation/distance of multiple data streams is of interest in a variety of applications, including financial analysis, video surveillance, and mining of biological data. However, distance measures commonly adopted for comparing time series, such as Euclidean and Dynamic Time Warping (DTW), either are known to be inaccurate or are too time-consuming to be applied in a streaming environment. In this paper we propose a novel DTW-like distance measure, called Stream-DTW (SDTW), which unlike DTW can be efficiently updated at each time step. We formally and experimentally demonstrate that SDTW speeds up the monitoring process by a factor that grows linearly with the size of the window sliding over the streams. For instance, with a sliding window of 512 samples, SDTW is about 600 times faster than DTW. We also show that SDTW is a tight approximation of DTW, errors never exceeding 10\%, and that it consistently outperforms approximations developed for the case of static time series.},
	author = {Capitani, Paolo   and Ciaccia, Paolo  },
	booktitle = {Including special issue: 20th Brazilian Symposium on Databases (SBBD 2005)},
	citeulike-article-id = {2737624},
	doi = {10.1016/j.datak.2006.08.012},
	journal = {Data \& Knowledge Engineering},
	keywords = {dtw, litreview, thesis},
	month = {September},
	number = {3},
	pages = {438--458},
	posted-at = {2008-12-01 03:48:48},
	priority = {2},
	title = {Warping the time on data streams},
	url = {http://dx.doi.org/10.1016/j.datak.2006.08.012},
	volume = {62},
	year = {2007}
}



@article{citeulike:2713605,
	abstract = {Abstract\&nbsp;\&nbsp;A new data mining technique used to classify normal and pre-seizure electroencephalograms is proposed. The technique is based on a dynamic time warping kernel combined with support vector machines (SVMs). The experimental results show that the technique is superior to the standard SVM and improves the brain activity classification.},
	author = {Chaovalitwongse, W.  and Pardalos, P. },
	citeulike-article-id = {2713605},
	doi = {10.1007/s10559-008-0012-y},
	journal = {Cybernetics and Systems Analysis},
	month = {January},
	number = {1},
	pages = {125--138},
	posted-at = {2008-12-01 03:43:26},
	priority = {2},
	title = {On the time series support vector machine using dynamic time warping kernel for brain activity classification},
	url = {http://dx.doi.org/10.1007/s10559-008-0012-y},
	volume = {44},
	year = {2008}
}



@article{citeulike:2838910,
	address = {Norwell, MA, USA},
	author = {Efrat, Alon   and Fan, Quanfu   and Venkatasubramanian, Suresh  },
	citeulike-article-id = {2838910},
	doi = {10.1007/s10851-006-0647-0},
	issn = {0924-9907},
	journal = {J. Math. Imaging Vis.},
	keywords = {dtw, litreview, thesis},
	month = {April},
	number = {3},
	pages = {203--216},
	posted-at = {2008-12-01 03:42:32},
	priority = {2},
	publisher = {Kluwer Academic Publishers},
	title = {Curve Matching, Time Warping, and Light Fields: New Algorithms for Computing Similarity between Curves},
	url = {http://dx.doi.org/10.1007/s10851-006-0647-0},
	volume = {27},
	year = {2007}
}



@incollection{citeulike:3728229,
	abstract = {As we have seen in Chap. 4, dynamic time warping is a flexible tool for comparing time series in the presence of nonlinear time deformations. In this context, the choice of suitable local cost or distance measures is of crucial importance, since they determine the kind of (spatial) similarity between the elements (frames) of the two sequences to be aligned. For the mocap domain, we introduce two conceptually different local distance measures – one based on joint angle parameters and the other based on 3D coordinates – and discuss their respective strengths and weaknesses (Sect. 10.1). The importance of DTW is then illustrated by some synthesis and analysis applications (Sect. 10.2). By comparing a motion data stream to itself, one obtains a cost or distance matrix that exhibits self-similarities within the motion. In Sect. 10.3, we describe how this idea can be exploited for motion retrieval. Finally, in Sect. 10.4, we discuss some work related to DTW-based motion retrieval.},
	citeulike-article-id = {3728229},
	doi = {10.1007/978-3-540-74048-3\_10},
	journal = {Information Retrieval for Music and Motion},
	keywords = {dtw, litreview, thesis},
	pages = {211--226},
	posted-at = {2008-11-29 22:30:44},
	priority = {0},
	title = {{DTW}-Based Motion Comparison and Retrieval},
	url = {http://dx.doi.org/10.1007/978-3-540-74048-3\_10},
	year = {2007}
}



@incollection{citeulike:3728228,
	abstract = {Dynamic time warping (DTW) is a well-known technique to find an optimal alignment between two given (time-dependent) sequences under certain restrictions (Fig. 4.1). Intuitively, the sequences are warped in a nonlinear fashion to match each other. Originally, DTW has been used to compare different speech patterns in automatic speech recognition, see [170]. In fields such as data mining and information retrieval, DTW has been successfully applied to automatically cope with time deformations and different speeds associated with time-dependent data. In this chapter, we introduce and discuss the main ideas of classical DTW (Sect. 4.1) and summarize several modifications concerning local as well as global parameters (Sect. 4.2). To speed up classical DTW, we describe in Sect. 4.3 a general multiscale DTW approach. In Sect. 4.4, we show how DTW can be employed to identify all subsequence within a long data stream that are similar to a given query sequence (Sect. 4.4). A discussion of related alignment techniques and references to the literature can be found in Sect. 4.5.},
	citeulike-article-id = {3728228},
	doi = {10.1007/978-3-540-74048-3\_4},
	journal = {Information Retrieval for Music and Motion},
	keywords = {dtw, litreview, thesis},
	pages = {69--84},
	posted-at = {2008-11-29 22:27:36},
	priority = {0},
	title = {{D}ynamic {T}ime {W}arping},
	url = {http://dx.doi.org/10.1007/978-3-540-74048-3\_4},
	year = {2007}
}



@inproceedings{citeulike:2019923,
	abstract = {Recently, we are attending to a huge evolution on the development of high performance computing platforms. Among these platforms, the GPU (Graphics Processing Units) stimulated by game industries, constantly demanding more graphical processing power, evolved from a simple graphical card to a general purpose computation parallel data processing device. This article shows the GPU's viability to general purpose computation, developing a speech recognition application inside. Dynamic Time Warping (DTW) is applied on a voice password identification. Normally, DTW requires large amount of data and processing time, so that it is an efficient technique to simple vocabulary, when the voice commands set is small. Using NVIDIA GeForce 8800 GTX, with 128 processing unit cores, and a CUDA (Compute Unified Device Architecture) software platform development architecture, the DTW application was implemented, and tested its performance.},
	author = {Poli, Gustavo   and Mari, Joao  F.  and Hiroki and Levada, Alexandre  L. },
	booktitle = {Computer Architecture and High Performance Computing, 2007. SBAC-PAD 2007. 19th International Symposium on},
	citeulike-article-id = {2019923},
	doi = {10.1109/SBAC-PAD.2007.21},
	journal = {Computer Architecture and High Performance Computing, 2007. SBAC-PAD 2007. 19th International Symposium on},
	keywords = {dtw, thesis},
	pages = {19--25},
	posted-at = {2008-11-20 17:42:35},
	priority = {2},
	title = {Voice Command Recognition with Dynamic Time Warping (DTW) using Graphics Processing Units (GPU) with Compute Unified Device Architecture (CUDA)},
	url = {http://dx.doi.org/10.1109/SBAC-PAD.2007.21},
	year = {2007}
}



@article{citeulike:3578001,
	abstract = {A computer system is described in which isolated words, spoken by a designated talker, are recognized through calculation of a minimum prediction residual. A reference pattern for each word to be recognized is stored as a time pattern of linear prediction coefficients (LPC). The total log prediction residual of an input signal is minimized by optimally registering the reference LPC onto the input autocorrelation coefficients using the dynamic programming algorithm (DP). The input signal is recognized as the reference word which produces the minimum prediction residual. A sequential decision procedure is used to reduce the amount of computation in DP. A frequency normalization with respect to the long-time spectral distribution is used to reduce effects of variations in the frequency response of telephone connections.  The system has been implemented on a DDP-516 computer for the 200-word recognition experiment. The recognition rate for a designated male talker is 97.3 percent for telephone input, and the recognition time is about 22 times real time.},
	author = {Itakura, F. },
	booktitle = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
	citeulike-article-id = {3578001},
	journal = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {1},
	pages = {67--72},
	posted-at = {2008-11-19 12:36:49},
	priority = {4},
	title = {Minimum prediction residual principle applied to speech recognition},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1162641},
	volume = {23},
	year = {1975}
}



@mastersthesis{citeulike:3577984,
	author = {Myers, C. S. },
	citeulike-article-id = {3577984},
	journal = {MS and BS thesis,  MIT Jun 20 1980,},
	keywords = {dtw, litreview, thesis},
	posted-at = {2008-11-19 12:30:07},
	priority = {2},
	title = {A Comparative Study Of Several Dynamic Time Warping Algorithms For Speech Recognition},
	url = {http://dspace.mit.edu/bitstream/1721.1/27909/1/07888629.pdf }
}



@article{citeulike:1920382,
	author = {Dunfield, Peter  F.  and Yuryev, Anton   and Senin, Pavel   and Smirnova, Angela  V.  and Stott, Matthew  B.  and Hou, Shaobin   and Ly, Binh   and Saw, Jimmy  H.  and Zhou, Zhemin   and Ren, Yan   and Wang, Jianmei   and Mountain, Bruce  W.  and Crowe, Michelle  A.  and Weatherby, Tina  M.  and Bodelier, Paul  L. E.  and Liesack, Werner   and Feng, Lu   and Wang, Lei   and Alam, Maqsudul  },
	citeulike-article-id = {1920382},
	doi = {10.1038/nature06411},
	issn = {0028-0836},
	journal = {Nature},
	keywords = {publication},
	month = {November},
	posted-at = {2008-11-08 22:50:08},
	priority = {0},
	publisher = {Nature Publishing Group},
	title = {Methane oxidation by an extremely acidophilic bacterium of the phylum Verrucomicrobia},
	url = {http://dx.doi.org/10.1038/nature06411},
	year = {2007}
}



@article{citeulike:2709869,
	author = {Ming, Ray   and Hou, Shaobin   and Feng, Yun   and Yu, Qingyi   and Dionne-Laporte, Alexandre   and Saw, Jimmy  H.  and Senin, Pavel   and Wang, Wei   and Ly, Benjamin  V.  and Lewis, Kanako  L.  and Salzberg, Steven  L.  and Feng, Lu   and Jones, Meghan  R.  and Skelton, Rachel  L.  and Murray, Jan  E.  and Chen, Cuixia   and Qian, Wubin   and Shen, Junguo   and Du, Peng   and Eustice, Moriah   and Tong, Eric   and Tang, Haibao   and Lyons, Eric   and Paull, Robert  E.  and Michael, Todd  P.  and Wall, Kerr   and Rice, Danny  W.  and Albert, Henrik   and Wang, Ming-Li   and Zhu, Yun  J.  and Schatz, Michael   and Nagarajan, Niranjan   and Acob, Ricelle  A.  and Guan, Peizhu   and Blas, Andrea   and Wai, Ching  M.  and Ackerman, Christine  M.  and Ren, Yan   and Liu, Chao   and Wang, Jianmei   and Wang, Jianping   and Na, Jong-Kuk   and Shakirov, Eugene  V.  and Haas, Brian   and Thimmapuram, Jyothi   and Nelson, David   and Wang, Xiyin   and Bowers, John  E.  and Gschwend, Andrea  R.  and Delcher, Arthur  L.  and Singh, Ratnesh   and Suzuki, Jon  Y.  and Tripathi, Savarni   and Neupane, Kabi   and Wei, Hairong   and Irikura, Beth   and Paidi, Maya   and Jiang, Ning   and Zhang, Wenli   and Presting, Gernot   and Windsor, Aaron   and Navajas-Perez, Rafael   and Torres, Manuel  J.  and Feltus, Alex  F.  and Porter, Brad   and Li, Yingjun   and Burroughs, Max  A.  and Luo, Ming-Cheng   and Liu, Lei   and Christopher, David  A.  and Mount, Stephen  M.  and Moore, Paul  H.  and Sugimura, Tak   and Jiang, Jiming   and Schuler, Mary  A.  and Friedman, Vikki   and Mitchell-Olds, Thomas   and Shippen, Dorothy  E.  and Depamphilis, Claude  W.  and Palmer, Jeffrey  D.  and Freeling, Michael   and Paterson, Andrew  H.  and Gonsalves, Dennis   and Wang, Lei   and Alam, Maqsudul  },
	citeulike-article-id = {2709869},
	doi = {10.1038/nature06856},
	journal = {Nature},
	keywords = {publication},
	month = {April},
	number = {7190},
	pages = {991--996},
	posted-at = {2008-11-08 22:49:20},
	priority = {0},
	publisher = {Nature Publishing Group},
	title = {The draft genome of the transgenic tropical fruit tree papaya (Carica papaya Linnaeus)},
	url = {http://dx.doi.org/10.1038/nature06856},
	volume = {452},
	year = {2008}
}



@article{citeulike:2949501,
	author = {Hou, Shaobin   and Makarova, Kira  S.  and Jimmy and Senin, Pavel   and Ly, Benjamin  V.  and Zhou, Zhemin   and Ren, Yan   and Wang, Jianmei   and Galperin, Michael  Y.  and Omelchenko, Marina  V.  and Wolf, Yuri  I.  and Yutin, Natalya   and Koonin, Eugene  V.  and Stott, Matthew  B.  and Mountain, Bruce  W.  and Crowe, Michelle  A.  and Smirnova, Angela  V.  and Dunfield, Peter  F.  and Feng, Lu   and Wang, Lei   and Alam, Maqsudul  },
	citeulike-article-id = {2949501},
	doi = {10.1186/1745-6150-3-26},
	issn = {1745-6150},
	journal = {Biology Direct},
	keywords = {publication},
	month = {July},
	pages = {26+},
	posted-at = {2008-11-08 22:48:37},
	priority = {0},
	title = {Complete genome sequence of the extremely acidophilic methanotroph isolate V4, "Methylacidiphilum infernorum", 
a representative of the bacterial phylum Verrucomicrobia},
	url = {http://dx.doi.org/10.1186/1745-6150-3-26},
	volume = {3},
	year = {2008}
}



@article{citeulike:3496861,
	abstract = {This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition. First, a general principle of time-normalization is given using time-warping function. Then, two time-normalized distance definitions, called symmetric and asymmetric forms, are derived from the principle. These two forms are compared with each other through theoretical discussions and experimental studies. The symmetric form algorithm superiority is established. A new technique, called slope constraint, is successfully introduced, in which the warping function slope is restricted so as to improve discrimination between words in different categories. The effective slope constraint characteristic is qualitatively analyzed, and the optimum slope constraint condition is determined through experiments. The optimized algorithm is then extensively subjected to experimental comparison with various DP-algorithms, previously applied to spoken word recognition by different research groups. The experiment shows that the present algorithm gives no more than about two-thirds errors, even compared to the best conventional algorithm.},
	author = {Sakoe, H.  and Chiba, S. },
	booktitle = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
	citeulike-article-id = {3496861},
	journal = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {1},
	pages = {43--49},
	posted-at = {2008-11-08 22:11:03},
	priority = {0},
	title = {Dynamic programming algorithm optimization for spoken word recognition},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1163055},
	volume = {26},
	year = {1978}
}




