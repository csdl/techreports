\documentstyle [nftimes,11pt,/group/csdl/tex/named-citations,
                       /group/csdl/tex/definemargins,
                       /group/csdl/tex/lmacros]{report}

\input{/group/csdl/tex/psfig/psfig}

\definemargins{1.0in}{1.0in}{1.0in}{1.0in}{0.3in}{0.3in}

\begin {document} 

\title{Comparing the cost effectiveness of Group Synchronous Review
Method and Individual Asynchronous Review Method using CSRS: \\
Results of Pilot Study} 

\author {Danu Tjahjono \\
         Department of Information and Computer Sciences \\
         University of Hawaii \\
         2565 The Mall\\
         Honolulu, HI 96822\\
         {\tt dat@uhics.ics.hawaii.edu}}

\date {ICS-TR-95-07\\ January, 1995}

\maketitle

\begin{abstract}
  This document describes a pilot experiment that compares the cost
  effectiveness of a group-based review method (EGSM) to that of an
  individual-based review method (EIAM) using CSRS. In this pilot study, no
  significant differences in review effectiveness and review cost were
  found. This document provides complete details on the procedures and
  outcomes from this pilot study, as well as the lessons learned which will
  be applied to an upcoming experimental study.
\end{abstract}

\chapter{Results of Pilot Experiment}

\section{Experimental Procedures}
The pilot experiment was conducted in the Fall 1994.
The subjects involve 24 students taking ICS-313. The subjects are
divided into 8 groups (G1..G8) of 3 participants each. 
Subjects are assigned to the groups based on their final scores in the
assignments. Specifically, we divide the subjects into 3 skill categories:
High (score 15-13), Med (score 12-10), Low (score <10). The three
participants in each group are selected randomly from the three
categories above. Furthermore, all participants assume the role of
Reviewer, one participant (in the High category) assumes the
additional role of Presenter, and another one (in the Medium category)
assumes the additional role of Moderator.

Two set of programs are selected for review. The programs are derived 
from the compiled and final versions of the student
assignments. They are constructed by first, classifying the programs
according to their common 
use of  data structures (e.g., array or pointer, char* or  built-in
String, etc), then choose the programs that contain the most
number of errors, and finally seed the selected programs with
additional errors occurring in the non selected programs. Only 1\%-5\%
of these 
errors are actually seeded. Finally, we recompile the program to
ensure no syntactical errors exist. We also ensure that no same
errors occur in both selected programs.

Each group signs up for 3 sessions corresponding to training session,
session I and session II. All three sessions take 1-2 hours. In
addition, we also have one introductory session for the
entire subjects to demonstrate  the use of CSRS in general. The entire
sessions were completed in three weeks. In session I, all the groups
review artifact I with half of the groups use EGSM, another half
use EIAM. In session II, all the groups review artifact II and
switch the review methods respectively. The actual assignments as to
which group should use which method first is based on the scheduling
of the group members. We encourage the groups to take EGSM first,
since all group members have to be present at the same time. Those
groups, who cannot make it in the first session, take EIAM instead.
For EIAM, individual members can take the review any time.
However, all members of EIAM group have to complete their individual
reviews before signing up for the group review (EGSM).
The groups assignments are shown in Table \ref{pilot-groups}.

\begin{table}[h]
  \begin{center}
    \begin{tabular} {|l|l|l|}
      \hline
      & {\bf Session I} & {\bf Session II}\\
      \hline
      & & \\
      {\bf EGSM} & G2,G1,G8,G5 & G6,G3,G4,G7 \\
      & & \\
      \hline
      & & \\
      {\bf EIAM} & G7,G6,G3,G4 & G8,G1,G5,G2 \\
      & &  \\
      \hline
     \end{tabular}
  \end{center}
  \caption{Pilot Group Assignments}
  \label{pilot-groups}
\end{table}

After completed both sessions, the groups spend 15 minutes filling out
questionnaires. 

%%The completed documentation guidelines for review participants are
%%shown in the Appendix. 


\section{Analysis of Pilot Experiment}
As mentioned earlier, one of the objective of the experiment is
to evaluate review effectiveness and review cost of synchronous review
method (EGSM) compared to asynchronous review method (EIAM).

The experimental design is based on the repeated 2x2 Latin Square. This
design allows one to evaluate the main factor (differences in review
methods) with two level of treatments (synchronous and asynchronous
methods) while blocking two major sources of variations from
review subjects and review artifacts. Each review group runs two
sessions (S1 and S2) with EGSM and EIAM review method, and source
artifact 1 (A1) and artifact 2 (A2) respectively (see Table
\ref{latin-square}) 
The result the experiment is shown in Table
\ref{total-faults}. There are 8 groups 
from ICS-313 class participated in the experiment ($G_1..G_8$). 
Each group has 3 subjects, except for Group1 and Group4 who only have
2 subjects (1 subject dropped).
Numbers in each cell represent the total number of faults in the
corresponding artifacts founds by the group (EGSM) or by the
individuals collectively (EIAM). 


\begin{table}[h]
  \begin{center}
    \begin{tabular} {|l|l|l|}
      \hline
      & {\bf A1} & {\bf A2}\\
      \hline
      & & \\
      {\bf $G_I$} & EGSM & EIAM \\
      & & \\
      \hline
      & & \\
      {\bf $G_{II}$} & EIAM & EGSM \\
      & &  \\
      \hline
     \end{tabular}
  \end{center}
  \caption{Basic 2x2 Latin Square Design}
  \label{latin-square}
\end{table}



\begin{table}[h]
  \begin{center}
    \begin{tabular} {|c|c|c|c|}
      \hline
      & & {\bf Session1} & {\bf Session2} \\
      & &  (A1: driver) & (A2: yard) \\
      \hline
      & & EGSM & EIAM \\
      \cline{2-4}  
      & G1 & 4 (2:27:46) & 10 (3:43:09)\\
      \cline{2-4}
 $G_I$ & G2 & 3 (2:01:39) & 3 (3:15:08) \\
      \cline{2-4}
      & G5 & 1 (3:48:39) & 5 (4:16:58) \\
      \cline{2-4}
      & G8 & 5 (3:36:24) & 6 (3:52:41) \\
      \hline
      & & EIAM & EGSM \\
      \cline{2-4}  
      & G3 & 6 (2:00:20) & 7 (3:28:54) \\
      \cline{2-4}
 $G_{II}$ & G4 & 4 (1:13:31) & 4 (1:38:10) \\
      \cline{2-4}
      & G6 & 6 (2:24:58) & 11 (4:24:39) \\
      \cline{2-4}
      & G7 & 6 (2:13:33) & 2 (3:05:57) \\
      \hline
     \end{tabular}
  \end{center}
  \caption{Total number of Faults and Total Review-Time}
  \label{total-faults}
\end{table}

In the following sections, we will present
the results of review effectiveness and review cost analysis.
The analysis will
follow the formulation of Latin Square Design \cite{Montgomery84}.

\subsection{Review effectiveness}

Review effectiveness is measured by the number of faults detected by
the groups. 

The statistical model for the repeated Latin Square design in general
is: 

$y_{ijkl} = \mu + \alpha_i + \tau_j + \beta_k + \rho_l + \epsilon_{ijkl}$\
for i,j,k = 1, 2, 3 (p=3); l = 1, 2, 3, 4, 5 (n=5). 

$y_{ijkl}$ is the observation in row {\sl i}, column {\sl k}, and
replicate {\sl l} for the {\sl j}th treatment.
$\mu$ is the overall mean, $\alpha_i$ is the {\sl i}th
row effect, $\tau_j$ is the {\sl j}th
treatment effect, $\beta_k$ is the
{\sl k}th column effect, $\rho_l$ is the {\sl l}th
replicate effect (i.e., variations in the row), and
$\epsilon_{ijkl}$ is the random error. 

In our case, the dependent variable measures the total number of
faults detected by the groups. The treatment effect corresponds to the
differences in review methods. The row effect corresponds to the
group variations, and the column effect corresponds to the
artifact variations.
Table \ref{effectiveness} shows the data with respect to the equation
above. 

\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
          & A1 (k=1)     & A2 (k=2) & $y_{i..l}$ \\
\hline                  
          & 4 (l=1,j=1)  & 10 (l=1,j=2) & 14 \\
$G_I$ (i=1) & 3 (l=2,j=1)  & 3 (l=2,j=2) & 6 \\
          & 1 (l=3,j=1)  & 5 (l=3,j=2) & 6\\
          & 5 (l=4,j=1)  & 6 (l=4,j=2) & 11\\
\hline                  
          & 6 (l=1,j=2)  & 7 (l=1,j=1) & 13\\
$G_{II}$(i=2) & 4 (l=2,j=2)  & 4 (l=2,j=1) & 8\\
           & 6 (l=3,j=2)  & 11 (l=3,j=1) & 17\\
          & 6 (l=4,j=2)  & 2 (l=4,j=1) & 8\\
\hline
$y_{..k.}$ & 35          & 48          & 83 (=$y_{....}$) \\
\hline
\end{tabular}
\end{center}
\caption{Review Effectiveness Data}
\label{effectiveness}
\end{table}


The main hypothesis we are testing is the null hypothesis $\tau_j=0$
for all j, that is, there is no difference in the effectiveness of the
review methods.
With this model, the total experimental variance can be partitioned into:

\begin{eqnarray*}
SS_{Total} & = & SS_{Treatments}+SS_{Rows}+SS_{Columns}+SS_{Replicates}+SS_{Error}
\end{eqnarray*}

The individual variance can be calculated as follow:

\begin{eqnarray*}
SS_{Treatments} & = & \sum_{j=1}^p \frac{y_{.j..}^2}{np}- \frac{y_{....}^2}{N}\\
                 & = & \frac{(13 + 24)^2 + (24 + 22)^2}{8} - \frac{83^2}{16}\\
                 & = & 435.63 - 430.56 \\
                 & = & 5.07\\
                 &   &\\
SS_{Rows} & = & \sum_{l=1}^n \sum_{i=1}^p \frac{y_{i..l}^2}{p}-\sum_{l=1}^n \frac{y_{...l}^2}{p^2}\\
          & = & \frac{14^2+6^2..+17^2+8^2}{2} - \frac{27^2+14^2+23^2+19^2}{4}\\
          & = & 487.50 - 453.75 \\
          & = & 33.75 \\
          &   &\\
SS_{Columns} & = & \sum_{k=1}^p \frac{y_{..k.}^2}{np} -  \frac{y_{....}^2}{N}\\
             & = & \frac{35^2+48^2}{8} - \frac{83^2}{16}\\
             & = & 441.12 - 430.56 \\
             & = & 10.56\\
             &   &\\
SS_{Replicates} & = & \sum_{l=1}^n \frac{y_{...l}^2}{p^2} - \frac{y_{....}^2}{N}\\
                & = & 453.75 - 430.56 \\
                & = & 23.19\\
                &   &\\
SS_{Total} & = & \sum_i \sum_j \sum_k \sum_l y_{ijkl}^2 - \frac{y_{....}^2}{N}\\
           & = & 4^2+10^2+...+6^2+2^2 - 430.56 \\
           & = & 535 - 430.56 \\
           & = & 105.56\\
           &   &\\
SS_{Error} & = & SS_{Total}-SS_{Treatments}-SS_{Rows}-SS{Columns}-SS{Replicates}\\
           & = & 105.56 - 5.07 - 33.75 - 10.56 - 23.19 \\
           & = & 32.99
\end{eqnarray*}



\begin{table}[tb]
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
Source of Variation & Sum of Squares & Degrees of Freedom & Mean Square & $F_0$\\
\hline
Methods        &  5.07   & 1    & 5.07 & 1.1\\
Artifacts (col) &  10.56   & 1   & 10.56  &  \\
Groups (row)    &  33.75   & 4    & 8.4375 &  \\
Replications    &  23.19      & 3    & 7.73     &  \\
Error             & 32.99     & 7   & 4.7128 &  \\
Total             & 105.56   & 15   & 7.037      &  \\
\hline
\end{tabular}
\end{center}
\caption{Analysis of Variance of Review Effectiveness}
\label{analysis-variance1}
\end{table}


The analysis of variance is summarized in Table \ref{analysis-variance1}.
Since $F_0$ (distributed as $F_{1,7}$) is smaller than
$F_{0.05,1,7}$ = 5.59 ($\alpha$ = 0.05),
we may conclude that there is no 
significant difference between the two review methods above with
significance level 0.05. Even with significant level 0.10 
($F_{0.10,1,7}$ = 3.59),  or 0.25 ($F_{0.25,1,7}$ = 1.69), we cannot
conclude there are differences in review effectiveness between the two
methods. 

\subsection{Review Cost}
Review Cost is measured by the amount of time (i.e., review time)
required to detect a fault. Review time for a group is calculated
by taking the 
sum of review time spent by individual participants. For EGSM, this
is simply calculated by taking the presenter's review time multiplied
by the number of participants. 

The analysis is basically the same as in the previous section, except
that the dependent variable is the review cost. Table
\ref{review-cost} shows the resulting data, and Table
\ref{analysis-variance2} show the corresponding analysis of variance.


\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
          & A1 (k=1)     & A2 (k=2) & $y_{i..l}$ \\
\hline                  
          & 36.9 (l=1,j=1)  & 22.3 (l=1,j=2) & 59.2 \\
$G_I$ (i=1) & 40.5 (l=2,j=1)  & 65.0 (l=2,j=2) & 105.5 \\
          & 228.6 (l=3,j=1)  & 51.4 (l=3,j=2) & 280\\
          & 43.3 (l=4,j=1)  & 38.8 (l=4,j=2) & 82.1\\
\hline                  
          & 10.1 (l=1,j=2)  & 29.8 (l=1,j=1) & 39.9\\
$G_{II}$(i=2) & 18.4 (l=2,j=2)  & 24.5 (l=2,j=1) & 42.9\\
           & 24.2 (l=3,j=2)  & 24.0 (l=3,j=1) & 48.2\\
          & 22.2 (l=4,j=2)  & 93.0 (l=4,j=1) & 115.2\\
\hline
$y_{..k.}$ & 424.2          & 348.8          & 773 (=$y_{....}$) \\
\hline
\end{tabular}
\end{center}
\caption{Review Cost (Minutes/Fault)}
\label{review-cost}
\end{table}


\begin{table}[tb]
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
Source of Variation & Sum of Squares & Degrees of Freedom & Mean Square & $F_0$\\
\hline
Methods        &  4495.703   & 1    & 4495.703 & 2.25\\
Artifacts (col) &  355.323   & 1   & 355.323  &  \\
Groups (row)    & 14779.525  & 4    & 3694.881 &  \\
Replications    & 7275.913    & 3    & 2425.304     &  \\
Error             & 13984.714  & 7   & 1997.8162 &  \\
Total             & 40891.178   & 15   & 2726.078      &  \\
\hline
\end{tabular}
\end{center}
\caption{Analysis of Variance of Review Cost}
\label{analysis-variance2}
\end{table}

The result of Table \ref{analysis-variance2} also shows that there are
no significant differences in review cost between the two methods at
the significant level of 0.05 and 0.10. However, it shows a
significant difference at the level of 0.25. From Table
\ref{review-cost}. it can be seen that EGSM (Group Method) is more
costly than EIAM (Individual Method).

\section{Lessons Learned}
In this section, we present some of the lessons we learned, and the
follow-up actions we will take for the main study.

\subsection{Results of data analysis}
The results of the data analysis clearly show that there are no
significant differences between group and individual review methods. 
However, we also observe that the lack of differences may be
attributed to the following factors:
\begin{itemize}
\item {\bf Insufficient comprehension of the code.}
One of the control variables in the experiment is the degree of
comprehension of the code. Unfortunately, post questionnaires show
that this variable varies widely among participants (1 to 5 on the
scale of 1-5).
One reason why we have this problem is that the experiment was
conducted two months after the participants completed their
assignments. Some participants commented that they have completely
forgotten their C++ programs. 

The main study will therefore require the experiment is conducted at
most two weeks after the students completed their assignments. 

\item {\bf Insufficient number of seeded errors.}
There are two artifacts used for the review. One has 25 known errors, the
other one has only 7 known errors.
In the first artifact, the groups only find up to 50\% of the errors, in
the second artifact some groups find almost all the errors (90\%). We
believe in the  latter case that the number of seeded errors are
insufficient. In the main study, we will seed sufficient number of
errors in both artifacts (> 20). 


\item {\bf Too many incorrect issues.}
There are too many incorrect issues raised by the participants. In most
cases, the number of incorrect issues are greater than the correct
ones. This can definitely affect review cost as more time is
needed to raise, discuss and record these issues.
One reason why this problem arises may be due to the fact that we 
encourage the participants to raise as many issues as possible 
even though they may be incorrect. We will remedy this situation by
rewarding the participants on their review effectiveness as well as
their review cost.

\end{itemize}

\subsection{Review process}
\begin{itemize}
\item {\bf The role of Moderator.}
In general, we do not know whether the moderator in this experiment
plays a significant role (i.e., whether review effectiveness is greatly 
affected by the skill of the moderator). No quantitative study on the
role of moderator has ever been conducted.

The main task of the moderator in our experiment (i.e., EGSM) is to
lead the group discussion and to prevent unproductive
discussion. In other words, the moderator has the
power to cut lengthy or improper discussion. However, we rarely
observe the moderator takes this action.

%We do not know whether, the lack of moderator action is due to the
%the smoothness of the discussion (the moderator does not think it is
%necessary to moderate/cut the discussion), the moderator is
%intimidated to do the job, or the moderator simply
%forgets to do his or her job. It may also due to the fact that we allow
%individual participants to vote 
%differently from other group members (i.e., consensus does not need to
%be reached).

The results of post questionnaires indicate that the degree of
disagreement among 
group members is slightly low (2.6 on the scale of 1-5). Domination by
some group members is low to moderate (2.8). Hostility among group
members is low (1.9 on the scale of 1-5). From this data, it seems
that there is only a slight need for the moderator to intervene.  
Our observation seems to indicate that the lack of moderator action
may be caused by the over-active role of the presenter as discussed
next. In fact, this observation is in agreement with the experiment
conducted by \cite{Brothers90}, in which they observe that the
moderator tends to loose 
influence to the Reader and Scribe. Both reader and scribe roles are
assumed by the Presenter in our experiment.
Despite lack of action, the participants rate their satisfaction
toward the moderator as moderate-high (3.7 on the scale of 1-5). 

In the main study, we will further control the role of moderator.
The principal investigator will play the role of the moderator.
This external moderator will still assume the meeting leader.
However, to prevent any bias in the experimental outcomes, he will not
involve in any decision making or group discussion.
Instead, this role will be restricted to only
administrative duties. That is, to ensure individual participants
perform their assigned roles properly. The moderator may also remind
the group when the discussions have gone too long without any
decision. This will be carried out based on some fixed amount of time
(to be determined later). When this time-out occurs, the
participants may create the issue and vote individually without having
to reach any consensus.


\item {\bf The role of Presenter.}
Presenter seems to play a significant role in this experiment
(EGSM). He or she 
controls the pace of review (through paraphrasing), and thus may
significantly affect the group performance. 
As mentioned previously, although we have a separate moderator, we
observe that the meeting leader is implicitly assumed by the
presenter. The presenter ensures that all participants have voiced
their concerns (i.e., have no more questions/comments regarding the
respective code 
under review), have voted properly on each issue, and in many times
decide whether to record the issues or not.

When asked whether the presenter was too fast in presenting the
materials, most participants did not feel so (1.8 on the scale of
1-5). In other words, the participants seem to have sufficient time to
digest the code as they are paraphrased. 
The data also shows that the groups rate their satisfaction toward the 
presenters as moderate-high (3.8).  

At this time, we do not know whether it is proper that the
presenter plays an over-active role. An attempt to ensure that the
presenter strictly performs the paraphrasing task may slow  down the
review process. At one instance during the training session, we ask the
presenter to strictly follow the moderator for initiating the
discussion after paraphrasing. We observe some discontinuities in the
discussion process. Normally, right after paraphrasing, the presenter
raises follow-up questions or comments naturally. When the moderator
takes over this task, the presenter has to wait until the moderator
allow him to speak. Thus, there are some unnecessary idle periods.
In our experiment, any participants can interrupt and raise issues
any time without waiting for the moderator to give the floor. We
believe that this process makes the discussion more active and
productive. 


\item {\bf Paraphrasing.}
We observe quite number of variations in paraphrasing skills among the 
presenters. Many presenters present the source code by letting the group
knows what the code does. Some presenters, however, talk very
little. Basically let individual members spot the issues on their own,
then discuss the  
issues once spotted. Other presenters simply read the code literally
as written (without giving much thought about what the code
does). 
The post questionnaires data indicate that presenters do not 
perform paraphrasing strictly at all time (3.3 on the scale of 1-5). 
The usefulness of paraphrasing is perceived as rather high
(3.7). Although whether it is actually inspired the participants to
find errors is perceived moderately (3.3).
One subject commented that paraphrasing was a waste of time. Some
voiced their difficulty in performing paraphrasing.

In the main study, we will ensure that the presenters get adequate
training in paraphrasing. 

\item {\bf Recording issues.}
The issue of who should record the errors in the group meeting (EGSM)
is still debatable. One may argue that the participant who finds the
errors should be required to record them since he or she knows the
exact nature of the errors. However, the rest of the group members may
have difficulty understanding the errors if the errors are not
sufficiently elaborated in the verbal discussion. Having a separate
recorder will ensure that the errors are discussed and understood
properly by all group members before being recorded. 

In our experiment (EGSM), the presenter records the issues agreed 
upon by the group. Initially, the EGSM system provides the operation
to record issues by any members of the group.
However, individual members of the
group soon do their own review (i.e., raise issues individually).
In other words, they no longer follow the presenter paraphrasing the
materials. 
This feature was then subsequently deleted from the system during
the training period. Only the presenter can record the issues raised
by the group. 
When the presenter himself/herself raising the 
issue, it is possible that the issue is not thoroughly discussed. The
data, however, show that most participants tend to agree with the
presenter (i.e., have high confidence-level on the issues first
suggested by the presenter). Therefore, we will keep this feature in
the main study.


\item {\bf Consensus.}
The degree of consensus within EGSM groups are generally high. Most
participants tend to agree with the issues raised by any members of
the group.  In EGSM, the consensus is expressed in terms of
Confidence-level: High, Medium, Low or None (for disagree). Only few
issues have 'None' confidence-level. 

Surprisingly, the consensus is also quite high for incorrect
issues. All participants tend to see the same problems once
they are identified.

As discussed previously, we will no longer encourage the participants
to raise both correct and incorrect issues.

\end{itemize}

\subsection{CSRS}
In general participants rate CSRS favorably on all aspects of the
system, which include ease of use and usefulness. The questionnaire
data also indicate that many participants believe the system can
make their review more effective and productive. 
We also observe that CSRS can effectively ensure that the
participants have performed their tasks properly. For example, 
in many occasion, the system informs
the presenter that some participants have not voted yet
although the presenter has repeatedly asked the participants to do so 
verbally. 

Two main problems identified by the participants regarding CSRS
include system instability (especially the EGSM system)
and limited viewing of source code (i.e., many participants
would like to have multiple windows displayed more than one source
nodes).  We will fix this problem in the main study.
Other comments of CSRS include mainly the misconception of what a
review system can do; many participants  
expect debugging facilities (including complete C++ documentation) be
included as part of the system.


\subsection{Group Method (EGSM) or Individual Method (EIAM)}
The results of post questionnaires indicate that most participants
prefer EGSM to EIAM.
The most commonly cited reasons include: 
one can learn from each others, and 
one can raise issues with more confidence. One participant
characterizes his issues raised with EGSM as {\it real issues} 
as supposed to {\it guessed issues} raised with EIAM.

However as we have seen, the data do not show that EGSM groups perform
better than EIAM groups. 

\newpage
\appendix
\input{Guidelines/FTR-Guide}
\input{Guidelines/CSRS-manual}
\input{Questionnaires/EGSM-questions}
\input{Questionnaires/EIAM-questions}
\input{Questionnaires/Post-post-questions}
\input{Reports/Driver}
\input{Reports/Yard}
\input{Reports/Error-list}
\input{Reports/EGSM-G1}
\input{Reports/EGSM-G2}
\input{Reports/EGSM-G3}
\input{Reports/EGSM-G4}
\input{Reports/EGSM-G5}
\input{Reports/EGSM-G6}
\input{Reports/EGSM-G7}
\input{Reports/EGSM-G8}
\input{Reports/EIAM-G1}
\input{Reports/EIAM-G2}
\input{Reports/EIAM-G3}
\input{Reports/EIAM-G4}
\input{Reports/EIAM-G5}
\input{Reports/EIAM-G6}
\input{Reports/EIAM-G7}
\input{Reports/EIAM-G8}

\newpage

\bibliography{/group/csdl/bib/csdl-trs,/group/csdl/bib/ftr}
\bibliographystyle{/group/csdl/tex/named-citations}

\end{document}

