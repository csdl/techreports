\documentclass{llncs}

% *** HANDLING AUTHORS AFFILIATIONS ***
%
\usepackage{authblk}

% *** GRAPHICS RELATED PACKAGES ***
%
\usepackage{graphicx}
\graphicspath{{figures/}}
\DeclareGraphicsExtensions{.pdf}

% *** MATH PACKAGES ***
%
\usepackage{amssymb,amsmath}

% *** ALIGNMENT PACKAGES ***
%
\usepackage{setspace}
\usepackage{array}
%% Puts space after macros, unless followed by punctuation
\usepackage{xspace}

% *** TABULAR ENVIRONMENT ***
%
\usepackage{tabularx,ragged2e,booktabs}
%\newcolumntype{b}{X}
%\newcolumntype{s}{>{\hsize=.65\hsize}X}
%\newcolumntype{g}{>{\hsize=.8\hsize}X}
%\newcolumntype{d}{>{\hsize=.75\hsize}X}

% *** SUBFIGURE PACKAGES ***
%
%\usepackage[font=small,labelfont=bf]{caption}
%\captionsetup[table]{skip=3pt}
%\usepackage{subfigure}

% *** URL PACKAGES ***
%
%% Package to linebreak URLs in a sane manner.
\usepackage{url}
\makeatletter
\def\url@smallurlstyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\ttfamily}}}
\makeatother
\urlstyle{smallurl}
\makeatletter
\def\url@tinyurlstyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\scriptsize\ttfamily}}}
\makeatother
\renewcommand{\UrlFont}{\scriptsize}
%
%% Make URLs clickable
%\usepackage[colorlinks, bookmarks=false]{hyperref}
\usepackage{hyperref}
%\usepackage{breakurl}
%\hypersetup{ colorlinks=false, citecolor=black,
%    filecolor=black, linkcolor=black, urlcolor=black
%}

%% Hawai`i with okina
\newcommand{\Hawaii}{Hawai`i\xspace}
%% Hawai`ian with okina
\newcommand{\Hawaiian}{Hawai`ian\xspace}
%% Manoa with kahako
\newcommand{\Manoa}{M\=anoa\xspace}

% *** HYPHENATION ***
%
\usepackage{hyphenat}
\hyphenation{sub-sequence gram-mar dis-co-ve-ry ano-ma-ly tra-jec-to-ry fra-ud de-fi-ni-ti-on 
sub-se-quen-ces sub-tra-jec-to-ry si-mi-lar pro-ven data-bases pa-ra-me-ter free ano-malies}

% *** NOTES ***
%
\usepackage[roman]{parnotes}
%
% This will go in the next version
%
\makeatletter
\def\parnoteclear{%
    \gdef\PN@text{}%
    \parnotereset
}
\makeatother


\begin{document}

\mainmatter  % start of an individual contribution

% first the title is needed
\title{{SAX-VSM-G}: grammar-based \\ time series classification.}

\author{Pavel Senin\inst{1,2}
 \and Jessica Lin\inst{3} \and Xing Wang\inst{3}
 \and Tim Oates\inst{4} \and Sunil Gandhi\inst{4} \and
 Arnold P.~Boedihardjo\inst{5} \and Crystal Chen\inst{5} \and Susan Frankenstein\inst{5}
}

\institute{
 University of \Hawaii at \Manoa, CSDL, \email{senin@hawaii.edu}
 \and
 INRA Toulouse, MIAT
 \and
 George Mason University, Dept. of Computer Science,\\ \email{\{jessica, xwang24\}@gmu.edu}
 \and
 University of Maryland, Baltimore County, Dept. of Computer Science,\\ \email{oates@cs.umbc.edu, sunilga1@umbc.edu}
 \and
 U.S. Army Corps of Engineers, Engineer Research and  Development Center,\\ \email{\{arnold.p.boedihardjo, crystal.chen, susan.frankenstein\}@usace.army.mil}
}

\maketitle


\begin{abstract}
In this paper, we extend our previous approach for interpretable time series classification based on symbolic discretization and vector space model by including a grammatical inference procedure which effectively enables variable-length class-characteristic patterns discovery and ranking. SAX-VSM-G is capable to automatically discover and rank variable-length time series patterns by their ``importance'' to the class, which enables accurate and robust classification, facilitates clustering, and provides an interpretable class generalization. As we shall show, while the classification accuracy of our technique is at the level of current state of the art, it offers superior  interpretability of class specificity and classification results through pattern weight tables and heatmap-like visualization.

\keywords{time series classification, machine learning}
\end{abstract}


\section{Introduction}
Time series classification (TSC) is an increasingly popular area of research providing solutions to the wide range of fields including but not limited to health care, image and motion recognition, environmental sciences, and data mining in general. Within last decades, many time series representations, similarity measures, and classification algorithms were proposed following the rapid progress in data collection and storage technologies \cite{review}. 

To date, the best overall performing classifier in the field is a nearest-neighbor algorithm (NN), which is simple, accurate, robust, and can be easily tweaked for a particular problem by the choice of a distance measure, approximation technique, or smoothing \cite{review}. However, NN technique has a number of significant disadvantages, where the major shortcoming is that it does not
offer any insight into the classification results. Another significant limitation is that NN classifier needs a significantly large training set representing the class variance in order to achieve a good accuracy. Finally, despite trivial initialization, traditional nearest neighbor classification is computationally expensive. 

Previously, in \cite{sax-vsm} we have addressed these limitations by proposing an alternative nearest-neighbor classification technique called {SAX-VSM} built upon sliding-window based symbolic aggregate approximation (SAX) \cite{sax} and Vector Space Model \cite{vsm}. As we have shown, our algorithm provides a superior interpretability, learns efficiently from a small training set, and has a low computational complexity in classification. However, based on a discretization via fixed-length sliding window, all class-characteristic patterns reported by {SAX-VSM} were of the same length. 

In this work we extend {SAX-VSM} by embedding the grammatical inference procedure, which, as we have shown before in \cite{grammarviz}\cite{grammarviz2}\cite{grammaranomaly} effectively enables variable-length recurrent and anomalous patterns discovery. We shall show, that variable length class-characteristic patterns discovered with our technique improve the both: classification accuracy and interpretability of its results. In addition, we show that our technique can be used as a general exploratory tool for time series data mining.

The paper is structured as follows. Section XX provides background into the existing algorithms and discusses relevant work.
Section XX, provides background for a proposed algorithm.
In Section XX, we describe our algorithm, and in Section XX, we
evaluate its performance.
Finally, we form our conclusions and discuss future work
in Section XX.


\section{Section II}


\section{Section III}


\section{Section IV}

\begin{thebibliography}{3}

\bibitem{review}
Wang, X., Mueen, A., Ding, H., Trajcevski, G., Scheuermann, P., Keogh, E.,
Experimental comparison of representation methods and distance measures for time series data.
Data Min. Knowl. Discov., 26, 2, 275--309 (2013)

\bibitem{sax-vsm}
Senin, P., Malinchik, S.,
{SAX-VSM}: Interpretable Time Series Classification Using {SAX} and {Vector Space Model}.
In Proc. of ICDM (2013) 

\bibitem{sax}
Lin, J., Keogh, E., Wei, L., Lonardi, S.,
Experiencing SAX: a novel symbolic representation of time series.
Data Min. Knowl. Discov., 107--144 (2007)

\bibitem{vsm}
Salton, G., Wong, A., Yang., C.,
A vector space model for automatic indexing.
Commun. ACM 18, 11, 613--620 (1975)

\bibitem{grammarviz}
Li, Y., Lin, J., and Oates, T.,
Visualizing variable-length time series motifs.
In Proc. of SDM (2012)

\bibitem{grammarviz2}
Senin, P., Lin, J., Wang, X., Oates, T., Gandhi, S., Boedihardjo, A.P., Chen, C., Frankenstein, S., Lerner, M.,
GrammarViz 2.0: a tool for grammar-based pattern discovery in time series.
In Proc. ECML/PKDD (2014)

\bibitem{grammaranomaly}
Senin, P., Lin, J., Wang, X., Oates, T., Gandhi, S., Boedihardjo, A.P., Chen, C., Frankenstein, S.,
Time series anomaly discovery with grammar-based compression.
In Proc. EDBT (2015)

\end{thebibliography}

\end{document}