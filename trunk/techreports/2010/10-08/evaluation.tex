\chapter{Evaluation}
\label{cha:evaluation}

This chapter describes the design of the experiment using the competition and associated website described in \autoref{cha:system-description}. First we cover the different sources of data available for the experiment, followed by analyses performed on the data. The research questions we propose to investigate are:

\begin{itemize}
	\item \emph{To what extent was the website adopted by the participants?} Without significant adoption, it is hard to evaluate the other website-related questions.
	\item \emph{How did energy use change during the competition?} This is the standard measure for an energy competition, with the expected result being energy conservation during the competition.
	\item \emph{How did energy use change after the competition?} Understanding changes in energy use after the competition is over gives insight into whether changes during the competition were sustainable. Existing research focuses primarily on the competition itself, not examining the reasons why energy usage might rebound after the competition is over.
	%	\item \emph{How can energy literacy be assessed?} We are hypothesizing that energy literacy leads to sustainable behavior change, so assessing energy literacy is important.
	\item \emph{How effective were the tasks available via the website?} By using website log data, we can track what tasks participants undertook, and compare that to changes in their energy literacy.
	\item \emph{How appropriate were the Kukui Nut values assigned to tasks?} The Kukui Nut points assigned to tasks are intended to motivate participants to perform the tasks, but the values were assigned without any participant data.
	\item \emph{What is the relationship between energy literacy and energy usage?} We hypothesize that more energy literate participants will conserve more energy, so we examine the relationship both during the competition and afterwards.
	\item \emph{How important was floor-level near-realtime feedback?} There are good reasons to believe that floor-level near-realtime feedback will lead to increased energy conservation, but they greatly increase the competition budget and logistical complexity. Is the trade-off worth it?
\end{itemize}

\section{Data Sources}

\subsection{Power Usage Data}
\label{sec:power-usage-data}

We will record both instantaneous power and cumulative energy consumed on a floor by floor basis for each residence hall, beginning at least one month before the competition starts and continuing for at least 6 months after the competition ends (see \autoref{app:power-energy} for an in-depth description of power, energy and their interrelationship). The sampling rate will be a minimum of 1 minute outside the competition period, and a maximum of 1 minute during the competition period (with a target of 10 seconds), with both rates kept constant during the study to the degree possible.

\subsection{Pre and Post-Competition Energy Literacy Questionnaires}
\label{sec:exp-literacy-questionnaire}

The energy literacy of participants will be assessed at the start and end of the competition. The assessment will be through a questionnaire that is presented to participants via the competition website as an activity that can be performed for Kukui Nut points. The pre-competition questionnaire will be made available only in the first week of the competition, while the post-competition questionnaire will be made available only in the final week of the competition. \autoref{app:energy-literacy} lists the questions that will make up the pre and post-competition questionnaires.

Since the website-administered questionnaire is simply a task that can selected by participants, there is the potential that only those participants that feel that they are energy literate will participate in the survey, leading to bias. For this reason, in addition to administration through the website, the questionnaire will be administered in person on paper to two randomly-selected floors. While the assignment of residents to a floor is not random, it is at least not self-selected. The questionnaire will be administered to the floors before the competition starts, and in the final week of the competition. The questionnaire will be removed from the activity lists shown to participants on the floors that were selected for in-person administration. However, those participants that fill out the survey on paper will receive Kukui Nut points just as if they had filled it out online.

\subsection{Website Log Data}

The competition website will log data about participants' actions on the site. All participant actions and events will be logged with a timestamp. A few examples of the type of events to be logged:

\begin{itemize}
\item Participant logs onto website
\item Participant selects goal for floor participation
\item Participant submits text to verify completion of an activity
\item Participant makes a selection to display energy consumption for a floor different from his/her own
\item Participant logs off of website
\end{itemize}

These events are used to create a profile of the participant, as described in \autoref{sec:participant-profile}.

\subsection{Post-Competition Feedback Questionnaire}
\label{sec:post-competition-feedback}
After the competition has ended, participants that used the website will be emailed a link to a qualitative questionnaire, as part of the energy literacy post-test described in \autoref{sec:exp-literacy-questionnaire}. This questionnaire will ask for participants' assessment of the competition, the website, and energy literacy in general. \autoref{app:qualitative-feedback} lists the questions to be placed in the questionnaire.

\subsection{Post-Post-Competition Sustainable Conservation Questionnaire}

In early in the following semester (February 2011), the power data for floors will be re-examined to see whether conservation begun as part of the competition has been sustained months later. Floors with particularly high sustained conservation (compared to pre-competition average floor power), and those with low or non-conservation will be selected for an additional questionnaire, and possible face-to-face interviews to determine residents' self-assessment about why they were or were not sustaining the conservation gains made during the competition.

\section{Data Analysis}

Based on the raw data collected, we can perform analyses that allow the data to be understood at a higher level of abstraction.

\subsection{Power analyses}

\subsubsection{Minimum floor power}
\label{sec:min-floor-power}
Minimum floor power is the power consumed by each floor before residents move in and with all switchable devices (such as lights) turned off. This reveals the power used by the hidden infrastructure of a floor, and may be differ between floors. The value is measured by recording the kWh consumed by each floor over a period of time (preferably days to average out any periodic consumption spikes) and divided by the length of the time interval.

\subsubsection{Pre-competition average floor power}
Pre-competition average floor power is the power consumed by each floor after residents move in, but before the competition has begun. This reveals the power use profile of the floor's residents, and will almost certainly differ between floors. The value is measured by recording the kWh consumed by each floor over a long period of time (preferably weeks to average out any periodic consumption spikes) and divided by the length of the time interval.

\subsubsection{Pre-competition total monthly floor energy}
Pre-competition total monthly floor energy is the energy consumed by each floor after residents move in, but before the competition has begun. This reveals the power use profile of the floor's residents, and will almost certainly differ between floors. The value is measured by recording the kWh consumed by each floor over a long period of time (preferably weeks to average out any periodic consumption spikes) and extrapolated to a monthly value. Thus if 15 days of data are recorded, then the pre-competition total monthly floor energy would be twice the kWh value recorded for the 15 day period.

\subsection{Participant profile}
\label{sec:participant-profile}

Since the website associates activity with a particular user, we can build a profile of each user that incorporates multiple sources of data. The fields in the participant profile are described in \autoref{tab:participant-profile}.

\begin{table}[htbp]
	\centering
		% need small font sizes to make table fit on page
%		\scriptsize
		\begin{tabular}{| l | p{8cm} | c |}
			\hline
			Field & Description & Possible values \\ \hline
			
			Visits & number of times the participant visited the personalized website & 0--? \\ \hline
	
			Pre-test & participant's score on the pre-competition energy literacy survey & 0--15 \\ \hline

			Post-test & participant's score on the post-competition energy literacy survey & 0--15 \\ \hline
	
			Test-diff & difference between Post-test minus Pre-test & -15 -- 15 \\ \hline

			Total-energy & total energy consumption during the competition for participant's floor & unknown \\ \hline
			
			Total-KN & total Kukui Nuts participant accumulated during the competition  & 0--? \\ \hline

			Tasks & total number of tasks completed during competition & 0--? \\ \hline

		\end{tabular}
	\caption{Fields of participant data profile}
	\label{tab:participant-profile}
\end{table}

We can categorize participants based on their profile. For example, participant website activity could be classified in as shown in \autoref{tab:visitation-levels}. Visiting the website is one level of activity, but completing tasks is a better measure of engagement with the website, as categorized in \autoref{tab:activity-levels}.

\begin{table}[htbp]
	\centering
		\begin{tabular}{| l | c |}
			\hline
			Visitation level & Visits \\ \hline
			
			None & 0 \\ \hline
	
			Rare & 1--5 \\ \hline

			Moderate & 6--19 \\ \hline

			Frequent & $>= 20$ \\ \hline

		\end{tabular}
	\caption{Participant visitation levels}
	\label{tab:visitation-levels}
\end{table}


\begin{table}[htbp]
	\centering
		\begin{tabular}{| l | c |}
			\hline
			Activity level & Tasks \\ \hline
			
			Inactive & 0 \\ \hline
	
			Low & 1--5 \\ \hline

			Medium & 6--19 \\ \hline

			High & $>= 20$ \\ \hline

		\end{tabular}
	\caption{Participant activity levels}
	\label{tab:activity-levels}
\end{table}

Using these two categorizations, we could classify a participant as a `voyeur' if they were a frequent visitor but had low activity, or a `poster child' if they were frequent and active visitor. A participant who rarely visited the website but was highly active might have been initially very interested, but their interest quickly waned.

We might similarly break the difference between pre-test and post-test energy literacy scores into 5 categories as shown in \autoref{tab:literacy-diff}. To assess the website's effect on energy literacy we can examine the literacy difference categories. Obviously participants with terrible literacy differences would be an area to follow up with interviews to see whether this was an artifact of the survey or actually indicative of dramatically reduced energy literacy.

\begin{table}[htbp]
	\centering
		\begin{tabular}{| l | c |}
			\hline
			Literacy change & Test-diff \\ \hline
				
			Terrible & -15 -- -10 \\ \hline

			Bad & -9 -- -4 \\ \hline

			Minor & -3 -- +3 \\ \hline

			Good & 4 -- 9 \\ \hline

			Excellent & 10 -- 15 \\ \hline

		\end{tabular}
	\caption{Energy literacy score difference categories}
	\label{tab:literacy-diff}
\end{table}

\subsection{Floor profile}
\label{sec:floor-profile}

We can also aggregate data from all the participants on a floor to generate a floor profile. The fields in the floor profile are described in \autoref{tab:floor-profile}. We define high floor participation as being a floor-participation value above 13, the minimum amount required to successfully complete an attendance goal (50\% floor participation threshold, see \autoref{sec:goals}).

The floor-post-test scores can be categorized into thirds as in \autoref{tab:literacy-categories}. Using these categories we can talk about whether floors with high floor-post-test scores also ranked among the lowest floor-energy-during values.

\begin{table}[htbp]
	\centering
		% need small font sizes to make table fit on page
		\begin{tabular}{| l | p{8cm} | c |}
			\hline
			Field & Description & Possible values \\ \hline
			
			Floor-participation & number of residents who logged into website at least once & 0--26 \\ \hline
	
			Floor-KN & number of Kukui Nut points accumulated by participants on the floor & 0--? \\ \hline

			Floor-post-test & mean of the floor's participants' post-competition energy literacy questionnaire scores & 0--15 \\ \hline

			Floor-energy-before & pre-competition average daily floor energy & unknown \\ \hline

			Floor-energy-during & average daily floor energy during competition & unknown \\ \hline

			Floor-energy-after & post-competition average daily floor energy & unknown \\ \hline

		\end{tabular}
	\caption{Fields of floor data profile}
	\label{tab:floor-profile}
\end{table}

\begin{table}[htbp]
	\centering
		\begin{tabular}{| l | c |}
			\hline
			Literacy level & Floor-post-test \\ \hline
				
			Low & 0--5 \\ \hline

			Medium & 6--10 \\ \hline

			High & 11--15 \\ \hline

		\end{tabular}
	\caption{Energy literacy score categories}
	\label{tab:literacy-categories}
\end{table}


\section{Research Questions}

Rather than use a traditional treatment-based design, we have opted to provide all participants with equal access to all the tools and information we hypothesize may be helpful via the competition website. Thus, instead of positing hypotheses to be assessed using significance testing, we focus on descriptive and exploratory statistics based around research questions.

\subsection{To what extent was the website adopted by the participants?}
\label{sec:adoption}

While great effort has gone into creating the competition website that will be used by the participants, failure of participants to use the website is a significant risk (see \autoref{sec:participant-engagement}). Therefore, it is important to assess whether participants actually adopted the website.

We plan to measure adoption in multiple ways. The first hurdle is getting participants to actually log into the website. Based on the website logs, we can measure what percentage of residents actually logged into the website at least once. Petersen et al.\ found in an Oberlin dorm energy competition that 46\% of participants viewed the competition website, though it did not require logging in \cite{petersen-dorm-energy-reduction}. Because of our website requires login, which might deter some users, we believe if 30\% of the potential participants actually log in, this would be indicative of website adoption. Another measure is the average number of visits per participant, as a single visit by a participant during the first few days of the competition would indicate that the participant did not find the website relevant or useful. We set the threshold for average number of visits per participant indicating adoption to 4, one for each round of the competition.

Once logged in, the primary interactive feature of the website is the competition task system. The number of tasks completed per participant will provide an indication of how engaged participants are in the energy literacy aspect of the competition. Following the definition in \autoref{tab:activity-levels}, we set the threshold for adoption at the medium activity level of 6 or more tasks completed on average per participant.

Finally, we can get direct data about participants' opinion of whether the website was useful through the post-competition questionnaire.

\subsection[How did energy use change during the competition?]{How did floor and dorm energy usage during the competition differ from the energy usage before the competition?}
\label{sec:competition-energy}

This question goes to the basic premise of any energy competition: that an organized competition that includes a quantitative measure of energy usage will lead to a reduction in energy usage. There are a variety of ways to quantify changes in energy use. One way is to compare the average daily energy used for each floor before the competition with the average daily energy used during the competition, giving an overall difference in energy use. Since weekend energy use may differ significantly from weekday usage, it is important to ensure that the days used for the average include the correct portion of weekdays to weekend days (5 to 2). Based on other student housing energy competitions (see \autoref{sec:dorm-energy-competitions}) we expect that the trend for average daily energy use to be lower for each residence hall compared to the usage before the competition.

We will also examine the daily energy used per floor and averaged across all floors of each building to look for trends in daily usage over the competition and pre-competition period. As the competition progresses through the 4 rounds, we would expect daily energy usage to trend downward as floors vie for the grand prize. Alternatively, an initially downward trend that reversed itself during the competition could indicate waning interest in the competition or frustration with behavior changes.

Hour-to-hour patterns of energy use can show what time of day participants are using energy, and how that might change during the competition. As an example of this type of analysis, \autoref{fig:bioheatmap} shows a heatmap visualization of 4 floors of Saunders Hall, the social sciences building on the UHM campus, generated using a WattDepot visualization gadget \cite{WattDepotGadgets}. The visualization shows the heaviest energy use between 12 and 6 PM, as expected for a building with classrooms and faculty offices.

\begin{figure}[htbp]
	\centering
		% The PNG is enlarged at scale=1, so scale it down a little
		\includegraphics[scale=0.8]{bioheatmap}
		\caption{Heatmap visualization of 4 floors of Saunders Hall}
		\label{fig:bioheatmap}
\end{figure}

The addition of energy feedback has been shown over several studies to lead to conservation values from 5\% to 15\% (see \autoref{sec:energy-feedback}). We expect the average energy use for each building during the competition to be reduced by at least 10\%. However, energy usage on an individual floor may or may not be reduced compared to the pre-competition period, as some floors may not actively participate in the competition. We expect average energy use during the competition to be greater than 10\% for the floors that are actively participating (see \autoref{sec:floor-profile}).

\subsection[How did energy use change after the competition?]{How did energy usage during the competition differ from the energy usage after the competition?}
\label{sec:post-competition-energy}

While the question in \autoref{sec:competition-energy} is the usual one asked about energy competitions, this question addresses the issue of sustainability: what do participants do after the incentives have been removed? Since student housing energy competitions typically last only a fraction of a semester, if the behavior is not sustained after the competition then the positive impact both to the environment and the institution's utility bill is limited. We will quantify the changes in energy use in the same way as described in \autoref{sec:competition-energy}.

We hypothesize that the energy usage will be higher after the competition is over, as the incentives will have been removed and overall focus on energy by the participants will be greatly reduced. However, some habits started during the competition may persist, and the website will still provide residents with energy usage feedback, which has been shown to reduce consumption.

%% Commented out until I can figure out what this really means or how to test it
%\subsection{How can energy literacy be assessed?}
%
%As discussed in \autoref{sec:energy-literacy}, DeWaters and Powers break energy literacy into three areas: knowledge, attitudes, and behaviors. Knowledge and attitudes can be assessed through a written instrument such as the energy literacy questionnaire described in \autoref{sec:exp-literacy-questionnaire}, but behaviors are difficult to assess in a written format. The tasks afforded by the website, however, provide a means to assess whether participants have acquired the skills and behaviors required to be energy literate. Activities such as performing an energy audit are available to participants via the website, demonstrating the acquisition of a skill. Assessment of behaviors is more challenging, but the completion of commitments available to participants via the website demonstrate at least the intent to change behavior, though without external verification. \fxerror{Need to explain how I will actually address this question}

\subsection[How effective were the tasks available via the website?]{How effective are the tasks available via the website at improving energy literacy and reducing energy usage?}
\label{sec:task-effectiveness}

The design of the website (described in \autoref{sec:website-design}) and the tasks it makes available to participants are specifically intended to increase the energy literacy of those that participate in them. The effectiveness of the set of tasks is critical to determine whether the added complexity of the tasks and Kukui Nut point system is worth the effort.

We will investigate this question in the following ways. First, we examine the correlation between Kukui Nuts earned by participants and their post-competition energy literacy score. We rank order all participants by the number of KN they earned, and then rank order all participants by the change in energy literacy score from pre-competition to post-competition. We can then compute the non-parametric Spearman's rank correlation coefficient $\rho$ which ranges from -1 to +1, with -1 indicating perfect negative correlation, 0 indicating no correlation, and +1 indicating perfect positive correlation. A strong positive correlation would provide evidence that those that actively used the website increased their energy literacy. The same comparison can be done between ranked KN scores and ranked post-competition energy literacy score, which would show correlation for participants who we active on the website but already had high energy literacy and thus little change in their energy literacy score post-competition.

Second, we will examine the correlation between total KN per floor and the difference between average daily energy usage before and during the competition. We use Spearman's rank correlation coefficient $\rho$, though this time we are ranking floors rather than participants. A strong positive correlation would suggest that tasks completed via the website may help participants to reduce their energy usage in the context of the competition.

Third, we look at the correlation between total KN per floor and the difference between average daily energy usage before and after the competition. Again, we compute $\rho$ using the floor KN ranking and a ranking of the difference in energy usage before and after the competition. A strong positive correlation here would indicate that website tasks help to sustain energy conservation after the competition.

Finally, we can get information about the participants' opinion of the effectiveness of the website using the questionnaire described in \autoref{sec:post-competition-feedback}.

\subsection{How appropriate were the Kukui Nut values assigned to tasks?}

Beyond just making tasks available to participants, the website assigns Kukui Nut point values to each task. The point values have been assigned by hand based on several factors:

\begin{itemize}
	\item the expected difficulty of the task
	\item the expected time required for the task
	\item a guess as to how useful the task is to increasing energy literacy and/or reducing energy consumption
	\item the degree to which verification is possible (i.e. commitments, which are self-verified, are worth less than activities and goals)
\end{itemize}

%Using the data collected from the competition, we can gain insight into whether the point assigned values were appropriate. One way to do this is look at the correlation between participant Kukui Nut scores and their change in energy literacy scores, as well as their post-competition energy literacy score. We can also look at total Kukui Nut scores for a floor and compare that to the energy consumption of the floor.

Evaluating the appropriateness of KN scores for individual tasks can be done by examining the correlation between a participant's completion of a particular task and the difference between that participant's pre and post-competition energy literacy scores. Tasks that are strongly correlated with improved energy literacy would be candidates for increased KN values for future competitions.

It also makes sense to examine the popularity of tasks. If a task was correlated with improved energy literacy scores but was not popular, then it makes sense to further increase the number of Kukui Nut points assigned to it in future competitions. Tasks that required multiple verification attempts by participants before being accepted by administrators could also be candidates for increased Kukui Nut values, since this represents additional effort on the part of participants.

\subsection{What is the relationship between energy literacy and energy usage?}

We hypothesize that more energy literate participants will conserve more energy. This is one of the goals of energy literacy: to make students understand the reasons for being concerned about energy use, and the techniques they can use to reduce their energy usage. This question can be broken down into three sub-questions:

\begin{enumerate}
	\item do floors with higher average pre-competition energy literacy scores have lower average daily energy use during the pre-competition period?
	\item do floors with higher average pre-competition energy literacy scores have a greater reduction in average daily energy use during the competition?
	\item do floors with higher average post-competition energy literacy scores have a lower sustained energy usage in the post-competition period?
\end{enumerate}

The first sub-question investigates whether participants who were already more energy literate were already using less energy before the competition started. This neglects the possibility of participants improving their energy literacy through means outside the competition during the pre-competition period (classes, involvement in campus organizations, etc.), but this seems a reasonable assumption.

The second sub-question examines whether those participants who started the competition with higher energy literacy scores used less energy during the competition, independently of any change of literacy during the competition.

The third sub-question looks at the critical question of the sustainability of behavior changes in the wake of the competition. Sustainability is the ultimate goal of any attempt at behavior change.

We will evaluate this question using the methods described in \autoref{sec:task-effectiveness}. While that question looked at the relationship between KN and energy, here we rank floors by their combined energy literacy score. A high post-competition energy literacy score accounts for both those participants that already had a high degree of energy literacy, and those that gained energy literacy during the competition.

\subsection[How important was floor-level near-realtime feedback?]{How important was floor-level near-realtime electricity usage feedback to achieving electricity conservation?}

Provision of floor-level near-realtime electricity usage feedback is one of the key features of this research. Providing feedback at the floor level enables competition between floors (instead of just between buildings as is commonly done), allows individual participants to see their behavior changes reflected in electricity usage (which would be swamped by the activity if measured at the building level), and provides a reason for participants to communicate and collaborate with their floormates. Near-realtime feedback allows participants to perform their own `experiments' and see how their behavior changes electricity usage.

Unfortunately, the logistics of floor-level near-realtime electricity metering provide some of the most significant challenges to the research: the cost of purchasing the meters, the time and effort required to have them installed by electricians, and the lead time required to have the meters in place before the competition can begin.

% I want some kind of operationalization here: How would you conclude that:
%"Floor level metering is critically important"
%or 
%"Floor level metering was completely irrelevant"

Thus it is reasonable to ask whether deploying floor-level near-realtime electricity metering is worth the effort. Since we are not undertaking a `treatment'-style experiment where some floors or buildings receive the metering and others do not, we look at indirect indications of the utility of the metering. One source of data is the popularity of tasks (based on website logs) that make use of the floor-level near-realtime metering, such as the floor goal of determining the floor's minimum power or the floor goal of reducing energy use by 10\% (see \autoref{sec:goal-list}). The other source of data is participant responses to questions about the usefulness of the floor-level near-realtime metering in the post-competition feedback questionnaire.

We believe the importance of floor-level near-realtime monitoring would be demonstrated if:

\begin{itemize}
	\item The website is adopted by the participants (using the threshold discussed in \autoref{sec:adoption}.
	\item Of those participants that completed at least one task, 25\% completed a task that required either floor-level monitoring or near-realtime monitoring.
	\item Respondents to the post-competition questionnaire agree on average that having floor-level near-realtime monitoring was helpful in the competition.
\end{itemize}

Ultimately, the decision to use floor-level near-realtime metering in future energy competitions will be a based on a cost/benefit analysis, and the answer for one institution or situation might not be appropriate for all.