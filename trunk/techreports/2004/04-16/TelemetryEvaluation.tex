\begin{comment}

\chapter{Evaluation}  \label{Chapter:Evaluation}

Two techniques to use:
\begin{itemize}
	\item \textit{Questionnaires and Interviews:} quick and simple if one knows what to ask. However, inappropriate questions will lead to incorrect answer.
	\item \textit{Ethnographic Studies:} An external observation of the process. (Ref: Ian Sommerville, Software Engineering, sixth edition, Pearson Education, Essex, 2001.)
\end{itemize}

Telemetry analyses and their associated telemetry streams allow user to see the entire history of relevant software metrics and how they change from the beginning of the project. The project decisions are based not only on current values of metrics but also on their trend over time. Compared to the more traditional software management where decisions are mainly based on the current status of project, telemetry gives project managers and developers more information. The evaluation will investigate whether the extra information in telemetry-style management could result in early detection of problems and improvement of judgement or not.


The current Hackystat telemetry sub-system offer analyses in both expert mode and customized mode. In expert mode, user must use Hackystat telemetry language to instruct the system to build telemetry streams from collected metrics. Hackystat telemetry language is a custom language specifically designed for Hackystat telemetry sub-system. Though it is not difficult to learn, it still takes time for one to get comfortable with it. As a result, I developed customized-mode telemetry analysis, where Hackystat administrator or project owner can define telemetry streams before-hand using telemetry language, and users can run analysis by selecting any pre-define telemetry stream from a list. This saves ordinary user from learning a new language and lows adoption barrier at the cost of flexibility. There is a tradeoff to make. I will investigate which telemetry streams are frequently-invoked so that I can pre-define them and make them available in customized analysis by default. Custom-mode telemetry analysis invocation log can be analyzed to compute invocation count for each predefined telemetry stream or report. Expert-mode telemetry analysis invocation log can be used to find out new telemetry streams users are trying to generate. Based on above information, I can adjust pre-defined telemetry definitions.




Both quantitative and qualitative data will be collected. Quantitative data will include the actually usage of telemetry analyses on Hackystat server, and other software metrics related to evaluation subjects' software development processes. Qualitative data will be collected through surveys distributed in class, which will contain user feedback on telemetry-styled software project management and the usability of the current implementation of Hackystat telemetry sub-system.


Usage information can be collected automatically by instrumenting telemetry analysis on Hackystat public server. Before any user can access any service provided by the public server, Hackystat requires user to register an account. Each time an analysis is invoked, user information will be sent to the server along with other request parameters. Therefore, it's possible to collect information such as the content of the telemetry analysis being requested and the frequency the analysis are invoked by a particular user. Evaluation subjects' software development product and process metrics are the data collected by various Hackystat sensors.


Telemetry analyses are based on software projects registered with Hackystat server. When they are invoked, the project information will be available to instrumentation as well. This means that the project status (e.g. indicators of size, quality, effort, complexity, etc.) at the time telemetry analyses are invoked can be computed, which enables me to establish a statistical correlation between them. One possible conclusion from such exercise could be when software developers are spending lots of time on testing, they tend to invoke quality related telemetry analyses more frequently, and project coverage tends to go up. Note that this observation does not imply any causal relationship, it merely suggests that some events tend to happen together. But causal relationship might be established when user feedback is considered. 

\end{comment}