\Section{Conclusions}
\label{sec:conclusions}

After accumulating the data trends provided by the Hackystat system,
we are able to gain insights that assist in understanding the
development of HPCS applications.  From the graphs presented earlier,
we are able to make interpretations about development activities,
development progress and application performance and functionality
tradeoffs.

\SubSection{Development Activities}
\label{sec:devactivities}

From the data presented in figure \ref{fig:commandlineinvocations} we
are able to interpret the developer activities of that particular day.
The daily dairy for 06-May-2004 lists all the commands issued to the
console on that day.  Figure \ref{fig:commandlineinvocations} is a
sample of all the command line invocations issued, but it provides
insight to the developer activities on that day.

For example, from the command line invocations and most active file
data for 06-May-2004, we can observe that the developer devoted the
most time on the {\it test_distribution.cc} file.  It so happens that this
file implements the distribution of 2-dimensional mesh from which the
truss topologies are constructed.  Furthermore, the distribution of
topologies is a significant function of the Optimal Truss problem and
has been designated as a milestone test of the system.  Therefore,
from this data, an observer can conclude that the developer was
investing his efforts on implementing functionality on this day,
rather than on increasing performance by optimizing code.

In addition, an observer, such as a project manager or the developer
himself, can observe the active time trend in figure
\ref{fig:activetime} to understand the time invested to implement a
particular milestone.  For example, in figure \ref{fig:activetime} on
06-May-2004, it is evident that the developer spent over 5 hours
editing code to implement the topology distribution milestone.

\SubSection{Development Progress}
\label{sec:devprogress}

The data presented in Progress Assessment through Milestone Tests (PAMT)
chart, figure \ref{fig:functionality}, provides a clear illustration
of the real-time progress being made on the Optimal Truss problem.

There are two trends presented in this figure, one representing the
total number of milestone tests defined for the Optimal Truss problem
and the other representing the number of milestone tests passing at
the conclusion of each day.  

In the Optimal Truss problem, the total milestone tests are
represented by the horizontal line fixed at 10 unit tests.  This
indicates that there are 10 milestone tests encompassing the Optimal
Truss problem and that the project manager has not added or removed
any of these milestones during this time interval.  It is quite
possible that a project manager may have to alter milestones in order
to meet deadlines and this analysis provides a trend for this purpose.
For example, if the total milestone tests is altered, the total tests
trend on the chart will move up or down accordingly.

The PAMT chart also allows an observer to track the progress made
through the application.  For example, in this figure, the lower trend
represents the number of milestone tests passing on each day.  Every
time a new milestone test passes, it indicates that another unit of
functionality has been added to the system provided that all
previously passing tests still pass after the change.

Coupling the PAMT data with the active time data in figure
\ref{fig:activetime}, an observer is also able to interpret a
quantitative measurement of how much development time was devoted to a
particular unit of functionality.  For example, on 06-May-2004,
approximately 5 hours of editing were invested to add one unit of
functionality to the application.  This is indicated by the number of
passing milestone tests increasing from one to two on this day.  In
addition, an observer can quickly understand the percentage complete
of the system.  On 06-May-2004, the Optimal Truss problem has 2 out of
10 milestone tests passing and is therefore 20\% complete.

\SubSection{Application Performance and Functionality Tradeoffs}
\label{sec:appperfvsfunctionality}

When one combines the data presented in the Performance chart, figure
\ref{fig:performance} and the PAMT Functionality chart, figure
\ref{fig:functionality} it is possible to understand some of the
performance and functionality issues in HPCS development.

One of the primary objectives of HPCS development is to obtain the
fastest possible execution time of the system.  This goal influences
developers to frequently (if not constantly) think about or perform
optimization on their code.

However, as functionality is added to the application, it is common
for the performance of the system to decrease, indicated by an
increase in execution time.

In the data presented in figures \ref{fig:performance} and
\ref{fig:functionality}, an observer obtains a clear picture of the
performance and functionality tradeoffs.  For example, execution time
between 04-May-2004 and 07-May-2004 increaseses roughly from 30.0
hours to 32.5 hours.  On the other hand, 3 additional milestone tests,
representing system functionality, are implemented successfully during
this interval.  This indicates that 3 units of functionality have been
added at the cost of 2.5 hours of execution time.

Data presented in these figures allow project managers to understand
how functionality increases affect system performance.  It also gives
them a starting point to determine which functionality should be
optimized in the case where the performance degradation is not
acceptable.  Trends such as these enable project managers and
developers to understand the development process and make in-process
decisions to affect the development outcome.
