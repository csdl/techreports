%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% diss-leap.tex -- 
%% Author          : Carleton Moore
%% Created On      : Thu Sep  2 11:04:22 1999
%% Last Modified By: Carleton Moore
%% Last Modified On: Wed Oct 27 10:27:29 1999
%% RCS: $Id: diss-leap.tex,v 1.4 1999/10/27 20:27:33 cmoore Exp $
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 1999 Carleton Moore
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 

\chapter{Supporting Software Developer Improvement with LEAP}
\label{sec:LEAP}
\begin{quote}
{\em Measures of productivity do not lead to improvement in productivity.} -
W. Edwards Deming
\end{quote}


%LEAP is a result of our recognition that many software development
%improvement initiatives suffer from one or more of the following problems:

%\begin{itemize}
%\item{{\bf Heavyweight development process constraints.} For example, many
%process improvement initiatives require adherence to strict documentation, audit 
%and development phase constraints.}
%\item{{\bf Measurement dysfunction.} The use of process metrics for employee
%performance evaluation can lead to ``dysfunctional'' behavior which skews the
%metric in the desired direction while compromising overall organizational
%performance.}
%\item{{\bf Organization-level analysis and improvement.} Typical process
%measurements aggregate data collected from multiple projects and
%organizations. Such data take time to accumulate, analyze, and produce
%meaningful process improvements.}
%\item{{\bf Manual data gathering.} Measurement may involve time-consuming
%clerical overhead that reduces the quality of the data and produces resistance
%to its collection.}
%\end{itemize}

%The goal of LEAP is to produce tools and techniques to support process
%improvement for individuals.  These tools and techniques must satisfy the four
%LEAP constraints: Light-weight, Empirical, Anti-measurement Dysfunction, and
%Portable.
 
This chapter discusses Project LEAP and the Leap toolkit.  It starts with a
brief summary of why I started work on Project LEAP.  Then it discusses the
design criteria for LEAP compliant tools.  It next discusses the Leap toolkit a 
reference implementation of the LEAP design philosophy.  Finally, it introduces 
three intended benefits of the Leap toolkit.


\section{Background}

After using the PSP for over two years, I noticed three general problems with
the PSP.  First, I started to question the quality of the data recorded.  I
noticed that I did not record all of our defects, in part because the overhead
of recording each defect is too expensive.  Anne Disney and Philip Johnson
conducted a study to look at the data quality of PSP data.  They found that
there are significant data quality issues with manual PSP.\cite{Disney98,
  Disney98a}

Second, my experiences with industrial partners, management practices and
Robert Austin's book ``Measuring and Managing Performance in
Organizations''\cite{Austin96} made me think about the issues of measurement
dysfunction in PSP and review data.  An organization may pressure their members
to produce ``good'' results.  There are many ways that the members can
manipulate the personal data collected in the PSP to get the ``right'' results.

Third, after four years, the results with adoption of PSP are mixed.  Pat
Ferguson and others report excellent results with PSP adoption at Advanced
Information Services, Motorola and Union Switch and Signal\cite{Ferguson97}.
However, Barry Shostak and others report poor adoption of PSP in
industry\cite{Shostak96,Emam96}. No research has been published that studies
the ``long term'' adoption of the PSP --- i.e., whether or not users trained in
the PSP are continuing to use it six months, a year, or more after the
training.

These issues motivated me to begin designing an automated, empirically based,
personal process improvement tool.  My goal is to reduce the collection and
analysis overhead for the engineer, and the measurement dysfunction of the
collection process.  This should improve the benefits to the engineer and the
long term adoption of empirically based process improvement.  To pursue this
work, I initiated Project LEAP,
\url{<http://csdl.ics.hawaii.edu/Research/LEAP/LEAP.html>}, and began
developing the Leap Toolkit,
\url{<http://csdl.ics.hawaii.edu/Tools/LEAP/LEAP.html>}.

\section{Design criteria}

As part of my initial research, I hypothesized that improved support for
software developer improvement would be obtained by attempting to satisfy four
major design criteria: light-weight, empirical, anti-measurement dysfunction,
and portable.

\subsection{Criteria \#1: Light-Weight}

The first principle is that any tool or process used in software developer
improvement should be light weight.  This means that the tool or process should 
not impose overhead on the developer.  Data collection should be easy to
perform and should not add significant effort to the process.  The processes
that are used, should not impose a burden on the developer. We do not want the
developer to worry about the improvement effort while they are doing the
development.  They should be worrying about the development.  Analyses and other 
work should also require as little effort by the developer as possible.  The
benefit of using the improvement processes should outweigh the cost of to the
developer.

This principle implies that any improvement process must be automated as much
as possible.  A manual process requires too much overhead by the developer.
The overhead of recording information by hand and manually doing the analyses
will out weigh the benefits of the process.  The PSP suffers from this.

\subsection{Criteria \#2: Empirical}

We believe in empirical data collection the improvements should be based upon
the developer's experiences. We want the developer to use the observe,
evaluate, modify method for improvement.  Each modification is then tested by
further observation to see if the change is actually an improvement or just a 
false start.  By using looking at their development empirically the developer
is able to judge for themselves what is best.

\subsection{Criteria \#3: Anti-measurement Dysfunction}

Based upon my experiences as a summer intern and Richard Austin's book {\em
Measuring and Managing Performance in Organizations}\cite{Austin96}, I believe 
that any process improvement method should deal with the issue of measurement
dysfunction. The empirical data collected could be misused.  This issue is
important since the development process is very interesting to people other
than the developer.  If there is measurement dysfunction then the data
collected and analyses will not reflect reality.  Any insights gained from this 
data and analyses will be faulty and may cause more problems than they solve.


\subsection{Criteria \#4: Portable}

Software developers often change jobs and the tool support for their
development improvement should be portable.  They should be able to take their
data and the tool support with them when they change organizations or jobs. A
tool that supports developer improvement that cannot follow the developer as
they move is not going to help those developers very much.

\section{Leap toolkit: a reference implementation of the LEAP philosophy}

The Leap toolkit incorporates three main threads of research, PSP, FTR, and
measurement dysfunction.  

\subsection{Support for personal process improvement}

The Leap toolkit is based strongly upon the PSP. The Leap toolkit uses the
three primary data types, defects, size, and time, from the PSP.  However,
unlike the PSP, developers are able to choose what types of data to collect to
help them meet their process improvement goals.  If the developer is just
interested in improving their estimation ability, they can record the size of
their projects and the amount of time it takes them to complete them.  The Leap
toolkit will provide the developer with different time estimation tools.

If the developer wants to prevent defects then they could just record their
defects and not worry about size or time.  The Leap toolkit will analyze their
defect data and provide them insight into which defects occur most often and
the developer can generate checklists that help them find those defects.  

\subsection{Support for Review}

From FTR, I took the idea of supporting multiple developers reviewing a work
product and sharing the defects they find. The defects that others find in your
work product may be more important than any of the defects you find in your own
work product.  By incorporating support for sharing defect data, the Leap
toolkit can support reviews.  In the Planning phase, review leaders can define
the work product, project, defect types and checklists for the reviewers.
During the preparation phase, the reviewers can use the Leap toolkit to record
the defects they find in the work product.  They can send their defects to the
review leader who can use the Leap toolkit to combine the defects into a single 
list.  During the review meeting the review leader can display the combined
defects and each may be discussed.  The author of the work product can take the
combined list of defects and add it to any defects that they found.  This
provides the author with more data about their development process.  

The Leap toolkit's flexibility allows the review leader to define their own
process, defect types, and decide what review metrics they are interested in
recording.  The Leap toolkit will allow each reviewer to record their effort and
the defects they find.  The Leap toolkit can analyze the defect, time, and size
data to produce reports on the defect density, defect detection rate and
effectiveness of the review process.

\subsection{Reducing Measurement Dysfunction}

No tool can stop measurement dysfunction.  My philosophy is to acknowledge that
measurement dysfunction can occur in both personal software process improvement
and review.  To address these issues I allow the developer full control over
the data shared.  The developer can decide exactly what data is shared and edit
the data.  This raises the measurement issues from the background to the
foreground.  

Even though no tool can stop measurement dysfunction, an improperly designed
tool can create measurement dysfunction.  If the user feels they have no
control over their data, they may feel pressure to provide the ``right'' data
and modify their behavior accordingly.  This lack of control may encourage
measurement dysfunction.

In combining the above three threads of research I kept the four LEAP design
criteria in mind.  The Leap toolkit satisfies the four design criteria.  The
following section describes how the Leap toolkit satisfies the design criteria.

\subsection{Providing Light Weight Support}

The Leap toolkit tries to reduce the overhead of software developer
improvement by automating many of the data collection process and reducing the
analysis overhead by doing the difficult calculations and conversions.

The Leap toolkit, unlike the PSP or PSP Studio, does not impose any development
process on the developer.  If the developer wants to use the same process as
PSP2.1 they may. If user does not want to have a design phase, Leap will also
support that process.  The user can define their own processes and Leap will
support data collection and analyses based upon their processes.

The Leap toolkit also allows the user to define their own size types.  This
allows the user to choose a size measure that is more effective and/or
convenient than lines of code used in the PSP.

\subsection{Supporting Empirical Data Analysis}

The Leap toolkit allows the developer to record their effort, work product size
and the defects they make while developing software.  Based upon historical
projects the Leap toolkit helps the developer to produce an estimate for the
total amount of effort the next project will take. 


\subsection{Reducing Measurement Dysfunction}

The Leap toolkit stores all its data in ASCII files.  This allows the developer
to control the access to the data.  Also, the Leap toolkit gives developers
complete control over the data that they share. Developers have full control of
where they save their Leap data. When users use the Leap toolkit's email
capability to share their data, the Leap toolkit asks the user what data to
send.  No data is shared without the user's knowledge.

When ever the Leap toolkit is
sending data over the Internet it asks what data does the developer want to
send.

The toolkit also makes it very easy to edit the data before it is sent or
saved. We did this for two reasons. First, if there is a data collection error
then the user can edit the data to correct the error. Second, the user can edit 
their data before they provide it to another person.  This allows the user to
decide what data the other persons sees.

\subsection{Providing a Portable Tool}

Since the Leap toolkit is written in Java, it can run on many different computer 
platforms.  By using ASCII files for data storage users can easily put the
files on a disk or transfer them.  Both of these features allows the user to
take their data and the Leap toolkit with them when they move.

\section{Intended Benefits of Leap toolkit's design}

We designed the Leap toolkit to be flexible and easy to use, while supporting
developer improvement.  Three important benefits of the Leap toolkit's design
are: (1) it prevents errors, (2) it improves time estimation, and (3) it
reduces collection errors.

\subsection{The Leap toolkit prevents many important classes of errors found in 
  the PSP}
\label{sec:leap-bene3}

The Leap toolkit tries to address each category of data error in Disney's study.
Disney's research classified the data errors into seven categories
\begin{itemize}
\item{{\bf Calculation Error:} The Leap toolkit does all the calculation.  The
    user does not have to perform these calculations.}
\item{{\bf Blank Fields and Sequence Error:} One principle behind the Leap
    toolkit's design is that it should support minimal definitions. If the user
    does not fill in a field the Leap toolkit will do as much analysis as
    possible.}
\item{{\bf Inter- and Intra-Project Transfer Error:} The Leap toolkit handles
    all data transfer so the user does not have to copy data from one form to
    another.}
\item{{\bf Entry Error:} The Leap toolkit provides default values or pop-up
    menus for many of the important fields. This allows the user to choose from
    defined values reducing the chance that they will incorrectly fill in a
    field.}
\item{{\bf Impossible Values:} The Leap toolkit has a rudimentary consistency
    checker for some types of data.  This checker indicates to the user when
    data values are ``impossible''.}
\end{itemize}

\subsection{The Leap toolkit improves estimation and planning}

The Leap toolkit is designed to improve the developer's estimation and planning 
skills.  For estimating size, the Leap toolkit supports multiple size
representations. The user may choose a size representation that best fits their 
development process.  They can experiment with their size estimation abilities
by using different sizes and seeing which is best for them. For example a
developer can estimate the number of function points and methods that a project 
will be.  When they complete the project they can see which estimate was more
accurate. 

For time estimation based upon size estimate, the Leap toolkit supports
multiple estimation models.  The user can choose between averages, linear
regression, exponential regression, power regression and logarithmic
regression.  The Leap toolkit allows the user to use their planned size values
or their actual size values when making an time estimate.  This flexibility
allows the developer to find their best method of time estimation.

The Leap toolkit also allows the user to filter their data.  This allows the
user to match their historical data to the current project. By matching similar 
projects the user's estimates should be more accurate.

\subsection{The Leap toolkit reduces collection stage errors}

Automated support for entry removes simple data entry error.  For example the
user does not have to write down the time that they start working.  This
reduces the chance that they make a mistake.  Also the Leap toolkit displays
the current elapsed time.  This feedback allows the user to check and see if
the Leap toolkit is accurately recording what is happening.

Since the Leap toolkit lowers the user's overhead, it should reduce collection
stage errors.  The user is more likely to collect accurate data if it is easy
to collect.  High overhead will cause the user to not bother collecting data.
Also the ease of analysis shows the user the benefit of accurate collection of
data.  This should motivate them to collect good data.


The next chapter discusses how I plan to evaluate these three benefits of the
Leap toolkit.
