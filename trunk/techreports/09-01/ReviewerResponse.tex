%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ReviewerResponse.tex --     Automated Software Engineering submission
%% Author          : Philip Johnson 
%% Created On      : Tue Jan 06 10:41:51 2009
%% Last Modified By: Philip Johnson
%% Last Modified On: Mon Jul 13 11:18:28 2009
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 2009  Philip Johnson
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 

\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{url}             


\begin{document}
\title{Responses to Reviewer Comments for \\
Operational Definition and Automated Inference of Test-Driven Development with Zorro}
\author{Hongbing Kou \and Philip M. Johnson \and Hakan Erdogmus}
\date{July, 2009}

\maketitle

\section{Editor's comment and response}


\bigskip {\noindent \em The single most important issue is touched on by both Reviewer \#1 and Reviewer \#2 (\#1's first comment
and \#2's triple-starred (***) comment). Please make certain you address that one well.  Both reviewers
have asked for more detail on the JESS encoding of your rules (in different ways). Please consider
spending a few paragraphs on this issue as well as consider whether adding an appendix with the
rule base is feasible. Finally, you will see that the reviewers' advice with respect to the unsuccessful industrial 
case study are not the same. I would strongly prefer that you adhere to reviewer \#2's advice in this regard,
as I feel a slightly deeper explanation of it could provide useful information to the reader and any researchers
wishing to follow up on your work.}

\noindent Response: (forthcoming)


\section{Reviewer 1 comments and responses}


{\noindent \em My main problem with the paper is that it seems there is a consistency issue with the description of episode types (Figure 3). Specifically, TF-1/TF-2/TF-3/TF-4 which are the only TDD conformant episodes include in their definition RF-3/CP-1/CP-2/CP-3 which are context sensitive or even non conformant.  I refer to the sub-pattern 'code editing -$>$ test pass' that is at the end of TF-1/TF-2/TF-3/TF-4. This sub-pattern is actually RF-3/CP-1/CP-2/CP-3 with different explanations for 'code editing' that cover the code editing possibilities. The implication is that you do not have a way to determine a TDD conformant episode. Please explain.}

\noindent Response: Instead of calling RF-3/CP-1/CP-2/CP-3 sub-patterns of
TF-1/TF-2/TF-3/TF-4, you could say that TF-1/TF-2/TF-3/TF-4 are more  deterministic development behaviors as they follow a more rigid workflow.
If there weren't test case creation activities (determined by increase of test methods and/or assertion statements), an episode once classified as TF-X would be RF-3 or CP-X. To make things easier, we could simply classify all development
behavior as production. But doing so would not help us understand how Test-Driven Development stands out and is actually different from other development processes such as Test-Last Development and ad-hoc. In summary,  rules of TF-X episodes are more specific than rules of RF-3 and CP-X episodes. The JESS rule engine would apply the most specific rules applicable on an episode in the recognition process, in turn we could differentiate TF-X episodes from RF-3 and CP-X episodes.

\noindent Hakan:  The reviewer is righ in being confused here. I think we should explain this differently (I don't think the engine matches the most specific rule. It's effectively the opposite.).First, we state in the paper that "The definition column only gives a typical instance for each episode category. The implementation allows repetitions of certain sub-patterns inside." So the ambiguity is understandable. The episodes are delimited by "Test pass" subpatters. The "Test pass" subpattern is matched initially to split a development data into disjoint episodes. Then each episode is assigned to a category. To assign an episode into a category, every part of the episode must match a subpattern, starting from the beginning of an episode. Therefore, for an episode to be matched to a category, the first subpattern of the episode must be matched to the first subpattern specified by that category's definition. For example, an episode beginning with a "Code editing" would not be assigned to category TF-1, since the first subpattern in TF-1 is "Test creation". But if the subpattern satisfies an additional constraint (a decrease in number of statements or methods in the associated source file), and is immediately followed by a "Test pass" subpattern that terminates the episode, the episode is assigned to category RF-3. In terms of regular expression matching, this stragegy corresponds to having an explicit episode-begin token that must be matched for every category pattern. 

each episode category as prescribed by that category

\bigskip {\noindent \em In the introduction: It is suggested to add references when first mentioning Zorro.}

\noindent Response: \cite{csdl2-07-04}

\bigskip {\noindent \em ".. once installed, there is no overhead on the developer with respect to data collection" seems too strong. The process that is activated by the developer is surely affected even if minimally.}

\noindent Response: Hakan: We should stand by this claim. The data collection plug-in once installed is invisible to the developer. There is no discernible performance penalty for the developer, nor any impact on the developer's usual activities. 

\bigskip {\noindent  \em Section 2 is named 'related work' but starts with 2.1 which is the practice of TDD which is not related work. It is suggested to present TDD in a separate section leaving the last two paragraphs of 2.1 in the related work.}

\noindent Response: Hakan: Done. Section 2.1 has been moved to a separate section (except the last two paragraphs). The last two paragraphs of the former Section 2.1 becomes the first subsection of "Related Work" titled "Claims about TDD".


\bigskip {\noindent \em  Section 2.4 starts with the noun "Automated software process research systems" - it is suggested to rephrase for clarity.}

\noindent Response: Hakan: Done. Changed to "Research on automated inference of software process"

\bigskip {\noindent \em  Also in 2.4 -ISPW 6/7 is not referenced or explained. Hackystat is not referenced.   Please reference these.}

\noindent Response: \cite{ispw6} and \cite{Hackystat:06,csdl2-04-11,csdl2-04-22,csdl2-03-12} Detailed description to ISPW-6 can be found at http://www.idi.ntnu.no/~epos/ispw6.html. Hakan: Done. Added citations to the manuscript. 

\bigskip {\noindent \em  In Section 3.2: It seems that you assume a 'nice work' of the user as presented in Figure 2. Taking real data it is not always so clear. It is expected to see also an unclear example in order to get the feeling of the problem and its translating. You write about the need to do it but then delve immediately to the episodes.}

\noindent Response: Exactly! The main purpose of this section is to describe the mechanism behind Zorro on inferring development behavior of TDD if a developer is acutally doing it. In section 3.3 we move a step forward to discuss different
TDD development behavior variations. 

\bigskip {\noindent \em  Relating to Figure 2, how do we know that for example step 1 is test creation. It is not shown in the stream and not further explained.}

\noindent Response: On the fact that this chart is already too wordy we eliminated some metric data associated with development activities. Each activity is an aggregration of a series of snapshot of file metrics. Metrics of test code include number of test cases and assertations with which we could infer test creations if these two metrics increase.

\bigskip {\noindent \em  In section 3.2 the data should be better explained so the analysis you present will be clearer. }

\noindent Response: (forthcoming)

\bigskip {\noindent \em  The example in Figure 2 shows only one TDD iteration. Readers can benefit from a complete TDD example that shows few test-code steps and refactoring (as the practice states).}

\noindent Response: The following section(3.3) addresses more variation of TDD iterations including TF-1/TF-2/TF-3/TF-4/RF/CP etc. 

\bigskip {\noindent \em   Do we have any indication that the test is not empty (trivial pass) in Figure 2 step 5? If yes, please add it in text.}

\noindent Response: Yes. As mentioned before we know number of test cases and assertations. 

\bigskip {\noindent \em  The TDD iteration you selected for Figure 2 does not include a test-fail event but rather a compilation-error event. Is there a reason for that? Please add in text.}

\noindent Response: This example is from the begining of a development session in TDD. Following principals of TDD this developer just returned a constant to make the first trival test pass. The compilation error is automatically reported by the IDE because the production code under test had not been developed yet.


\bigskip {\noindent \em  In Section 3.3: Test creation is not explained. Is this for a class or a method? Both? }

\noindent Response: Not class but test cases and assertions.

\bigskip {\noindent \em  With respect to the TF-X definitions, can you elaborate on why you searched patterns that end with 'test pass' vs patterns that end with 'test fail'? This is another way to look at these rules and it can be of interest to the readers.}

\noindent Response: Completely agree. We plan to add more ways to tokenize development streams to other types of episodes to study development process 
other than TDD, one idea is to study when and how deveopers change from one artifact to another in development. The reason that we choose successful test run as end activity of an episode is that TDD advocates that developers should frequently run test suites to get rapid feedback and then make failing test work quickly (the stop-light metaphor). 

\bigskip {\noindent \em  Code editing as appears in the different episodes is not clear. Does it mean editing in a specific file? Specific method? Why 100 bytes is the number to differ between CP-2 and CP-3? How do you match test editing with the appropriate code editing? According to method? Class file? Please elaborate.}

\noindent Response: 100 is a magic number here and changing it to 200 or other values would not change its nature. This number tells whether there is  significant amount of work in an episode. If there is significant amount of work produced in a very short time period, a developer is likely not following TDD and likely copies and pastes code from elsewhere. 

\bigskip {\noindent \em  It is not clear why 'test editing -$>$ test pass' is necessarily refactoring (RF-1).}

\noindent Response: Because there is no test creation and we have the metrics
(test cases and assertions) to determine this.

\bigskip {\noindent \em  What between episodes and rules? Are these the same?}

\noindent Response: (forthcoming)

\bigskip {\noindent \em  For refactoring you may also check cyclomatic complexity so to not lean only on number of methods and statements.}

\noindent Response: It would be interesting to include it.

\bigskip {\noindent \em  Can you explain why the TF-X episodes do not include 'test editing' or why all start with 'test creation'? It seems odd for TDD conformant episodes.}

\noindent Response: Test editing means that test code has been changed but we
did not observe new test cases. If there were, we would claim the editing activity as test creation.  That said, new production code should be driven by failing unit tests in TDD so TF-X must have test creation(s). Developer can edit test code although the development process is Test-Last. 

\bigskip {\noindent \em  What is activity in LN-1? It seems everything is included in LN-1.}

\noindent Response: Short-iteeration is a characteristic of TDD and an iteration should last a few seconds to several minutes only. And developers can only have limited number of activities in such a short period of time. The development process would most likely be ad-hoc not TDD if hundred development activities are contributed. LN-1 is defined so that TDD recognition rules won't be evaluated on these kinds of software development process.

\bigskip {\noindent \em  In Section 3.4: The terminology is changed in Figure 4: in the first case shown in the figure? does production edit is code edit? If so it is CP-2 and it is unambiguous. }

\noindent Response: Yes. Agree.

\bigskip {\noindent \em  The second case in Figure 2 seems as RF-1 and CP-2 so why TDD conformant?}

\noindent Response: (forthcoming)

\bigskip {\noindent \em  How come that the associated file is not applicable? (p. 17 line 29-30)}

\noindent Response: This is due to the fact that the IDE can fire a build event without associating this activity with a file. 

\bigskip {\noindent \em  Does event type in the UI is activity? Also, in Figure 5 does PR is CP?}

\noindent Response: Yes, it is episode type. 

\bigskip {\noindent \em  You refer to real world data in p. 18 line 47. Please elaborate if this is from one person? A team? With pair programming? Without? Which kind of a project? Skills and experience? Etc.}

\noindent Response: This data is from a single developer without pair-programming. We use this chart to illustrate the capability of analysis one can do with Zorro. We did not use data from a case study or experiment. 

\bigskip {\noindent \em  How do you explain Figure 7? You write it is interesting still do not give any further discussion. }

\noindent Response: "This seems to resonate the statement that TDD helps to improve code coverage." (Philip, can you word it better)

\bigskip {\noindent \em  In Section 4:  In the introduction you write that you have industrial-based case studies. It was expected to see them here (Section 4). Then I saw you mentioned them in Section 5 mainly to say it didn't go well yet. I suggest omitting all sentences with this respect (from the introduction and section 5). Of course it can be mentioned as future direction without all the explanations why it didn't go well so far).}

\noindent Response: Do we want to massage our experiemnt to make this paper look better?  Guess we wouldn't from science point of view. The lessons learned should benefit others who might consider doing the same.

\section{Reviewer 2 comments and responses}


This is a very well written paper, describing interesting work on a significant issue, namely measuring and
reporting on compliance with a defined process.  I have a few questions/comments below, but basically
feel it is a strong manuscript.

\bigskip {\noindent \em  Please provide a reference for Hackystat in sec 3.1}

\noindent Response: (forthcoming)

\bigskip {\noindent \em  [sec 3.1, "SDSA" subsection] What if a developer works on
  two or more independent problems (e.g. failing tests) concurrently?
  Can your tool find two episodes whose events overlap in time?
  E.g., Create test1. Create test2. Test1 fail. Test2 fail. Edit sourcefile 1.
  Edit sourcefile 2. Compile. Test1 pass. Test2 pass. 
  If so, please say this and explain briefly how it does this.
  If not, please discuss this possibility and explain if it is a limitation and
  whether it arises in practice.}

\noindent Response: Yes in most case. The metrics we collect are file-based. That said, if you can differentiate files of project A from file of projects B based on their  locations, then you could be abke to analyze them separately.
But if they happen to sit in the same folder, then it would be a problem.

\bigskip {\noindent \em  [sec 3.3] Are the JESS rules 1-for-1 with the lines of Figure 3, or are they
  more involved?  Please discuss this encoding and any issues it raises.
  Also, please provide the JESS rule base as an appendix if this is feasible.
  (I.e. if this is, say, $<$= 5 pages) Otherwise, is the rulebase available on the web?
  In any case, we need some discussion of the JESS-encoding and statistics about how
  many rules, possibly a brief discussion of run-time complexity of JESS on this problem.}

\noindent Response: (forthcoming)


\bigskip {\noindent \em  *** [Fig 3 and text surrounding] Some of your definitions appear to intersect, such as one
  is a superset (prefix, suffix, etc) of another. Does your rule matching always choose
  the longest possible match or the most specific match, both of which are pretty common
  in Rule Based Systems applications? Or do you have some other parsing strategy? 
  Please discuss/clarify.  E.g. RF-3 is a suffix of TF-1.}

\noindent Response: The most specific rules are matched in episode recognition.
Philip, can you add a paragraph to describe this. The first reviewer has this question as well.

\bigskip {\noindent \em  Please provide a reference for JESS the first time it is mentioned.}

\noindent Response: \cite{Friedman-Hill:03}

\bigskip {\noindent \em  [sec 5] Please move the discussion of the failed industrial case study from here
  to sec 4 (e.g. a new sec 4.3). Please explain the circumstances you feel led to failure,
  to the extent possible without revealing proprietary information or being gratuitously
  ad hominem.  (E.g. I don't want a full explanation of whose fault anything was, just
  a high level understanding of the main issues: did the prototype not work in the
  industrial IT architecture, time or cost constraints intervened, or what?)}

\noindent Response: (forthcoming) Philippe, can you address this?

\bibliographystyle{spbasic}      % basic style, author-year citations
\bibliography{tdd,zorro,csdl-trs,hackystat,psp}
\end{document}
