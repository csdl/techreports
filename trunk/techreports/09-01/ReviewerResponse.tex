%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% -*- Mode: Latex -*- %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ReviewerResponse.tex --     Automated Software Engineering submission
%% Author          : Philip Johnson 
%% Created On      : Tue Jan 06 10:41:51 2009
%% Last Modified By: Philip Johnson
%% Last Modified On: Wed Sep 23 11:52:56 2009
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Copyright (C) 2009  Philip Johnson
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% 

\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{url}             


\begin{document}
\title{Responses to Reviewer Comments for \\
Operational Definition and Automated Inference of Test-Driven Development with Zorro}
\author{Hongbing Kou \and Philip M. Johnson \and Hakan Erdogmus}
\date{September, 2009}

\maketitle

\section{Editor's comments and responses}


\bigskip {\noindent \em The single most important issue is touched on by both Reviewer \#1 and Reviewer \#2 (\#1's first comment
and \#2's triple-starred (***) comment). Please make certain you address that one well.  Both reviewers
have asked for more detail on the JESS encoding of your rules (in different ways). Please consider
spending a few paragraphs on this issue as well as consider whether adding an appendix with the
rule base is feasible.}

\noindent Response: the paper now provides more detail on the JESS encoding.   The rule base is rather large for an appendix, so the paper now includes a link to the JESS rule base. 

\bigskip {\noindent \em 
Finally, you will see that the reviewers' advice with respect to the unsuccessful industrial 
case study are not the same. I would strongly prefer that you adhere to reviewer \#2's advice in this regard,
as I feel a slightly deeper explanation of it could provide useful information to the reader and any researchers
wishing to follow up on your work.}

\noindent Response: The paper now includes more detail. 


\section{Reviewer 1 comments and responses}


{\noindent \em My main problem with the paper is that it seems there is a consistency issue with the description of episode types (Figure 3). Specifically, TF-1/TF-2/TF-3/TF-4 which are the only TDD conformant episodes include in their definition RF-3/CP-1/CP-2/CP-3 which are context sensitive or even non conformant.  I refer to the sub-pattern 'code editing -$>$ test pass' that is at the end of TF-1/TF-2/TF-3/TF-4. This sub-pattern is actually RF-3/CP-1/CP-2/CP-3 with different explanations for 'code editing' that cover the code editing possibilities. The implication is that you do not have a way to determine a TDD conformant episode. Please explain.}

\noindent The reviewer is justifiably confused.  We have improved the
presentation of episode types and rule matching. In general, the "Test pass" subpattern is matched initially
to split a development data into disjoint episodes. Then, each episode is
assigned to a category. To assign an episode into a category, every part of
the episode must match a subpattern, starting from the beginning of an
episode. Therefore, for an episode to be matched to a category, the first
subpattern of the episode must be matched to the first subpattern specified
by that category's definition. For example, an episode beginning with a
"Code editing" would not be assigned to category TF-1, since the first
subpattern in TF-1 is "Test creation". But if the subpattern satisfies an
additional constraint (a decrease in number of statements or methods in the
associated source file), and is immediately followed by a "Test pass"
subpattern that terminates the episode, the episode is assigned to category
RF-3. In terms of regular expression matching, this stragegy corresponds to
having an explicit episode-begin token that must be matched for every
category pattern.

\bigskip {\noindent \em In the introduction: It is suggested to add references when first mentioning Zorro.}

\noindent Response: Done.

\bigskip {\noindent \em ".. once installed, there is no overhead on the developer with respect to data collection" seems too strong. The process that is activated by the developer is surely affected even if minimally.}

\noindent Response: We have softened our wording: ``Zorro is unobtrusive:  
it works in the background listening on the events of interest in the environment 
in which it is installed. It does not require input from the developer. 
However it incurs a small performance penalty, which depends on the environment." 


\bigskip {\noindent  \em Section 2 is named 'related work' but starts with 2.1 which is the practice of TDD which is not related work. It is suggested to present TDD in a separate section leaving the last two paragraphs of 2.1 in the related work.}

\noindent Response: Done. 

\bigskip {\noindent \em  Section 2.4 starts with the noun "Automated software process research systems" - it is suggested to rephrase for clarity.}

\noindent Response: Done. Changed to "Research on automated inference of software process"

\bigskip {\noindent \em  Also in 2.4 -ISPW 6/7 is not referenced or explained. Hackystat is not referenced.   Please reference these.}

\noindent Response: Done.

\bigskip {\noindent \em  In Section 3.2: It seems that you assume a 'nice work' of the user as presented in Figure 2. Taking real data it is not always so clear. It is expected to see also an unclear example in order to get the feeling of the problem and its translating. You write about the need to do it but then delve immediately to the episodes.}

\noindent Response: Section 3.2 is intentionally designed to introduce the user to our approach using a simple, ``clean'' example.  We disagree with the claim that we ``assume a 'nice work' of the user'': the last paragraph of Section 3.2 explicitly stated that real-world development is more complicated than this introductory example.   Having said that, we have added an example of a more challenging scenario to the end of Section 3.2 to make the point more clear. 


\bigskip {\noindent \em  Relating to Figure 2, how do we know that for example step 1 is test creation. It is not shown in the stream and not further explained.}

\noindent Response: More detail added to clarify this.

\bigskip {\noindent \em  In section 3.2 the data should be better explained so the analysis you present will be clearer. }

\noindent Response: Done.

\bigskip {\noindent \em  The example in Figure 2 shows only one TDD iteration. Readers can benefit from a complete TDD example that shows few test-code steps and refactoring (as the practice states).}

\noindent Response: The example in Figure 2 shows two TDD iterations.  The following section explains several other variations.  

\bigskip {\noindent \em   Do we have any indication that the test is not empty (trivial pass) in Figure 2 step 5? If yes, please add it in text.}

\noindent Response:  Yes, we know that because we know the size of methods and whether they contain test cases and assertations. More detail is added.

\bigskip {\noindent \em  The TDD iteration you selected for Figure 2 does not include a test-fail event but rather a compilation-error event. Is there a reason for that? Please add in text.}

\noindent Response: Done.

\bigskip {\noindent \em  In Section 3.3: Test creation is not explained. Is this for a class or a method? Both? }

\noindent Response: Not class but test methods and assertions. More detail added.

\bigskip {\noindent \em  With respect to the TF-X definitions, can you elaborate on why you searched patterns that end with 'test pass' vs patterns that end with 'test fail'? This is another way to look at these rules and it can be of interest to the readers.}

\noindent Response: Zorro's purpose is to analyze TDD and its variants that
operate on the principle of incremental development. In TDD, test-passes
are landmark events. They indicate the end of an incremental development
cycle. Test fails represent transient states and happen often. Episodes
delimited by test-fail events are not in themselves meaningful.

\bigskip {\noindent \em  Code editing as appears in the different episodes is not clear. Does it mean editing in a specific file? Specific method? Why 100 bytes is the number to differ between CP-2 and CP-3? How do you match test editing with the appropriate code editing? According to method? Class file? Please elaborate.}

\noindent Response: 100 is just a threshold we use in the heuristic to
signify significant work. Minor code editing is permitted, but editing
significant amount of new production code without running tests
(e.g. either adding a large chunk of functionality, or a big refactoring)
in one increment, i.e., in a single episode, would be counter to TDD.  We have 
added additional explanation to clarify this.

\bigskip {\noindent \em  It is not clear why 'test editing -$>$ test pass' is necessarily refactoring (RF-1).}

\noindent Response: Because if there is no test creation (and we have the
metrics on test methods and assertions to determine that) or no production
editing, then the episode is about refactoring existing tests. Test code is
code and may be subject to refactoring. This is now explained in the text.

\bigskip {\noindent \em  What between episodes and rules? Are these the same?}

\noindent Response: Rules are used to infer the action types, episode types, and episode conformance. Now explained in beginning of section 3.3.

\bigskip {\noindent \em  For refactoring you may also check cyclomatic complexity so to not lean only on number of methods and statements.}

\noindent Response: Agreed, this would be an interesting issue for further research.

\bigskip {\noindent \em  Can you explain why the TF-X episodes do not include 'test editing' or why all start with 'test creation'? It seems odd for TDD conformant episodes.}

\noindent Response: Test editing means that test code has been changed but
we did not observe new test cases. If there were, we would claim the
editing activity as test creation.  That said, new production code should
be driven by failing unit tests in TDD so TF-X must have test
creation(s). Developer can edit test code although the development process
is Test-Last.

\bigskip {\noindent \em  What is activity in LN-1? It seems everything is included in LN-1.}

\noindent Response: TDD is an incremental process and as such a large amount of work should not be performed without running and passing tests. Such long duration episodes are detected by a preset threshold. We have added additional explanation to the text.


\bigskip {\noindent \em  In Section 3.4: The terminology is changed in Figure 4: in the first case shown in the figure? does production edit is code edit? If so it is CP-2 and it is unambiguous. }

\noindent Response: Code edit and production edit are synonyms. We have edited the text to use ``production code edit'' uniformly. 


\bigskip {\noindent \em  The second case in Figure 2 seems as RF-1 and CP-2 so why TDD conformant?}

\noindent Response: We assume the reviewer is referring to Figure 4. We have updated the text to explain more clearly why it is TDD conformant.

\bigskip {\noindent \em  How come that the associated file is not applicable? (p. 17 line 29-30)}

\noindent Response: This is due to the fact that the IDE can fire a build event without associating this activity with a file. 

\bigskip {\noindent \em  Does event type in the UI is activity? Also, in Figure 5 does PR is CP?}

\noindent Response: Yes, it is an episode type. 

\bigskip {\noindent \em  You refer to real world data in p. 18 line 47. Please elaborate if this is from one person? A team? With pair programming? Without? Which kind of a project? Skills and experience? Etc.}

\noindent Response: Contextual information added.

\bigskip {\noindent \em  How do you explain Figure 7? You write it is interesting still do not give any further discussion. }

\noindent Response: "This seems to resonate the statement that TDD helps to improve code coverage." (Philip, can you word it better)

\bigskip {\noindent \em  In Section 4:  In the introduction you write that you have industrial-based case studies. It was expected to see them here (Section 4). Then I saw you mentioned them in Section 5 mainly to say it didn't go well yet. I suggest omitting all sentences with this respect (from the introduction and section 5). Of course it can be mentioned as future direction without all the explanations why it didn't go well so far).}

\noindent Response: Do we want to massage our experiemnt to make this paper look better?  Guess we wouldn't from science point of view. The lessons learned should benefit others who might consider doing the same.

\section{Reviewer 2 comments and responses}


This is a very well written paper, describing interesting work on a significant issue, namely measuring and
reporting on compliance with a defined process.  I have a few questions/comments below, but basically
feel it is a strong manuscript.

\bigskip {\noindent \em  Please provide a reference for Hackystat in sec 3.1}

\noindent Response: (forthcoming)

\bigskip {\noindent \em  [sec 3.1, "SDSA" subsection] What if a developer works on
  two or more independent problems (e.g. failing tests) concurrently?
  Can your tool find two episodes whose events overlap in time?
  E.g., Create test1. Create test2. Test1 fail. Test2 fail. Edit sourcefile 1.
  Edit sourcefile 2. Compile. Test1 pass. Test2 pass. 
  If so, please say this and explain briefly how it does this.
  If not, please discuss this possibility and explain if it is a limitation and
  whether it arises in practice.}

\noindent Response: Yes in most case. The metrics we collect are file-based. That said, if you can differentiate files of project A from file of projects B based on their  locations, then you could be abke to analyze them separately.
But if they happen to sit in the same folder, then it would be a problem.

\bigskip {\noindent \em  [sec 3.3] Are the JESS rules 1-for-1 with the lines of Figure 3, or are they
  more involved?  Please discuss this encoding and any issues it raises.
  Also, please provide the JESS rule base as an appendix if this is feasible.
  (I.e. if this is, say, $<$= 5 pages) Otherwise, is the rulebase available on the web?
  In any case, we need some discussion of the JESS-encoding and statistics about how
  many rules, possibly a brief discussion of run-time complexity of JESS on this problem.}

\noindent Response: (forthcoming)


\bigskip {\noindent \em  *** [Fig 3 and text surrounding] Some of your definitions appear to intersect, such as one
  is a superset (prefix, suffix, etc) of another. Does your rule matching always choose
  the longest possible match or the most specific match, both of which are pretty common
  in Rule Based Systems applications? Or do you have some other parsing strategy? 
  Please discuss/clarify.  E.g. RF-3 is a suffix of TF-1.}

\noindent Response: The most specific rules are matched in episode recognition.
Philip, can you add a paragraph to describe this. The first reviewer has this question as well.

\bigskip {\noindent \em  Please provide a reference for JESS the first time it is mentioned.}

\noindent Response: \cite{Friedman-Hill:03}

\bigskip {\noindent \em  [sec 5] Please move the discussion of the failed industrial case study from here
  to sec 4 (e.g. a new sec 4.3). Please explain the circumstances you feel led to failure,
  to the extent possible without revealing proprietary information or being gratuitously
  ad hominem.  (E.g. I don't want a full explanation of whose fault anything was, just
  a high level understanding of the main issues: did the prototype not work in the
  industrial IT architecture, time or cost constraints intervened, or what?)}

\noindent Response: (forthcoming) Philippe, can you address this?

\bibliographystyle{spbasic}      % basic style, author-year citations
\bibliography{tdd,zorro,csdl-trs,hackystat,psp}
\end{document}
