@inproceedings{citeulike:4025073,
	abstract = {Time series data poses a significant variation to the traditional segmentation techniques of data mining because the observation is derived from multiple instances of the same underlying record. Additionally, the standard segmentation methods employed in traditional clustering require instances to be classified exactly by attaching an event to a specific cluster at the exclusion of other clusters. This paper is an investigation into the predictive power of the clustering technique on stock market data and its ability to provide stock predictions that can be utilised in strategies that outperform the underlying market. This uses a brute force approach to the prediction of stock prices based on the formation of a cluster around the query sequence. The prediction is then applied in a model designed to capitalise on the derived prediction. The predictive accuracy of minimum distance clusters produced promising results with a prediction error incorporated into the forecast strategy.},
	address = {Darlinghurst, Australia, Australia},
	author = {Nayak, Richi   and Braak, Paul  T. },
	booktitle = {AIDM '07: Proceedings of the 2nd international workshop on Integrating artificial intelligence and data mining},
	citeulike-article-id = {4025073},
	isbn = {978-1-920682-65-1},
	keywords = {litreview, similarity, thesis},
	location = {Gold Coast, Australia},
	pages = {95--103},
	posted-at = {2009-02-09 09:56:43},
	priority = {2},
	publisher = {Australian Computer Society, Inc.},
	title = {Temporal pattern matching for the prediction of stock prices},
	url = {http://portal.acm.org/citation.cfm?id=1386993.1387003},
	year = {2007}
}



@article{citeulike:973785,
	address = {New York, NY, USA},
	author = {Li, Tao   and Li, Qi   and Zhu, Shenghuo   and Ogihara, Mitsunori  },
	citeulike-article-id = {973785},
	doi = {http://dx.doi.org/10.1145/772862.772870},
	issn = {1931-0145},
	journal = {SIGKDD Explor. Newsl.},
	keywords = {litreview, thesis, wavelet},
	month = {December},
	number = {2},
	pages = {49--68},
	posted-at = {2009-02-09 09:54:19},
	priority = {2},
	publisher = {ACM Press},
	title = {A survey on wavelet applications in data mining},
	url = {http://dx.doi.org/10.1145/772862.772870},
	volume = {4},
	year = {2002}
}



@article{citeulike:2693625,
	address = {New York, NY, USA},
	author = {Maier, David  },
	citeulike-article-id = {2693625},
	doi = {http://dx.doi.org/10.1145/322063.322075},
	issn = {0004-5411},
	journal = {J. ACM},
	keywords = {lcs, litreview, thesis},
	month = {April},
	number = {2},
	pages = {322--336},
	posted-at = {2009-02-09 09:33:53},
	priority = {2},
	publisher = {ACM},
	title = {The Complexity of Some Problems on Subsequences and Supersequences},
	url = {http://dx.doi.org/10.1145/322063.322075},
	volume = {25},
	year = {1978}
}



@inproceedings{citeulike:4024793,
	abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article.  ACM has opted to expose the complete List rather than only correct and linked references.},
	address = {New York, NY, USA},
	author = {Hadlock, F. },
	booktitle = {IEA/AIE '88: Proceedings of the 1st international conference on Industrial and engineering applications of artificial intelligence and expert systems},
	citeulike-article-id = {4024793},
	doi = {http://dx.doi.org/10.1145/55674.55676},
	isbn = {0-89791-271-3},
	keywords = {lcs, litreview, thesis},
	location = {Tullahoma, Tennessee, United States},
	pages = {645--653},
	posted-at = {2009-02-09 09:31:17},
	priority = {2},
	publisher = {ACM},
	title = {An efficient algorithm for pattern detection and classification},
	url = {http://dx.doi.org/10.1145/55674.55676},
	year = {1988}
}



@inproceedings{citeulike:2659746,
	abstract = {The aim of this paper is to give a comprehensive comparison of well-known longest common subsequence algorithms (for two input strings) and study their behaviour in various application environments. The performance of the methods depends heavily on the properties of the problem instance as well as the supporting data structures used in the implementation. We want to make also a clear distinction between methods that determine the actual lcs and those calculating only its length, since the execution time and more importantly, the space demand depends crucially on the type of the task. To our knowledge, this is the first time this kind of survey has been done. Due to the page limits, the paper gives only a coarse overview of the performance of the algorithms; more detailed studies are reported elsewhere},
	author = {Bergroth, L.  and Hakonen, H.  and Raita, T. },
	booktitle = {String Processing and Information Retrieval, 2000. SPIRE 2000. Proceedings. Seventh International Symposium on},
	citeulike-article-id = {2659746},
	doi = {http://dx.doi.org/10.1109/SPIRE.2000.878178},
	journal = {String Processing and Information Retrieval, 2000. SPIRE 2000. Proceedings. Seventh International Symposium on},
	keywords = {lcs, litreview, thesis},
	pages = {39--48},
	posted-at = {2009-02-09 09:26:20},
	priority = {2},
	title = {A survey of longest common subsequence algorithms},
	url = {http://dx.doi.org/10.1109/SPIRE.2000.878178},
	year = {2000}
}



@inproceedings{citeulike:4022060,
	abstract = {Monitoring predefined patterns in streaming time series is useful to applications such as trend-related analysis, sensor networks and video surveillance. Most current studies on such monitoring employ Euclidean distance to calculate the similarities between given query patterns and subsequences of streaming time series. Euclidean distance has been shown to be ineffective in measuring distances of time series in which shifting and scaling usually exist. Consequently, warping distances such as dynamic time warping (DTW), longest common subsequence (LCSS), have been proposed to handle warps in temporal dimension. However, they are inadequate in handling shifting and scaling in amplitude dimension. Moreover, they have been designed mainly for full sequence matching, whereas in online monitoring applications, we typically have no knowledge on the positions and lengths of possible matching subsequences. In this paper, we first discuss the weaknesses of existing warping distances on detecting patterns from streaming time series. We then propose a novel warping distance, which we name Spatial Assembling Distance (SpADe), that is able to handle shifting and scaling in both temporal and amplitude dimensions. We further propose an efficient approach for continuous pattern detection using SpADe, that is fundamental for subsequence matching on streaming data. Finally, our experimental results show that SpADe is effective and efficient for continuous pattern detection in streaming time series.},
	author = {Chen, Yueguo   and Nascimento, M. A.  and Ooi, Beng  C.  and Tung, A. K. H. },
	booktitle = {Data Engineering, 2007. ICDE 2007. IEEE 23rd International Conference on},
	citeulike-article-id = {4022060},
	doi = {http://dx.doi.org/10.1109/ICDE.2007.367924},
	journal = {Data Engineering, 2007. ICDE 2007. IEEE 23rd International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {786--795},
	posted-at = {2009-02-07 17:10:12},
	priority = {2},
	title = {SpADe: On Shape-based Pattern Detection in Streaming Time Series},
	url = {http://dx.doi.org/10.1109/ICDE.2007.367924},
	year = {2007}
}



@inproceedings{citeulike:4022058,
	abstract = {Matching video segments in order to detect their similarity is a necessary task in retrieval and summarization applications. In order to determine nearly identical content, such as repeated takes of the same scene, very precise matching of sequences of features extracted from the video segments needs to be performed. In this paper we compare the performance of three distance measures for the task of clustering multiple takes of the same scene: dynamic time warping (DTW) and two variants of longest common subsequence (LCSS). We also evaluate the influence of the quality of the input segmentation on the performance of the algorithms.},
	author = {Bailer, W. },
	booktitle = {Database and Expert Systems Application, 2008. DEXA '08. 19th International Conference on},
	citeulike-article-id = {4022058},
	doi = {http://dx.doi.org/10.1109/DEXA.2008.26},
	journal = {Database and Expert Systems Application, 2008. DEXA '08. 19th International Conference on},
	pages = {595--599},
	posted-at = {2009-02-07 17:06:10},
	priority = {2},
	title = {A Comparison of Distance Measures for Clustering Video Sequences},
	url = {http://dx.doi.org/10.1109/DEXA.2008.26},
	year = {2008}
}



@article{citeulike:4021682,
	abstract = {In a way similar to the string-to-string correction problem, we address discrete time series similarity in light of a time-series-to-time-series-correction problem for which the similarity between two time series is measured as the minimum cost sequence of edit operations needed to transform one time series into another. To define the edit operations, we use the paradigm of a graphical editing process and end up with a dynamic programming algorithm that we call time warp edit distance (TWED). TWED is slightly different in form from dynamic time warping (DTW), longest common subsequence (LCSS), or edit distance with real penalty (ERP) algorithms. In particular, it highlights a parameter that controls a kind of stiffness of the elastic measure along the time axis. We show that the similarity provided by TWED is a potentially useful metric in time series retrieval applications since it could benefit from the triangular inequality property to speed up the retrieval process while tuning the parameters of the elastic measure. In that context, a lower bound is derived to link the matching of time series into down sampled representation spaces to the matching into the original space. The empiric quality of the TWED distance is evaluated on a simple classification task. Compared to edit distance, DTW, LCSS, and ERP, TWED has proved to be quite effective on the considered experimental task.},
	author = {Marteau, P. F. },
	booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	citeulike-article-id = {4021682},
	doi = {http://dx.doi.org/10.1109/TPAMI.2008.76},
	journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	number = {2},
	pages = {306--318},
	posted-at = {2009-02-07 14:07:24},
	priority = {2},
	title = {Time Warp Edit Distance with Stiffness Adjustment for Time Series Matching},
	url = {http://dx.doi.org/10.1109/TPAMI.2008.76},
	volume = {31},
	year = {2009}
}



@book{citeulike:1454223,
	abstract = {{A timeless classic in how complex information should be presented graphically.  The Strunk \& White  of visual design. Should occupy a place of honor--within arm's reach--of everyone  attempting to understand or depict numerical data graphically.  The design of the book is an exemplar of the principles it espouses:  elegant typography and layout, and seamless integration of lucid text and perfectly chosen graphical examples. Very Highly Recommended.}},
	author = {Tufte, Edward  R. },
	citeulike-article-id = {1454223},
	howpublished = {Hardcover},
	isbn = {096139210X},
	keywords = {dtw, litreview, thesis},
	posted-at = {2009-02-06 14:23:45},
	priority = {2},
	publisher = {{Graphics Press}},
	title = {The Visual Display of Quantitative Information},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/096139210X}
}



@inproceedings{citeulike:4015923,
	abstract = {Visualisations play an important part in the development of ideas. They make ingredients and relations explicit, guide thinking processes of the designer or scientist, and support communications, often across the boundaries of disciplines. In the fields of cognitive psychology and human-machine interaction, block diagrams have been a dominant means for representing cognitive systems. However, we believe that this form of representation may constrain how we think about cognition in undesirable ways. This form of representation biases viewers to see cognition as a sequential, step-by-step process, under emphasizing the dynamical properties of closed-loop, adaptive processes. Block diagrams emphasize activity and internal mental operations (awareness) and occlude the ecological or work domain (situational) constraints},
	author = {Stappers, P. J.  and Flach, J. M. },
	booktitle = {Systems, Man and Cybernetics, 2004 IEEE International Conference on},
	citeulike-article-id = {4015923},
	doi = {http://dx.doi.org/10.1109/ICSMC.2004.1398404},
	journal = {Systems, Man and Cybernetics, 2004 IEEE International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {821--826 vol.1},
	posted-at = {2009-02-06 14:04:52},
	priority = {2},
	title = {Visualizing cognitive systems: getting past block diagrams},
	url = {http://dx.doi.org/10.1109/ICSMC.2004.1398404},
	volume = {1},
	year = {2004}
}



@article{citeulike:3994742,
	author = {Tinbergen, J. },
	citeulike-article-id = {3994742},
	journal = {Zeitschrift f\"{u}r National- \"{o}konomie 1},
	pages = {669--679},
	posted-at = {2009-02-02 11:58:41},
	priority = {2},
	title = {Bestimmung und Deutung von Angebotskurven. Ein Beispiel.},
	year = {1930}
}



@misc{citeulike:3994561,
	author = {Hanau, A. },
	citeulike-article-id = {3994561},
	institution = {Vierteljahrshefte zur Konjunkturforschung 7},
	keywords = {dtw, litreview, thesis},
	posted-at = {2009-02-02 11:40:50},
	priority = {2},
	publisher = {Vierteljahrshefte zur Konjunkturforschung 7},
	title = {Die Prognose der Schweinepreise},
	year = {1928}
}



@misc{citeulike:3994263,
	author = {Koopmans, T. C. },
	citeulike-article-id = {3994263},
	institution = {Netherlands Economic Institute},
	keywords = {dtw, litreview, thesis},
	location = {Haarlem},
	posted-at = {2009-02-02 11:33:05},
	priority = {2},
	publisher = {Netherlands Economic Institute},
	title = {Linear Regression Analysis of Economic Time Series},
	year = {1937}
}



@inproceedings{citeulike:1237593,
	author = {Fu, Ada  W.  and Keogh, Eamonn   and Leo and Ratanamahatana, Chotirat  A. },
	booktitle = {VLDB '05: Proceedings of the 31st international conference on Very large data bases},
	citeulike-article-id = {1237593},
	isbn = {1595931546},
	pages = {649--660},
	posted-at = {2009-02-01 20:27:56},
	priority = {2},
	publisher = {VLDB Endowment},
	title = {Scaling and time warping in time series querying},
	url = {http://portal.acm.org/citation.cfm?id=1083592.1083668},
	year = {2005}
}



@article{citeulike:1082000,
	abstract = {Senior Member-Walid G. Aref and Senior Member-Ahmed K. Elmagarmid},
	address = {Piscataway, NJ, USA},
	author = {Elfeky, Mohamed  G. },
	citeulike-article-id = {1082000},
	doi = {http://dx.doi.org/10.1109/TKDE.2005.114},
	issn = {1041-4347},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	month = {July},
	number = {7},
	pages = {875--887},
	posted-at = {2009-02-01 20:11:27},
	priority = {2},
	publisher = {IEEE Educational Activities Department},
	title = {Periodicity Detection in Time Series Databases},
	url = {http://dx.doi.org/10.1109/TKDE.2005.114},
	volume = {17},
	year = {2005}
}



@inproceedings{citeulike:825581,
	address = {New York, NY, USA},
	author = {Faloutsos, Christos   and Ranganathan, M.  and Manolopoulos, Yannis  },
	booktitle = {SIGMOD '94: Proceedings of the 1994 ACM SIGMOD international conference on Management of data},
	citeulike-article-id = {825581},
	doi = {http://dx.doi.org/10.1145/191839.191925},
	issn = {0163-5808},
	keywords = {dtw, litreview, thesis},
	pages = {419--429},
	posted-at = {2009-02-01 20:11:02},
	priority = {2},
	publisher = {ACM Press},
	title = {Fast subsequence matching in time-series databases},
	url = {http://dx.doi.org/10.1145/191839.191925},
	year = {1994}
}



@article{citeulike:3991527,
	author = {Young, P.  and Shellswell, S. },
	booktitle = {Automatic Control, IEEE Transactions on},
	citeulike-article-id = {3991527},
	journal = {Automatic Control, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {2},
	pages = {281--283},
	posted-at = {2009-02-01 16:52:35},
	priority = {2},
	title = {Time series analysis, forecasting and control},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1099963},
	volume = {17},
	year = {1972}
}



@book{citeulike:3449765,
	abstract = {Time Series Analysis With Applications in R, Second Edition, presents an
accessible approach to understanding time series models and their
applications. Although the emphasis is on time domain ARIMA models and their
analysis, the new edition devotes two chapters to the frequency domain and
three to time series regression models, models for heteroscedasticity, and
threshold models. All of the ideas and methods are illustrated with both real
and simulated data sets.

A unique feature of this edition is its integration with the R computing
environment. The tables and graphical displays are accompanied by the R
commands used to produce them. An extensive R package, TSA, which contains
many new or revised R functions and all of the data used in the book,
accompanies the written text. Script files of R commands for each chapter are
available for download. There is also an extensive appendix in the book that
leads the reader through the use of R commands and the new R package to carry
out the analyses.},
	author = {Cryer, Jonathan  D.  and Chan, Kung-Sik  },
	citeulike-article-id = {3449765},
	edition = {2nd},
	howpublished = {Hardcover},
	isbn = {0387759581},
	keywords = {dtw, litreview, thesis},
	month = {October},
	posted-at = {2009-02-01 12:18:27},
	priority = {2},
	publisher = {Springer},
	title = {Time Series Analysis: With Applications in R (Springer Texts in Statistics)},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387759581},
	year = {2008}
}



@book{citeulike:2206845,
	abstract = {{<B>Time Series: Theory and Methods</B> is a systematic account of linear time series models and their application to the modelling and prediction of data collected sequentially in time. The aim is to provide specific techniques for handling data and at the same time to provide a thorough understanding of the mathematical basis for techniques. Both time and frequency domain methods are discussed, but the book is written in such a way that either approach could be emphasized. The book intended to be a text for graduate students in statistics, mathematics, engineering, and the natural or social sciences. It contains substantial chapters on multivariate series and state-space models (including applications of the Kalman recursions to missing-value problems) and shorter accounts of special topics including long-range dependence, infinite variance processes and non-linear models. Most of the programs used in the book are available on diskettes for the IBM-PC. These diskettes, with the accompanying manual, <I>ITSM: The Interactive Time Series</I> <I>Modelling </I> <I>Package</I> <I> for the</I> <I>PC</I>, also by Brockwell and Davis, can be purchased from Springer-Verlag.}},
	author = {Brockwell, Peter  J.  and Davis, Richard  A. },
	citeulike-article-id = {2206845},
	howpublished = {Hardcover},
	isbn = {0387974296},
	keywords = {dtw, litreview, thesis},
	month = {September},
	posted-at = {2009-02-01 11:02:02},
	priority = {2},
	publisher = {Springer},
	title = {Time Series: Theory and Methods (Springer Series in Statistics)},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387974296},
	year = {1998}
}



@book{citeulike:3991239,
	abstract = {This book presents modern developments in time series econometrics that are
applied to macroeconomic and financial time series. It attempts to bridge the
gap between methods and realistic applications. This book contains the most
important approaches to analyse time series which may be stationary or
nonstationary. Modelling and forecasting univariate time series is the
starting point. For multiple stationary time series Granger causality tests
and vector autoregressive models are presented. For real applied work the
modelling of nonstationary uni- or multivariate time series is most important.
Therefore, unit root and cointegration analysis as well as vector error
correction models play a central part. Modelling volatilities of financial
time series with autoregressive conditional heteroskedastic models is also
treated.},
	author = {Kirchg\"{a}ssner, Gebhard   and Wolters, J\"{u}rgen  },
	citeulike-article-id = {3991239},
	edition = {1},
	howpublished = {Hardcover},
	isbn = {354073290X},
	keywords = {dtw, litreview, thesis},
	month = {October},
	posted-at = {2009-02-01 10:47:08},
	priority = {2},
	publisher = {Springer},
	title = {Introduction to Modern Time Series Analysis},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/354073290X},
	year = {2007}
}



@book{citeulike:3991222,
	abstract = {This monograph of carefully collected articles reviews recent developments in
theoretical and applied statistical science, highlights current noteworthy
results and illustrates their applications; and points out possible new
directions to pursue. With its enlightening account of statistical discoveries
and its numerous figures and tables, Probability and Statistical Models with
Applications is a must read for probabilists and theoretical and applied
statisticians.},
	citeulike-article-id = {3991222},
	edition = {1},
	howpublished = {Hardcover},
	isbn = {1584881240},
	keywords = {dtw, litreview, thesis},
	month = {September},
	posted-at = {2009-02-01 10:12:49},
	priority = {2},
	publisher = {Chapman \& Hall/CRC},
	title = {Probability and Statistical Models with Applications},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1584881240},
	year = {2000}
}



@book{citeulike:3989988,
	abstract = {The Wiley Classics Library consists of selected books that have become
recognized classics in their respective fields. With these new unabridged and
inexpensive editions, Wiley hopes to extend the life of these important works
by making them available to future generations of mathematicians and
scientists. Currently available in the Series: T. W. Anderson Statistical
Analysis of Time Series T. S. Arthanari \& Yadolah Dodge Mathematical
Programming in Statistics Emil Artin Geometric Algebra Norman T. J. Bailey The
Elements of Stochastic Processes with Applications to the Natural Sciences
George E. P. Box \& George C. Tiao Bayesian Inference in Statistical Analysis
R. W. Carter Simple Groups of Lie Type William G. Cochran \& Gertrude M. Cox
Experimental Designs, Second Edition Richard Courant Differential and Integral
Calculus, Volume I Richard Courant Differential and Integral Calculus, Volume
II Richard Courant \& D. Hilbert Methods of Mathematical Physics, Volume I
Richard Courant \& D. Hilbert Methods of Mathematical Physics, Volume II D. R.
Cox Planning of Experiments Harold M. S. Coxeter Introduction to Modern
Geometry, Second Edition Charles W. Curtis \& Irving Reiner Representation
Theory of Finite Groups and Associative Algebras Charles W. Curtis \& Irving
Reiner Methods of Representation Theory with Applications to Finite Groups and
Orders, Volume I Charles W. Curtis \& Irving Reiner Methods of Representation
Theory with Applications to Finite Groups and Orders, Volume II Bruno de
Finetti Theory of Probability, Volume 1 Bruno de Finetti Theory of
Probability, Volume 2 W. Edwards Deming Sample Design in Business Research
Amos de Shalit \& Herman Feshbach Theoretical Nuclear Physics, Volume 1
—Nuclear Structure J. L. Doob Stochastic Processes Nelson Dunford \& Jacob T.
Schwartz Linear Operators, Part One, General Theory Nelson Dunford \& Jacob T.
Schwartz Linear Operators, Part Two, Spectral Theory—Self Adjoint Operators in
Hilbert Space Nelson Dunford \& Jacob T. Schwartz Linear Operators, Part Three,
Spectral Operators Herman Fsehbach Theoretical Nuclear Physics: Nuclear
Reactions Bernard Friedman Lectures on Applications-Oriented Mathematics
Gerald d. Hahn \& Samuel S. Shapiro Statistical Models in Engineering Morris H.
Hansen, William N. Hurwitz \& William G. Madow Sample Survey Methods and
Theory, Volume I—Methods and Applications Morris H. Hansen, William N. Hurwitz
\& William G. Madow Sample Survey Methods and Theory, Volume II—Theory Peter
Henrici Applied and Computational Complex Analysis, Volume 1—Power
Series—lntegration—Conformal Mapping—Location of Zeros Peter Henrici Applied
and Computational Complex Analysis, Volume 2—Special Functions—Integral
Transforms—Asymptotics—Continued Fractions Peter Henrici Applied and
Computational Complex Analysis, Volume 3—Discrete Fourier Analysis—Cauchy
Integrals—Construction of Conformal Maps—Univalent Functions Peter Hilton \&
Yel-Chiang Wu A Course in Modern Algebra Harry Hochetadt Integral Equations
Erwin O. Kreyezig Introductory Functional Analysis with Applications William
H. Louisell Quantum Statistical Properties of Radiation All Hasan Nayfeh
Introduction to Perturbation Techniques Emanuel Parzen Modern Probability
Theory and Its Applications P.M. Prenter Splines and Variational Methods
Walter Rudin Fourier Analysis on Groups C. L. Siegel Topics in Complex
Function Theory, Volume I—Elliptic Functions and Uniformization Theory C. L.
Siegel Topics in Complex Function Theory, Volume II—Automorphic and Abelian
integrals C. L Siegel Topics in Complex Function Theory, Volume III—Abelian
Functions \& Modular Functions of Several Variables J. J. Stoker Differential
Geometry J. J. Stoker Water Waves: The Mathematical Theory with Applications
J. J. Stoker Nonlinear Vibrations in Mechanical and Electrical Systems},
	author = {Anderson, T. W. },
	citeulike-article-id = {3989988},
	edition = {1},
	howpublished = {Paperback},
	isbn = {0471047457},
	keywords = {dtw, litreview, thesis},
	month = {June},
	posted-at = {2009-02-01 10:02:38},
	priority = {2},
	publisher = {Wiley-Interscience},
	title = {The Statistical Analysis of Time Series},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0471047457},
	year = {1994}
}



@article{citeulike:2090933,
	abstract = {Time series data, due to their numerical and continuous nature, are difficult to process, analyze, and mine. However, these tasks become easier when the data can be transformed into meaningful symbols. Most recent works on time series only address how to identify a given pattern from a time series and do not consider the problem of identifying a suitable set of time points for segmenting the time series in accordance with a given set of pattern templates (e.g., a set of technical patterns for stock analysis). However, the use of fixed-length segmentation is an oversimplified approach to this problem; hence, a dynamic approach (with high controllability) is preferable so that the time series can be segmented flexibly and effectively according to the needs of the users and the applications. In view of the fact that this segmentation problem is an optimization problem and evolutionary computation is an appropriate tool to solve it, we propose an evolutionary time series segmentation algorithm. This approach allows a sizeable set of pattern templates to be generated for mining or query. In addition, defining similarity between time series (or time series segments) is of fundamental importance in fitness computation. By identifying the perceptually important points directly from the time domain, time series segments and templates of different lengths can be compared and intuitive pattern matching can be carried out in an effective and efficient manner. Encouraging experimental results are reported from tests that segment both artificial time series generated from the combinations of pattern templates and the time series of selected Hong Kong stocks.},
	author = {Chung, Fu-Lai   and Fu, Tak-Chung   and Ng, V.  and Luk, R. W. P. },
	booktitle = {Evolutionary Computation, IEEE Transactions on},
	citeulike-article-id = {2090933},
	doi = {http://dx.doi.org/10.1109/TEVC.2004.832863},
	journal = {Evolutionary Computation, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {5},
	pages = {471--489},
	posted-at = {2009-01-27 14:11:56},
	priority = {2},
	title = {An evolutionary approach to pattern-based time series segmentation},
	url = {http://dx.doi.org/10.1109/TEVC.2004.832863},
	volume = {8},
	year = {2004}
}



@inproceedings{citeulike:3513035,
	abstract = {Recognition of hand-drawn shapes is an important and widely studied problem. By adopting a generative probabilistic framework we are able to formulate a robust and flexible approach to shape recognition which allows for a wide range of shapes and which can recognize new shapes from a single exemplar. It also provides meaningful probabilistic measures of model score which can be used as part of a larger probabilistic framework for interpreting a page of ink. We also show how Bayesian model comparison allows the trade-off between data fit and model complexity to be optimized automatically.},
	address = {Washington, DC, USA},
	author = {Krishnapuram, Balaji   and Bishop, Christopher  M.  and Szummer, Martin  },
	booktitle = {IWFHR '04: Proceedings of the Ninth International Workshop on Frontiers in Handwriting Recognition},
	citeulike-article-id = {3513035},
	doi = {http://dx.doi.org/10.1109/IWFHR.2004.46},
	isbn = {0-7695-2187-8},
	keywords = {dtw, litreview, thesis},
	pages = {20--25},
	posted-at = {2009-01-26 13:43:27},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Generative Models and Bayesian Model Comparison for Shape Recognition},
	url = {http://dx.doi.org/10.1109/IWFHR.2004.46},
	year = {2004}
}



@book{citeulike:3822011,
	abstract = {This collection of twenty-three original papers represents the first effort to
bring together the work of constraint programming researchers scattered across
multiple disciplines and across the world. The collection contributes to the
understanding of the common principles of this emerging general paradigm, the
investigation of its theoretical foundations as well as applications to real-
world computing problems. It is organized around themes of concurrency and
reactive systems, languages and environments, algorithms, computer graphics,
and artificial intelligence. Constraint programming aims at supporting a wide
range of complex applications which are often modeled naturally in terms of
constraints. Early work, in the 1960s and 1970s, made use of constraints in
computer graphics, user interfaces, and artificial intelligence. Such work
introduced a declarative component in otherwise-procedural systems to reduce
the development effort. The mid-1980s have witnessed the emergence of general-
purpose programming languages based on constraints, such as constraint logic
programming and concurrent constraint programming, with significant
applications in academia and industry. Today, an increasing number of
researchers from all over the map of computing are looking at different
aspects of this new computational paradigm.},
	citeulike-article-id = {3822011},
	howpublished = {Hardcover},
	isbn = {0262193612},
	keywords = {dtw, litreview, thesis},
	month = {May},
	posted-at = {2008-12-23 13:02:48},
	priority = {2},
	publisher = {The MIT Press},
	title = {Principles and Practice of Constraint Programming},
	url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0262193612},
	year = {1995}
}



@inproceedings{citeulike:3821484,
	abstract = {A Query by Humming system allows the user to find a song by humming part of the tune. No musical training is needed. Previous query by humming systems have not provided satisfactory results for various reasons. Some systems have low retrieval precision because they rely on melodic contour information from the hum tune, which in turn relies on the error-prone note segmentation process. Some systems yield better precision when matching the melody directly from audio, but they are slow because of their extensive use of Dynamic Time Warping (DTW). Our approach improves both the retrieval precision and speed compared to previous approaches. We treat music as a time series and exploit and improve well-developed techniques from time series databases to index the music for fast similarity queries. We improve on existing DTW indexes technique by introducing the concept of  envelope transforms , which gives a general guideline for extending existing dimensionality reduction methods to DTW indexes. The net result is high scalability. We confirm our claims through extensive experiments.},
	address = {New York, NY, USA},
	author = {Zhu, Yunyue   and Shasha, Dennis  },
	booktitle = {SIGMOD '03: Proceedings of the 2003 ACM SIGMOD international conference on Management of data},
	citeulike-article-id = {3821484},
	doi = {http://dx.doi.org/10.1145/872757.872780},
	isbn = {1-58113-634-X},
	keywords = {dtw, litreview, thesis},
	location = {San Diego, California},
	pages = {181--192},
	posted-at = {2008-12-23 05:35:52},
	priority = {2},
	publisher = {ACM},
	title = {Warping indexes with envelope transforms for query by humming},
	url = {http://dx.doi.org/10.1145/872757.872780},
	year = {2003}
}



@article{citeulike:3056920,
	address = {New York, NY, USA},
	author = {Hjaltason, Gisli  R.  and Samet, Hanan  },
	citeulike-article-id = {3056920},
	doi = {http://dx.doi.org/10.1145/958942.958948},
	issn = {0362-5915},
	journal = {ACM Trans. Database Syst.},
	keywords = {dtw, litreview, thesis},
	month = {December},
	number = {4},
	pages = {517--580},
	posted-at = {2008-12-22 22:38:00},
	priority = {2},
	publisher = {ACM},
	title = {Index-driven similarity search in metric spaces (Survey Article)},
	url = {http://dx.doi.org/10.1145/958942.958948},
	volume = {28},
	year = {2003}
}



@inproceedings{citeulike:3816328,
	abstract = {The problem of finding patterns of interest in time series databases (query by content) is an important one, with applications in virtually every field of science. A variety of approaches have been suggested. These approaches are robust to noise, offset translation, and amplitude scaling to varying degrees. However, they are all extremely sensitive to scaling in the time axis (longitudinal scaling). We present a method for similarity search that is robust to scaling in the time axis, in addition to noise, offset translation, and amplitude scaling. The method has been tested on medical, financial, space telemetry and artificial data. Furthermore the method is exceptionally fast, with the predicted 2 to 4 orders of magnitude speedup actually observed. The method uses a piecewise linear representation of the original data. We also introduce a new algorithm which both decides the optimal number of linear segments to use, and produces the actual linear representation},
	author = {Keogh, E. },
	booktitle = {Tools with Artificial Intelligence, 1997. Proceedings., Ninth IEEE International Conference on},
	citeulike-article-id = {3816328},
	doi = {http://dx.doi.org/10.1109/TAI.1997.632306},
	journal = {Tools with Artificial Intelligence, 1997. Proceedings., Ninth IEEE International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {578--584},
	posted-at = {2008-12-22 01:04:00},
	priority = {2},
	title = {Fast similarity search in the presence of longitudinal scaling in time series databases},
	url = {http://dx.doi.org/10.1109/TAI.1997.632306},
	year = {1997}
}



@inproceedings{citeulike:3816327,
	abstract = {We introduce a new model of similarity of time sequences that captures the intuitive notion that two sequences should be considered similar if they have enough non-overlapping time-ordered pairs of subsequences thar are similar. The model allows the amplitude of one of the two sequences to be scaled by any suitable amount and its offset adjusted appropriately. Two subsequences are considered similar if one can be enclosed within an envelope of a specified width drawn around the other. The model also allows non-matching gaps in the matching subsequences. The matching subsequences need not be aligned along the time axis. Given this model of similarity, we present fast search techniques for discovering all similar sequences in a set of sequences. These techniques can also be used to find all (sub)sequences similar to a given sequence. We applied this matching system to the U.S. mutual funds data and discovered interesting matches.},
	author = {Agrawal, Rakesh   and Lin, King-Ip   and Sawhney, Harpreet  S.  and Shim, Kyuseok  },
	booktitle = {In VLDB},
	citeulike-article-id = {3816327},
	keywords = {dtw, litreview, thesis},
	pages = {490--501},
	posted-at = {2008-12-22 01:02:20},
	priority = {2},
	title = {Fast Similarity Search in the Presence of Noise, Scaling, and Translation in Time-Series Databases},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.4179},
	year = {1995}
}



@article{citeulike:3816322,
	abstract = {Motivation: Increasingly, biological processes are being studied   through time series of RNA expression data collected for large   numbers of genes. Because common processes may unfold at varying   rates in different experiments or individuals, methods are needed that will allow corresponding expression states in different time series to be mapped to one another.  Results: We present implementations of time warping algorithms   applicable to RNA and protein expression data and demonstrate their application to published yeast RNA expression time series. Programs executing two warping algorithms are described, a simple warping algorithm and an interpolative algorithm, along with programs that generate graphics that visually present alignment information. We show time warping to be superior to simple clustering at mapping corresponding time states. We document the impact of statistical measurement noise and sample size on the quality of time alignments,  and present issues related to statistical assessment of alignment   quality through alignment scores. We also discuss directions for algorithm improvement including development of multiple time series alignments and possible applications to causality searches and non-temporal processes ( concentration warping').  Availability: Academic implementations of alignment programs   genewarp and genewarpi and the graphics generation programs grphwarp and grphwarpi are available as Win32 system DOS box executables on our web site along with documentation on their use. The publicly available data on which they were demonstrated may be found at http://genome-www.stanford.edu/cellcycle/.   Postscript files generated by grphwarp and grphwarpi may be directly printed or viewed using GhostView software available at http://www.cs.wisc.edu/\~{}ghost/.  Contact: church@arep.med.harvard.edu  Supplementary information: http://arep.med.harvard.edu/timewarp/supplement.htm. 10.1093/bioinformatics/17.6.495},
	author = {Aach, John   and Church, George  M. },
	citeulike-article-id = {3816322},
	doi = {http://dx.doi.org/10.1093/bioinformatics/17.6.495},
	journal = {Bioinformatics},
	keywords = {dtw, litreview, thesis},
	month = {June},
	number = {6},
	pages = {495--508},
	posted-at = {2008-12-22 00:51:21},
	priority = {2},
	title = {Aligning gene expression time series with time warping algorithms},
	url = {http://dx.doi.org/10.1093/bioinformatics/17.6.495},
	volume = {17},
	year = {2001}
}



@incollection{citeulike:3816243,
	abstract = {Widespread interest in discovering features and trends in time- series has generated a need for tools that support interactive exploration.This paper introduces timeboxes: a powerful direct-manipulation metaphor for the specification of queries over time series datasets. Our TimeSearcher implementation of timeboxes supports interactive formulation and modification of queries, thus speeding the process of exploring time series data sets and guiding data mining.},
	author = {Hochheiser, Harry   and Shneiderman, Ben  },
	citeulike-article-id = {3816243},
	doi = {http://dx.doi.org/10.1007/3-540-45650-3\_38},
	journal = {Discovery Science},
	keywords = {dtw, litreview, thesis},
	pages = {441--446},
	posted-at = {2008-12-21 23:13:53},
	priority = {2},
	title = {Interactive Exploration of Time Series Data},
	url = {http://dx.doi.org/10.1007/3-540-45650-3\_38},
	year = {2001}
}



@book{citeulike:1109201,
	address = {Menlo Park, CA, USA},
	author = {Fayyad, Usama  M.  and Piatetsky-Shapiro, Gregory   and Smyth, Padhraic   and Uthurusamy, Ramasamy  },
	citeulike-article-id = {1109201},
	editor = {Fayyad, Usama  M.  and Piatetsky-Shapiro, Gregory   and Smyth, Padhraic   and Uthurusamy, Ramasamy  },
	isbn = {0262560976},
	keywords = {dtw, litreview, thesis},
	posted-at = {2008-12-21 23:12:28},
	priority = {2},
	publisher = {American Association for Artificial Intelligence},
	title = {Advances in knowledge discovery and data mining},
	url = {http://portal.acm.org/citation.cfm?id=257938},
	year = {1996}
}



@inproceedings{citeulike:3816224,
	abstract = {Sequential data is easily understood through a simple line graph, yet systems to search such data typically rely on complex interfaces or query languages. This paper presents QuerySketch, a financial database application in which graphs are used for query input as well as output. QuerySketch allows users to sketch a graph freehand, then view stocks whose price histories match the sketch. Using the same graphical format for both input and output results in an interface that is powerful, flexible, yet easy to use.},
	address = {New York, NY, USA},
	author = {Wattenberg, Martin  },
	booktitle = {CHI '01: CHI '01 extended abstracts on Human factors in computing systems},
	citeulike-article-id = {3816224},
	doi = {http://dx.doi.org/10.1145/634067.634292},
	isbn = {1-58113-340-5},
	keywords = {dtw, litreview},
	location = {Seattle, Washington},
	pages = {381--382},
	posted-at = {2008-12-21 22:53:35},
	priority = {2},
	publisher = {ACM},
	title = {Sketching a graph to query a time-series database},
	url = {http://dx.doi.org/10.1145/634067.634292},
	year = {2001}
}



@inproceedings{citeulike:3816213,
	abstract = {Query-by-Example is a query language for use by non-programmers querying a relational data base. In an earlier paper, the features of this language were introduced; however, it was assumed that the data base was already defined and available to the user.},
	address = {New York, NY, USA},
	author = {Zloof, Mosh\'e  M. },
	booktitle = {VLDB '75: Proceedings of the 1st International Conference on Very Large Data Bases},
	citeulike-article-id = {3816213},
	doi = {http://dx.doi.org/10.1145/1282480.1282482},
	keywords = {dtw, litreview, thesis},
	location = {Framingham, Massachusetts},
	pages = {1--24},
	posted-at = {2008-12-21 22:48:45},
	priority = {2},
	publisher = {ACM},
	title = {Query-by-example: the invocation and definition of tables and forms},
	url = {http://dx.doi.org/10.1145/1282480.1282482},
	year = {1975}
}



@incollection{citeulike:3815893,
	abstract = {Conceptually, the techniques of linguistic pattern recognition are largely independent of the medium, but overall performance is influenced by the preprocessing to such an extent that until a few years ago the pattern recognition step was generally viewed as a small appendix to the main body of signal processing knowledge. To this day, it remains impossible to build a serious system without paying close attention to preprocessing, and deep algorithmic work on the recognizer will often yield smaller gains than seemingly more superficial changes to the front end. In Section 9.1, we introduce a speech coding method, linear prediction, that has played an important role in practical application since the 1970s.We extend the discussion of quantization started in Section 8.1 from scalars to vectors and discuss the Fourier transform-based (homomorphic) techniques that currently dominate the field.},
	citeulike-article-id = {3815893},
	doi = {http://dx.doi.org/10.1007/978-1-84628-986-6\_9},
	journal = {Mathematical Linguistics},
	keywords = {dtw, litreview, thesis},
	pages = {219--246},
	posted-at = {2008-12-21 17:43:45},
	priority = {2},
	title = {Speech and handwriting},
	url = {http://dx.doi.org/10.1007/978-1-84628-986-6\_9},
	year = {2008}
}



@incollection{citeulike:3815889,
	abstract = {Efficient retrieval of time series data has gained recent attention from the research community. In particular, finding meaningful distance measurements for various applications is one of the most important issues in the field, since no single distance measurement works for all applications. In this paper, we propose a different distance measurement for time series applications based on Constraint Continuous Editing Distance (CCED) that adjusts the potential energy of each sequence for optimal similarity. Furthermore, we also propose a lower bounding distance for CCED for efficient indexing and fast retrieval, even though CCED does not satisfy triangle inequality.},
	author = {Chhieng, Van   and Wong, Raymond  },
	citeulike-article-id = {3815889},
	doi = {http://dx.doi.org/10.1007/978-3-540-71703-4\_51},
	journal = {Advances in Databases: Concepts, Systems and Applications},
	keywords = {dtw, litreview, thesis},
	pages = {598--610},
	posted-at = {2008-12-21 17:38:37},
	priority = {2},
	title = {Adaptive Distance Measurement for Time Series Databases},
	url = {http://dx.doi.org/10.1007/978-3-540-71703-4\_51},
	year = {2008}
}



@article{citeulike:3815887,
	abstract = {Abstract\&nbsp;\&nbsp;In this paper, we define time series query filtering, the problem of monitoring the streaming time series for a set of predefined patterns. This problem is of great practical importance given the massive volume of streaming time series available through sensors, medical patient records, financial indices and space telemetry. Since the data may arrive at a high rate and the number of predefined patterns can be relatively large, it may be impossible for the comparison algorithm to keep up. We propose a novel technique that exploits the commonality among the predefined patterns to allow monitoring at higher bandwidths, while maintaining a guarantee of no false dismissals. Our approach is based on the widely used envelope-based lower-bounding technique. As we will demonstrate on extensive experiments in diverse domains, our approach achieves tremendous improvements in performance in the offline case, and significant improvements in the fastest possible arrival rate of the data stream that can be processed with guaranteed no false dismissals. As a further demonstration of the utility of our approach, we demonstrate that it can make semisupervised learning of time series classifiers tractable.},
	author = {Wei, Li   and Keogh, Eamonn   and Van Herle, Helga   and Mafra-Neto, Agenor   and Abbott, Russell  },
	citeulike-article-id = {3815887},
	doi = {http://dx.doi.org/10.1007/s10115-006-0033-7},
	journal = {Knowledge and Information Systems},
	keywords = {dtw, litreview, thesis},
	month = {April},
	number = {3},
	pages = {313--344},
	posted-at = {2008-12-21 17:37:36},
	priority = {2},
	title = {Efficient query filtering for streaming time series with applications to semisupervised learning of time series classifiers},
	url = {http://dx.doi.org/10.1007/s10115-006-0033-7},
	volume = {11},
	year = {2007}
}



@incollection{citeulike:3815884,
	abstract = {It is well known that Dynamic Time Warping (DTW) is superior to Euclidean distance as a similarity measure in time series analyses. Use of DTW with the recently introduced warping window constraints and lower bounding measures has significantly increased the accuracy of time series classification while reducing the computational expense required. The warping window technique learns arbitrary constraints on the warping path while performing time series alignment. This work utilizes genetic algorithms to find the optimal warping window constraints which provide a better classification accuracy. Performance of the proposed methodology has been investigated on two problems from diverse domains with favorable results.},
	author = {Kumar, Pankaj   and Gupta, Ankur   and Jayaraman, Valadi  K.  and Kulkarni, Bhaskard  },
	citeulike-article-id = {3815884},
	doi = {http://dx.doi.org/10.1007/978-3-540-72960-0\_12},
	journal = {Advances in Metaheuristics for Hard Optimization},
	keywords = {dtw, litreview, thesis},
	pages = {251--261},
	posted-at = {2008-12-21 17:35:01},
	priority = {2},
	title = {Aligning Time Series with Genetically Tuned Dynamic Time Warping Algorithm},
	url = {http://dx.doi.org/10.1007/978-3-540-72960-0\_12},
	year = {2008}
}



@article{citeulike:785210,
	author = {Keogh, Eamonn   and Ratanamahatana, Chotirat  A. },
	citeulike-article-id = {785210},
	doi = {http://dx.doi.org/10.1007/s10115-004-0154-9},
	journal = {Knowledge and Information Systems},
	keywords = {dtw, litreview, thesis},
	month = {March},
	number = {3},
	pages = {358--386},
	posted-at = {2008-12-21 17:31:59},
	priority = {2},
	title = {Exact indexing of dynamic time warping},
	url = {http://dx.doi.org/10.1007/s10115-004-0154-9},
	volume = {7},
	year = {2005}
}



@incollection{citeulike:3815880,
	abstract = {Constraints are a natural mechanism for the specification of similarity queries on time-series data. However, to realize the expressive power of constraint programming in this context, one must provide the matching implementation technology for efficient indexing of very large data sets. In this paper, we formalize the intuitive notions of exact and approximate similarity between time-series patterns and data. Our definition of similarity extends the distance metric used in [2, 7] with invariance under a group of transformations. Our main observation is that the resulting, more expressive, set of constraint queries can be supported by a new indexing technique, which preserves all the desirable properties of the indexing scheme proposed in [2, 7].},
	author = {Goldin, Dina   and Kanellakis, Paris  },
	citeulike-article-id = {3815880},
	doi = {http://dx.doi.org/10.1007/3-540-60299-2\_9},
	journal = {Principles and Practice of Constraint Programming — CP '95},
	keywords = {dtw, litreview, thesis},
	pages = {137--153},
	posted-at = {2008-12-21 17:28:50},
	priority = {2},
	title = {On similarity queries for time-series data: Constraint specification and implementation},
	url = {http://dx.doi.org/10.1007/3-540-60299-2\_9},
	year = {1995}
}



@incollection{citeulike:3815871,
	citeulike-article-id = {3815871},
	doi = {http://dx.doi.org/10.1007/978-3-540-37014-7\_2},
	journal = {Dynamic Programming},
	keywords = {litreview},
	pages = {45--100},
	posted-at = {2008-12-21 17:15:50},
	priority = {2},
	title = {Applications of Dynamic Programming},
	url = {http://dx.doi.org/10.1007/978-3-540-37014-7\_2},
	year = {2007}
}



@inproceedings{citeulike:3815864,
	abstract = {We investigate techniques for similarity analysis of spatio-temporal trajectories for mobile objects. Such data may contain a large number of outliers, which degrade the performance of Euclidean and time warping distance. Therefore, we propose the use of non-metric distance functions based on the longest common subsequence (LCSS), in conjunction with a sigmoidal matching function. Finally, we compare these new methods to various L<sub>p</sub> norms and also to time warping distance (for real and synthetic data) and present experimental results that validate the accuracy and efficiency of our approach, especially in the presence of noise.},
	author = {Vlachos, M.  and Gunopulos, D.  and Kollios, G. },
	booktitle = {Database and Expert Systems Applications, 2002. Proceedings. 13th International Workshop on},
	citeulike-article-id = {3815864},
	journal = {Database and Expert Systems Applications, 2002. Proceedings. 13th International Workshop on},
	keywords = {dtw, litreview, thesis},
	pages = {721--726},
	posted-at = {2008-12-21 17:09:37},
	priority = {2},
	title = {Robust similarity measures for mobile object trajectories},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1045983},
	year = {2002}
}



@incollection{citeulike:2902692,
	abstract = {Similarity of objects is one of the crucial concepts in several applications, including data mining. For complex objects, similarity is nontrivial to define. In this paper we present an intuitive model for measuring the similarity between two time series. The model takes into account outliers, different scaling functions, and variable sampling rates. Using methods from computational geometry, we show that this notion of similarity can be computed in polynomial time. Using statistical approximation techniques, the algorithms can be speeded up considerably. We give preliminary experimental results that show the naturalness of the notion.},
	author = {Das, Gautam   and Gunopulos, Dimitrios   and Mannila, Heikki  },
	citeulike-article-id = {2902692},
	doi = {http://dx.doi.org/10.1007/3-540-63223-9\_109},
	journal = {Principles of Data Mining and Knowledge Discovery},
	keywords = {dtw, litreview, thesis},
	pages = {88--100},
	posted-at = {2008-12-21 17:07:58},
	priority = {2},
	title = {Finding similar time series},
	url = {http://dx.doi.org/10.1007/3-540-63223-9\_109},
	year = {1997}
}



@inproceedings{citeulike:2902876,
	address = {New York, NY, USA},
	author = {Gunopulos, Dimitrios   and Das, Gautam  },
	booktitle = {KDD '00: Tutorial notes of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining},
	citeulike-article-id = {2902876},
	doi = {http://dx.doi.org/10.1145/349093.349108},
	isbn = {1581133057},
	keywords = {dtw, litreview, thesis},
	pages = {243--307},
	posted-at = {2008-12-21 17:06:02},
	priority = {2},
	publisher = {ACM},
	title = {Time series similarity measures (tutorial PM-2)},
	url = {http://dx.doi.org/10.1145/349093.349108},
	year = {2000}
}



@inproceedings{citeulike:3815082,
	author = {Chu, Selina   and Keogh, Eamonn   and Hart, David   and Pazzani, Michael  },
	citeulike-article-id = {3815082},
	journal = {Proceedings of the Second SIAM Intl. Conf. on Data Mining},
	keywords = {litreview, thesis},
	posted-at = {2008-12-21 04:29:45},
	priority = {2},
	title = {Iterative Deepening Dynamic Time
Warping for Time Series},
	url = {http://www.siam.org/meetings/sdm02/proceedings/sdm02-12.pdf},
	year = {2002}
}



@inproceedings{citeulike:3815076,
	abstract = {After the generation of multimedia data turned digital, an explosion of interest in their data storage, retrieval, and processing has drastically increased. This includes videos, images, and audios, where we now have higher expectations in exploiting these data at hands. Typical manipulations are in some forms of video/image/audio processing, including automatic speech recognition, which require fairly large amount of storage and are computationally intensive. In our recent work, we have demonstrated the utility of time series representation in the task of clustering multimedia data using k-medoids method, which allows considerable amount of reduction in computational effort and storage space. However, k- means is a much more generic clustering method when Euclidean distance is used. In this work, we will demonstrate that unfortunately, k-means clustering will sometimes fail to give correct results, an unaware fact that may be overlooked by many researchers. This is especially the case when Dynamic Time Warping (DTW) is used as the distance measure in averaging the shape of time series. We also will demonstrate that the current averaging algorithm may not produce the real average of the time series, thus generates incorrect k-means clustering results, and then show potential causes why DTW averaging methods may not achieve meaningful clustering results. Lastly, we conclude with a suggestion of a method to potentially find the shape-based time series average that satisfies the required properties.},
	author = {Niennattrakul, V.  and Ratanamahatana, C. A. },
	booktitle = {Multimedia and Ubiquitous Engineering, 2007. MUE '07. International Conference on},
	citeulike-article-id = {3815076},
	doi = {http://dx.doi.org/10.1109/MUE.2007.165},
	journal = {Multimedia and Ubiquitous Engineering, 2007. MUE '07. International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {733--738},
	posted-at = {2008-12-21 04:17:26},
	priority = {2},
	title = {On Clustering Multimedia Time Series Data Using K-Means and Dynamic Time Warping},
	url = {http://dx.doi.org/10.1109/MUE.2007.165},
	year = {2007}
}



@inproceedings{citeulike:3815040,
	abstract = {Fast similarity searching in large time sequence databases has typically used Euclidean distance as a dissimilarity metric. However, for several applications, including matching of voice, audio and medical signals (e.g., electrocardiograms), one is required to permit local accelerations and decelerations in the rate of sequences, leading to a popular, field tested dissimilarity metric called the \&ldquo;time warping\&rdquo; distance. From the indexing viewpoint, this metric presents two major challenges: (a) it does not lead to any natural indexable \&ldquo;features\&rdquo;, and (b) comparing two sequences requires time quadratic in the sequence length. To address each problem, we propose to use: (a) a modification of the so called \&ldquo;FastMap\&rdquo;, to map sequences into points, with little compromise of \&ldquo;recall\&rdquo; (typically zero); and (b) a fast linear test, to help us discard quickly many of the false alarms that FastMap will typically introduce. Using both ideas in cascade, our proposed method achieved up to an order of magnitude speed-up over sequential scanning on both real and synthetic datasets},
	author = {Yi, Byoung-Kee   and Jagadish, H. V.  and Faloutsos, C. },
	booktitle = {Data Engineering, 1998. Proceedings., 14th International Conference on},
	citeulike-article-id = {3815040},
	doi = {http://dx.doi.org/10.1109/ICDE.1998.655778},
	journal = {Data Engineering, 1998. Proceedings., 14th International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {201--208},
	posted-at = {2008-12-21 02:21:14},
	priority = {2},
	title = {Efficient retrieval of similar time sequences under time warping},
	url = {http://dx.doi.org/10.1109/ICDE.1998.655778},
	year = {1998}
}



@inproceedings{citeulike:3789964,
	abstract = {Abstract: Considerable effort has been put towards developing intelligent and natural interfaces between users and computer systems. This is done by means of a variety of modes of information (visual, audio, pen, etc.) either used individually or in combination. In this work, we focus on the visual sensory information to recognize human activity in form of hand-arm movements from a small, predefined vocabulary. We accomplish this task by means of a matching technique by determining the distance between the unknown input and a set of previously defined templates. A dynamic time warping (DTW) algorithm is used to perform the time alignment and normalization by computing a temporal transformation allowing the two signals to be matched. The system is trained with finite video sequences of single gesture performances whose start and end point are accurately known. Preliminary experiments are accomplished off-line and result in a recognition accuracy of up to 92\%.},
	address = {Washington, DC, USA},
	author = {Corradini, Andrea  },
	booktitle = {RATFG-RTS '01: Proceedings of the IEEE ICCV Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems (RATFG-RTS'01)},
	citeulike-article-id = {3789964},
	keywords = {dtw, litreview, thesis},
	posted-at = {2008-12-15 17:14:19},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Dynamic Time Warping for Off-Line Recognition of a Small Gesture Vocabulary},
	url = {http://portal.acm.org/citation.cfm?id=882476.883586},
	year = {2001}
}



@inproceedings{citeulike:3789957,
	abstract = {In this paper an approach to classify hand shapes into different classes according to the similarity measures between features is proposed. We show how to use an Exploratory Data Analysis to extract novel, single feature of hand from images. Based on the obtained curve-like shape of the feature, hands are classified into one of 21 possible classes of Croatian sign language using Dynamic Time Warping and Longest Common Subsequence as similarity measures. Performance of the system was evaluated with 1260 images. Results show that high classification accuracy can be obtained from a single feature recognition and a small number of training sample.},
	author = {Kuzmanic, A.  and Zanchi, V. },
	booktitle = {EUROCON, 2007. The International Conference on "Computer as a Tool"},
	citeulike-article-id = {3789957},
	doi = {http://dx.doi.org/10.1109/EURCON.2007.4400350},
	journal = {EUROCON, 2007. The International Conference on "Computer as a Tool"},
	keywords = {dtw, litreview, thesis},
	pages = {264--269},
	posted-at = {2008-12-15 17:10:27},
	priority = {2},
	title = {Hand shape classification using DTW and LCSS as similarity measures for vision-based gesture recognition system},
	url = {http://dx.doi.org/10.1109/EURCON.2007.4400350},
	year = {2007}
}



@article{citeulike:2584345,
	abstract = {This survey describes the state of the art of online handwriting recognition during a period of renewed activity in the field. It is based on an extensive review of the literature, including journal articles, conference proceedings, and patents. Online versus offline recognition, digitizer technology, and handwriting properties and recognition problems are discussed. Shape recognition algorithms, preprocessing and postprocessing techniques, experimental systems, and commercial products are examined},
	author = {Tappert, C. C.  and Suen, C. Y.  and Wakahara, T. },
	booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	citeulike-article-id = {2584345},
	doi = {http://dx.doi.org/10.1109/34.57669},
	journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {8},
	pages = {787--808},
	posted-at = {2008-12-15 17:04:49},
	priority = {2},
	title = {The state of the art in online handwriting recognition},
	url = {http://dx.doi.org/10.1109/34.57669},
	volume = {12},
	year = {1990}
}



@article{citeulike:3789944,
	abstract = {This paper compares the current state of the art in online Japanese character recognition with techniques in western handwriting recognition. It discusses important developments in preprocessing, classification, and postprocessing for Japanese character recognition in recent years and relates them to the developments in western handwriting recognition. Comparing eastern and western handwriting recognition techniques allows learning from very different approaches and understanding the underlying common foundations of handwriting recognition. This is very important when it comes to developing compact modules for integrated systems supporting many writing systems capable of recognizing multilanguage documents.},
	author = {Jaeger, S.  and Liu, C. L.  and Nakagawa, M. },
	citeulike-article-id = {3789944},
	doi = {http://dx.doi.org/10.1007/s10032-003-0107-y},
	journal = {International Journal on Document Analysis and Recognition},
	keywords = {dtw, litreview, thesis},
	month = {October},
	number = {2},
	pages = {75--88},
	posted-at = {2008-12-15 16:59:51},
	priority = {2},
	title = {The state of the art in Japanese online handwriting recognition compared to techniques in western handwriting recognition},
	url = {http://dx.doi.org/10.1007/s10032-003-0107-y},
	volume = {6},
	year = {2003}
}



@article{citeulike:125682,
	author = {Yutao, Shou   and Nikos, Mamoulis   and David, Cheung  },
	citeulike-article-id = {125682},
	doi = {http://dx.doi.org/10.1007/s10994-005-5828-3},
	issn = {0885-6125},
	journal = {Machine Learning},
	keywords = {dtw, litreview, thesis},
	month = {February},
	number = {2-3},
	pages = {231--267},
	posted-at = {2008-12-15 16:45:58},
	priority = {2},
	publisher = {Kluwer Academic Publishers},
	title = {Fast and Exact Warping of Time Series Using Adaptive Segmental Approximations},
	url = {http://dx.doi.org/10.1007/s10994-005-5828-3},
	volume = {58},
	year = {2005}
}



@incollection{citeulike:3789897,
	abstract = {As the world has shifted towards manipulation of information and its technology, we have been increasingly overwhelmed by the amount of available multimedia data while having higher expectations to fully exploit these data at hands. One of the attempts is to develop content-based multimedia information retrieval systems, which greatly facilitate us to intuitively search by its contents; a classic example is a Query-by-Humming system. Nevertheless, typical content-based search for multimedia data usually requires a large amount of storages and is computationally intensive. Recently, time series representation has been successfully applied to a wide variety of research, including multimedia retrieval due to the great reduction in time and space complexity. Besides, an enhancement, Uniform Scaling, has been proposed and applied prior to distance calculation, as well as it has been demonstrated that Uniform Scaling can outperform Euclidean distance. These previous work on Uniform Scaling, nonetheless, overlook the importance and effects of normalisation, which make their frameworks impractical for real world data. Therefore, in this paper, we justify this importance of normalisation in multimedia data and propose an efficient solution for searching multimedia time series data under Uniform Scaling and normalisation.},
	author = {Euachongprasit, Waiyawuth   and Ratanamahatana, Chotirat  },
	citeulike-article-id = {3789897},
	doi = {http://dx.doi.org/10.1007/978-3-540-78646-7\_49},
	journal = {Advances in Information Retrieval},
	keywords = {dtw, litreview, thesis},
	pages = {506--513},
	posted-at = {2008-12-15 16:16:06},
	priority = {2},
	title = {Efficient Multimedia Time Series Data Retrieval Under Uniform Scaling and Normalisation},
	url = {http://dx.doi.org/10.1007/978-3-540-78646-7\_49},
	year = {2008}
}



@incollection{citeulike:3789894,
	abstract = {Relatively few query tools exist for data exploration and pattern identification in time series data sets. In previous work we introduced Timeboxes. Timeboxes are rectangular, direct-manipulation queries for studying time-series datasets. We demonstrated how Timeboxes can be used to support interactive exploration via dynamic queries, along with overviews of query results and drag-and-drop support for query-by-example. In this paper, we extend our work by introducing Variable Time Timeboxes (VTT). VTTs are a natural generalization of Timeboxes, which permit the specification of queries that allow a degree of uncertainty in the time axis. We carefully motivate the need for these more expressive queries, and demonstrate the utility of our approach on several data sets.},
	author = {Keogh, Eamonn   and Hochheiser, Harry   and Shneiderman, Ben  },
	citeulike-article-id = {3789894},
	doi = {http://dx.doi.org/10.1007/3-540-36109-X\_19},
	journal = {Flexible Query Answering Systems},
	keywords = {dtw, litreview, thesis},
	pages = {240--250},
	posted-at = {2008-12-15 16:14:09},
	priority = {2},
	title = {An Augmented Visual Query Mechanism for Finding Patterns in Time Series Data},
	url = {http://dx.doi.org/10.1007/3-540-36109-X\_19},
	year = {2002}
}



@misc{citeulike:3788829,
	author = {Dimitrios, Gunopulos  },
	citeulike-article-id = {3788829},
	keywords = {litreview, thesis},
	posted-at = {2008-12-15 06:48:48},
	priority = {2},
	title = {Time Series Similarity Measures},
	url = {http://mrw.interscience.wiley.com/emrw/9780470011812/eob/article/b2a12074/current/abstract}
}



@article{citeulike:3788783,
	abstract = {Abstract--In this paper, we give a comprehensive description of our writer-independent online handwriting recognition system frog on hand. The focus of this work concerns the presentation of the classification/training approach, which we call cluster generative statistical dynamic time warping (CSDTW). CSDTW is a general, scalable, HMM-based method for variable-sized, sequential data that holistically combines cluster analysis and statistical sequence modeling. It can handle general classification problems that rely on this sequential type of data, e.g., speech recognition, genome processing, robotics, etc. Contrary to previous attempts, clustering and statistical sequence modeling are embedded in a single feature space and use a closely related distance measure. We show character recognition experiments of frog on hand using CSDTW on the UNIPEN online handwriting database. The recognition accuracy is significantly higher than reported results of other handwriting recognition systems. Finally, we describe the real-time implementation of frog on hand on a Linux Compaq iPAQ embedded device.},
	address = {Washington, DC, USA},
	author = {Bahlmann, Claus   and Burkhardt, Hans  },
	citeulike-article-id = {3788783},
	doi = {http://dx.doi.org/10.1109/TPAMI.2004.1262308},
	issn = {0162-8828},
	journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
	keywords = {dtw, litreview, thesis},
	number = {3},
	pages = {299--310},
	posted-at = {2008-12-15 06:30:08},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {The Writer Independent Online Handwriting Recognition System frog on hand and Cluster Generative Statistical Dynamic Time Warping},
	url = {http://dx.doi.org/10.1109/TPAMI.2004.1262308},
	volume = {26},
	year = {2004}
}



@article{citeulike:3744226,
	abstract = {Poor handwriting is a diagnostic criterion for developmental coordination disorder. Typical of poor handwriting is its low overall quality and the high variability of the spatial characteristics of the letters, usually assessed with a subjective handwriting scale. Recently, Dynamic Time Warping (DTW), a technique originally developed for speech recognition, was introduced for pattern recognition in handwriting. The present study evaluates its application to analyze poor handwriting. Forty children attending Dutch mainstream primary schools were recruited and based on their scores on the Concise Evaluation Scale for Children's Handwriting (Dutch abbreviation: BHK), 20 good and 20 poor writers (of whom 13 were scheduled for handwriting intervention) were identified. The groups were matched for age (7-9 years), school grade (grades 2 and 3) and handedness. The children subsequently wrote sequences of the letter "a" on a graphics tablet in three conditions (normal, fast, and accurate). Classical kinematics were obtained and for each individual letter DTW was used to calculate the distance from the mean shape. The DTW data revealed much higher variability in the letter forms of the poor writers that was independent of the kinematic results of larger trajectories, faster movements, and higher pen pressure. The current results suggest that DTW is a valid and objective technique for letter-form analysis in handwriting and may hence be useful to evaluate the rehabilitation treatments of children suffering from poor handwriting. In education research it may be exploited to explore how children (should) learn to write.},
	author = {Di Brina, C.  and Niels, R.  and Overvelde, A.  and Levi, G.  and Hulstijn, W. },
	citeulike-article-id = {3744226},
	doi = {http://dx.doi.org/10.1016/j.humov.2008.02.012},
	issn = {0167-9457},
	journal = {Human movement science},
	keywords = {dtw, litreview, thesis},
	month = {April},
	number = {2},
	pages = {242--255},
	posted-at = {2008-12-04 02:15:21},
	priority = {2},
	title = {Dynamic time warping: a new method in the study of poor handwriting.},
	url = {http://dx.doi.org/10.1016/j.humov.2008.02.012},
	volume = {27},
	year = {2008}
}



@article{citeulike:3736775,
	abstract = {We present an efficient and robust multiscale DTW (Ms-
DTW) approach to music synchronization for time-aligning
CD recordings of different interpretations of the same piece.
The general strategy is to recursively project an alignment
path computed at a coarse resolution level to the next higher
level and then to refine the projected path. As main contributions,
we address several crucial issues including the design
and specification of robust and scalable audio features, suitable
local cost measures,MsDTWlevels, constraint regions,
as well as sampling rate adaptation and structural enhancement
strategies. Extensive experiments on Western classical
music show that our MsDTW-based algorithm yields the
same alignment result as the classical DTW-based strategy
while significantly reducing the running time and memory
requirements. Even for pieces of a duration of 10 to 15 minutes,
the alignment (based on previously extracted feature
sequences) can be computed in less than a second.},
	author = {Muller, M.  and Mattes, H.  and Kurth, F. },
	booktitle = {in Proc. ISMIR},
	citeulike-article-id = {3736775},
	keywords = {dtw, litreview, thesis},
	location = {Victoria, Canada},
	pages = {192--197},
	posted-at = {2008-12-02 19:47:57},
	priority = {2},
	title = {An efficient multiscale approach to
audio synchronization},
	year = {2006}
}



@article{citeulike:3736765,
	abstract = {Dynamic Time Warping (DTW) has a quadratic time and space complexity that limits its use to small time series. In this paper we introduce FastDTW, an approximation of DTW that has a linear time and space complexity. FastDTW uses a multilevel approach that recursively projects a solution from a coarser resolution and refines the projected solution. We prove the linear time and space complexity of FastDTW both theoretically and empirically. We also analyze the accuracy of FastDTW by comparing it to two other types of existing approximate DTW algorithms: constraints (such as Sakoe-Chiba Bands) and abstraction. Our results show a large improvement in accuracy over existing methods.},
	address = {Amsterdam, The Netherlands, The Netherlands},
	author = {Salvador, Stan   and Chan, Philip  },
	citeulike-article-id = {3736765},
	issn = {1088-467X},
	journal = {Intell. Data Anal.},
	keywords = {dtw, litreview, thesis},
	number = {5},
	pages = {561--580},
	posted-at = {2008-12-02 19:42:38},
	priority = {2},
	publisher = {IOS Press},
	title = {Toward accurate dynamic time warping in linear time and space},
	url = {http://portal.acm.org/citation.cfm?id=1367993},
	volume = {11},
	year = {2007}
}



@inproceedings{citeulike:3733947,
	abstract = {In this paper, we discuss an on-line signature verification system based on dynamic time-warping (DTW). The DTW-algorithm originates from the field of speech recognition, and has been applied successfully in the signature verification area more than once. However, until now, few adaptations have been made in order to take the specific characteristics of signature verification into account. According to us, one of the most important differences is the availability of a rather large number of reference patterns, making it possible to determine which parts of a reference signature are important and which are not. By disconnecting the DTW-stage and the feature extraction process we are able to deal efficiently with this extra amount of information. We demonstrate the benefits of our approach by building and evaluating a complete system},
	author = {Martens, R.  and Claesen, L. },
	booktitle = {Pattern Recognition, 1996., Proceedings of the 13th International Conference on},
	citeulike-article-id = {3733947},
	doi = {http://dx.doi.org/10.1109/ICPR.1996.546791},
	journal = {Pattern Recognition, 1996., Proceedings of the 13th International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {38--42 vol.3},
	posted-at = {2008-12-02 03:27:24},
	priority = {2},
	title = {On-line signature verification by dynamic time-warping},
	url = {http://dx.doi.org/10.1109/ICPR.1996.546791},
	volume = {3},
	year = {1996}
}



@inproceedings{citeulike:3733945,
	abstract = {We focus on the use of the dynamic time warping (DTW) technique in the signature verification area. The DTW algorithm originates from the field of speech recognition, where it is a highly appreciated component of speaker specific isolated word recognisers. A few years ago the DTW algorithm was successfully introduced in the area of online signature verification. The characteristics of speech recognition and signature verification are however rather different. Starting from these dissimilarities, our objective is to extract an alternative DTW approach that is better suited to the signature verification problem},
	author = {Martens, R.  and Claesen, L. },
	booktitle = {Document Analysis and Recognition, 1997., Proceedings of the Fourth International Conference on},
	citeulike-article-id = {3733945},
	doi = {http://dx.doi.org/10.1109/ICDAR.1997.620587},
	journal = {Document Analysis and Recognition, 1997., Proceedings of the Fourth International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {653--656 vol.2},
	posted-at = {2008-12-02 03:26:10},
	priority = {2},
	title = {Dynamic programming optimisation for on-line signature verification},
	url = {http://dx.doi.org/10.1109/ICDAR.1997.620587},
	volume = {2},
	year = {1997}
}



@article{citeulike:1807913,
	abstract = {Despite their known weaknesses, hidden Markov models (HMMs) have been the dominant technique for acoustic modeling in speech recognition for over two decades. Still, the advances in the HMM framework have not solved its key problems: it discards information about time dependencies and is prone to overgeneralization. In this paper, we attempt to overcome these problems by relying on straightforward template matching. The basis for the recognizer is the well-known DTW algorithm. However, classical DTW continuous speech recognition results in an explosion of the search space. The traditional top-down search is therefore complemented with a data-driven selection of candidates for DTW alignment. We also extend the DTW framework with a flexible subword unit mechanism and a class sensitive distance measure-two components suggested by state-of-the-art HMM systems. The added flexibility of the unit selection in the template-based framework leads to new approaches to speaker and environment adaptation. The template matching system reaches a performance somewhat worse than the best published HMM results for the Resource Management benchmark, but thanks to complementarity of errors between the HMM and DTW systems, the combination of both leads to a decrease in word error rate with 17\% compared to the HMM results},
	author = {De Wachter, M.  and Matton, M.  and Demuynck, K.  and Wambacq, P.  and Cools, R.  and Van Compernolle, D. },
	booktitle = {Audio, Speech and Language Processing, IEEE Transactions on [see also Speech and Audio Processing, IEEE Transactions on]},
	citeulike-article-id = {1807913},
	doi = {http://dx.doi.org/10.1109/TASL.2007.894524},
	journal = {Audio, Speech and Language Processing, IEEE Transactions on [see also Speech and Audio Processing, IEEE Transactions on]},
	keywords = {dtw, litreview, thesis},
	number = {4},
	pages = {1377--1390},
	posted-at = {2008-12-02 03:20:17},
	priority = {2},
	title = {Template-Based Continuous Speech Recognition},
	url = {http://dx.doi.org/10.1109/TASL.2007.894524},
	volume = {15},
	year = {2007}
}



@inproceedings{citeulike:1033529,
	abstract = {For many performance analysis problems, the ability to reason across traces is invaluable. However, due to non-determinism in the OS and virtual machines, even two identical runs of an application yield slightly different traces. For example, it is unlikely that two identical runs of an application will suffer context switches at exactly the same points. These sorts of variations across traces make it difficult to reason across traces. This paper describes and evaluates an algorithm, dynamic time warping (DTW) that can be used to align traces, thus enabling us to reason across traces. While DTW comes from prior work our use of DTW is novel. Also we describe and evaluate an enhancement to DTW that significantly improves the quality of its alignments. Our results show that for applications whose performance varies significantly over time, DTW does a great job at aligning the traces. For applications whose performance stays largely constant for significant periods of time, the original DTW does not perform well; however, our enhanced DTW performs much better.},
	author = {Mytkowicz, T.  and Diwan, A.  and Hauswirth, M.  and Sweeney, P. F. },
	citeulike-article-id = {1033529},
	doi = {http://dx.doi.org/10.1109/IPDPS.2006.1639592},
	journal = {Parallel and Distributed Processing Symposium, 2006. IPDPS 2006. 20th International},
	keywords = {dtw, litreview, thesis},
	pages = {8 pp.+},
	posted-at = {2008-12-02 03:17:17},
	priority = {2},
	title = {Aligning traces for performance evaluation},
	url = {http://dx.doi.org/10.1109/IPDPS.2006.1639592},
	year = {2006}
}



@incollection{citeulike:3733930,
	abstract = {In this paper, we report the results of recognition of online handwritten Tamil characters. We experimented with two different approaches. One is subspace based method wherein the interactions between the features in the feature spate are assumed to be linear. In the second approach, we investigated an elastic matching technique using dynamic programming principles. We compare the methods to find their suitability for an on-line form-filling application in writer dependent, independent and adaptive scenarios. The comparison is in terms of average recognition accuracy and the number of training samples required to obtain an acceptable performance. While the first criterion evaluates effective recognition capability of a scheme, the second one is important for studying the effectiveness of a scheme in real time applications. We also perform error analysis to determine the advisability of combining the classifiers.},
	author = {Joshi, Niranjan   and Sita, G.  and Ramakrishnan, A. G.  and Madhvanath, Sriganesh  },
	citeulike-article-id = {3733930},
	journal = {Neural Information Processing},
	keywords = {dtw, litreview, thesis},
	pages = {806--813},
	posted-at = {2008-12-02 03:12:44},
	priority = {2},
	title = {Tamil Handwriting Recognition Using Subspace and DTW Based Classifiers},
	url = {http://www.springerlink.com/content/v8xlqt222kvw63kj
},
	year = {2004}
}



@article{citeulike:3733907,
	abstract = {One of the most challenging areas in the field of automatic control is the design of automatic control devices that 'learn' to improve their performamce based upon experience, i.e., that can adapt themselves to circumstances as they find them. The military and commercial implications of such devices are impressive, and interest in the two main areas of research in the field of control, the USA and the USSR, runs high. Unfortunately, though, both theory and construction of adaptive controllers are in their infancy, and some time may pass before they are commonplace. Nonetheless, development at this time of adequate theories of processes of this nature is essential.  The purpose of our paper is to show how the functional equation technique of a new mathematical discipline, dynamic programming, can be used in the formulation and solution of a variety of optimization problems concerning the design of adaptive devices. Although, occasionally, a solution in closed form can be obtained, in general, numerical solution via the use of high-speed digital computers is contemplated.  We discuss here the closely allied problems of formulating adaptive control processes in precise mathematical terms and of presenting feasible computational algoritbms for determining numerical solutioms.  To illustrate the general concepts, consider a system which is governed by the inhomogeneous Van der Pol equation<tex>ddot{x} + mu(x^{2} - 1) dot{x} + x = r(t), 0 leq t leq T</tex>, where<tex>r(t)</tex>is a random function whose statistical properties are only partially known to a feedback control device which seeks to keep the system near the unstable equilibrium state<tex>x = 0, dot{x} = 0</tex>. It proposes to do this by selecting the value of \&\#956; as a function of the state of the system at time<tex>t</tex>, and the time<tex>t</tex>itself. By observing the random process<tex>r(t)</tex>, the controller may, with the passage of time, infer more and more concerning the statistical properties of the function<tex>r(t)</tex>and thus may be expected to improve the quality of its control decisions. In this way the controller adapts itself to circumstances as it finds them. The process is thus an interesting example of adaptive control, and, conceivably, with some immediate ap- plications.  Lastly, some areas of this general domain requiring additional research are indicated.},
	author = {Bellman, R.  and Kalaba, R. },
	booktitle = {Automatic Control, IRE Transactions on},
	citeulike-article-id = {3733907},
	journal = {Automatic Control, IRE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {2},
	pages = {1--9},
	posted-at = {2008-12-02 02:50:59},
	priority = {2},
	title = {On adaptive control processes},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1104847},
	volume = {4},
	year = {1959}
}



@article{citeulike:3733894,
	abstract = {Comprehensive two-dimensional gas chromatography (GC \&\#xd7; GC) is now recognized as the preferred technique for the detailed analysis and characterization of complex mixtures of volatile compounds. However, for comparison purposes, taking into account all the information contained in the chromatogram is far from trivial. In this paper, it is shown that the combination of peak alignment by dynamic time warping and multivariate analysis facilitated the comparison of complex chromatograms of tobacco extracts. The comparison is shown to be efficient enough to provide a clear discrimination among three types of tobacco. A tentative interpretation of loadings is presented in order to give access to the compounds which differ from one sample to another. Once located, mass spectrometry was used to identify markers of tobacco type.},
	author = {Vial, J.  and Nocairi, H.  and Sassiat, P.  and Mallipatu, S.  and Cognon, G.  and Thiebaut, D.  and Teillet, B.  and Rutledge, D. },
	citeulike-article-id = {3733894},
	doi = {http://dx.doi.org/10.1016/j.chroma.2008.09.027},
	issn = {00219673},
	journal = {Journal of Chromatography A},
	keywords = {dtw, litreview, thesis},
	month = {September},
	posted-at = {2008-12-02 02:32:00},
	priority = {2},
	title = {Combination of dynamic time warping and multivariate analysis for the comparison of comprehensive two-dimensional gas chromatogramsApplication to plant extracts},
	url = {http://dx.doi.org/10.1016/j.chroma.2008.09.027},
	year = {2008}
}



@incollection{citeulike:3733893,
	abstract = {The problem of similarity search in time series database has attracted a lot of interest in the data mining field. DTW(Dynamic Time Warping) is a robust distance measure function for time series, which can handle time shifting and scaling. The main defect of DTW lies in its relatively high computational complexity of similarity search. In this paper, we develop a simple but efficient approximation technique for DTW to speed up the search process. Our method is based on a variation of the traditional histograms of the time series. This method can work with a time linear with the size of the database. In our experiment, we proved that the proposed technique is efficient and produces few false dismissals in most applications.},
	author = {Gu, Jie   and Jin, Xiaomin  },
	citeulike-article-id = {3733893},
	doi = {http://dx.doi.org/10.1007/11875581\_101},
	journal = {Intelligent Data Engineering and Automated Learning – IDEAL 2006},
	keywords = {dtw, litreview, thesis},
	pages = {841--848},
	posted-at = {2008-12-02 02:31:17},
	priority = {2},
	title = {A Simple Approximation for Dynamic Time Warping Search in Large Time Series Database},
	url = {http://dx.doi.org/10.1007/11875581\_101},
	year = {2006}
}



@inproceedings{citeulike:3731715,
	abstract = {Finding similar patterns in a time sequence is a well-studied problem. Most of the current techniques work well for queries of a prespecified length, but not for variable length queries. We propose a new indexing technique that works well for variable length queries. The central idea is to store index structures at different resolutions for a given dataset. The resolutions are based on wavelets. For a given query, a number of subqueries at different resolutions are generated. The ranges of the subqueries are progressively refined based on results from previous subqueries. Our experiments show that the total cost for our method is 4 to 20 times less than the current techniques including linear scan. Because of the need to store information at multiple resolution levels, the storage requirement of our method could potentially be large. In the second part of the paper we show how the index information can be compressed with minimal information loss. According to our experimental results, even after compressing the size of the index to one fifth, the total cost of our method is 3 to 15 times less than the current techniques},
	author = {Kahveci, T.  and Singh, A. },
	booktitle = {Data Engineering, 2001. Proceedings. 17th International Conference on},
	citeulike-article-id = {3731715},
	doi = {http://dx.doi.org/10.1109/ICDE.2001.914838},
	journal = {Data Engineering, 2001. Proceedings. 17th International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {273--282},
	posted-at = {2008-12-01 06:05:35},
	priority = {2},
	title = {Variable length queries for time series data},
	url = {http://dx.doi.org/10.1109/ICDE.2001.914838},
	year = {2001}
}



@inproceedings{citeulike:3731713,
	abstract = {We investigate the problem of searching similar multiattribute time sequences. Such sequences arise naturally in a number of medical, financial, video, weather forecast, and stock market databases where more than one attribute is of interest at a time instant. We first solve the simple case in which the distance is defined as the Euclidean distance. Later we extend it to shift and scale invariance. We formulate a new symmetric scale and shift invariant notion of distance for such sequences. We also propose a new index structure that transforms the data sequences and clusters them according to their shiftings and scalings. This clustering improves the efficiency considerably. According to our experiments with real and synthetic datasets, the index structure's performance is 5 to 45 times better than competing techniques, the exact speedup based on other optimizations such as caching and replication.},
	author = {Kahveci, T.  and Singh, A.  and Gurel, A. },
	booktitle = {Scientific and Statistical Database Management, 2002. Proceedings. 14th International Conference on},
	citeulike-article-id = {3731713},
	doi = {http://dx.doi.org/10.1109/SSDM.2002.1029718},
	journal = {Scientific and Statistical Database Management, 2002. Proceedings. 14th International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {175--184},
	posted-at = {2008-12-01 06:04:10},
	priority = {2},
	title = {Similarity searching for multi-attribute sequences},
	url = {http://dx.doi.org/10.1109/SSDM.2002.1029718},
	year = {2002}
}



@inproceedings{citeulike:3731711,
	abstract = {Note: OCR errors may be found in this Reference List extracted from the full text article.  ACM has opted to expose the complete List rather than only correct and linked references.},
	address = {New York, NY, USA},
	author = {Kelvin and Wong, Man  H. },
	booktitle = {PODS '99: Proceedings of the eighteenth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems},
	citeulike-article-id = {3731711},
	doi = {http://dx.doi.org/10.1145/303976.304000},
	isbn = {1-58113-062-7},
	keywords = {dtw, litreview, thesis},
	location = {Philadelphia, Pennsylvania, United States},
	pages = {237--248},
	posted-at = {2008-12-01 06:02:47},
	priority = {2},
	publisher = {ACM},
	title = {Fast time-series searching with scaling and shifting},
	url = {http://dx.doi.org/10.1145/303976.304000},
	year = {1999}
}



@article{citeulike:3731706,
	abstract = {We consider the problem of finding similar patterns in a time sequence. Typical applications of this problem involve large databases consisting of long time sequences of different lengths. Current time sequence search techniques work well for queries of a prespecified length, but not for arbitrary length queries. We propose a novel indexing technique that works well for arbitrary length queries. The proposed technique stores index structures at different resolutions for a given data set. We prove that this index structure is superior to existing index structures that use a single resolution. We propose a range query and nearest neighbor query technique on this index structure and prove the optimality of our index structure for these search techniques. The experimental results show that our method is 4 to 20 times faster than the current techniques, including sequential scan, for range queries and 3 times faster than sequential scan and other techniques for nearest neighbor queries. Because of the need to store information at multiple resolution levels, the storage requirement of our method could potentially be large. In the second part, we show how the index information can be compressed with minimal information loss. According to our experimental results, even after compressing the size of the index to one fifth, the total cost of our method is 3 to 15 times less than the current techniques.},
	author = {Kahveci, T.  and Singh, A. K. },
	booktitle = {Knowledge and Data Engineering, IEEE Transactions on},
	citeulike-article-id = {3731706},
	doi = {http://dx.doi.org/10.1109/TKDE.2004.1269667},
	journal = {Knowledge and Data Engineering, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {4},
	pages = {418--433},
	posted-at = {2008-12-01 05:59:02},
	priority = {2},
	title = {Optimizing similarity search for arbitrary length time series queries},
	url = {http://dx.doi.org/10.1109/TKDE.2004.1269667},
	volume = {16},
	year = {2004}
}



@inproceedings{citeulike:2264785,
	abstract = {We investigate techniques for analysis and retrieval of object trajectories in two or three dimensional space. Such data usually contain a large amount of noise, that has made previously used metrics fail. Therefore, we formalize non-metric similarity functions based on the longest common subsequence (LCSS), which are very robust to noise and furthermore provide an intuitive notion of similarity between trajectories by giving more weight to similar portions of the sequences. Stretching of sequences in time is allowed, as well as global translation of the sequences in space. Efficient approximate algorithms that compute these similarity measures are also provided. We compare these new methods to the widely used Euclidean and time warping distance functions (for real and synthetic data) and show the superiority of our approach, especially in the strong presence of noise. We prove a weaker version of the triangle inequality and employ it in an indexing structure to answer nearest neighbor queries. Finally, we present experimental results that validate the accuracy and efficiency of our approach},
	author = {Vlachos, M.  and Kollios, G.  and Gunopulos, D. },
	booktitle = {Data Engineering, 2002. Proceedings. 18th International Conference on},
	citeulike-article-id = {2264785},
	doi = {http://dx.doi.org/10.1109/ICDE.2002.994784},
	journal = {Data Engineering, 2002. Proceedings. 18th International Conference on},
	keywords = {dtw, litreview, thesis},
	pages = {673--684},
	posted-at = {2008-12-01 05:57:25},
	priority = {2},
	title = {Discovering similar multidimensional trajectories},
	url = {http://dx.doi.org/10.1109/ICDE.2002.994784},
	year = {2002}
}



@article{citeulike:603020,
	abstract = {The technique of dynamic programming for the time registration of a reference and a test pattern has found widespread use in the area of isolated word recognition. Recently, a number of variations on the basic time warping algorithm have been proposed by Sakoe and Chiba, and Rabiner, Rosenberg, and Levinson. These algorithms all assume that the test input is the time pattern of a feature vector from an isolated word whose endpoints are known (at least approximately). The major differences in the methods are the global path constraints (i.e., the region of possible warping paths), the local continuity constraints on the path, and the distance weighting and normalization used to give the overall minimum distance. The purpose of this investigation is to study the effects of such variations on the performance of different dynamic time warping algorithms for a realistic speech database. The performance measures that were used include: speed of operation, memory requirements, and recognition accuracy. The results show that both axis orientation and relative length of the reference and the test patterns are important factors in recognition accuracy. Our results suggest a new approach to dynamic time warping for isolated words in which both the reference and test patterns are linearly warped to a fixed length, and then a simplified dynamic time warping algorithm is used to handle the nonlinear component of the time alignment. Results with this new algorithm show performance comparable to or better than that of all other dynamic time warping algorithms that were studied.},
	author = {Myers, C.  and Rabiner, L.  and Rosenberg, A. },
	citeulike-article-id = {603020},
	journal = {Acoustics, Speech, and Signal Processing [see also IEEE Transactions on Signal Processing], IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {6},
	pages = {623--635},
	posted-at = {2008-12-01 03:52:05},
	priority = {2},
	title = {Performance tradeoffs in dynamic time warping algorithms for isolated word recognition},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1163491},
	volume = {28},
	year = {1980}
}



@inproceedings{citeulike:964832,
	address = {Washington, DC, USA},
	author = {Zhang, Zhang   and Huang, Kaiqi   and Tan, Tieniu  },
	booktitle = {ICPR '06: Proceedings of the 18th International Conference on Pattern Recognition (ICPR'06)},
	citeulike-article-id = {964832},
	doi = {http://dx.doi.org/10.1109/ICPR.2006.392},
	keywords = {dtw, litreview, thesis},
	pages = {1135--1138},
	posted-at = {2008-12-01 03:51:45},
	priority = {2},
	publisher = {IEEE Computer Society},
	title = {Comparison of Similarity Measures for Trajectory Clustering in Outdoor Surveillance Scenes},
	url = {http://dx.doi.org/10.1109/ICPR.2006.392},
	year = {2006}
}



@article{citeulike:3568196,
	abstract = {To recognize speech, handwriting or sign language, many hybrid approaches have been proposed that combine Dynamic Time Warping (DTW) or Hidden Markov Models (HMM) with discriminative classifiers. However, all methods rely directly on the likelihood models of DTW/HMM. We hypothesize that time warping and classification should be separated because of conflicting likelihood modelling demands. To overcome these restrictions, we propose to use Statistical DTW (SDTW) only for time warping, while classifying the warped features with a different method. Two novel statistical classifiers are proposed (CDFD and Q-DFFM), both using a selection of discriminative features (DF), and are shown to outperform HMM and SDTW. However, we have found that combining likelihoods of multiple models in a second classification stage degrades performance of the proposed classifiers, while improving performance with HMM and SDTW. A proof-of-concept experiment, combining DFFM mappings of multiple SDTW models with SDTW likelihoods, shows that also for model-combining, hybrid classification can provide significant improvement over SDTW. Although recognition is mainly based on 3D hand motion features, these results can be expected to generalize to recognition with more detailed measurements such as hand/body pose and facial expression.},
	author = {Lichtenauer, J. F.  and Hendriks, E. A.  and Reinders, M. J. },
	booktitle = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	citeulike-article-id = {3568196},
	doi = {http://dx.doi.org/10.1109/TPAMI.2008.123},
	journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {11},
	pages = {2040--2046},
	posted-at = {2008-12-01 03:49:25},
	priority = {2},
	title = {Sign Language Recognition by Combining Statistical DTW and Independent Classification},
	url = {http://dx.doi.org/10.1109/TPAMI.2008.123},
	volume = {30},
	year = {2008}
}



@article{citeulike:2737624,
	abstract = {Continuously monitoring through time the correlation/distance of multiple data streams is of interest in a variety of applications, including financial analysis, video surveillance, and mining of biological data. However, distance measures commonly adopted for comparing time series, such as Euclidean and Dynamic Time Warping (DTW), either are known to be inaccurate or are too time-consuming to be applied in a streaming environment. In this paper we propose a novel DTW-like distance measure, called Stream-DTW (SDTW), which unlike DTW can be efficiently updated at each time step. We formally and experimentally demonstrate that SDTW speeds up the monitoring process by a factor that grows linearly with the size of the window sliding over the streams. For instance, with a sliding window of 512 samples, SDTW is about 600 times faster than DTW. We also show that SDTW is a tight approximation of DTW, errors never exceeding 10\%, and that it consistently outperforms approximations developed for the case of static time series.},
	author = {Capitani, Paolo   and Ciaccia, Paolo  },
	booktitle = {Including special issue: 20th Brazilian Symposium on Databases (SBBD 2005)},
	citeulike-article-id = {2737624},
	doi = {http://dx.doi.org/10.1016/j.datak.2006.08.012},
	journal = {Data \& Knowledge Engineering},
	keywords = {dtw, litreview, thesis},
	month = {September},
	number = {3},
	pages = {438--458},
	posted-at = {2008-12-01 03:48:48},
	priority = {2},
	title = {Warping the time on data streams},
	url = {http://dx.doi.org/10.1016/j.datak.2006.08.012},
	volume = {62},
	year = {2007}
}



@article{citeulike:2713605,
	abstract = {Abstract\&nbsp;\&nbsp;A new data mining technique used to classify normal and pre-seizure electroencephalograms is proposed. The technique is based on a dynamic time warping kernel combined with support vector machines (SVMs). The experimental results show that the technique is superior to the standard SVM and improves the brain activity classification.},
	author = {Chaovalitwongse, W.  and Pardalos, P. },
	citeulike-article-id = {2713605},
	doi = {http://dx.doi.org/10.1007/s10559-008-0012-y},
	journal = {Cybernetics and Systems Analysis},
	month = {January},
	number = {1},
	pages = {125--138},
	posted-at = {2008-12-01 03:43:26},
	priority = {2},
	title = {On the time series support vector machine using dynamic time warping kernel for brain activity classification},
	url = {http://dx.doi.org/10.1007/s10559-008-0012-y},
	volume = {44},
	year = {2008}
}



@article{citeulike:2838910,
	address = {Norwell, MA, USA},
	author = {Efrat, Alon   and Fan, Quanfu   and Venkatasubramanian, Suresh  },
	citeulike-article-id = {2838910},
	doi = {http://dx.doi.org/10.1007/s10851-006-0647-0},
	issn = {0924-9907},
	journal = {J. Math. Imaging Vis.},
	keywords = {dtw, litreview, thesis},
	month = {April},
	number = {3},
	pages = {203--216},
	posted-at = {2008-12-01 03:42:32},
	priority = {2},
	publisher = {Kluwer Academic Publishers},
	title = {Curve Matching, Time Warping, and Light Fields: New Algorithms for Computing Similarity between Curves},
	url = {http://dx.doi.org/10.1007/s10851-006-0647-0},
	volume = {27},
	year = {2007}
}



@incollection{citeulike:3728229,
	abstract = {As we have seen in Chap. 4, dynamic time warping is a flexible tool for comparing time series in the presence of nonlinear time deformations. In this context, the choice of suitable local cost or distance measures is of crucial importance, since they determine the kind of (spatial) similarity between the elements (frames) of the two sequences to be aligned. For the mocap domain, we introduce two conceptually different local distance measures – one based on joint angle parameters and the other based on 3D coordinates – and discuss their respective strengths and weaknesses (Sect. 10.1). The importance of DTW is then illustrated by some synthesis and analysis applications (Sect. 10.2). By comparing a motion data stream to itself, one obtains a cost or distance matrix that exhibits self-similarities within the motion. In Sect. 10.3, we describe how this idea can be exploited for motion retrieval. Finally, in Sect. 10.4, we discuss some work related to DTW-based motion retrieval.},
	citeulike-article-id = {3728229},
	doi = {http://dx.doi.org/10.1007/978-3-540-74048-3\_10},
	journal = {Information Retrieval for Music and Motion},
	keywords = {dtw, litreview, thesis},
	pages = {211--226},
	posted-at = {2008-11-29 22:30:44},
	priority = {0},
	title = {DTW-Based Motion Comparison and Retrieval},
	url = {http://dx.doi.org/10.1007/978-3-540-74048-3\_10},
	year = {2007}
}



@incollection{citeulike:3728228,
	abstract = {Dynamic time warping (DTW) is a well-known technique to find an optimal alignment between two given (time-dependent) sequences under certain restrictions (Fig. 4.1). Intuitively, the sequences are warped in a nonlinear fashion to match each other. Originally, DTW has been used to compare different speech patterns in automatic speech recognition, see [170]. In fields such as data mining and information retrieval, DTW has been successfully applied to automatically cope with time deformations and different speeds associated with time-dependent data. In this chapter, we introduce and discuss the main ideas of classical DTW (Sect. 4.1) and summarize several modifications concerning local as well as global parameters (Sect. 4.2). To speed up classical DTW, we describe in Sect. 4.3 a general multiscale DTW approach. In Sect. 4.4, we show how DTW can be employed to identify all subsequence within a long data stream that are similar to a given query sequence (Sect. 4.4). A discussion of related alignment techniques and references to the literature can be found in Sect. 4.5.},
	citeulike-article-id = {3728228},
	doi = {http://dx.doi.org/10.1007/978-3-540-74048-3\_4},
	journal = {Information Retrieval for Music and Motion},
	keywords = {dtw, litreview, thesis},
	pages = {69--84},
	posted-at = {2008-11-29 22:27:36},
	priority = {0},
	title = {Dynamic Time Warping},
	url = {http://dx.doi.org/10.1007/978-3-540-74048-3\_4},
	year = {2007}
}



@inproceedings{citeulike:2019923,
	abstract = {Recently, we are attending to a huge evolution on the development of high performance computing platforms. Among these platforms, the GPU (Graphics Processing Units) stimulated by game industries, constantly demanding more graphical processing power, evolved from a simple graphical card to a general purpose computation parallel data processing device. This article shows the GPU's viability to general purpose computation, developing a speech recognition application inside. Dynamic Time Warping (DTW) is applied on a voice password identification. Normally, DTW requires large amount of data and processing time, so that it is an efficient technique to simple vocabulary, when the voice commands set is small. Using NVIDIA GeForce 8800 GTX, with 128 processing unit cores, and a CUDA (Compute Unified Device Architecture) software platform development architecture, the DTW application was implemented, and tested its performance.},
	author = {Poli, Gustavo   and Mari, Joao  F.  and Hiroki and Levada, Alexandre  L. },
	booktitle = {Computer Architecture and High Performance Computing, 2007. SBAC-PAD 2007. 19th International Symposium on},
	citeulike-article-id = {2019923},
	doi = {http://dx.doi.org/10.1109/SBAC-PAD.2007.21},
	journal = {Computer Architecture and High Performance Computing, 2007. SBAC-PAD 2007. 19th International Symposium on},
	keywords = {dtw, thesis},
	pages = {19--25},
	posted-at = {2008-11-20 17:42:35},
	priority = {2},
	title = {Voice Command Recognition with Dynamic Time Warping (DTW) using Graphics Processing Units (GPU) with Compute Unified Device Architecture (CUDA)},
	url = {http://dx.doi.org/10.1109/SBAC-PAD.2007.21},
	year = {2007}
}



@article{citeulike:3578001,
	abstract = {A computer system is described in which isolated words, spoken by a designated talker, are recognized through calculation of a minimum prediction residual. A reference pattern for each word to be recognized is stored as a time pattern of linear prediction coefficients (LPC). The total log prediction residual of an input signal is minimized by optimally registering the reference LPC onto the input autocorrelation coefficients using the dynamic programming algorithm (DP). The input signal is recognized as the reference word which produces the minimum prediction residual. A sequential decision procedure is used to reduce the amount of computation in DP. A frequency normalization with respect to the long-time spectral distribution is used to reduce effects of variations in the frequency response of telephone connections.  The system has been implemented on a DDP-516 computer for the 200-word recognition experiment. The recognition rate for a designated male talker is 97.3 percent for telephone input, and the recognition time is about 22 times real time.},
	author = {Itakura, F. },
	booktitle = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
	citeulike-article-id = {3578001},
	journal = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {1},
	pages = {67--72},
	posted-at = {2008-11-19 12:36:49},
	priority = {4},
	title = {Minimum prediction residual principle applied to speech recognition},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1162641},
	volume = {23},
	year = {1975}
}



@mastersthesis{citeulike:3577984,
	author = {Myers, C. S. },
	citeulike-article-id = {3577984},
	journal = {MS and BS thesis,  MIT Jun 20 1980,},
	keywords = {dtw, litreview, thesis},
	posted-at = {2008-11-19 12:30:07},
	priority = {2},
	title = {A Comparative Study Of Several Dynamic Time Warping Algorithms For Speech Recognition},
	url = {http://dspace.mit.edu/bitstream/1721.1/27909/1/07888629.pdf }
}



@article{citeulike:1920382,
	author = {Dunfield, Peter  F.  and Yuryev, Anton   and Senin, Pavel   and Smirnova, Angela  V.  and Stott, Matthew  B.  and Hou, Shaobin   and Ly, Binh   and Saw, Jimmy  H.  and Zhou, Zhemin   and Ren, Yan   and Wang, Jianmei   and Mountain, Bruce  W.  and Crowe, Michelle  A.  and Weatherby, Tina  M.  and Bodelier, Paul  L. E.  and Liesack, Werner   and Feng, Lu   and Wang, Lei   and Alam, Maqsudul  },
	citeulike-article-id = {1920382},
	doi = {http://dx.doi.org/10.1038/nature06411},
	issn = {0028-0836},
	journal = {Nature},
	keywords = {publication},
	month = {November},
	posted-at = {2008-11-08 22:50:08},
	priority = {0},
	publisher = {Nature Publishing Group},
	title = {Methane oxidation by an extremely acidophilic bacterium of the phylum Verrucomicrobia},
	url = {http://dx.doi.org/10.1038/nature06411},
	year = {2007}
}



@article{citeulike:2709869,
	author = {Ming, Ray   and Hou, Shaobin   and Feng, Yun   and Yu, Qingyi   and Dionne-Laporte, Alexandre   and Saw, Jimmy  H.  and Senin, Pavel   and Wang, Wei   and Ly, Benjamin  V.  and Lewis, Kanako  L.  and Salzberg, Steven  L.  and Feng, Lu   and Jones, Meghan  R.  and Skelton, Rachel  L.  and Murray, Jan  E.  and Chen, Cuixia   and Qian, Wubin   and Shen, Junguo   and Du, Peng   and Eustice, Moriah   and Tong, Eric   and Tang, Haibao   and Lyons, Eric   and Paull, Robert  E.  and Michael, Todd  P.  and Wall, Kerr   and Rice, Danny  W.  and Albert, Henrik   and Wang, Ming-Li   and Zhu, Yun  J.  and Schatz, Michael   and Nagarajan, Niranjan   and Acob, Ricelle  A.  and Guan, Peizhu   and Blas, Andrea   and Wai, Ching  M.  and Ackerman, Christine  M.  and Ren, Yan   and Liu, Chao   and Wang, Jianmei   and Wang, Jianping   and Na, Jong-Kuk   and Shakirov, Eugene  V.  and Haas, Brian   and Thimmapuram, Jyothi   and Nelson, David   and Wang, Xiyin   and Bowers, John  E.  and Gschwend, Andrea  R.  and Delcher, Arthur  L.  and Singh, Ratnesh   and Suzuki, Jon  Y.  and Tripathi, Savarni   and Neupane, Kabi   and Wei, Hairong   and Irikura, Beth   and Paidi, Maya   and Jiang, Ning   and Zhang, Wenli   and Presting, Gernot   and Windsor, Aaron   and Navajas-Perez, Rafael   and Torres, Manuel  J.  and Feltus, Alex  F.  and Porter, Brad   and Li, Yingjun   and Burroughs, Max  A.  and Luo, Ming-Cheng   and Liu, Lei   and Christopher, David  A.  and Mount, Stephen  M.  and Moore, Paul  H.  and Sugimura, Tak   and Jiang, Jiming   and Schuler, Mary  A.  and Friedman, Vikki   and Mitchell-Olds, Thomas   and Shippen, Dorothy  E.  and Depamphilis, Claude  W.  and Palmer, Jeffrey  D.  and Freeling, Michael   and Paterson, Andrew  H.  and Gonsalves, Dennis   and Wang, Lei   and Alam, Maqsudul  },
	citeulike-article-id = {2709869},
	doi = {http://dx.doi.org/10.1038/nature06856},
	journal = {Nature},
	keywords = {publication},
	month = {April},
	number = {7190},
	pages = {991--996},
	posted-at = {2008-11-08 22:49:20},
	priority = {0},
	publisher = {Nature Publishing Group},
	title = {The draft genome of the transgenic tropical fruit tree papaya (Carica papaya Linnaeus)},
	url = {http://dx.doi.org/10.1038/nature06856},
	volume = {452},
	year = {2008}
}



@article{citeulike:2949501,
	author = {Hou, Shaobin   and Makarova, Kira  S.  and Jimmy and Senin, Pavel   and Ly, Benjamin  V.  and Zhou, Zhemin   and Ren, Yan   and Wang, Jianmei   and Galperin, Michael  Y.  and Omelchenko, Marina  V.  and Wolf, Yuri  I.  and Yutin, Natalya   and Koonin, Eugene  V.  and Stott, Matthew  B.  and Mountain, Bruce  W.  and Crowe, Michelle  A.  and Smirnova, Angela  V.  and Dunfield, Peter  F.  and Feng, Lu   and Wang, Lei   and Alam, Maqsudul  },
	citeulike-article-id = {2949501},
	doi = {http://dx.doi.org/10.1186/1745-6150-3-26},
	issn = {1745-6150},
	journal = {Biology Direct},
	keywords = {publication},
	month = {July},
	pages = {26+},
	posted-at = {2008-11-08 22:48:37},
	priority = {0},
	title = {Complete genome sequence of the extremely acidophilic methanotroph isolate V4, "Methylacidiphilum infernorum", 
a representative of the bacterial phylum Verrucomicrobia},
	url = {http://dx.doi.org/10.1186/1745-6150-3-26},
	volume = {3},
	year = {2008}
}



@article{citeulike:3496861,
	abstract = {This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition. First, a general principle of time-normalization is given using time-warping function. Then, two time-normalized distance definitions, called symmetric and asymmetric forms, are derived from the principle. These two forms are compared with each other through theoretical discussions and experimental studies. The symmetric form algorithm superiority is established. A new technique, called slope constraint, is successfully introduced, in which the warping function slope is restricted so as to improve discrimination between words in different categories. The effective slope constraint characteristic is qualitatively analyzed, and the optimum slope constraint condition is determined through experiments. The optimized algorithm is then extensively subjected to experimental comparison with various DP-algorithms, previously applied to spoken word recognition by different research groups. The experiment shows that the present algorithm gives no more than about two-thirds errors, even compared to the best conventional algorithm.},
	author = {Sakoe, H.  and Chiba, S. },
	booktitle = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
	citeulike-article-id = {3496861},
	journal = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
	keywords = {dtw, litreview, thesis},
	number = {1},
	pages = {43--49},
	posted-at = {2008-11-08 22:11:03},
	priority = {0},
	title = {Dynamic programming algorithm optimization for spoken word recognition},
	url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1163055},
	volume = {26},
	year = {1978}
}




